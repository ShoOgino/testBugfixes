{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest#testLargeInput().mjava","commits":[{"id":"523c1863d7ec17e9a5067cef7e233c388f8ab263","date":1367931848,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest#testLargeInput().mjava","pathOld":"/dev/null","sourceNew":"  public void testLargeInput() throws IOException {\n    final String input = _TestUtil.randomSimpleString(random(), 1024 * 5);\n    final int minGram = _TestUtil.nextInt(random(), 1, 1024);\n    final int maxGram = _TestUtil.nextInt(random(), minGram, 5 * 1024);\n    EdgeNGramTokenizer tk = new EdgeNGramTokenizer(TEST_VERSION_CURRENT, new StringReader(input), EdgeNGramTokenizer.Side.FRONT, minGram, maxGram);\n    final CharTermAttribute charTermAtt = tk.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = tk.addAttribute(OffsetAttribute.class);\n    final PositionIncrementAttribute posIncAtt = tk.addAttribute(PositionIncrementAttribute.class);\n    tk.reset();\n    for (int i = minGram; i <= maxGram && i <= input.length(); ++i) {\n      assertTrue(tk.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(i, offsetAtt.endOffset());\n      assertEquals(1, posIncAtt.getPositionIncrement());\n      assertEquals(input.substring(0, i), charTermAtt.toString());\n    }\n    assertFalse(tk.incrementToken());\n    tk.end();\n    assertEquals(input.length(), offsetAtt.startOffset());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7567347acd9579d742a2ffd4feb1a32062fb1bc3","date":1367935406,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest#testLargeInput().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest#testLargeInput().mjava","sourceNew":"  public void testLargeInput() throws IOException {\n    final String input = _TestUtil.randomSimpleString(random(), 1024 * 5);\n    final int minGram = _TestUtil.nextInt(random(), 1, 1024);\n    final int maxGram = _TestUtil.nextInt(random(), minGram, 5 * 1024);\n    EdgeNGramTokenizer tk = new EdgeNGramTokenizer(TEST_VERSION_CURRENT, new StringReader(input), minGram, maxGram);\n    final CharTermAttribute charTermAtt = tk.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = tk.addAttribute(OffsetAttribute.class);\n    final PositionIncrementAttribute posIncAtt = tk.addAttribute(PositionIncrementAttribute.class);\n    tk.reset();\n    for (int i = minGram; i <= maxGram && i <= input.length(); ++i) {\n      assertTrue(tk.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(i, offsetAtt.endOffset());\n      assertEquals(1, posIncAtt.getPositionIncrement());\n      assertEquals(input.substring(0, i), charTermAtt.toString());\n    }\n    assertFalse(tk.incrementToken());\n    tk.end();\n    assertEquals(input.length(), offsetAtt.startOffset());\n  }\n\n","sourceOld":"  public void testLargeInput() throws IOException {\n    final String input = _TestUtil.randomSimpleString(random(), 1024 * 5);\n    final int minGram = _TestUtil.nextInt(random(), 1, 1024);\n    final int maxGram = _TestUtil.nextInt(random(), minGram, 5 * 1024);\n    EdgeNGramTokenizer tk = new EdgeNGramTokenizer(TEST_VERSION_CURRENT, new StringReader(input), EdgeNGramTokenizer.Side.FRONT, minGram, maxGram);\n    final CharTermAttribute charTermAtt = tk.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = tk.addAttribute(OffsetAttribute.class);\n    final PositionIncrementAttribute posIncAtt = tk.addAttribute(PositionIncrementAttribute.class);\n    tk.reset();\n    for (int i = minGram; i <= maxGram && i <= input.length(); ++i) {\n      assertTrue(tk.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(i, offsetAtt.endOffset());\n      assertEquals(1, posIncAtt.getPositionIncrement());\n      assertEquals(input.substring(0, i), charTermAtt.toString());\n    }\n    assertFalse(tk.incrementToken());\n    tk.end();\n    assertEquals(input.length(), offsetAtt.startOffset());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704","date":1371043069,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest#testLargeInput().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest#testLargeInput().mjava","sourceNew":"  public void testLargeInput() throws IOException {\n    // test sliding\n    final int minGram = _TestUtil.nextInt(random(), 1, 100);\n    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);\n    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), \"\");\n  }\n\n","sourceOld":"  public void testLargeInput() throws IOException {\n    final String input = _TestUtil.randomSimpleString(random(), 1024 * 5);\n    final int minGram = _TestUtil.nextInt(random(), 1, 1024);\n    final int maxGram = _TestUtil.nextInt(random(), minGram, 5 * 1024);\n    EdgeNGramTokenizer tk = new EdgeNGramTokenizer(TEST_VERSION_CURRENT, new StringReader(input), minGram, maxGram);\n    final CharTermAttribute charTermAtt = tk.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = tk.addAttribute(OffsetAttribute.class);\n    final PositionIncrementAttribute posIncAtt = tk.addAttribute(PositionIncrementAttribute.class);\n    tk.reset();\n    for (int i = minGram; i <= maxGram && i <= input.length(); ++i) {\n      assertTrue(tk.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(i, offsetAtt.endOffset());\n      assertEquals(1, posIncAtt.getPositionIncrement());\n      assertEquals(input.substring(0, i), charTermAtt.toString());\n    }\n    assertFalse(tk.incrementToken());\n    tk.end();\n    assertEquals(input.length(), offsetAtt.startOffset());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest#testLargeInput().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerTest#testLargeInput().mjava","sourceNew":"  public void testLargeInput() throws IOException {\n    // test sliding\n    final int minGram = TestUtil.nextInt(random(), 1, 100);\n    final int maxGram = TestUtil.nextInt(random(), minGram, 100);\n    testNGrams(minGram, maxGram, TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), \"\");\n  }\n\n","sourceOld":"  public void testLargeInput() throws IOException {\n    // test sliding\n    final int minGram = _TestUtil.nextInt(random(), 1, 100);\n    final int maxGram = _TestUtil.nextInt(random(), minGram, 100);\n    testNGrams(minGram, maxGram, _TestUtil.nextInt(random(), 3 * 1024, 4 * 1024), \"\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"523c1863d7ec17e9a5067cef7e233c388f8ab263":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704":["7567347acd9579d742a2ffd4feb1a32062fb1bc3"],"6613659748fe4411a7dcf85266e55db1f95f7315":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6613659748fe4411a7dcf85266e55db1f95f7315"],"7567347acd9579d742a2ffd4feb1a32062fb1bc3":["523c1863d7ec17e9a5067cef7e233c388f8ab263"]},"commit2Childs":{"523c1863d7ec17e9a5067cef7e233c388f8ab263":["7567347acd9579d742a2ffd4feb1a32062fb1bc3"],"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["523c1863d7ec17e9a5067cef7e233c388f8ab263"],"7567347acd9579d742a2ffd4feb1a32062fb1bc3":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}