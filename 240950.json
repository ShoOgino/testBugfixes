{"path":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","commits":[{"id":"384e84fe86b09273dea9bb358ff47fc7781f3f17","date":1272992848,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"solr/src/test/org/apache/solr/analysis/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n    TrimFilterFactory factory = new TrimFilterFactory();\n    Map<String,String> args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"false\");\n    factory.init(args);\n    TokenStream ts = factory.create(new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21)));\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    factory = new TrimFilterFactory();\n    args = new HashMap<String,String>();\n    args.put(\"updateOffsets\", \"true\");\n    factory.init(args);\n    ts = factory.create(new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3)));\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f080986da691a3bba7b757f43ab72cdc82b57ce","date":1273069619,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","pathOld":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter#testTrim().mjava","sourceNew":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","sourceOld":"  public void testTrim() throws Exception {\n    char[] a = \" a \".toCharArray();\n    char[] b = \"b   \".toCharArray();\n    char[] ccc = \"cCc\".toCharArray();\n    char[] whitespace = \"   \".toCharArray();\n    char[] empty = \"\".toCharArray();\n\n    TokenStream ts = new IterTokenStream(new Token(a, 0, a.length, 1, 5),\n                    new Token(b, 0, b.length, 6, 10),\n                    new Token(ccc, 0, ccc.length, 11, 15),\n                    new Token(whitespace, 0, whitespace.length, 16, 20),\n                    new Token(empty, 0, empty.length, 21, 21));\n    ts = new TrimFilter(ts, false);\n\n    assertTokenStreamContents(ts, new String[] { \"a\", \"b\", \"cCc\", \"\", \"\"});\n\n    a = \" a\".toCharArray();\n    b = \"b \".toCharArray();\n    ccc = \" c \".toCharArray();\n    whitespace = \"   \".toCharArray();\n    ts = new IterTokenStream(\n            new Token(a, 0, a.length, 0, 2),\n            new Token(b, 0, b.length, 0, 2),\n            new Token(ccc, 0, ccc.length, 0, 3),\n            new Token(whitespace, 0, whitespace.length, 0, 3));\n    ts = new TrimFilter(ts, true);\n    \n    assertTokenStreamContents(ts, \n        new String[] { \"a\", \"b\", \"c\", \"\" },\n        new int[] { 1, 0, 1, 3 },\n        new int[] { 2, 1, 2, 3 },\n        new int[] { 1, 1, 1, 1 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"384e84fe86b09273dea9bb358ff47fc7781f3f17":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["384e84fe86b09273dea9bb358ff47fc7781f3f17"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f080986da691a3bba7b757f43ab72cdc82b57ce"]},"commit2Childs":{"384e84fe86b09273dea9bb358ff47fc7781f3f17":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["384e84fe86b09273dea9bb358ff47fc7781f3f17"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}