{"path":"solr/core/src/test/org/apache/solr/cloud/CloudStateUpdateTest#testIncrementalUpdate().mjava","commits":[{"id":"3c12159f094951abca20de13adfd11224da456e1","date":1317314664,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CloudStateUpdateTest#testIncrementalUpdate().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testIncrementalUpdate() throws Exception {\n    System.setProperty(\"CLOUD_UPDATE_DELAY\", \"1\");\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n    ZkTestServer server = null;\n    SolrZkClient zkClient = null;\n    ZkController zkController = null;\n    \n    server = new ZkTestServer(zkDir);\n    server.run();\n    try {\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n      \n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      String shardsPath1 = \"/collections/collection1/shards/shardid1\";\n      String shardsPath2 = \"/collections/collection1/shards/shardid2\";\n      zkClient.makePath(shardsPath1);\n      zkClient.makePath(shardsPath2);\n      \n      addShardToZk(zkClient, shardsPath1, SHARD1, URL1);\n      addShardToZk(zkClient, shardsPath1, SHARD2, URL2);\n      addShardToZk(zkClient, shardsPath2, SHARD3, URL3);\n      \n      removeShardFromZk(server.getZkAddress(), zkClient, shardsPath1);\n      \n      zkController = new ZkController(server.getZkAddress(), TIMEOUT, 1000,\n          \"localhost\", \"8983\", \"solr\");\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      CloudState cloudInfo = zkController.getCloudState();\n      Map<String,Slice> slices = cloudInfo.getSlices(\"collection1\");\n      assertFalse(slices.containsKey(\"shardid1\"));\n      \n      zkClient.makePath(shardsPath1);\n      addShardToZk(zkClient, shardsPath1, SHARD1, URL1);\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      cloudInfo = zkController.getCloudState();\n      slices = cloudInfo.getSlices(\"collection1\");\n      assertTrue(slices.containsKey(\"shardid1\"));\n      \n      updateUrl(zkClient, shardsPath1, SHARD1, \"fake\");\n      \n      addShardToZk(zkClient, shardsPath2, SHARD4, URL4);\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      cloudInfo = zkController.getCloudState();\n      String url = cloudInfo.getSlices(\"collection1\").get(\"shardid1\").getShards().get(SHARD1).get(\"url\");\n      \n      // because of incremental update, we don't expect to find the new 'fake'\n      // url - instead we should still\n      // be using the original url - the correct way to update this would be to\n      // remove the whole node and readd it\n      assertEquals(URL1, url);\n      \n    } finally {\n      server.shutdown();\n      zkClient.close();\n      zkController.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/CloudStateUpdateTest#testIncrementalUpdate().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testIncrementalUpdate() throws Exception {\n    System.setProperty(\"CLOUD_UPDATE_DELAY\", \"1\");\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n    ZkTestServer server = null;\n    SolrZkClient zkClient = null;\n    ZkController zkController = null;\n    \n    server = new ZkTestServer(zkDir);\n    server.run();\n    try {\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n      \n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      String shardsPath1 = \"/collections/collection1/shards/shardid1\";\n      String shardsPath2 = \"/collections/collection1/shards/shardid2\";\n      zkClient.makePath(shardsPath1);\n      zkClient.makePath(shardsPath2);\n      \n      addShardToZk(zkClient, shardsPath1, SHARD1, URL1);\n      addShardToZk(zkClient, shardsPath1, SHARD2, URL2);\n      addShardToZk(zkClient, shardsPath2, SHARD3, URL3);\n      \n      removeShardFromZk(server.getZkAddress(), zkClient, shardsPath1);\n      \n      zkController = new ZkController(server.getZkAddress(), TIMEOUT, 1000,\n          \"localhost\", \"8983\", \"solr\");\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      CloudState cloudInfo = zkController.getCloudState();\n      Map<String,Slice> slices = cloudInfo.getSlices(\"collection1\");\n      assertFalse(slices.containsKey(\"shardid1\"));\n      \n      zkClient.makePath(shardsPath1);\n      addShardToZk(zkClient, shardsPath1, SHARD1, URL1);\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      cloudInfo = zkController.getCloudState();\n      slices = cloudInfo.getSlices(\"collection1\");\n      assertTrue(slices.containsKey(\"shardid1\"));\n      \n      updateUrl(zkClient, shardsPath1, SHARD1, \"fake\");\n      \n      addShardToZk(zkClient, shardsPath2, SHARD4, URL4);\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      cloudInfo = zkController.getCloudState();\n      String url = cloudInfo.getSlices(\"collection1\").get(\"shardid1\").getShards().get(SHARD1).get(\"url\");\n      \n      // because of incremental update, we don't expect to find the new 'fake'\n      // url - instead we should still\n      // be using the original url - the correct way to update this would be to\n      // remove the whole node and readd it\n      assertEquals(URL1, url);\n      \n    } finally {\n      server.shutdown();\n      zkClient.close();\n      zkController.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/CloudStateUpdateTest#testIncrementalUpdate().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testIncrementalUpdate() throws Exception {\n    System.setProperty(\"CLOUD_UPDATE_DELAY\", \"1\");\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n    ZkTestServer server = null;\n    SolrZkClient zkClient = null;\n    ZkController zkController = null;\n    \n    server = new ZkTestServer(zkDir);\n    server.run();\n    try {\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n      \n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      String shardsPath1 = \"/collections/collection1/shards/shardid1\";\n      String shardsPath2 = \"/collections/collection1/shards/shardid2\";\n      zkClient.makePath(shardsPath1);\n      zkClient.makePath(shardsPath2);\n      \n      addShardToZk(zkClient, shardsPath1, SHARD1, URL1);\n      addShardToZk(zkClient, shardsPath1, SHARD2, URL2);\n      addShardToZk(zkClient, shardsPath2, SHARD3, URL3);\n      \n      removeShardFromZk(server.getZkAddress(), zkClient, shardsPath1);\n      \n      zkController = new ZkController(server.getZkAddress(), TIMEOUT, 1000,\n          \"localhost\", \"8983\", \"solr\");\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      CloudState cloudInfo = zkController.getCloudState();\n      Map<String,Slice> slices = cloudInfo.getSlices(\"collection1\");\n      assertFalse(slices.containsKey(\"shardid1\"));\n      \n      zkClient.makePath(shardsPath1);\n      addShardToZk(zkClient, shardsPath1, SHARD1, URL1);\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      cloudInfo = zkController.getCloudState();\n      slices = cloudInfo.getSlices(\"collection1\");\n      assertTrue(slices.containsKey(\"shardid1\"));\n      \n      updateUrl(zkClient, shardsPath1, SHARD1, \"fake\");\n      \n      addShardToZk(zkClient, shardsPath2, SHARD4, URL4);\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      cloudInfo = zkController.getCloudState();\n      String url = cloudInfo.getSlices(\"collection1\").get(\"shardid1\").getShards().get(SHARD1).get(\"url\");\n      \n      // because of incremental update, we don't expect to find the new 'fake'\n      // url - instead we should still\n      // be using the original url - the correct way to update this would be to\n      // remove the whole node and readd it\n      assertEquals(URL1, url);\n      \n    } finally {\n      server.shutdown();\n      zkClient.close();\n      zkController.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/CloudStateUpdateTest#testIncrementalUpdate().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testIncrementalUpdate() throws Exception {\n    System.setProperty(\"CLOUD_UPDATE_DELAY\", \"1\");\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n    ZkTestServer server = null;\n    SolrZkClient zkClient = null;\n    ZkController zkController = null;\n    \n    server = new ZkTestServer(zkDir);\n    server.run();\n    try {\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n      \n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      String shardsPath1 = \"/collections/collection1/shards/shardid1\";\n      String shardsPath2 = \"/collections/collection1/shards/shardid2\";\n      zkClient.makePath(shardsPath1);\n      zkClient.makePath(shardsPath2);\n      \n      addShardToZk(zkClient, shardsPath1, SHARD1, URL1);\n      addShardToZk(zkClient, shardsPath1, SHARD2, URL2);\n      addShardToZk(zkClient, shardsPath2, SHARD3, URL3);\n      \n      removeShardFromZk(server.getZkAddress(), zkClient, shardsPath1);\n      \n      zkController = new ZkController(server.getZkAddress(), TIMEOUT, 1000,\n          \"localhost\", \"8983\", \"solr\");\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      CloudState cloudInfo = zkController.getCloudState();\n      Map<String,Slice> slices = cloudInfo.getSlices(\"collection1\");\n      assertFalse(slices.containsKey(\"shardid1\"));\n      \n      zkClient.makePath(shardsPath1);\n      addShardToZk(zkClient, shardsPath1, SHARD1, URL1);\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      cloudInfo = zkController.getCloudState();\n      slices = cloudInfo.getSlices(\"collection1\");\n      assertTrue(slices.containsKey(\"shardid1\"));\n      \n      updateUrl(zkClient, shardsPath1, SHARD1, \"fake\");\n      \n      addShardToZk(zkClient, shardsPath2, SHARD4, URL4);\n      \n      zkController.getZkStateReader().updateCloudState(true);\n      cloudInfo = zkController.getCloudState();\n      String url = cloudInfo.getSlices(\"collection1\").get(\"shardid1\").getShards().get(SHARD1).get(\"url\");\n      \n      // because of incremental update, we don't expect to find the new 'fake'\n      // url - instead we should still\n      // be using the original url - the correct way to update this would be to\n      // remove the whole node and readd it\n      assertEquals(URL1, url);\n      \n    } finally {\n      server.shutdown();\n      zkClient.close();\n      zkController.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0d22ac6a4146774c1bc8400160fc0b6150294e92":["3c12159f094951abca20de13adfd11224da456e1","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"3c12159f094951abca20de13adfd11224da456e1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["3c12159f094951abca20de13adfd11224da456e1","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["3c12159f094951abca20de13adfd11224da456e1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"]},"commit2Childs":{"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"3c12159f094951abca20de13adfd11224da456e1":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3c12159f094951abca20de13adfd11224da456e1"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}