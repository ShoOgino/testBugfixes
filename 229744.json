{"path":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","commits":[{"id":"4d17492f26096e19670d947d1be5e9adc52b1d3d","date":1224931200,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(DocumentsWriter.FlushState).mjava","sourceNew":"  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      if (4+state.numDocsInStore*16 != state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","sourceOld":"  synchronized void closeDocStore(final DocumentsWriter.FlushState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      if (4+state.numDocsInStore*16 != state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6e9e8b4258e08645a02d6b454cdb1689f6763d2","date":1232122713,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","sourceNew":"  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","sourceOld":"  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      if (4+state.numDocsInStore*16 != state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","bugFix":["5350389bf83287111f7760b9e3db3af8e3648474"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55ddd0022d1d26b52ed711e90ab77de2b36130c6","date":1251466592,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","sourceNew":"  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      final String fileName = state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(fileName))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(fileName) + \" length in bytes of \" + fileName + \" file exists?=\" + state.directory.fileExists(fileName));\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","sourceOld":"  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a9e385641d717e641408d8fbbc62be8fc766357","date":1256746606,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","sourceNew":"  @Override\n  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      final String fileName = state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(fileName))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(fileName) + \" length in bytes of \" + fileName + \" file exists?=\" + state.directory.fileExists(fileName));\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","sourceOld":"  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      final String fileName = state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(fileName))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(fileName) + \" length in bytes of \" + fileName + \" file exists?=\" + state.directory.fileExists(fileName));\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"775efee7f959e0dd3df7960b93767d9e00b78751","date":1267203159,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","sourceNew":"  @Override\n  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      String idxName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_INDEX_EXTENSION);\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(idxName))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(idxName) + \" length in bytes of \" + idxName + \" file exists?=\" + state.directory.fileExists(idxName));\n\n      String fldName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      String docName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n      state.flushedFiles.add(idxName);\n      state.flushedFiles.add(fldName);\n      state.flushedFiles.add(docName);\n\n      docWriter.removeOpenFile(idxName);\n      docWriter.removeOpenFile(fldName);\n      docWriter.removeOpenFile(docName);\n\n      lastDocID = 0;\n    }    \n  }\n\n","sourceOld":"  @Override\n  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      final String fileName = state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(fileName))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(fileName) + \" length in bytes of \" + fileName + \" file exists?=\" + state.directory.fileExists(fileName));\n\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      state.flushedFiles.add(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      docWriter.removeOpenFile(state.docStoreSegmentName + \".\" + IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n\n      lastDocID = 0;\n    }    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriter#closeDocStore(SegmentWriteState).mjava","sourceNew":"  @Override\n  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      String idxName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_INDEX_EXTENSION);\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(idxName))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(idxName) + \" length in bytes of \" + idxName + \" file exists?=\" + state.directory.fileExists(idxName));\n\n      String fldName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      String docName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n      state.flushedFiles.add(idxName);\n      state.flushedFiles.add(fldName);\n      state.flushedFiles.add(docName);\n\n      docWriter.removeOpenFile(idxName);\n      docWriter.removeOpenFile(fldName);\n      docWriter.removeOpenFile(docName);\n\n      lastDocID = 0;\n    }    \n  }\n\n","sourceOld":"  @Override\n  synchronized void closeDocStore(final SegmentWriteState state) throws IOException {\n    if (tvx != null) {\n      // At least one doc in this run had term vectors\n      // enabled\n      fill(state.numDocsInStore - docWriter.getDocStoreOffset());\n      tvx.close();\n      tvf.close();\n      tvd.close();\n      tvx = null;\n      assert state.docStoreSegmentName != null;\n      String idxName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_INDEX_EXTENSION);\n      if (4+((long) state.numDocsInStore)*16 != state.directory.fileLength(idxName))\n        throw new RuntimeException(\"after flush: tvx size mismatch: \" + state.numDocsInStore + \" docs vs \" + state.directory.fileLength(idxName) + \" length in bytes of \" + idxName + \" file exists?=\" + state.directory.fileExists(idxName));\n\n      String fldName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_FIELDS_EXTENSION);\n      String docName = IndexFileNames.segmentFileName(state.docStoreSegmentName, IndexFileNames.VECTORS_DOCUMENTS_EXTENSION);\n      state.flushedFiles.add(idxName);\n      state.flushedFiles.add(fldName);\n      state.flushedFiles.add(docName);\n\n      docWriter.removeOpenFile(idxName);\n      docWriter.removeOpenFile(fldName);\n      docWriter.removeOpenFile(docName);\n\n      lastDocID = 0;\n    }    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c6e9e8b4258e08645a02d6b454cdb1689f6763d2":["4d17492f26096e19670d947d1be5e9adc52b1d3d"],"775efee7f959e0dd3df7960b93767d9e00b78751":["8a9e385641d717e641408d8fbbc62be8fc766357"],"55ddd0022d1d26b52ed711e90ab77de2b36130c6":["c6e9e8b4258e08645a02d6b454cdb1689f6763d2"],"8a9e385641d717e641408d8fbbc62be8fc766357":["55ddd0022d1d26b52ed711e90ab77de2b36130c6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4d17492f26096e19670d947d1be5e9adc52b1d3d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["775efee7f959e0dd3df7960b93767d9e00b78751"]},"commit2Childs":{"c6e9e8b4258e08645a02d6b454cdb1689f6763d2":["55ddd0022d1d26b52ed711e90ab77de2b36130c6"],"775efee7f959e0dd3df7960b93767d9e00b78751":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"55ddd0022d1d26b52ed711e90ab77de2b36130c6":["8a9e385641d717e641408d8fbbc62be8fc766357"],"8a9e385641d717e641408d8fbbc62be8fc766357":["775efee7f959e0dd3df7960b93767d9e00b78751"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d17492f26096e19670d947d1be5e9adc52b1d3d"],"4d17492f26096e19670d947d1be5e9adc52b1d3d":["c6e9e8b4258e08645a02d6b454cdb1689f6763d2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}