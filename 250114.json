{"path":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","commits":[{"id":"9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc","date":1251117853,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"/dev/null","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      assertTrue(\"token \"+i+\" exists\", ts.incrementToken());\n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["e64a71406348a5942a2166256238aff8313d0914","360d15dc189fb48153cb62234f7d20819e4e292e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"df24bb60fdf46b297fdeb45d5b545cce91160ab8","date":1253896462,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      ts.clearAttributes(); // extra safety to enforce, that the state is not preserved\n      assertTrue(\"token \"+i+\" exists\", ts.incrementToken());\n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      assertTrue(\"token \"+i+\" exists\", ts.incrementToken());\n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":["e64a71406348a5942a2166256238aff8313d0914"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06f858bea57ed29f393be1061f0c8cdb5944a14c","date":1253899571,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \"+i+\" exists\", ts.incrementToken());\n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      ts.clearAttributes(); // extra safety to enforce, that the state is not preserved\n      assertTrue(\"token \"+i+\" exists\", ts.incrementToken());\n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":["e64a71406348a5942a2166256238aff8313d0914"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \"+i+\" exists\", ts.incrementToken());\n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \"+i+\" exists\", ts.incrementToken());\n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":["e64a71406348a5942a2166256238aff8313d0914"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"360d15dc189fb48153cb62234f7d20819e4e292e","date":1263562938,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \"+i+\" exists\", ts.incrementToken());\n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","bugFix":["9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc"],"bugIntro":["e64a71406348a5942a2166256238aff8313d0914"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e64a71406348a5942a2166256238aff8313d0914","date":1263756357,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(ts, output, startOffsets, endOffsets, types, posIncrements, null);\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = ts.getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.term());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","bugFix":["06f858bea57ed29f393be1061f0c8cdb5944a14c","9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc","8d78f014fded44fbde905f4f84cdc21907b371e8","df24bb60fdf46b297fdeb45d5b545cce91160ab8","360d15dc189fb48153cb62234f7d20819e4e292e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(ts, output, startOffsets, endOffsets, types, posIncrements, null);\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {\n    assertTokenStreamContents(ts, output, startOffsets, endOffsets, types, posIncrements, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"df24bb60fdf46b297fdeb45d5b545cce91160ab8":["9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc"],"e64a71406348a5942a2166256238aff8313d0914":["360d15dc189fb48153cb62234f7d20819e4e292e"],"06f858bea57ed29f393be1061f0c8cdb5944a14c":["df24bb60fdf46b297fdeb45d5b545cce91160ab8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8d78f014fded44fbde905f4f84cdc21907b371e8":["06f858bea57ed29f393be1061f0c8cdb5944a14c"],"9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["e64a71406348a5942a2166256238aff8313d0914"],"360d15dc189fb48153cb62234f7d20819e4e292e":["8d78f014fded44fbde905f4f84cdc21907b371e8"]},"commit2Childs":{"df24bb60fdf46b297fdeb45d5b545cce91160ab8":["06f858bea57ed29f393be1061f0c8cdb5944a14c"],"e64a71406348a5942a2166256238aff8313d0914":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"06f858bea57ed29f393be1061f0c8cdb5944a14c":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["360d15dc189fb48153cb62234f7d20819e4e292e"],"9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc":["df24bb60fdf46b297fdeb45d5b545cce91160ab8"],"360d15dc189fb48153cb62234f7d20819e4e292e":["e64a71406348a5942a2166256238aff8313d0914"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}