{"path":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","commits":[{"id":"86a0a50d2d14aaee1e635bbec914468551f7f9a2","date":1482234306,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            if (finishedDocValues.contains(perField.fieldInfo.name) == false) {\n              perField.docValuesWriter.finish(maxDoc);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(maxDoc);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"/dev/null","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            if (finishedDocValues.contains(perField.fieldInfo.name) == false) {\n              perField.docValuesWriter.finish(maxDoc);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"773bf150032d3ef6c95997a154fb914b82875cb8","date":1590150786,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            if (finishedDocValues.contains(perField.fieldInfo.name) == false) {\n              perField.docValuesWriter.finish(maxDoc);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4","date":1599581893,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a6f8af01d9b3067b143bbdc0a492720e2af97cf","date":1600157724,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"680b6449f09827f58fe987aff279e014c311d966","date":1600247985,"type":5,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4":["773bf150032d3ef6c95997a154fb914b82875cb8"],"680b6449f09827f58fe987aff279e014c311d966":["6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"773bf150032d3ef6c95997a154fb914b82875cb8":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["680b6449f09827f58fe987aff279e014c311d966"]},"commit2Childs":{"6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4":["680b6449f09827f58fe987aff279e014c311d966","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"680b6449f09827f58fe987aff279e014c311d966":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["680b6449f09827f58fe987aff279e014c311d966"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":[],"773bf150032d3ef6c95997a154fb914b82875cb8":["6926606ec5e0dd8d4ec79166d39a3b4ddb862bf4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","773bf150032d3ef6c95997a154fb914b82875cb8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}