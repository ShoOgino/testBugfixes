{"path":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","commits":[{"id":"ee3a275f925be62184fad78d647fa70e27ac7cea","date":1301416659,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"45669a651c970812a680841b97a77cce06af559f","date":1301922222,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/analysis-extras/src/main/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/main/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60c9885566d6f83ba835be67d76ecbf214685052","date":1317096458,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6e919043fa85ee891123768dd655a98edbbf63c","date":1322225413,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, part);\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","bugFix":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, part);\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    try (TokenStream source = analyzer.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n      \n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable analyze range part: \" + part, e);\n    }\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, part);\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n      \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","bugFix":["e6e919043fa85ee891123768dd655a98edbbf63c","ee3a275f925be62184fad78d647fa70e27ac7cea","c83d6c4335f31cae14f625a222bc842f20073dcd","60c9885566d6f83ba835be67d76ecbf214685052"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64","date":1385598663,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#getCollationKey(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the text with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef getCollationKey(String field, String text) {\n    try (TokenStream source = analyzer.tokenStream(field, text)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for text: \" + text);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n      \n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to analyze text: \" + text, e);\n    }\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    try (TokenStream source = analyzer.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n      \n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable analyze range part: \" + part, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":4,"author":"Michael McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":null,"sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    try (TokenStream source = analyzer.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n      \n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable analyze range part: \" + part, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"60c9885566d6f83ba835be67d76ecbf214685052":["ee3a275f925be62184fad78d647fa70e27ac7cea"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["e6e919043fa85ee891123768dd655a98edbbf63c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ee3a275f925be62184fad78d647fa70e27ac7cea"],"14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["e6e919043fa85ee891123768dd655a98edbbf63c"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a3776dccca01c11e7046323cfad46a3b4a471233","ee3a275f925be62184fad78d647fa70e27ac7cea"],"a3776dccca01c11e7046323cfad46a3b4a471233":["ee3a275f925be62184fad78d647fa70e27ac7cea","ee3a275f925be62184fad78d647fa70e27ac7cea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64"],"45669a651c970812a680841b97a77cce06af559f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ee3a275f925be62184fad78d647fa70e27ac7cea"],"e6e919043fa85ee891123768dd655a98edbbf63c":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["60c9885566d6f83ba835be67d76ecbf214685052"],"ee3a275f925be62184fad78d647fa70e27ac7cea":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64"]},"commit2Childs":{"60c9885566d6f83ba835be67d76ecbf214685052":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["135621f3a0670a9394eb563224a3b76cc4dddc0f","45669a651c970812a680841b97a77cce06af559f","ee3a275f925be62184fad78d647fa70e27ac7cea"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"45669a651c970812a680841b97a77cce06af559f":[],"ee3a275f925be62184fad78d647fa70e27ac7cea":["60c9885566d6f83ba835be67d76ecbf214685052","135621f3a0670a9394eb563224a3b76cc4dddc0f","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","a3776dccca01c11e7046323cfad46a3b4a471233","45669a651c970812a680841b97a77cce06af559f"],"e6e919043fa85ee891123768dd655a98edbbf63c":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["e6e919043fa85ee891123768dd655a98edbbf63c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","135621f3a0670a9394eb563224a3b76cc4dddc0f","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","74f45af4339b0daf7a95c820ab88c1aea74fbce0","45669a651c970812a680841b97a77cce06af559f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}