{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    Directory dir = newDirectory();\n\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new LimitTokenCountAnalyzer(new MockAnalyzer(random()), 100000)));\n\n    Document doc = new Document();\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<10000;i++)\n      b.append(\" a\");\n    b.append(\" x\");\n    doc.add(newField(\"field\", b.toString(), TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    writer.close();\n\n    IndexReader reader = IndexReader.open(dir);\n    Term t = new Term(\"field\", \"x\");\n    assertEquals(1, reader.docFreq(t));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    Directory dir = newDirectory();\n\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new LimitTokenCountAnalyzer(new MockAnalyzer(random()), 100000)));\n\n    Document doc = new Document();\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<10000;i++)\n      b.append(\" a\");\n    b.append(\" x\");\n    doc.add(newField(\"field\", b.toString(), TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    writer.close();\n\n    IndexReader reader = IndexReader.open(dir);\n    Term t = new Term(\"field\", \"x\");\n    assertEquals(1, reader.docFreq(t));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    Directory dir = newDirectory();\n\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new LimitTokenCountAnalyzer(new MockAnalyzer(random()), 100000)));\n\n    Document doc = new Document();\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<10000;i++)\n      b.append(\" a\");\n    b.append(\" x\");\n    doc.add(newField(\"field\", b.toString(), TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    writer.close();\n\n    IndexReader reader = DirectoryReader.open(dir);\n    Term t = new Term(\"field\", \"x\");\n    assertEquals(1, reader.docFreq(t));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    Directory dir = newDirectory();\n\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new LimitTokenCountAnalyzer(new MockAnalyzer(random()), 100000)));\n\n    Document doc = new Document();\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<10000;i++)\n      b.append(\" a\");\n    b.append(\" x\");\n    doc.add(newField(\"field\", b.toString(), TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    writer.close();\n\n    IndexReader reader = IndexReader.open(dir);\n    Term t = new Term(\"field\", \"x\");\n    assertEquals(1, reader.docFreq(t));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    Directory dir = newDirectory();\n\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new LimitTokenCountAnalyzer(new MockAnalyzer(random()), 100000)));\n\n    Document doc = new Document();\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<10000;i++)\n      b.append(\" a\");\n    b.append(\" x\");\n    doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n    writer.addDocument(doc);\n    writer.close();\n\n    IndexReader reader = DirectoryReader.open(dir);\n    Term t = new Term(\"field\", \"x\");\n    assertEquals(1, reader.docFreq(t));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    Directory dir = newDirectory();\n\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new LimitTokenCountAnalyzer(new MockAnalyzer(random()), 100000)));\n\n    Document doc = new Document();\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<10000;i++)\n      b.append(\" a\");\n    b.append(\" x\");\n    doc.add(newField(\"field\", b.toString(), TextField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    writer.close();\n\n    IndexReader reader = DirectoryReader.open(dir);\n    Term t = new Term(\"field\", \"x\");\n    assertEquals(1, reader.docFreq(t));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5009d80b96d7223e4120e40035a8b8c1d48cb134","date":1353482392,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = _TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig\n                                           (TEST_VERSION_CURRENT, a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    Directory dir = newDirectory();\n\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new LimitTokenCountAnalyzer(new MockAnalyzer(random()), 100000)));\n\n    Document doc = new Document();\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<10000;i++)\n      b.append(\" a\");\n    b.append(\" x\");\n    doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n    writer.addDocument(doc);\n    writer.close();\n\n    IndexReader reader = DirectoryReader.open(dir);\n    Term t = new Term(\"field\", \"x\");\n    assertEquals(1, reader.docFreq(t));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = _TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig\n                                           (TEST_VERSION_CURRENT, a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    Directory dir = newDirectory();\n\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new LimitTokenCountAnalyzer(new MockAnalyzer(random()), 100000)));\n\n    Document doc = new Document();\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<10000;i++)\n      b.append(\" a\");\n    b.append(\" x\");\n    doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n    writer.addDocument(doc);\n    writer.close();\n\n    IndexReader reader = DirectoryReader.open(dir);\n    Term t = new Term(\"field\", \"x\");\n    assertEquals(1, reader.docFreq(t));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig\n                                           (TEST_VERSION_CURRENT, a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = _TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig\n                                           (TEST_VERSION_CURRENT, a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig\n                                           (TEST_VERSION_CURRENT, a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.shutdown();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig\n                                           (TEST_VERSION_CURRENT, a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig\n                                           (TEST_VERSION_CURRENT, a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.shutdown();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n      a.close();\n    }\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenCountAnalyzer#testLimitTokenCountIndexWriter().mjava","sourceNew":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n      a.close();\n    }\n  }\n\n","sourceOld":"  public void testLimitTokenCountIndexWriter() throws IOException {\n    \n    for (boolean consumeAll : new boolean[] { true, false }) {\n      Directory dir = newDirectory();\n      int limit = TestUtil.nextInt(random(), 50, 101000);\n      MockAnalyzer mock = new MockAnalyzer(random());\n\n      // if we are consuming all tokens, we can use the checks, \n      // otherwise we can't\n      mock.setEnableChecks(consumeAll);\n      Analyzer a = new LimitTokenCountAnalyzer(mock, limit, consumeAll);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(a));\n\n      Document doc = new Document();\n      StringBuilder b = new StringBuilder();\n      for(int i=1;i<limit;i++)\n        b.append(\" a\");\n      b.append(\" x\");\n      b.append(\" z\");\n      doc.add(newTextField(\"field\", b.toString(), Field.Store.NO));\n      writer.addDocument(doc);\n      writer.close();\n      \n      IndexReader reader = DirectoryReader.open(dir);\n      Term t = new Term(\"field\", \"x\");\n      assertEquals(1, reader.docFreq(t));\n      t = new Term(\"field\", \"z\");\n      assertEquals(0, reader.docFreq(t));\n      reader.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["d0ef034a4f10871667ae75181537775ddcf8ade4","a56958d7f71a28824f20031ffbb2e13502a0274e"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"6613659748fe4411a7dcf85266e55db1f95f7315":["5009d80b96d7223e4120e40035a8b8c1d48cb134"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["04f07771a2a7dd3a395700665ed839c3dae2def2","5009d80b96d7223e4120e40035a8b8c1d48cb134"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["6613659748fe4411a7dcf85266e55db1f95f7315"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"5009d80b96d7223e4120e40035a8b8c1d48cb134":["04f07771a2a7dd3a395700665ed839c3dae2def2"]},"commit2Childs":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["407687e67faf6e1f02a211ca078d8e3eed631027","5009d80b96d7223e4120e40035a8b8c1d48cb134"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5009d80b96d7223e4120e40035a8b8c1d48cb134":["6613659748fe4411a7dcf85266e55db1f95f7315","407687e67faf6e1f02a211ca078d8e3eed631027"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}