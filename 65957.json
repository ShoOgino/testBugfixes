{"path":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      postingsHash = new RawPostingList[newSize];\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      postingsHash = new RawPostingList[newSize];\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9","date":1269379515,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      postingsHash = new int[newSize];\n      Arrays.fill(postingsHash, -1);\n      postingsArray = null;\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      postingsHash = new RawPostingList[newSize];\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      final long previousSize = postingsHash.length;\n      postingsHash = new int[newSize];\n      bytesUsed((newSize-previousSize)*RamUsageEstimator.NUM_BYTES_INT);\n      Arrays.fill(postingsHash, -1);\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n\n    if (postingsArray != null) {\n      final int startSize = postingsArray.size;\n      postingsArray = postingsArray.shrink(targetSize, false);\n      bytesUsed(postingsArray.bytesPerPosting() * (postingsArray.size - startSize));\n    }\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      postingsHash = new int[newSize];\n      Arrays.fill(postingsHash, -1);\n      postingsArray = null;\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f58dd714e47e4b20e7ddf69802a24d8278a50d3d","date":1270583819,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      final long previousSize = postingsHash.length;\n      postingsHash = new int[newSize];\n      bytesUsed((newSize-previousSize)*RamUsageEstimator.NUM_BYTES_INT);\n      Arrays.fill(postingsHash, -1);\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n\n    // Fully free the postings array on each flush:\n    if (postingsArray != null) {\n      bytesUsed(-postingsArray.bytesPerPosting() * postingsArray.size);\n      postingsArray = null;\n    }\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      final long previousSize = postingsHash.length;\n      postingsHash = new int[newSize];\n      bytesUsed((newSize-previousSize)*RamUsageEstimator.NUM_BYTES_INT);\n      Arrays.fill(postingsHash, -1);\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n\n    if (postingsArray != null) {\n      final int startSize = postingsArray.size;\n      postingsArray = postingsArray.shrink(targetSize, false);\n      bytesUsed(postingsArray.bytesPerPosting() * (postingsArray.size - startSize));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"24736f886f499d15345d6c4b717b9fe84a70dae2","date":1274900864,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    final int newSize = 4;\n    if (newSize != postingsHash.length) {\n      final long previousSize = postingsHash.length;\n      postingsHash = new int[newSize];\n      bytesUsed((newSize-previousSize)*RamUsageEstimator.NUM_BYTES_INT);\n      Arrays.fill(postingsHash, -1);\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n\n    // Fully free the postings array on each flush:\n    if (postingsArray != null) {\n      bytesUsed(-postingsArray.bytesPerPosting() * postingsArray.size);\n      postingsArray = null;\n    }\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    // Cannot use ArrayUtil.shrink because we require power\n    // of 2:\n    int newSize = postingsHash.length;\n    while(newSize >= 8 && newSize/4 > targetSize) {\n      newSize /= 2;\n    }\n\n    if (newSize != postingsHash.length) {\n      final long previousSize = postingsHash.length;\n      postingsHash = new int[newSize];\n      bytesUsed((newSize-previousSize)*RamUsageEstimator.NUM_BYTES_INT);\n      Arrays.fill(postingsHash, -1);\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n\n    // Fully free the postings array on each flush:\n    if (postingsArray != null) {\n      bytesUsed(-postingsArray.bytesPerPosting() * postingsArray.size);\n      postingsArray = null;\n    }\n  }\n\n","bugFix":["5350389bf83287111f7760b9e3db3af8e3648474"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","date":1286023472,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false); \n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    final int newSize = 4;\n    if (newSize != postingsHash.length) {\n      final long previousSize = postingsHash.length;\n      postingsHash = new int[newSize];\n      bytesUsed((newSize-previousSize)*RamUsageEstimator.NUM_BYTES_INT);\n      Arrays.fill(postingsHash, -1);\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n\n    // Fully free the postings array on each flush:\n    if (postingsArray != null) {\n      bytesUsed(-postingsArray.bytesPerPosting() * postingsArray.size);\n      postingsArray = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false);\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    assert postingsCompacted || numPostings == 0;\n\n    final int newSize = 4;\n    if (newSize != postingsHash.length) {\n      final long previousSize = postingsHash.length;\n      postingsHash = new int[newSize];\n      bytesUsed((newSize-previousSize)*RamUsageEstimator.NUM_BYTES_INT);\n      Arrays.fill(postingsHash, -1);\n      postingsHashSize = newSize;\n      postingsHashHalfSize = newSize/2;\n      postingsHashMask = newSize-1;\n    }\n\n    // Fully free the postings array on each flush:\n    if (postingsArray != null) {\n      bytesUsed(-postingsArray.bytesPerPosting() * postingsArray.size);\n      postingsArray = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false);\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false); \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false);\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false); \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false);\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false); \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#shrinkHash(int).mjava","sourceNew":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false);\n  }\n\n","sourceOld":"  void shrinkHash(int targetSize) {\n    // Fully free the bytesHash on each flush but keep the pool untouched\n    // bytesHash.clear will clear the ByteStartArray and in turn the ParallelPostingsArray too\n    bytesHash.clear(false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["24736f886f499d15345d6c4b717b9fe84a70dae2"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"24736f886f499d15345d6c4b717b9fe84a70dae2":["f58dd714e47e4b20e7ddf69802a24d8278a50d3d"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["24736f886f499d15345d6c4b717b9fe84a70dae2","5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392"],"f58dd714e47e4b20e7ddf69802a24d8278a50d3d":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"a3776dccca01c11e7046323cfad46a3b4a471233":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["135621f3a0670a9394eb563224a3b76cc4dddc0f","b3e06be49006ecac364d39d12b9c9f74882f9b9f","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","a3776dccca01c11e7046323cfad46a3b4a471233"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"24736f886f499d15345d6c4b717b9fe84a70dae2":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["f58dd714e47e4b20e7ddf69802a24d8278a50d3d"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"f58dd714e47e4b20e7ddf69802a24d8278a50d3d":["24736f886f499d15345d6c4b717b9fe84a70dae2"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}