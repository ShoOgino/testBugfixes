{"path":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","commits":[{"id":"042e4d934397657ba04c82b46cc5665076bc5c58","date":1336511170,"type":1,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4485732f2b76c4d25f5b4d6d48bc1b5204817e8e","date":1340876809,"type":3,"author":"Jan HÃ¸ydahl","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9279c7cd47f17e1e8b674a3741ff5f040bc680be","date":1341675760,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2acf500f78aa12b92e371fd89c719291986b6b90","date":1341846236,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"46d8ada1fff8d18cb197c38c7983225162599948","date":1341853497,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ae9ffabd75a5e21eb54bc365eaebeaf858c4f0","date":1422056685,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c05ecea3671609c138d91d6fe0d0aa71dd86e992","date":1446668020,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","date":1574619880,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @SuppressWarnings({\"deprecation\", \"unchecked\", \"rawtypes\"})\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        org.apache.xml.serialize.BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new org.apache.xml.serialize.TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new org.apache.xml.serialize.OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new org.apache.xml.serialize.XMLSerializer(writer, new org.apache.xml.serialize.OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9c3baacabd473e8ecd6c4948aabacead49b88e","date":1574700980,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  @SuppressWarnings({\"deprecation\", \"unchecked\", \"rawtypes\"})\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        org.apache.xml.serialize.BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new org.apache.xml.serialize.TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new org.apache.xml.serialize.OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new org.apache.xml.serialize.XMLSerializer(writer, new org.apache.xml.serialize.OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: {}\", pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file {}\", resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString()); // logOk\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: \"+pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file \"+resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19eeb5bbd032a02cb82a253c4c9ae35863ea2dc","date":1591973782,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\"})\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: {}\", pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file {}\", resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString()); // logOk\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          @SuppressWarnings({\"rawtypes\"})\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: {}\", pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file {}\", resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString()); // logOk\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2d19164145b2a65acf62a657c75f4a249b649c0","date":1601732857,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","pathOld":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream,UpdateRequestProcessor).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\"})\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: {}\", pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file {}\", resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString()); // nowarn\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          @SuppressWarnings({\"rawtypes\"})\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\"})\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp,\n      ContentStream stream, UpdateRequestProcessor processor) throws Exception {\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ROOT));\n      parser = new DefaultParser(config.getMediaTypeRegistry()).getParsers().get(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(TikaMetadataKeys.RESOURCE_NAME_KEY, resourceName);\n      }\n      // Provide stream's content type as hint for auto detection\n      if(stream.getContentType() != null) {\n        metadata.add(HttpHeaders.CONTENT_TYPE, stream.getContentType());\n      }\n\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n        metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n        metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n        metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n        // HtmlParser and TXTParser regard Metadata.CONTENT_ENCODING in metadata\n        String charset = ContentStreamBase.getCharsetFromContentType(stream.getContentType());\n        if(charset != null){\n          metadata.add(HttpHeaders.CONTENT_ENCODING, charset);\n        }\n\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, req.getSchema());\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = parseContextConfig.create();\n\n\n          context.set(Parser.class, parser);\n          context.set(HtmlMapper.class, MostlyPassthroughHtmlMapper.INSTANCE);\n\n          // Password handling\n          RegexRulesPasswordProvider epp = new RegexRulesPasswordProvider();\n          String pwMapFile = params.get(ExtractingParams.PASSWORD_MAP_FILE);\n          if(pwMapFile != null && pwMapFile.length() > 0) {\n            InputStream is = req.getCore().getResourceLoader().openResource(pwMapFile);\n            if(is != null) {\n              log.debug(\"Password file supplied: {}\", pwMapFile);\n              epp.parse(is);\n            }\n          }\n          context.set(PasswordProvider.class, epp);\n          String resourcePassword = params.get(ExtractingParams.RESOURCE_PASSWORD);\n          if(resourcePassword != null) {\n            epp.setExplicitPassword(resourcePassword);\n            log.debug(\"Literal password supplied for file {}\", resourceName);\n          }\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString()); // logOk\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          @SuppressWarnings({\"rawtypes\"})\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"14ae9ffabd75a5e21eb54bc365eaebeaf858c4f0":["08970e5b8411182a29412c177eff67ec1110095b"],"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["2acf500f78aa12b92e371fd89c719291986b6b90"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["c05ecea3671609c138d91d6fe0d0aa71dd86e992"],"9279c7cd47f17e1e8b674a3741ff5f040bc680be":["4485732f2b76c4d25f5b4d6d48bc1b5204817e8e"],"2acf500f78aa12b92e371fd89c719291986b6b90":["4485732f2b76c4d25f5b4d6d48bc1b5204817e8e","9279c7cd47f17e1e8b674a3741ff5f040bc680be"],"4485732f2b76c4d25f5b4d6d48bc1b5204817e8e":["042e4d934397657ba04c82b46cc5665076bc5c58"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"08970e5b8411182a29412c177eff67ec1110095b":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"46d8ada1fff8d18cb197c38c7983225162599948":["4485732f2b76c4d25f5b4d6d48bc1b5204817e8e","2acf500f78aa12b92e371fd89c719291986b6b90"],"c05ecea3671609c138d91d6fe0d0aa71dd86e992":["14ae9ffabd75a5e21eb54bc365eaebeaf858c4f0"],"042e4d934397657ba04c82b46cc5665076bc5c58":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["042e4d934397657ba04c82b46cc5665076bc5c58","2acf500f78aa12b92e371fd89c719291986b6b90"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"b2d19164145b2a65acf62a657c75f4a249b649c0":["c19eeb5bbd032a02cb82a253c4c9ae35863ea2dc"],"c19eeb5bbd032a02cb82a253c4c9ae35863ea2dc":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b2d19164145b2a65acf62a657c75f4a249b649c0"]},"commit2Childs":{"14ae9ffabd75a5e21eb54bc365eaebeaf858c4f0":["c05ecea3671609c138d91d6fe0d0aa71dd86e992"],"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["08970e5b8411182a29412c177eff67ec1110095b"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"9279c7cd47f17e1e8b674a3741ff5f040bc680be":["2acf500f78aa12b92e371fd89c719291986b6b90"],"2acf500f78aa12b92e371fd89c719291986b6b90":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"4485732f2b76c4d25f5b4d6d48bc1b5204817e8e":["9279c7cd47f17e1e8b674a3741ff5f040bc680be","2acf500f78aa12b92e371fd89c719291986b6b90","46d8ada1fff8d18cb197c38c7983225162599948"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["c19eeb5bbd032a02cb82a253c4c9ae35863ea2dc"],"08970e5b8411182a29412c177eff67ec1110095b":["14ae9ffabd75a5e21eb54bc365eaebeaf858c4f0"],"46d8ada1fff8d18cb197c38c7983225162599948":[],"c05ecea3671609c138d91d6fe0d0aa71dd86e992":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"042e4d934397657ba04c82b46cc5665076bc5c58":["4485732f2b76c4d25f5b4d6d48bc1b5204817e8e","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["042e4d934397657ba04c82b46cc5665076bc5c58"],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"b2d19164145b2a65acf62a657c75f4a249b649c0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c19eeb5bbd032a02cb82a253c4c9ae35863ea2dc":["b2d19164145b2a65acf62a657c75f4a249b649c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}