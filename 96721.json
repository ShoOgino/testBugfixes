{"path":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","commits":[{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < Lucene40StoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n      if (format > Lucene40StoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < Lucene40StoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n      if (format > Lucene40StoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30","date":1327936772,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      // its a 4.0 codec: so its not too-old, its corrupt.\n      // TODO: change this to CodecUtil.checkHeader\n      if (Lucene40StoredFieldsWriter.FORMAT_CURRENT != indexStream.readInt()) {\n        throw new CorruptIndexException(\"unexpected fdx header: \" + indexStream);\n      }\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      this.size = (int) (indexSize >> 3);\n      // Verify two sources of \"maxDoc\" agree:\n      if (this.size != si.docCount) {\n        throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < Lucene40StoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n      if (format > Lucene40StoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"296df632fd63421ea20756fa11ad36fbc6f4c8a9","date":1327957998,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      // its a 4.0 codec: so its not too-old, its corrupt.\n      // TODO: change this to CodecUtil.checkHeader\n      if (Lucene40StoredFieldsWriter.FORMAT_CURRENT != indexStream.readInt()) {\n        throw new CorruptIndexException(\"unexpected fdx header: \" + indexStream);\n      }\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      this.size = (int) (indexSize >> 3);\n      // Verify two sources of \"maxDoc\" agree:\n      if (this.size != si.docCount) {\n        throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < Lucene40StoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n      if (format > Lucene40StoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"410e066f093e407222d9681429d209084e783149","date":1327958394,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      // its a 4.0 codec: so its not too-old, its corrupt.\n      // TODO: change this to CodecUtil.checkHeader\n      if (Lucene40StoredFieldsWriter.FORMAT_CURRENT != indexStream.readInt()) {\n        throw new CorruptIndexException(\"unexpected fdx header: \" + indexStream);\n      }\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      this.size = (int) (indexSize >> 3);\n      // Verify two sources of \"maxDoc\" agree:\n      if (this.size != si.docCount) {\n        throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < Lucene40StoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n      if (format > Lucene40StoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      // its a 4.0 codec: so its not too-old, its corrupt.\n      // TODO: change this to CodecUtil.checkHeader\n      if (Lucene40StoredFieldsWriter.FORMAT_CURRENT != indexStream.readInt()) {\n        throw new CorruptIndexException(\"unexpected fdx header: \" + indexStream);\n      }\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      this.size = (int) (indexSize >> 3);\n      // Verify two sources of \"maxDoc\" agree:\n      if (this.size != si.docCount) {\n        throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      // its a 4.0 codec: so its not too-old, its corrupt.\n      // TODO: change this to CodecUtil.checkHeader\n      if (Lucene40StoredFieldsWriter.FORMAT_CURRENT != indexStream.readInt()) {\n        throw new CorruptIndexException(\"unexpected fdx header: \" + indexStream);\n      }\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      this.size = (int) (indexSize >> 3);\n      // Verify two sources of \"maxDoc\" agree:\n      if (this.size != si.docCount) {\n        throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"410e066f093e407222d9681429d209084e783149":["a0ae5e3ed1232483b7b8a014f175a5fe43595982","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["a0ae5e3ed1232483b7b8a014f175a5fe43595982","1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"410e066f093e407222d9681429d209084e783149":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["410e066f093e407222d9681429d209084e783149","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["410e066f093e407222d9681429d209084e783149","296df632fd63421ea20756fa11ad36fbc6f4c8a9","1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30"],"1538bc2b1cdbe17dacb2c1e6d11a8dc7a18c6d30":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["410e066f093e407222d9681429d209084e783149","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}