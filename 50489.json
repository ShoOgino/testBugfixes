{"path":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ecc11368dc265bfdad90214f8bf5da99016ab1e2","date":1294144090,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":5,"author":"Michael Busch","isMerge":true,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["9454a6510e2db155fb01faa5c049b06ece95fab9","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"868da859b43505d9d2a023bfeae6dd0c795f5295":["9454a6510e2db155fb01faa5c049b06ece95fab9","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":[],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["70ad682703b8585f5d0a637efec044d57ec05efb","ecc11368dc265bfdad90214f8bf5da99016ab1e2","868da859b43505d9d2a023bfeae6dd0c795f5295"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}