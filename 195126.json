{"path":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = new RAMDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = new RAMDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7f8e68717c68517265937c911e1ce9f25750247","date":1274071103,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = new RAMDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = new RAMDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = new MockRAMDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = new RAMDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory(random);\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = new MockRAMDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory(random);\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = new RAMDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"323f871ffe96b871d8c534a614be60751bb023c2","date":1294820532,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(IndexReader indexreader, int i)\n              throws IOException {\n            this.baseDoc = i;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = new IndexSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0d520cd04d39f8caa0a53ed23e60beb30e8fb9f","date":1310403131,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final OpenBitSet bitset = new OpenBitSet();\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, customType, new TokenStreamConcurrent()));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n      document.add(new Field(FIELD, new TokenStreamConcurrent(),\n          TermVector.WITH_POSITIONS_OFFSETS));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd","date":1317197236,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, customType, new TokenStreamConcurrent()));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              (TermPositionVector) indexReader.getTermFreqVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory, true);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      try {\n        final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n            new SpanTermQuery(new Term(FIELD, \"fox\")),\n            new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n        final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n        indexSearcher.search(phraseQuery, new Collector() {\n          private int baseDoc;\n\n          @Override\n          public boolean acceptsDocsOutOfOrder() {\n            return true;\n          }\n\n          @Override\n          public void collect(int i) throws IOException {\n            bitset.set(this.baseDoc + i);\n          }\n\n          @Override\n          public void setNextReader(AtomicReaderContext context)\n              throws IOException {\n            this.baseDoc = context.docBase;\n          }\n\n          @Override\n          public void setScorer(org.apache.lucene.search.Scorer scorer)\n              throws IOException {\n            // Do Nothing\n          }\n        });\n        assertEquals(1, bitset.cardinality());\n        final int maxDoc = indexReader.maxDoc();\n        final Highlighter highlighter = new Highlighter(\n            new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n            new QueryScorer(phraseQuery));\n        for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n            .nextSetBit(position + 1)) {\n          assertEquals(0, position);\n          final TokenStream tokenStream = TokenSources.getTokenStream(\n              indexReader.getTermVector(position,\n                  FIELD), false);\n          assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n              TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n        }\n      } finally {\n        indexSearcher.close();\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testConcurrentSpan().mjava","sourceNew":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","sourceOld":"  public void testConcurrentSpan() throws CorruptIndexException,\n      LockObtainFailedException, IOException, InvalidTokenOffsetsException {\n    final String TEXT = \"the fox jumped\";\n    final Directory directory = newDirectory();\n    final IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false)));\n    try {\n      final Document document = new Document();\n\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectorOffsets(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectors(true);\n      document.add(new Field(FIELD, new TokenStreamConcurrent(), customType));\n      indexWriter.addDocument(document);\n    } finally {\n      indexWriter.close();\n    }\n    final IndexReader indexReader = IndexReader.open(directory);\n    try {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      final Query phraseQuery = new SpanNearQuery(new SpanQuery[] {\n          new SpanTermQuery(new Term(FIELD, \"fox\")),\n          new SpanTermQuery(new Term(FIELD, \"jumped\")) }, 0, true);\n      final FixedBitSet bitset = new FixedBitSet(indexReader.maxDoc());\n      indexSearcher.search(phraseQuery, new Collector() {\n        private int baseDoc;\n\n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int i) throws IOException {\n          bitset.set(this.baseDoc + i);\n        }\n\n        @Override\n        public void setNextReader(AtomicReaderContext context)\n            throws IOException {\n          this.baseDoc = context.docBase;\n        }\n\n        @Override\n        public void setScorer(org.apache.lucene.search.Scorer scorer)\n            throws IOException {\n          // Do Nothing\n        }\n      });\n      assertEquals(1, bitset.cardinality());\n      final int maxDoc = indexReader.maxDoc();\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      for (int position = bitset.nextSetBit(0); position >= 0 && position < maxDoc-1; position = bitset\n          .nextSetBit(position + 1)) {\n        assertEquals(0, position);\n        final TokenStream tokenStream = TokenSources.getTokenStream(\n            indexReader.getTermVector(position,\n                FIELD), false);\n        assertEquals(highlighter.getBestFragment(new TokenStreamConcurrent(),\n            TEXT), highlighter.getBestFragment(tokenStream, TEXT));\n      }\n    } finally {\n      indexReader.close();\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["3cc749c053615f5871f3b95715fe292f34e70a53","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3cc749c053615f5871f3b95715fe292f34e70a53"],"c7f8e68717c68517265937c911e1ce9f25750247":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["c7f8e68717c68517265937c911e1ce9f25750247","1f653cfcf159baeaafe5d01682a911e95bba4012"],"c0d520cd04d39f8caa0a53ed23e60beb30e8fb9f":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["1f653cfcf159baeaafe5d01682a911e95bba4012","790e1fde4caa765b3faaad3fbcd25c6973450336"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["c7f8e68717c68517265937c911e1ce9f25750247"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["c0d520cd04d39f8caa0a53ed23e60beb30e8fb9f"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["868da859b43505d9d2a023bfeae6dd0c795f5295","790e1fde4caa765b3faaad3fbcd25c6973450336"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"323f871ffe96b871d8c534a614be60751bb023c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3cc749c053615f5871f3b95715fe292f34e70a53":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["323f871ffe96b871d8c534a614be60751bb023c2"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a3776dccca01c11e7046323cfad46a3b4a471233":["790e1fde4caa765b3faaad3fbcd25c6973450336","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["3cc749c053615f5871f3b95715fe292f34e70a53","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","323f871ffe96b871d8c534a614be60751bb023c2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"c7f8e68717c68517265937c911e1ce9f25750247":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"c0d520cd04d39f8caa0a53ed23e60beb30e8fb9f":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["c0d520cd04d39f8caa0a53ed23e60beb30e8fb9f","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","29ef99d61cda9641b6250bf9567329a6e65f901d","323f871ffe96b871d8c534a614be60751bb023c2"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["c7f8e68717c68517265937c911e1ce9f25750247"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["3cc749c053615f5871f3b95715fe292f34e70a53"],"323f871ffe96b871d8c534a614be60751bb023c2":["790e1fde4caa765b3faaad3fbcd25c6973450336","868da859b43505d9d2a023bfeae6dd0c795f5295"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","1c5b026d03cbbb03ca4c0b97d14e9839682281dc","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"962d04139994fce5193143ef35615499a9a96d78":[],"790e1fde4caa765b3faaad3fbcd25c6973450336":["f2c5f0cb44df114db4228c8f77861714b5cabaea","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}