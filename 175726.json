{"path":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19275ba31e621f6da1b83bf13af75233876fd3d4","date":1374846698,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.shutdown();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                              .setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.shutdown();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random())).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.shutdown();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                              .setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                              .setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.shutdown();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.shutdown();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"feb4029567b43f074ed7b6eb8fb126d355075dfd","date":1544812585,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                              .setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.getDocStats().maxDoc);\n    writer.commit();\n    writer.close();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.getDocStats().maxDoc);\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.getDocStats().maxDoc);\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.getDocStats().maxDoc);\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.getDocStats().maxDoc);\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                              .setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"6613659748fe4411a7dcf85266e55db1f95f7315":["19275ba31e621f6da1b83bf13af75233876fd3d4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["6613659748fe4411a7dcf85266e55db1f95f7315"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["feb4029567b43f074ed7b6eb8fb126d355075dfd"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["feb4029567b43f074ed7b6eb8fb126d355075dfd"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["6613659748fe4411a7dcf85266e55db1f95f7315"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","19275ba31e621f6da1b83bf13af75233876fd3d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}