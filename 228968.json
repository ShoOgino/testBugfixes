{"path":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","commits":[{"id":"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753","date":1416999434,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"/dev/null","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (Files.exists(leafIndex.resolve(\"done\")) == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6bfe104fc023fadc9e709f8d17403d2cc61133fe","date":1454446396,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (Files.exists(leafIndex.resolve(\"done\")) == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (Files.exists(leafIndex.resolve(\"done\")) == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (Files.exists(leafIndex.resolve(\"done\")) == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (Files.exists(leafIndex.resolve(\"done\")) == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            final LeafReader parLeafReader;\n            if (infos.size() == 1) {\n              parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n            } else {\n              // This just means we didn't forceMerge above:\n              parLeafReader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));\n            }\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d211216c83f01894810543d1c107160a9ae3650b","date":1488289605,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.addReaderClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790693f23f4e88a59fbb25e47cc25f6d493b03cb","date":1553077690,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, false, IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"763da4a9605e47013078edc323b9d4b608f0f9e0","date":1555353576,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, false, IOContext.DEFAULT, Collections.emptyMap());\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, false, IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e83191a3e02851a0b67e5335e6922f3e9ea86d","date":1583489709,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, false, IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, false, IOContext.DEFAULT, Collections.emptyMap());\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bec68e7c41fed133827595747d853cad504e481e","date":1583501052,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDemoParallelLeafReader.ReindexingReader#getParallelLeafReader(LeafReader,boolean,long).mjava","sourceNew":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","sourceOld":"    // Returns a ref\n    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {\n      assert leaf instanceof SegmentReader;\n      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;\n\n      long infoSchemaGen = getSchemaGen(info);\n\n      if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: getParallelLeafReader: \" + leaf + \" infoSchemaGen=\" + infoSchemaGen + \" vs schemaGen=\" + schemaGen + \" doCache=\" + doCache);\n\n      if (infoSchemaGen == schemaGen) {\n        if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: segment is already current schemaGen=\" + schemaGen + \"; skipping\");\n        return null;\n      }\n\n      if (infoSchemaGen > schemaGen) {\n        throw new IllegalStateException(\"segment infoSchemaGen (\" + infoSchemaGen + \") cannot be greater than requested schemaGen (\" + schemaGen + \")\");\n      }\n\n      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);\n\n      // While loop because the parallel reader may be closed out from under us, so we must retry:\n      while (true) {\n\n        // TODO: make this sync finer, i.e. just the segment + schemaGen\n        synchronized (this) {\n          LeafReader parReader = parallelReaders.get(segIDGen);\n      \n          assert doCache || parReader == null;\n\n          if (parReader == null) {\n\n            Path leafIndex = segsPath.resolve(segIDGen.toString());\n\n            final Directory dir = openDirectory(leafIndex);\n\n            if (slowFileExists(dir, \"done\") == false) {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: build segment index for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n\n              if (dir.listAll().length != 0) {\n                // It crashed before finishing last time:\n                if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: remove old incomplete index files: \" + leafIndex);\n                IOUtils.rm(leafIndex);\n              }\n\n              reindex(infoSchemaGen, schemaGen, leaf, dir);\n\n              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will\n              // later try again:\n              dir.createOutput(\"done\", IOContext.DEFAULT).close();\n            } else {\n              if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: segment index already exists for \" + leaf + \" \" + segIDGen + \" (source: \" + info.getDiagnostics().get(\"source\") + \") dir=\" + leafIndex);\n            }\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: now check index \" + dir);\n            //TestUtil.checkIndex(dir);\n\n            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n            assert infos.size() == 1;\n            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, false, IOContext.DEFAULT);\n\n            //checkParallelReader(leaf, parLeafReader, schemaGen);\n\n            if (DEBUG) System.out.println(Thread.currentThread().getName() + \": TEST: opened parallel reader: \" + parLeafReader);\n            if (doCache) {\n              parallelReaders.put(segIDGen, parLeafReader);\n\n              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else\n              // the pruning may remove our directory:\n              closedSegments.remove(segIDGen);\n\n              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));\n\n            } else {\n              // Used only for merged segment warming:\n              // Messy: we close this reader now, instead of leaving open for reuse:\n              if (DEBUG) System.out.println(\"TEST: now decRef non cached refCount=\" + parLeafReader.getRefCount());\n              parLeafReader.decRef();\n              dir.close();\n\n              // Must do this after dir is closed, else another thread could \"rm -rf\" while we are closing (which makes MDW.close's\n              // checkIndex angry):\n              closedSegments.add(segIDGen);\n              parReader = null;\n            }\n            parReader = parLeafReader;\n\n          } else {\n            if (parReader.tryIncRef() == false) {\n              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now\n              // closed and we must try again.\n              if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: tryIncRef failed for \" + parReader + \"; retry\");\n              parReader = null;\n              continue;\n            }\n            if (DEBUG) System.out.println(Thread.currentThread().getName()+ \": TEST: use existing already opened parReader=\" + parReader + \" refCount=\" + parReader.getRefCount());\n            //checkParallelReader(leaf, parReader, schemaGen);\n          }\n\n          // We return the new reference to caller\n          return parReader;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"5a207d19eac354d649c3f0e2cce070017c78125e":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753","b470f36a9372c97283360b1304eacbde22df6c0d"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753","b470f36a9372c97283360b1304eacbde22df6c0d"],"bec68e7c41fed133827595747d853cad504e481e":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["d211216c83f01894810543d1c107160a9ae3650b"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["5a207d19eac354d649c3f0e2cce070017c78125e"],"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b470f36a9372c97283360b1304eacbde22df6c0d":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"d211216c83f01894810543d1c107160a9ae3650b":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["d211216c83f01894810543d1c107160a9ae3650b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bec68e7c41fed133827595747d853cad504e481e"]},"commit2Childs":{"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"5a207d19eac354d649c3f0e2cce070017c78125e":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"bec68e7c41fed133827595747d853cad504e481e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["bec68e7c41fed133827595747d853cad504e481e"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["d211216c83f01894810543d1c107160a9ae3650b"],"4d9aa91d3fdd25528bac3b2e6115d54fc2f28753":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3","b470f36a9372c97283360b1304eacbde22df6c0d","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"d211216c83f01894810543d1c107160a9ae3650b":["31741cf1390044e38a2ec3127cf302ba841bfd75","92212fd254551a0b1156aafc3a1a6ed1a43932ad"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d9aa91d3fdd25528bac3b2e6115d54fc2f28753"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["b470f36a9372c97283360b1304eacbde22df6c0d"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","92212fd254551a0b1156aafc3a1a6ed1a43932ad","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}