{"path":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery#testEnforceDeletions().mjava","commits":[{"id":"60596f28be69b10c37a56a303c2dbea07b2ca4ba","date":1425060541,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Query startQuery = new TermQuery(new Term(\"id\", \"1\"));\n\n    CachingWrapperQuery query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertTrue(query.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = query.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = query.missCount;\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, query.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = query.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(query.missCount > missCount);\n    missCount = query.missCount;\n\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery#testEnforceDeletions().mjava","pathOld":"/dev/null","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Query startQuery = new TermQuery(new Term(\"id\", \"1\"));\n\n    CachingWrapperQuery query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertTrue(query.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = query.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = query.missCount;\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, query.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = query.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(query.missCount > missCount);\n    missCount = query.missCount;\n\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d52e48927ca4ef3655a261f2230b968b6fdf3608","date":1444652107,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Query startQuery = new TermQuery(new Term(\"id\", \"1\"));\n\n    CachingWrapperQuery query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertTrue(query.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = query.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = query.missCount;\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, query.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = query.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(query.missCount > missCount);\n    missCount = query.missCount;\n\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Query startQuery = new TermQuery(new Term(\"id\", \"1\"));\n\n    CachingWrapperQuery query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertTrue(query.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = query.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = query.missCount;\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, query.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = query.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(query.missCount > missCount);\n    missCount = query.missCount;\n\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cfc8e07724f6bd95be343b1c03ae917c9de69cc","date":1446026743,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery#testEnforceDeletions().mjava","sourceNew":null,"sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Query startQuery = new TermQuery(new Term(\"id\", \"1\"));\n\n    CachingWrapperQuery query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertTrue(query.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = query.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = query.missCount;\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, query.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = query.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(query.missCount > missCount);\n    missCount = query.missCount;\n\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","60596f28be69b10c37a56a303c2dbea07b2ca4ba"],"d52e48927ca4ef3655a261f2230b968b6fdf3608":["60596f28be69b10c37a56a303c2dbea07b2ca4ba"],"4cfc8e07724f6bd95be343b1c03ae917c9de69cc":["d52e48927ca4ef3655a261f2230b968b6fdf3608"],"60596f28be69b10c37a56a303c2dbea07b2ca4ba":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4cfc8e07724f6bd95be343b1c03ae917c9de69cc"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"d52e48927ca4ef3655a261f2230b968b6fdf3608":["4cfc8e07724f6bd95be343b1c03ae917c9de69cc"],"60596f28be69b10c37a56a303c2dbea07b2ca4ba":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","d52e48927ca4ef3655a261f2230b968b6fdf3608"],"4cfc8e07724f6bd95be343b1c03ae917c9de69cc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","60596f28be69b10c37a56a303c2dbea07b2ca4ba"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}