{"path":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","commits":[{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,int).mjava","sourceNew":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, readBufferSize);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"143d45d6fe43d56d1f541059577c929fc0ad27a1","date":1323026648,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","sourceNew":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    boolean normsInitiallyEmpty = norms.isEmpty(); // only used for assert\n    long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n    // nocommit: change to a real check? see LUCENE-3619\n    assert singleNormStream == null || !normsInitiallyEmpty || nextNormSeek == singleNormStream.length();\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11f75174865a8734695cd60a4093339a4e63fcbb","date":1323039567,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","sourceNew":null,"sourceOld":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    boolean normsInitiallyEmpty = norms.isEmpty(); // only used for assert\n    long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n    // nocommit: change to a real check? see LUCENE-3619\n    assert singleNormStream == null || !normsInitiallyEmpty || nextNormSeek == singleNormStream.length();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8099eba57cdbcce07a786d4f70916be3f02e365","date":1323094558,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","sourceNew":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    boolean normsInitiallyEmpty = norms.isEmpty(); // only used for assert\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n    assert singleNormStream == null || !normsInitiallyEmpty || nextNormSeek == singleNormStream.length();\n  }\n\n","sourceOld":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","sourceNew":null,"sourceOld":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    boolean normsInitiallyEmpty = norms.isEmpty(); // only used for assert\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n    assert singleNormStream == null || !normsInitiallyEmpty || nextNormSeek == singleNormStream.length();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentReader#openNorms(Directory,IOContext).mjava","sourceNew":null,"sourceOld":"  private void openNorms(Directory cfsDir, IOContext context) throws IOException {\n    boolean normsInitiallyEmpty = norms.isEmpty(); // only used for assert\n    long nextNormSeek = SegmentNorms.NORMS_HEADER.length; //skip header (header unused for now)\n    int maxDoc = maxDoc();\n    for (FieldInfo fi : core.fieldInfos) {\n      if (norms.containsKey(fi.name)) {\n        // in case this SegmentReader is being re-opened, we might be able to\n        // reuse some norm instances and skip loading them here\n        continue;\n      }\n      if (fi.isIndexed && !fi.omitNorms) {\n        Directory d = directory();\n        String fileName = si.getNormFileName(fi.number);\n        if (!si.hasSeparateNorms(fi.number)) {\n          d = cfsDir;\n        }\n        \n        // singleNormFile means multiple norms share this file\n        boolean singleNormFile = IndexFileNames.matchesExtension(fileName, IndexFileNames.NORMS_EXTENSION);\n        IndexInput normInput = null;\n        long normSeek;\n\n        if (singleNormFile) {\n          normSeek = nextNormSeek;\n          if (singleNormStream == null) {\n            singleNormStream = d.openInput(fileName, context);\n            singleNormRef = new AtomicInteger(1);\n          } else {\n            singleNormRef.incrementAndGet();\n          }\n          // All norms in the .nrm file can share a single IndexInput since\n          // they are only used in a synchronized context.\n          // If this were to change in the future, a clone could be done here.\n          normInput = singleNormStream;\n        } else {\n          normInput = d.openInput(fileName, context);\n          // if the segment was created in 3.2 or after, we wrote the header for sure,\n          // and don't need to do the sketchy file size check. otherwise, we check \n          // if the size is exactly equal to maxDoc to detect a headerless file.\n          // NOTE: remove this check in Lucene 5.0!\n          String version = si.getVersion();\n          final boolean isUnversioned = \n            (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n            && normInput.length() == maxDoc();\n          if (isUnversioned) {\n            normSeek = 0;\n          } else {\n            normSeek = SegmentNorms.NORMS_HEADER.length;\n          }\n        }\n\n        norms.put(fi.name, new SegmentNorms(normInput, fi.number, normSeek, this));\n        nextNormSeek += maxDoc; // increment also if some norms are separate\n      }\n    }\n    assert singleNormStream == null || !normsInitiallyEmpty || nextNormSeek == singleNormStream.length();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"143d45d6fe43d56d1f541059577c929fc0ad27a1":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"11f75174865a8734695cd60a4093339a4e63fcbb":["143d45d6fe43d56d1f541059577c929fc0ad27a1"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["e8099eba57cdbcce07a786d4f70916be3f02e365","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["e8099eba57cdbcce07a786d4f70916be3f02e365","11f75174865a8734695cd60a4093339a4e63fcbb"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"e8099eba57cdbcce07a786d4f70916be3f02e365":["ddc4c914be86e34b54f70023f45a60fa7f04e929"]},"commit2Childs":{"143d45d6fe43d56d1f541059577c929fc0ad27a1":["11f75174865a8734695cd60a4093339a4e63fcbb"],"11f75174865a8734695cd60a4093339a4e63fcbb":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","5d004d0e0b3f65bb40da76d476d659d7888270e8","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["143d45d6fe43d56d1f541059577c929fc0ad27a1","5d004d0e0b3f65bb40da76d476d659d7888270e8","e8099eba57cdbcce07a786d4f70916be3f02e365"],"e8099eba57cdbcce07a786d4f70916be3f02e365":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}