{"path":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","bugFix":null,"bugIntro":["d743dbdc40bef0a47a5d54d99623ef0c2eb5923e","02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","bugFix":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d743dbdc40bef0a47a5d54d99623ef0c2eb5923e","date":1344896544,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","bugFix":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.getTopReaderContext().leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0e3c1c21aac8ecf75706605133012833585c7","date":1347535263,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,Term).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, Term term) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.leaves()) {\n      AtomicReader r = ctx.reader();\n      if (!r.hasDeletions()) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(term);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(term);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    long totalTF = 0L;\n    for (final AtomicReaderContext ctx : reader.leaves()) {\n      AtomicReader r = ctx.reader();\n      Bits liveDocs = r.getLiveDocs();\n      if (liveDocs == null) {\n        // TODO: we could do this up front, during the scan\n        // (next()), instead of after-the-fact here w/ seek,\n        // if the codec supports it and there are no del\n        // docs...\n        final long totTF = r.totalTermFreq(field, termText);\n        if (totTF != -1) {\n          totalTF += totTF;\n          continue;\n        } // otherwise we fall-through\n      }\n      // note: what should we do if field omits freqs? currently it counts as 1...\n      DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n      if (de != null) {\n        while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n          totalTF += de.freq();\n      }\n    }\n    \n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"b6a0e3c1c21aac8ecf75706605133012833585c7":["d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"d743dbdc40bef0a47a5d54d99623ef0c2eb5923e":["02331260bb246364779cb6f04919ca47900d01bb"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["d6f074e73200c07d54f242d3880a8da5a35ff97b","d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b6a0e3c1c21aac8ecf75706605133012833585c7"],"02331260bb246364779cb6f04919ca47900d01bb":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"b6a0e3c1c21aac8ecf75706605133012833585c7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"d743dbdc40bef0a47a5d54d99623ef0c2eb5923e":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","b6a0e3c1c21aac8ecf75706605133012833585c7","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"02331260bb246364779cb6f04919ca47900d01bb":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}