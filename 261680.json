{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","commits":[{"id":"6e6076d5869e894e98558285d9c9be9179d93921","date":1404559951,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"/dev/null","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer(TEST_VERSION_CURRENT);\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer(TEST_VERSION_CURRENT);\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff4227bb146f97aabae888091c19e48c88dbb0db","date":1406758576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","sourceOld":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer(TEST_VERSION_CURRENT);\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer(TEST_VERSION_CURRENT);\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cdab62f058ea765dd33deb05b4f19b7d626c801","date":1406803479,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer(TEST_VERSION_CURRENT);\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer(TEST_VERSION_CURRENT);\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","sourceOld":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","sourceOld":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer(TEST_VERSION_CURRENT);\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer(TEST_VERSION_CURRENT);\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n    IOUtils.close(wrapper3, wrapper2, wrapper1, specialAnalyzer, defaultAnalyzer);\n  }\n\n","sourceOld":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n    IOUtils.close(wrapper3, wrapper2, wrapper1, specialAnalyzer, defaultAnalyzer);\n  }\n\n","sourceOld":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e859719dc778fb66d3d21e7be08cd408fc2bde98","date":1446717611,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n    IOUtils.close(wrapper3, wrapper2, wrapper1, specialAnalyzer, defaultAnalyzer);\n  }\n\n","sourceOld":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        try {\n          assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        } catch (IOException e) {\n          Rethrow.rethrow(e);\n        }\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n    IOUtils.close(wrapper3, wrapper2, wrapper1, specialAnalyzer, defaultAnalyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0863fceed0d2c2aa8e5b2a14268cf9eacd44ee4f","date":1513697302,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    ts3 = wrapper1.tokenStream(\"somethingElse\", text);\n    assertSame(ts1, ts2);\n    assertSame(ts2, ts3);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n    IOUtils.close(wrapper3, wrapper2, wrapper1, specialAnalyzer, defaultAnalyzer);\n  }\n\n","sourceOld":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    assertSame(ts1, ts2);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n    IOUtils.close(wrapper3, wrapper2, wrapper1, specialAnalyzer, defaultAnalyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fac252ef8e3d0bbff9303ffbf675e824a729dfaf","date":1537347776,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper#testReuseWrapped().mjava","sourceNew":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    ts3 = wrapper1.tokenStream(\"somethingElse\", text);\n    assertSame(ts1, ts2);\n    assertSame(ts2, ts3);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getSource(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n    IOUtils.close(wrapper3, wrapper2, wrapper1, specialAnalyzer, defaultAnalyzer);\n  }\n\n","sourceOld":"  public void testReuseWrapped() throws Exception {\n    final String text = \"Qwerty\";\n\n    final Analyzer specialAnalyzer = new SimpleAnalyzer();\n    final Analyzer defaultAnalyzer = new WhitespaceAnalyzer();\n\n    TokenStream ts1, ts2, ts3, ts4;\n\n    final PerFieldAnalyzerWrapper wrapper1 = new PerFieldAnalyzerWrapper(defaultAnalyzer,\n        Collections.<String,Analyzer>singletonMap(\"special\", specialAnalyzer));\n\n    // test that the PerFieldWrapper returns the same instance as original Analyzer:\n    ts1 = defaultAnalyzer.tokenStream(\"something\", text);\n    ts2 = wrapper1.tokenStream(\"something\", text);\n    ts3 = wrapper1.tokenStream(\"somethingElse\", text);\n    assertSame(ts1, ts2);\n    assertSame(ts2, ts3);\n\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n\n    // Wrap with another wrapper, which does *not* extend DelegatingAnalyzerWrapper:\n    final AnalyzerWrapper wrapper2 = new AnalyzerWrapper(wrapper1.getReuseStrategy()) {\n      @Override\n      protected Analyzer getWrappedAnalyzer(String fieldName) {\n        return wrapper1;\n      }\n\n      @Override\n      protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n        assertNotSame(specialAnalyzer.tokenStream(\"special\", text), components.getTokenStream());\n        TokenFilter filter = new ASCIIFoldingFilter(components.getTokenStream());\n        return new TokenStreamComponents(components.getTokenizer(), filter);\n      }\n    };\n    ts3 = wrapper2.tokenStream(\"special\", text);\n    assertNotSame(ts1, ts3);\n    assertTrue(ts3 instanceof ASCIIFoldingFilter);\n    // check that cache did not get corrumpted:\n    ts2 = wrapper1.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    \n    // Wrap PerField with another PerField. In that case all TokenStreams returned must be the same:\n    final PerFieldAnalyzerWrapper wrapper3 = new PerFieldAnalyzerWrapper(wrapper1,\n        Collections.<String,Analyzer>singletonMap(\"moreSpecial\", specialAnalyzer));\n    ts1 = specialAnalyzer.tokenStream(\"special\", text);\n    ts2 = wrapper3.tokenStream(\"special\", text);\n    assertSame(ts1, ts2);\n    ts3 = specialAnalyzer.tokenStream(\"moreSpecial\", text);\n    ts4 = wrapper3.tokenStream(\"moreSpecial\", text);\n    assertSame(ts3, ts4);\n    assertSame(ts2, ts3);\n    IOUtils.close(wrapper3, wrapper2, wrapper1, specialAnalyzer, defaultAnalyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["6e6076d5869e894e98558285d9c9be9179d93921"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["379db3ad24c4f0214f30a122265a6d6be003a99d","a56958d7f71a28824f20031ffbb2e13502a0274e"],"6e6076d5869e894e98558285d9c9be9179d93921":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fac252ef8e3d0bbff9303ffbf675e824a729dfaf":["0863fceed0d2c2aa8e5b2a14268cf9eacd44ee4f"],"0863fceed0d2c2aa8e5b2a14268cf9eacd44ee4f":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a56958d7f71a28824f20031ffbb2e13502a0274e":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fac252ef8e3d0bbff9303ffbf675e824a729dfaf"]},"commit2Childs":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"6e6076d5869e894e98558285d9c9be9179d93921":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"fac252ef8e3d0bbff9303ffbf675e824a729dfaf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6e6076d5869e894e98558285d9c9be9179d93921"],"0863fceed0d2c2aa8e5b2a14268cf9eacd44ee4f":["fac252ef8e3d0bbff9303ffbf675e824a729dfaf"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","e859719dc778fb66d3d21e7be08cd408fc2bde98"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["0863fceed0d2c2aa8e5b2a14268cf9eacd44ee4f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}