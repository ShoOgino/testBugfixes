{"path":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"/dev/null","sourceNew":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":null,"sourceOld":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"/dev/null","sourceNew":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd04250707c52f2a0cecd6303dcc85617b122f6d","date":1304372426,"type":5,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":null,"sourceOld":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1da8d55113b689b06716246649de6f62430f15c0","dd04250707c52f2a0cecd6303dcc85617b122f6d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["1da8d55113b689b06716246649de6f62430f15c0","dd04250707c52f2a0cecd6303dcc85617b122f6d"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"dd04250707c52f2a0cecd6303dcc85617b122f6d":["1da8d55113b689b06716246649de6f62430f15c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dd04250707c52f2a0cecd6303dcc85617b122f6d"]},"commit2Childs":{"1da8d55113b689b06716246649de6f62430f15c0":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","dd04250707c52f2a0cecd6303dcc85617b122f6d"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"dd04250707c52f2a0cecd6303dcc85617b122f6d":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}