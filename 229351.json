{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#finish(IndexOutput,IndexOutput,IndexOutput).mjava","commits":[{"id":"78e689a3b60e84c75dc6dd7b181a71fc19ef8482","date":1591689554,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#finish(IndexOutput,IndexOutput,IndexOutput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#finish(IndexOutput).mjava","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput}s and returns a {@link Runnable} that\n   *  writes the index of the tree if at least one point has been added, or {@code null} otherwise. */\n  public Runnable finish(IndexOutput metaOut, IndexOutput indexOut, IndexOutput dataOut) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (pointCount == 0) {\n      return null;\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n    final int numLeaves = Math.toIntExact((pointCount + maxPointsInLeafNode - 1) / maxPointsInLeafNode);\n    final int numSplits = numLeaves - 1;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numSplits*bytesPerDim)];\n    byte[] splitDimensionValues = new byte[numSplits];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, numIndexDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    final long dataStartFP = dataOut.getFilePointer();\n    boolean success = false;\n    try {\n\n      final int[] parentSplits = new int[numIndexDims];\n      build(0, numLeaves, points,\n             dataOut, radixSelector,\n            minPackedValue.clone(), maxPackedValue.clone(),\n            parentSplits,\n            splitPackedValues,\n            splitDimensionValues,\n            leafBlockFPs,\n            new int[maxPointsInLeafNode]);\n      assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    scratchBytesRef1.bytes = splitPackedValues;\n    scratchBytesRef1.length = bytesPerDim;\n    BKDTreeLeafNodes leafNodes  = new BKDTreeLeafNodes() {\n      @Override\n      public long getLeafLP(int index) {\n        return leafBlockFPs[index];\n      }\n\n      @Override\n      public BytesRef getSplitValue(int index) {\n        scratchBytesRef1.offset = index * bytesPerDim;\n        return scratchBytesRef1;\n      }\n\n      @Override\n      public int getSplitDimension(int index) {\n        return splitDimensionValues[index] & 0xff;\n      }\n\n      @Override\n      public int numLeaves() {\n        return leafBlockFPs.length;\n      }\n    };\n\n    return () -> {\n      // Write index:\n      try {\n        writeIndex(metaOut, indexOut, maxPointsInLeafNode, leafNodes, dataStartFP);\n      } catch (IOException e) {\n        throw new UncheckedIOException(e);\n      }\n    };\n  }\n\n","sourceOld":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n    final int numLeaves = Math.toIntExact((pointCount + maxPointsInLeafNode - 1) / maxPointsInLeafNode);\n    final int numSplits = numLeaves - 1;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numSplits*bytesPerDim)];\n    byte[] splitDimensionValues = new byte[numSplits];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, numIndexDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n      final int[] parentSplits = new int[numIndexDims];\n      build(0, numLeaves, points,\n             out, radixSelector,\n            minPackedValue.clone(), maxPackedValue.clone(),\n            parentSplits,\n            splitPackedValues,\n            splitDimensionValues,\n            leafBlockFPs,\n            new int[maxPointsInLeafNode]);\n      assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    scratchBytesRef1.bytes = splitPackedValues;\n    scratchBytesRef1.length = bytesPerDim;\n    BKDTreeLeafNodes leafNodes  = new BKDTreeLeafNodes() {\n      @Override\n      public long getLeafLP(int index) {\n        return leafBlockFPs[index];\n      }\n\n      @Override\n      public BytesRef getSplitValue(int index) {\n        scratchBytesRef1.offset = index * bytesPerDim;\n        return scratchBytesRef1;\n      }\n\n      @Override\n      public int getSplitDimension(int index) {\n        return splitDimensionValues[index] & 0xff;\n      }\n\n      @Override\n      public int numLeaves() {\n        return leafBlockFPs.length;\n      }\n    };\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, maxPointsInLeafNode, leafNodes);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb94bf667d51f9c390c99d97afb36b7caab6b6e9","date":1599548621,"type":3,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#finish(IndexOutput,IndexOutput,IndexOutput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#finish(IndexOutput,IndexOutput,IndexOutput).mjava","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput}s and returns a {@link Runnable} that\n   *  writes the index of the tree if at least one point has been added, or {@code null} otherwise. */\n  public Runnable finish(IndexOutput metaOut, IndexOutput indexOut, IndexOutput dataOut) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (pointCount == 0) {\n      return null;\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n    final int numLeaves = Math.toIntExact((pointCount + config.maxPointsInLeafNode - 1) / config.maxPointsInLeafNode);\n    final int numSplits = numLeaves - 1;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numSplits*config.bytesPerDim)];\n    byte[] splitDimensionValues = new byte[numSplits];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= config.maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" config.maxPointsInLeafNode=\" + config.maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(config, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    final long dataStartFP = dataOut.getFilePointer();\n    boolean success = false;\n    try {\n\n      final int[] parentSplits = new int[config.numIndexDims];\n      build(0, numLeaves, points,\n             dataOut, radixSelector,\n            minPackedValue.clone(), maxPackedValue.clone(),\n            parentSplits,\n            splitPackedValues,\n            splitDimensionValues,\n            leafBlockFPs,\n            new int[config.maxPointsInLeafNode]);\n      assert Arrays.equals(parentSplits, new int[config.numIndexDims]);\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    scratchBytesRef1.bytes = splitPackedValues;\n    scratchBytesRef1.length = config.bytesPerDim;\n    BKDTreeLeafNodes leafNodes  = new BKDTreeLeafNodes() {\n      @Override\n      public long getLeafLP(int index) {\n        return leafBlockFPs[index];\n      }\n\n      @Override\n      public BytesRef getSplitValue(int index) {\n        scratchBytesRef1.offset = index * config.bytesPerDim;\n        return scratchBytesRef1;\n      }\n\n      @Override\n      public int getSplitDimension(int index) {\n        return splitDimensionValues[index] & 0xff;\n      }\n\n      @Override\n      public int numLeaves() {\n        return leafBlockFPs.length;\n      }\n    };\n\n    return () -> {\n      // Write index:\n      try {\n        writeIndex(metaOut, indexOut, config.maxPointsInLeafNode, leafNodes, dataStartFP);\n      } catch (IOException e) {\n        throw new UncheckedIOException(e);\n      }\n    };\n  }\n\n","sourceOld":"  /** Writes the BKD tree to the provided {@link IndexOutput}s and returns a {@link Runnable} that\n   *  writes the index of the tree if at least one point has been added, or {@code null} otherwise. */\n  public Runnable finish(IndexOutput metaOut, IndexOutput indexOut, IndexOutput dataOut) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (pointCount == 0) {\n      return null;\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n    final int numLeaves = Math.toIntExact((pointCount + maxPointsInLeafNode - 1) / maxPointsInLeafNode);\n    final int numSplits = numLeaves - 1;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numSplits*bytesPerDim)];\n    byte[] splitDimensionValues = new byte[numSplits];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, numIndexDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    final long dataStartFP = dataOut.getFilePointer();\n    boolean success = false;\n    try {\n\n      final int[] parentSplits = new int[numIndexDims];\n      build(0, numLeaves, points,\n             dataOut, radixSelector,\n            minPackedValue.clone(), maxPackedValue.clone(),\n            parentSplits,\n            splitPackedValues,\n            splitDimensionValues,\n            leafBlockFPs,\n            new int[maxPointsInLeafNode]);\n      assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    scratchBytesRef1.bytes = splitPackedValues;\n    scratchBytesRef1.length = bytesPerDim;\n    BKDTreeLeafNodes leafNodes  = new BKDTreeLeafNodes() {\n      @Override\n      public long getLeafLP(int index) {\n        return leafBlockFPs[index];\n      }\n\n      @Override\n      public BytesRef getSplitValue(int index) {\n        scratchBytesRef1.offset = index * bytesPerDim;\n        return scratchBytesRef1;\n      }\n\n      @Override\n      public int getSplitDimension(int index) {\n        return splitDimensionValues[index] & 0xff;\n      }\n\n      @Override\n      public int numLeaves() {\n        return leafBlockFPs.length;\n      }\n    };\n\n    return () -> {\n      // Write index:\n      try {\n        writeIndex(metaOut, indexOut, maxPointsInLeafNode, leafNodes, dataStartFP);\n      } catch (IOException e) {\n        throw new UncheckedIOException(e);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bb94bf667d51f9c390c99d97afb36b7caab6b6e9":["78e689a3b60e84c75dc6dd7b181a71fc19ef8482"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"78e689a3b60e84c75dc6dd7b181a71fc19ef8482":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb94bf667d51f9c390c99d97afb36b7caab6b6e9"]},"commit2Childs":{"bb94bf667d51f9c390c99d97afb36b7caab6b6e9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["78e689a3b60e84c75dc6dd7b181a71fc19ef8482"],"78e689a3b60e84c75dc6dd7b181a71fc19ef8482":["bb94bf667d51f9c390c99d97afb36b7caab6b6e9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}