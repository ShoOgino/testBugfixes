{"path":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","commits":[{"id":"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793","date":1408030244,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int).mjava","sourceNew":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestSortedVsStoredFields(int minLength, int maxLength) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = r.getSortedDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        BytesRef scratch = docValues.get(i);\n        assertEquals(binaryValue, scratch);\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11134e449dabe11d6d0ff6a564d84b82cbe93722","date":1477299083,"type":6,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestBinaryVsStoredFields(double,Supplier[byte[]]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  private void doTestBinaryVsStoredFields(double density, Supplier<byte[]> bytes) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new BinaryDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      byte[] buffer = bytes.get();\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    \n    // compare again\n    writer.forceMerge(1);\n    ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11134e449dabe11d6d0ff6a564d84b82cbe93722","date":1477299083,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,double,Supplier[byte[]]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  protected void doTestSortedVsStoredFields(int numDocs, double density, Supplier<byte[]> bytes) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      byte[] buffer = bytes.get();\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2714c85633b642b29871cf5ff8d17d3ba7bfd76","date":1477307753,"type":6,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestBinaryVsStoredFields(double,Supplier[byte[]]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  private void doTestBinaryVsStoredFields(double density, Supplier<byte[]> bytes) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new BinaryDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      byte[] buffer = bytes.get();\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    \n    // compare again\n    writer.forceMerge(1);\n    ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2714c85633b642b29871cf5ff8d17d3ba7bfd76","date":1477307753,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,double,Supplier[byte[]]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  protected void doTestSortedVsStoredFields(int numDocs, double density, Supplier<byte[]> bytes) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      byte[] buffer = bytes.get();\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":6,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestBinaryVsStoredFields(double,Supplier[byte[]]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  private void doTestBinaryVsStoredFields(double density, Supplier<byte[]> bytes) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new BinaryDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      byte[] buffer = bytes.get();\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    \n    // compare again\n    writer.forceMerge(1);\n    ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":5,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,double,Supplier[byte[]]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestSortedVsStoredFields(int,int,int).mjava","sourceNew":"  protected void doTestSortedVsStoredFields(int numDocs, double density, Supplier<byte[]> bytes) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      byte[] buffer = bytes.get();\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        if (binaryValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(binaryValue, docValues.binaryValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  protected void doTestSortedVsStoredFields(int numDocs, int minLength, int maxLength) throws Exception {\n    Directory dir = newFSDirectory(createTempDir(\"dvduel\"));\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = new StoredField(\"stored\", new byte[0]);\n    Field dvField = new SortedDocValuesField(\"dv\", new BytesRef());\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      final int length;\n      if (minLength == maxLength) {\n        length = minLength; // fixed length\n      } else {\n        length = TestUtil.nextInt(random(), minLength, maxLength);\n      }\n      byte buffer[] = new byte[length];\n      random().nextBytes(buffer);\n      storedField.setBytesValue(buffer);\n      dvField.setBytesValue(buffer);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    // compare\n    DirectoryReader ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.forceMerge(1);\n    \n    // compare again\n    ir = writer.getReader();\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      BinaryDocValues docValues = DocValues.getBinary(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        BytesRef binaryValue = r.document(i).getBinaryValue(\"stored\");\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(binaryValue, docValues.binaryValue());\n      }\n    }\n    ir.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"11134e449dabe11d6d0ff6a564d84b82cbe93722":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["c9fb5f46e264daf5ba3860defe623a89d202dd87","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d2714c85633b642b29871cf5ff8d17d3ba7bfd76"],"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d2714c85633b642b29871cf5ff8d17d3ba7bfd76":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","11134e449dabe11d6d0ff6a564d84b82cbe93722"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["c9fb5f46e264daf5ba3860defe623a89d202dd87","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d2714c85633b642b29871cf5ff8d17d3ba7bfd76"]},"commit2Childs":{"11134e449dabe11d6d0ff6a564d84b82cbe93722":["d2714c85633b642b29871cf5ff8d17d3ba7bfd76"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["11134e449dabe11d6d0ff6a564d84b82cbe93722","d2714c85633b642b29871cf5ff8d17d3ba7bfd76","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":[],"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"d2714c85633b642b29871cf5ff8d17d3ba7bfd76":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}