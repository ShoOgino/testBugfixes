{"path":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","commits":[{"id":"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87","date":1328967626,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n      doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\"));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.storeTermVector) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n      doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\"));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.storeTermVector) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n      doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\"));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.storeTermVector) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"76923f6a33f2c4bec7f584e3f251261afe7ea276","date":1337149711,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n      doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\"));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n      doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\"));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.storeTermVector) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n      doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\"));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n      doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\"));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.storeTermVector) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n      doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\"));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\"));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<String>();\n      Collection<String> indexedFieldNames = new HashSet<String>();\n      Collection<String> notIndexedFieldNames = new HashSet<String>();\n      Collection<String> tvFieldNames = new HashSet<String>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.shutdown();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.shutdown();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.shutdown();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.shutdown();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.shutdown();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n              setOpenMode(OpenMode.APPEND).\n              setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.shutdown();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.shutdown();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.shutdown();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"556a4aab886d75371b2af129d87be3c2795cea76","date":1414954991,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.isIndexed()) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"34d6426cef006e0c3625cabe7a7ec1c2b08bc501","date":1454683374,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         );\n\n    Document doc = new Document();\n\n    FieldType customType3 = new FieldType();\n    customType3.setStored(true);\n      \n    doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n    doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n    doc.add(new Field(\"unindexed\", \"test1\", customType3));\n    doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n    writer.addDocument(doc);\n\n    writer.close();\n    // set up reader\n    DirectoryReader reader = DirectoryReader.open(d);\n    FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n    assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n    assertNotNull(fieldInfos.fieldInfo(\"text\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n    reader.close();\n    // add more documents\n    writer = new IndexWriter(\n                             d,\n                             newIndexWriterConfig(new MockAnalyzer(random()))\n                             .setOpenMode(OpenMode.APPEND)\n                             .setMergePolicy(newLogMergePolicy())\n                             );\n    // want to get some more segments here\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new fields are in some different segments (we hope)\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new termvector fields\n\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n      \n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"termvector\", customType5));\n      doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n      doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n      writer.addDocument(doc);\n    }\n      \n    writer.close();\n\n    // verify fields again\n    reader = DirectoryReader.open(d);\n    fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n    Collection<String> allFieldNames = new HashSet<>();\n    Collection<String> indexedFieldNames = new HashSet<>();\n    Collection<String> notIndexedFieldNames = new HashSet<>();\n    Collection<String> tvFieldNames = new HashSet<>();\n\n    for(FieldInfo fieldInfo : fieldInfos) {\n      final String name = fieldInfo.name;\n      allFieldNames.add(name);\n      if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n        indexedFieldNames.add(name);\n      } else {\n        notIndexedFieldNames.add(name);\n      }\n      if (fieldInfo.hasVectors()) {\n        tvFieldNames.add(name);\n      }\n    }\n\n    assertTrue(allFieldNames.contains(\"keyword\"));\n    assertTrue(allFieldNames.contains(\"text\"));\n    assertTrue(allFieldNames.contains(\"unindexed\"));\n    assertTrue(allFieldNames.contains(\"unstored\"));\n    assertTrue(allFieldNames.contains(\"keyword2\"));\n    assertTrue(allFieldNames.contains(\"text2\"));\n    assertTrue(allFieldNames.contains(\"unindexed2\"));\n    assertTrue(allFieldNames.contains(\"unstored2\"));\n    assertTrue(allFieldNames.contains(\"tvnot\"));\n    assertTrue(allFieldNames.contains(\"termvector\"));\n    assertTrue(allFieldNames.contains(\"tvposition\"));\n    assertTrue(allFieldNames.contains(\"tvoffset\"));\n    assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only indexed fields were returned\n    assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n    assertTrue(indexedFieldNames.contains(\"keyword\"));\n    assertTrue(indexedFieldNames.contains(\"text\"));\n    assertTrue(indexedFieldNames.contains(\"unstored\"));\n    assertTrue(indexedFieldNames.contains(\"keyword2\"));\n    assertTrue(indexedFieldNames.contains(\"text2\"));\n    assertTrue(indexedFieldNames.contains(\"unstored2\"));\n    assertTrue(indexedFieldNames.contains(\"tvnot\"));\n    assertTrue(indexedFieldNames.contains(\"termvector\"));\n    assertTrue(indexedFieldNames.contains(\"tvposition\"));\n    assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n    assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only unindexed fields were returned\n    assertEquals(2, notIndexedFieldNames.size());    // the following fields\n    assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n    assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n    // verify index term vector fields  \n    assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n    assertTrue(tvFieldNames.contains(\"termvector\"));\n\n    reader.close();\n    d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         );\n\n    Document doc = new Document();\n\n    FieldType customType3 = new FieldType();\n    customType3.setStored(true);\n      \n    doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n    doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n    doc.add(new Field(\"unindexed\", \"test1\", customType3));\n    doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n    writer.addDocument(doc);\n\n    writer.close();\n    // set up reader\n    DirectoryReader reader = DirectoryReader.open(d);\n    FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n    assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n    assertNotNull(fieldInfos.fieldInfo(\"text\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n    reader.close();\n    // add more documents\n    writer = new IndexWriter(\n                             d,\n                             newIndexWriterConfig(new MockAnalyzer(random()))\n                             .setOpenMode(OpenMode.APPEND)\n                             .setMergePolicy(newLogMergePolicy())\n                             );\n    // want to get some more segments here\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new fields are in some different segments (we hope)\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new termvector fields\n\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n      \n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"termvector\", customType5));\n      doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n      doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n      writer.addDocument(doc);\n    }\n      \n    writer.close();\n\n    // verify fields again\n    reader = DirectoryReader.open(d);\n    fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n    Collection<String> allFieldNames = new HashSet<>();\n    Collection<String> indexedFieldNames = new HashSet<>();\n    Collection<String> notIndexedFieldNames = new HashSet<>();\n    Collection<String> tvFieldNames = new HashSet<>();\n\n    for(FieldInfo fieldInfo : fieldInfos) {\n      final String name = fieldInfo.name;\n      allFieldNames.add(name);\n      if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n        indexedFieldNames.add(name);\n      } else {\n        notIndexedFieldNames.add(name);\n      }\n      if (fieldInfo.hasVectors()) {\n        tvFieldNames.add(name);\n      }\n    }\n\n    assertTrue(allFieldNames.contains(\"keyword\"));\n    assertTrue(allFieldNames.contains(\"text\"));\n    assertTrue(allFieldNames.contains(\"unindexed\"));\n    assertTrue(allFieldNames.contains(\"unstored\"));\n    assertTrue(allFieldNames.contains(\"keyword2\"));\n    assertTrue(allFieldNames.contains(\"text2\"));\n    assertTrue(allFieldNames.contains(\"unindexed2\"));\n    assertTrue(allFieldNames.contains(\"unstored2\"));\n    assertTrue(allFieldNames.contains(\"tvnot\"));\n    assertTrue(allFieldNames.contains(\"termvector\"));\n    assertTrue(allFieldNames.contains(\"tvposition\"));\n    assertTrue(allFieldNames.contains(\"tvoffset\"));\n    assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only indexed fields were returned\n    assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n    assertTrue(indexedFieldNames.contains(\"keyword\"));\n    assertTrue(indexedFieldNames.contains(\"text\"));\n    assertTrue(indexedFieldNames.contains(\"unstored\"));\n    assertTrue(indexedFieldNames.contains(\"keyword2\"));\n    assertTrue(indexedFieldNames.contains(\"text2\"));\n    assertTrue(indexedFieldNames.contains(\"unstored2\"));\n    assertTrue(indexedFieldNames.contains(\"tvnot\"));\n    assertTrue(indexedFieldNames.contains(\"termvector\"));\n    assertTrue(indexedFieldNames.contains(\"tvposition\"));\n    assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n    assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only unindexed fields were returned\n    assertEquals(2, notIndexedFieldNames.size());    // the following fields\n    assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n    assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n    // verify index term vector fields  \n    assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n    assertTrue(tvFieldNames.contains(\"termvector\"));\n\n    reader.close();\n    d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         );\n\n    Document doc = new Document();\n\n    FieldType customType3 = new FieldType();\n    customType3.setStored(true);\n      \n    doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n    doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n    doc.add(new Field(\"unindexed\", \"test1\", customType3));\n    doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n    writer.addDocument(doc);\n\n    writer.close();\n    // set up reader\n    DirectoryReader reader = DirectoryReader.open(d);\n    FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n    assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n    assertNotNull(fieldInfos.fieldInfo(\"text\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n    reader.close();\n    // add more documents\n    writer = new IndexWriter(\n                             d,\n                             newIndexWriterConfig(new MockAnalyzer(random()))\n                             .setOpenMode(OpenMode.APPEND)\n                             .setMergePolicy(newLogMergePolicy())\n                             );\n    // want to get some more segments here\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new fields are in some different segments (we hope)\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new termvector fields\n\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n      \n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"termvector\", customType5));\n      doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n      doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n      writer.addDocument(doc);\n    }\n      \n    writer.close();\n\n    // verify fields again\n    reader = DirectoryReader.open(d);\n    fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n    Collection<String> allFieldNames = new HashSet<>();\n    Collection<String> indexedFieldNames = new HashSet<>();\n    Collection<String> notIndexedFieldNames = new HashSet<>();\n    Collection<String> tvFieldNames = new HashSet<>();\n\n    for(FieldInfo fieldInfo : fieldInfos) {\n      final String name = fieldInfo.name;\n      allFieldNames.add(name);\n      if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n        indexedFieldNames.add(name);\n      } else {\n        notIndexedFieldNames.add(name);\n      }\n      if (fieldInfo.hasVectors()) {\n        tvFieldNames.add(name);\n      }\n    }\n\n    assertTrue(allFieldNames.contains(\"keyword\"));\n    assertTrue(allFieldNames.contains(\"text\"));\n    assertTrue(allFieldNames.contains(\"unindexed\"));\n    assertTrue(allFieldNames.contains(\"unstored\"));\n    assertTrue(allFieldNames.contains(\"keyword2\"));\n    assertTrue(allFieldNames.contains(\"text2\"));\n    assertTrue(allFieldNames.contains(\"unindexed2\"));\n    assertTrue(allFieldNames.contains(\"unstored2\"));\n    assertTrue(allFieldNames.contains(\"tvnot\"));\n    assertTrue(allFieldNames.contains(\"termvector\"));\n    assertTrue(allFieldNames.contains(\"tvposition\"));\n    assertTrue(allFieldNames.contains(\"tvoffset\"));\n    assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only indexed fields were returned\n    assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n    assertTrue(indexedFieldNames.contains(\"keyword\"));\n    assertTrue(indexedFieldNames.contains(\"text\"));\n    assertTrue(indexedFieldNames.contains(\"unstored\"));\n    assertTrue(indexedFieldNames.contains(\"keyword2\"));\n    assertTrue(indexedFieldNames.contains(\"text2\"));\n    assertTrue(indexedFieldNames.contains(\"unstored2\"));\n    assertTrue(indexedFieldNames.contains(\"tvnot\"));\n    assertTrue(indexedFieldNames.contains(\"termvector\"));\n    assertTrue(indexedFieldNames.contains(\"tvposition\"));\n    assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n    assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only unindexed fields were returned\n    assertEquals(2, notIndexedFieldNames.size());    // the following fields\n    assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n    assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n    // verify index term vector fields  \n    assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n    assertTrue(tvFieldNames.contains(\"termvector\"));\n\n    reader.close();\n    d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         );\n\n    Document doc = new Document();\n\n    FieldType customType3 = new FieldType();\n    customType3.setStored(true);\n      \n    doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n    doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n    doc.add(new Field(\"unindexed\", \"test1\", customType3));\n    doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n    writer.addDocument(doc);\n\n    writer.close();\n    // set up reader\n    DirectoryReader reader = DirectoryReader.open(d);\n    FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n    assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n    assertNotNull(fieldInfos.fieldInfo(\"text\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n    reader.close();\n    // add more documents\n    writer = new IndexWriter(\n                             d,\n                             newIndexWriterConfig(new MockAnalyzer(random()))\n                             .setOpenMode(OpenMode.APPEND)\n                             .setMergePolicy(newLogMergePolicy())\n                             );\n    // want to get some more segments here\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new fields are in some different segments (we hope)\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new termvector fields\n\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n      \n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"termvector\", customType5));\n      doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n      doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n      writer.addDocument(doc);\n    }\n      \n    writer.close();\n\n    // verify fields again\n    reader = DirectoryReader.open(d);\n    fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n    Collection<String> allFieldNames = new HashSet<>();\n    Collection<String> indexedFieldNames = new HashSet<>();\n    Collection<String> notIndexedFieldNames = new HashSet<>();\n    Collection<String> tvFieldNames = new HashSet<>();\n\n    for(FieldInfo fieldInfo : fieldInfos) {\n      final String name = fieldInfo.name;\n      allFieldNames.add(name);\n      if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n        indexedFieldNames.add(name);\n      } else {\n        notIndexedFieldNames.add(name);\n      }\n      if (fieldInfo.hasVectors()) {\n        tvFieldNames.add(name);\n      }\n    }\n\n    assertTrue(allFieldNames.contains(\"keyword\"));\n    assertTrue(allFieldNames.contains(\"text\"));\n    assertTrue(allFieldNames.contains(\"unindexed\"));\n    assertTrue(allFieldNames.contains(\"unstored\"));\n    assertTrue(allFieldNames.contains(\"keyword2\"));\n    assertTrue(allFieldNames.contains(\"text2\"));\n    assertTrue(allFieldNames.contains(\"unindexed2\"));\n    assertTrue(allFieldNames.contains(\"unstored2\"));\n    assertTrue(allFieldNames.contains(\"tvnot\"));\n    assertTrue(allFieldNames.contains(\"termvector\"));\n    assertTrue(allFieldNames.contains(\"tvposition\"));\n    assertTrue(allFieldNames.contains(\"tvoffset\"));\n    assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only indexed fields were returned\n    assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n    assertTrue(indexedFieldNames.contains(\"keyword\"));\n    assertTrue(indexedFieldNames.contains(\"text\"));\n    assertTrue(indexedFieldNames.contains(\"unstored\"));\n    assertTrue(indexedFieldNames.contains(\"keyword2\"));\n    assertTrue(indexedFieldNames.contains(\"text2\"));\n    assertTrue(indexedFieldNames.contains(\"unstored2\"));\n    assertTrue(indexedFieldNames.contains(\"tvnot\"));\n    assertTrue(indexedFieldNames.contains(\"termvector\"));\n    assertTrue(indexedFieldNames.contains(\"tvposition\"));\n    assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n    assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only unindexed fields were returned\n    assertEquals(2, notIndexedFieldNames.size());    // the following fields\n    assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n    assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n    // verify index term vector fields  \n    assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n    assertTrue(tvFieldNames.contains(\"termvector\"));\n\n    reader.close();\n    d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n      Directory d = newDirectory();\n      // set up writer\n      IndexWriter writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n      );\n\n      Document doc = new Document();\n\n      FieldType customType3 = new FieldType();\n      customType3.setStored(true);\n      \n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n\n      writer.close();\n      // set up reader\n      DirectoryReader reader = DirectoryReader.open(d);\n      FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n      assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n      assertNotNull(fieldInfos.fieldInfo(\"text\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n      assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n      reader.close();\n      // add more documents\n      writer = new IndexWriter(\n          d,\n          newIndexWriterConfig(new MockAnalyzer(random()))\n             .setOpenMode(OpenMode.APPEND)\n             .setMergePolicy(newLogMergePolicy())\n      );\n      // want to get some more segments here\n      int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new fields are in some different segments (we hope)\n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n        doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n        doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n        writer.addDocument(doc);\n      }\n      // new termvector fields\n\n      FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n      customType5.setStoreTermVectors(true);\n      FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n      customType6.setStoreTermVectors(true);\n      customType6.setStoreTermVectorOffsets(true);\n      FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n      customType7.setStoreTermVectors(true);\n      customType7.setStoreTermVectorPositions(true);\n      FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n      customType8.setStoreTermVectors(true);\n      customType8.setStoreTermVectorOffsets(true);\n      customType8.setStoreTermVectorPositions(true);\n      \n      for (int i = 0; i < 5*mergeFactor; i++) {\n        doc = new Document();\n        doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n        doc.add(new Field(\"termvector\", \"termvector\", customType5));\n        doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n        doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n        doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n        writer.addDocument(doc);\n      }\n      \n      writer.close();\n\n      // verify fields again\n      reader = DirectoryReader.open(d);\n      fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n      Collection<String> allFieldNames = new HashSet<>();\n      Collection<String> indexedFieldNames = new HashSet<>();\n      Collection<String> notIndexedFieldNames = new HashSet<>();\n      Collection<String> tvFieldNames = new HashSet<>();\n\n      for(FieldInfo fieldInfo : fieldInfos) {\n        final String name = fieldInfo.name;\n        allFieldNames.add(name);\n        if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n          indexedFieldNames.add(name);\n        } else {\n          notIndexedFieldNames.add(name);\n        }\n        if (fieldInfo.hasVectors()) {\n          tvFieldNames.add(name);\n        }\n      }\n\n      assertTrue(allFieldNames.contains(\"keyword\"));\n      assertTrue(allFieldNames.contains(\"text\"));\n      assertTrue(allFieldNames.contains(\"unindexed\"));\n      assertTrue(allFieldNames.contains(\"unstored\"));\n      assertTrue(allFieldNames.contains(\"keyword2\"));\n      assertTrue(allFieldNames.contains(\"text2\"));\n      assertTrue(allFieldNames.contains(\"unindexed2\"));\n      assertTrue(allFieldNames.contains(\"unstored2\"));\n      assertTrue(allFieldNames.contains(\"tvnot\"));\n      assertTrue(allFieldNames.contains(\"termvector\"));\n      assertTrue(allFieldNames.contains(\"tvposition\"));\n      assertTrue(allFieldNames.contains(\"tvoffset\"));\n      assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only indexed fields were returned\n      assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n      assertTrue(indexedFieldNames.contains(\"keyword\"));\n      assertTrue(indexedFieldNames.contains(\"text\"));\n      assertTrue(indexedFieldNames.contains(\"unstored\"));\n      assertTrue(indexedFieldNames.contains(\"keyword2\"));\n      assertTrue(indexedFieldNames.contains(\"text2\"));\n      assertTrue(indexedFieldNames.contains(\"unstored2\"));\n      assertTrue(indexedFieldNames.contains(\"tvnot\"));\n      assertTrue(indexedFieldNames.contains(\"termvector\"));\n      assertTrue(indexedFieldNames.contains(\"tvposition\"));\n      assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n      assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n      // verify that only unindexed fields were returned\n      assertEquals(2, notIndexedFieldNames.size());    // the following fields\n      assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n      assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n      // verify index term vector fields  \n      assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n      assertTrue(tvFieldNames.contains(\"termvector\"));\n\n      reader.close();\n      d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testGetFieldNames().mjava","sourceNew":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         );\n\n    Document doc = new Document();\n\n    FieldType customType3 = new FieldType();\n    customType3.setStored(true);\n      \n    doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n    doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n    doc.add(new Field(\"unindexed\", \"test1\", customType3));\n    doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n    writer.addDocument(doc);\n\n    writer.close();\n    // set up reader\n    DirectoryReader reader = DirectoryReader.open(d);\n    FieldInfos fieldInfos = FieldInfos.getMergedFieldInfos(reader);\n    assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n    assertNotNull(fieldInfos.fieldInfo(\"text\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n    reader.close();\n    // add more documents\n    writer = new IndexWriter(\n                             d,\n                             newIndexWriterConfig(new MockAnalyzer(random()))\n                             .setOpenMode(OpenMode.APPEND)\n                             .setMergePolicy(newLogMergePolicy())\n                             );\n    // want to get some more segments here\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new fields are in some different segments (we hope)\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new termvector fields\n\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n      \n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"termvector\", customType5));\n      doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n      doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n      writer.addDocument(doc);\n    }\n      \n    writer.close();\n\n    // verify fields again\n    reader = DirectoryReader.open(d);\n    fieldInfos = FieldInfos.getMergedFieldInfos(reader);\n\n    Collection<String> allFieldNames = new HashSet<>();\n    Collection<String> indexedFieldNames = new HashSet<>();\n    Collection<String> notIndexedFieldNames = new HashSet<>();\n    Collection<String> tvFieldNames = new HashSet<>();\n\n    for(FieldInfo fieldInfo : fieldInfos) {\n      final String name = fieldInfo.name;\n      allFieldNames.add(name);\n      if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n        indexedFieldNames.add(name);\n      } else {\n        notIndexedFieldNames.add(name);\n      }\n      if (fieldInfo.hasVectors()) {\n        tvFieldNames.add(name);\n      }\n    }\n\n    assertTrue(allFieldNames.contains(\"keyword\"));\n    assertTrue(allFieldNames.contains(\"text\"));\n    assertTrue(allFieldNames.contains(\"unindexed\"));\n    assertTrue(allFieldNames.contains(\"unstored\"));\n    assertTrue(allFieldNames.contains(\"keyword2\"));\n    assertTrue(allFieldNames.contains(\"text2\"));\n    assertTrue(allFieldNames.contains(\"unindexed2\"));\n    assertTrue(allFieldNames.contains(\"unstored2\"));\n    assertTrue(allFieldNames.contains(\"tvnot\"));\n    assertTrue(allFieldNames.contains(\"termvector\"));\n    assertTrue(allFieldNames.contains(\"tvposition\"));\n    assertTrue(allFieldNames.contains(\"tvoffset\"));\n    assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only indexed fields were returned\n    assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n    assertTrue(indexedFieldNames.contains(\"keyword\"));\n    assertTrue(indexedFieldNames.contains(\"text\"));\n    assertTrue(indexedFieldNames.contains(\"unstored\"));\n    assertTrue(indexedFieldNames.contains(\"keyword2\"));\n    assertTrue(indexedFieldNames.contains(\"text2\"));\n    assertTrue(indexedFieldNames.contains(\"unstored2\"));\n    assertTrue(indexedFieldNames.contains(\"tvnot\"));\n    assertTrue(indexedFieldNames.contains(\"termvector\"));\n    assertTrue(indexedFieldNames.contains(\"tvposition\"));\n    assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n    assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only unindexed fields were returned\n    assertEquals(2, notIndexedFieldNames.size());    // the following fields\n    assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n    assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n    // verify index term vector fields  \n    assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n    assertTrue(tvFieldNames.contains(\"termvector\"));\n\n    reader.close();\n    d.close();\n  }\n\n","sourceOld":"  /**\n   * Tests the IndexReader.getFieldNames implementation\n   * @throws Exception on error\n   */\n  public void testGetFieldNames() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         );\n\n    Document doc = new Document();\n\n    FieldType customType3 = new FieldType();\n    customType3.setStored(true);\n      \n    doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n    doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n    doc.add(new Field(\"unindexed\", \"test1\", customType3));\n    doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n    writer.addDocument(doc);\n\n    writer.close();\n    // set up reader\n    DirectoryReader reader = DirectoryReader.open(d);\n    FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n    assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n    assertNotNull(fieldInfos.fieldInfo(\"text\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n    assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n    reader.close();\n    // add more documents\n    writer = new IndexWriter(\n                             d,\n                             newIndexWriterConfig(new MockAnalyzer(random()))\n                             .setOpenMode(OpenMode.APPEND)\n                             .setMergePolicy(newLogMergePolicy())\n                             );\n    // want to get some more segments here\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new fields are in some different segments (we hope)\n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new StringField(\"keyword2\", \"test1\", Field.Store.YES));\n      doc.add(new TextField(\"text2\", \"test1\", Field.Store.YES));\n      doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n      doc.add(new TextField(\"unstored2\",\"test1\", Field.Store.NO));\n      writer.addDocument(doc);\n    }\n    // new termvector fields\n\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n      \n    for (int i = 0; i < 5*mergeFactor; i++) {\n      doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"tvnot\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"termvector\", customType5));\n      doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n      doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n      writer.addDocument(doc);\n    }\n      \n    writer.close();\n\n    // verify fields again\n    reader = DirectoryReader.open(d);\n    fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n    Collection<String> allFieldNames = new HashSet<>();\n    Collection<String> indexedFieldNames = new HashSet<>();\n    Collection<String> notIndexedFieldNames = new HashSet<>();\n    Collection<String> tvFieldNames = new HashSet<>();\n\n    for(FieldInfo fieldInfo : fieldInfos) {\n      final String name = fieldInfo.name;\n      allFieldNames.add(name);\n      if (fieldInfo.getIndexOptions() != IndexOptions.NONE) {\n        indexedFieldNames.add(name);\n      } else {\n        notIndexedFieldNames.add(name);\n      }\n      if (fieldInfo.hasVectors()) {\n        tvFieldNames.add(name);\n      }\n    }\n\n    assertTrue(allFieldNames.contains(\"keyword\"));\n    assertTrue(allFieldNames.contains(\"text\"));\n    assertTrue(allFieldNames.contains(\"unindexed\"));\n    assertTrue(allFieldNames.contains(\"unstored\"));\n    assertTrue(allFieldNames.contains(\"keyword2\"));\n    assertTrue(allFieldNames.contains(\"text2\"));\n    assertTrue(allFieldNames.contains(\"unindexed2\"));\n    assertTrue(allFieldNames.contains(\"unstored2\"));\n    assertTrue(allFieldNames.contains(\"tvnot\"));\n    assertTrue(allFieldNames.contains(\"termvector\"));\n    assertTrue(allFieldNames.contains(\"tvposition\"));\n    assertTrue(allFieldNames.contains(\"tvoffset\"));\n    assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only indexed fields were returned\n    assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n    assertTrue(indexedFieldNames.contains(\"keyword\"));\n    assertTrue(indexedFieldNames.contains(\"text\"));\n    assertTrue(indexedFieldNames.contains(\"unstored\"));\n    assertTrue(indexedFieldNames.contains(\"keyword2\"));\n    assertTrue(indexedFieldNames.contains(\"text2\"));\n    assertTrue(indexedFieldNames.contains(\"unstored2\"));\n    assertTrue(indexedFieldNames.contains(\"tvnot\"));\n    assertTrue(indexedFieldNames.contains(\"termvector\"));\n    assertTrue(indexedFieldNames.contains(\"tvposition\"));\n    assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n    assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n      \n    // verify that only unindexed fields were returned\n    assertEquals(2, notIndexedFieldNames.size());    // the following fields\n    assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n    assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n              \n    // verify index term vector fields  \n    assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n    assertTrue(tvFieldNames.contains(\"termvector\"));\n\n    reader.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"34d6426cef006e0c3625cabe7a7ec1c2b08bc501":["556a4aab886d75371b2af129d87be3c2795cea76"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5a207d19eac354d649c3f0e2cce070017c78125e":["556a4aab886d75371b2af129d87be3c2795cea76","b470f36a9372c97283360b1304eacbde22df6c0d"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["556a4aab886d75371b2af129d87be3c2795cea76","b470f36a9372c97283360b1304eacbde22df6c0d"],"556a4aab886d75371b2af129d87be3c2795cea76":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","76923f6a33f2c4bec7f584e3f251261afe7ea276"],"b470f36a9372c97283360b1304eacbde22df6c0d":["556a4aab886d75371b2af129d87be3c2795cea76","34d6426cef006e0c3625cabe7a7ec1c2b08bc501"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["5a207d19eac354d649c3f0e2cce070017c78125e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["04e775de416dd2d8067b10db1c8af975a1d5017e"]},"commit2Childs":{"34d6426cef006e0c3625cabe7a7ec1c2b08bc501":["b470f36a9372c97283360b1304eacbde22df6c0d"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5a207d19eac354d649c3f0e2cce070017c78125e":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"556a4aab886d75371b2af129d87be3c2795cea76":["34d6426cef006e0c3625cabe7a7ec1c2b08bc501","5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3","b470f36a9372c97283360b1304eacbde22df6c0d"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["556a4aab886d75371b2af129d87be3c2795cea76"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["76923f6a33f2c4bec7f584e3f251261afe7ea276","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}