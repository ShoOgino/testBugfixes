{"path":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,float,TokenStream,String,IndexReader).mjava","commits":[{"id":"2dfdf766e55e943d942055d7de53c7ad6bc45283","date":1441632886,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,float,TokenStream,String,IndexReader).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException If there is a low-level I/O error\n   */\n  public Map<String,WeightedSpanTerm> getWeightedSpanTermsWithScores(Query query, float boost, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = fieldName;\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map<String,WeightedSpanTerm> terms = new PositionCheckingMap<>();\n    extract(query, boost, terms);\n\n    int totalNumDocs = reader.maxDoc();\n    Set<String> weightedTerms = terms.keySet();\n    Iterator<String> it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log(totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n      IOUtils.close(internalReader);\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException If there is a low-level I/O error\n   */\n  public Map<String,WeightedSpanTerm> getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = fieldName;\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map<String,WeightedSpanTerm> terms = new PositionCheckingMap<>();\n    extract(query, terms);\n\n    int totalNumDocs = reader.maxDoc();\n    Set<String> weightedTerms = terms.keySet();\n    Iterator<String> it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log(totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n      IOUtils.close(internalReader);\n    }\n\n    return terms;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81d0720146de53dd3a4a023d2a3d1089d86d748d","date":1442268215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,float,TokenStream,String,IndexReader).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,float,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException If there is a low-level I/O error\n   */\n  public Map<String,WeightedSpanTerm> getWeightedSpanTermsWithScores(Query query, float boost, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = fieldName;\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map<String,WeightedSpanTerm> terms = new PositionCheckingMap<>();\n    extract(query, boost, terms);\n\n    int totalNumDocs = reader.maxDoc();\n    Set<String> weightedTerms = terms.keySet();\n    Iterator<String> it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // IDF algorithm taken from ClassicSimilarity class\n        float idf = (float) (Math.log(totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n      IOUtils.close(internalReader);\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException If there is a low-level I/O error\n   */\n  public Map<String,WeightedSpanTerm> getWeightedSpanTermsWithScores(Query query, float boost, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = fieldName;\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map<String,WeightedSpanTerm> terms = new PositionCheckingMap<>();\n    extract(query, boost, terms);\n\n    int totalNumDocs = reader.maxDoc();\n    Set<String> weightedTerms = terms.keySet();\n    Iterator<String> it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log(totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n      IOUtils.close(internalReader);\n    }\n\n    return terms;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"81d0720146de53dd3a4a023d2a3d1089d86d748d":["2dfdf766e55e943d942055d7de53c7ad6bc45283"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["81d0720146de53dd3a4a023d2a3d1089d86d748d"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2dfdf766e55e943d942055d7de53c7ad6bc45283"],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["81d0720146de53dd3a4a023d2a3d1089d86d748d"],"81d0720146de53dd3a4a023d2a3d1089d86d748d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}