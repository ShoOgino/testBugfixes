{"path":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#testTokenStream2().mjava","commits":[{"id":"837108f624718d0896bef7acd0150b66ebd816db","date":1395274740,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#testTokenStream2().mjava","pathOld":"/dev/null","sourceNew":"  public void testTokenStream2() throws IOException {\n    // '㌰', '<<'゙, '5', '℃', '№', '㈱', '㌘', 'ｻ', '<<', 'ｿ', '<<'\n    String input = \"㌰゙5℃№㈱㌘ｻﾞｿﾞ\";\n\n    CharFilter reader = new ICUNormalizer2CharFilter(new StringReader(input),\n      Normalizer2.getInstance(null, \"nfkc_cf\", Normalizer2.Mode.COMPOSE));\n\n    Tokenizer tokenStream = new NGramTokenizer(TEST_VERSION_CURRENT, 1, 1);\n    tokenStream.setReader(reader);\n\n    assertTokenStreamContents(tokenStream,\n      new String[] {\"ピ\", \"ゴ\", \"5\", \"°\", \"c\", \"n\", \"o\", \"(\", \"株\", \")\", \"グ\", \"ラ\", \"ム\", \"ザ\", \"ゾ\"},\n      new int[]{0, 1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9},\n      new int[]{1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9, 11},\n      input.length()\n    );\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75","date":1399205975,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#testTokenStream2().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#testTokenStream2().mjava","sourceNew":"  public void testTokenStream2() throws IOException {\n    // '㌰', '<<'゙, '5', '℃', '№', '㈱', '㌘', 'ｻ', '<<', 'ｿ', '<<'\n    String input = \"㌰゙5℃№㈱㌘ｻﾞｿﾞ\";\n\n    CharFilter reader = new ICUNormalizer2CharFilter(new StringReader(input),\n      Normalizer2.getInstance(null, \"nfkc_cf\", Normalizer2.Mode.COMPOSE));\n\n    Tokenizer tokenStream = new NGramTokenizer(TEST_VERSION_CURRENT, newAttributeFactory(), 1, 1);\n    tokenStream.setReader(reader);\n\n    assertTokenStreamContents(tokenStream,\n      new String[] {\"ピ\", \"ゴ\", \"5\", \"°\", \"c\", \"n\", \"o\", \"(\", \"株\", \")\", \"グ\", \"ラ\", \"ム\", \"ザ\", \"ゾ\"},\n      new int[]{0, 1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9},\n      new int[]{1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9, 11},\n      input.length()\n    );\n  }\n\n","sourceOld":"  public void testTokenStream2() throws IOException {\n    // '㌰', '<<'゙, '5', '℃', '№', '㈱', '㌘', 'ｻ', '<<', 'ｿ', '<<'\n    String input = \"㌰゙5℃№㈱㌘ｻﾞｿﾞ\";\n\n    CharFilter reader = new ICUNormalizer2CharFilter(new StringReader(input),\n      Normalizer2.getInstance(null, \"nfkc_cf\", Normalizer2.Mode.COMPOSE));\n\n    Tokenizer tokenStream = new NGramTokenizer(TEST_VERSION_CURRENT, 1, 1);\n    tokenStream.setReader(reader);\n\n    assertTokenStreamContents(tokenStream,\n      new String[] {\"ピ\", \"ゴ\", \"5\", \"°\", \"c\", \"n\", \"o\", \"(\", \"株\", \")\", \"グ\", \"ラ\", \"ム\", \"ザ\", \"ゾ\"},\n      new int[]{0, 1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9},\n      new int[]{1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9, 11},\n      input.length()\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#testTokenStream2().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#testTokenStream2().mjava","sourceNew":"  public void testTokenStream2() throws IOException {\n    // '㌰', '<<'゙, '5', '℃', '№', '㈱', '㌘', 'ｻ', '<<', 'ｿ', '<<'\n    String input = \"㌰゙5℃№㈱㌘ｻﾞｿﾞ\";\n\n    CharFilter reader = new ICUNormalizer2CharFilter(new StringReader(input),\n      Normalizer2.getInstance(null, \"nfkc_cf\", Normalizer2.Mode.COMPOSE));\n\n    Tokenizer tokenStream = new NGramTokenizer(newAttributeFactory(), 1, 1);\n    tokenStream.setReader(reader);\n\n    assertTokenStreamContents(tokenStream,\n      new String[] {\"ピ\", \"ゴ\", \"5\", \"°\", \"c\", \"n\", \"o\", \"(\", \"株\", \")\", \"グ\", \"ラ\", \"ム\", \"ザ\", \"ゾ\"},\n      new int[]{0, 1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9},\n      new int[]{1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9, 11},\n      input.length()\n    );\n  }\n\n","sourceOld":"  public void testTokenStream2() throws IOException {\n    // '㌰', '<<'゙, '5', '℃', '№', '㈱', '㌘', 'ｻ', '<<', 'ｿ', '<<'\n    String input = \"㌰゙5℃№㈱㌘ｻﾞｿﾞ\";\n\n    CharFilter reader = new ICUNormalizer2CharFilter(new StringReader(input),\n      Normalizer2.getInstance(null, \"nfkc_cf\", Normalizer2.Mode.COMPOSE));\n\n    Tokenizer tokenStream = new NGramTokenizer(TEST_VERSION_CURRENT, newAttributeFactory(), 1, 1);\n    tokenStream.setReader(reader);\n\n    assertTokenStreamContents(tokenStream,\n      new String[] {\"ピ\", \"ゴ\", \"5\", \"°\", \"c\", \"n\", \"o\", \"(\", \"株\", \")\", \"グ\", \"ラ\", \"ム\", \"ザ\", \"ゾ\"},\n      new int[]{0, 1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9},\n      new int[]{1, 2, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 9, 11},\n      input.length()\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"837108f624718d0896bef7acd0150b66ebd816db":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"],"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75":["837108f624718d0896bef7acd0150b66ebd816db"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["379db3ad24c4f0214f30a122265a6d6be003a99d"]},"commit2Childs":{"837108f624718d0896bef7acd0150b66ebd816db":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["837108f624718d0896bef7acd0150b66ebd816db"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}