{"path":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","sourceNew":"  @Override\n  public void end() throws IOException {\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    streamState = State.END;\n  }\n\n","sourceOld":"  @Override\n  public void end() throws IOException {\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    streamState = State.END;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c46b5eed1428b2cecc6851b67142702486279f89","date":1332284557,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","sourceNew":"  @Override\n  public void end() throws IOException {\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    try {\n      assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void end() throws IOException {\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    streamState = State.END;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03","date":1377018786,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","sourceNew":"  @Override\n  public void end() throws IOException {\n    super.end();\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    try {\n      assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void end() throws IOException {\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    try {\n      assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","sourceNew":"  @Override\n  public void end() throws IOException {\n    super.end();\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    try {\n      assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void end() throws IOException {\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    try {\n      assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"50d5b588b112eeb3d6b2a3fcc43a40ef0615a529","date":1419024596,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","sourceNew":"  @Override\n  public void end() throws IOException {\n    try {\n      super.end();\n      int finalOffset = correctOffset(off);\n      offsetAtt.setOffset(finalOffset, finalOffset);\n      // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n      // these tests should disable this check (in general you should consume the entire stream)\n      if (streamState != State.INCREMENT_FALSE) {\n        fail(\"end() called before incrementToken() returned false!\");\n      }\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void end() throws IOException {\n    super.end();\n    int finalOffset = correctOffset(off);\n    offsetAtt.setOffset(finalOffset, finalOffset);\n    // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n    // these tests should disable this check (in general you should consume the entire stream)\n    try {\n      assert !enableChecks || streamState == State.INCREMENT_FALSE : \"end() called before incrementToken() returned false!\";\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24a98f5fdd23e04f85819dbc63b47a12f7c44311","date":1482439157,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","sourceNew":"  @Override\n  public void end() throws IOException {\n    try {\n      super.end();\n      int finalOffset = correctOffset(off);\n      offsetAtt.setOffset(finalOffset, finalOffset);\n      // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n      // these tests should disable this check (in general you should consume the entire stream)\n      if (streamState != State.INCREMENT_FALSE) {\n        fail(\"end() called in wrong state=\" + streamState + \"!\");\n      }\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void end() throws IOException {\n    try {\n      super.end();\n      int finalOffset = correctOffset(off);\n      offsetAtt.setOffset(finalOffset, finalOffset);\n      // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n      // these tests should disable this check (in general you should consume the entire stream)\n      if (streamState != State.INCREMENT_FALSE) {\n        fail(\"end() called before incrementToken() returned false!\");\n      }\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/MockTokenizer#end().mjava","sourceNew":"  @Override\n  public void end() throws IOException {\n    try {\n      super.end();\n      int finalOffset = correctOffset(off);\n      offsetAtt.setOffset(finalOffset, finalOffset);\n      // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n      // these tests should disable this check (in general you should consume the entire stream)\n      if (streamState != State.INCREMENT_FALSE) {\n        fail(\"end() called in wrong state=\" + streamState + \"!\");\n      }\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void end() throws IOException {\n    try {\n      super.end();\n      int finalOffset = correctOffset(off);\n      offsetAtt.setOffset(finalOffset, finalOffset);\n      // some tokenizers, such as limiting tokenizers, call end() before incrementToken() returns false.\n      // these tests should disable this check (in general you should consume the entire stream)\n      if (streamState != State.INCREMENT_FALSE) {\n        fail(\"end() called before incrementToken() returned false!\");\n      }\n    } finally {\n      streamState = State.END;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["c46b5eed1428b2cecc6851b67142702486279f89","f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"24a98f5fdd23e04f85819dbc63b47a12f7c44311":["50d5b588b112eeb3d6b2a3fcc43a40ef0615a529"],"50d5b588b112eeb3d6b2a3fcc43a40ef0615a529":["f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03"],"c46b5eed1428b2cecc6851b67142702486279f89":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03":["c46b5eed1428b2cecc6851b67142702486279f89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["24a98f5fdd23e04f85819dbc63b47a12f7c44311"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["50d5b588b112eeb3d6b2a3fcc43a40ef0615a529","24a98f5fdd23e04f85819dbc63b47a12f7c44311"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["c46b5eed1428b2cecc6851b67142702486279f89"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"24a98f5fdd23e04f85819dbc63b47a12f7c44311":["cd5edd1f2b162a5cfa08efd17851a07373a96817","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"50d5b588b112eeb3d6b2a3fcc43a40ef0615a529":["24a98f5fdd23e04f85819dbc63b47a12f7c44311","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"c46b5eed1428b2cecc6851b67142702486279f89":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03"],"f3f8a0f8bebc057ea4bdf65150b3fdc539db3d03":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","50d5b588b112eeb3d6b2a3fcc43a40ef0615a529"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[]},"heads":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cd5edd1f2b162a5cfa08efd17851a07373a96817","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}