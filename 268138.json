{"path":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer#writeTermVectors(TermVectorsWriter,Fields,FieldInfos).mjava","commits":[{"id":"86a0a50d2d14aaee1e635bbec914468551f7f9a2","date":1482234306,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer#writeTermVectors(TermVectorsWriter,Fields,FieldInfos).mjava","pathOld":"/dev/null","sourceNew":"  /** Safe (but, slowish) default method to copy every vector field in the provided {@link TermVectorsWriter}. */\n  private static void writeTermVectors(TermVectorsWriter writer, Fields vectors, FieldInfos fieldInfos) throws IOException {\n    if (vectors == null) {\n      writer.startDocument(0);\n      writer.finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    writer.startDocument(numFields);\n\n    String lastFieldName = null;\n\n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n\n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n\n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator();\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n\n      writer.startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator();\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n\n        writer.startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);\n          assert docsAndPositionsEnum != null;\n\n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n\n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            writer.addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        writer.finishTerm();\n      }\n      assert termCount == numTerms;\n      writer.finishField();\n    }\n    assert fieldCount == numFields;\n    writer.finishDocument();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SortingTermVectorsConsumer#writeTermVectors(TermVectorsWriter,Fields,FieldInfos).mjava","pathOld":"/dev/null","sourceNew":"  /** Safe (but, slowish) default method to copy every vector field in the provided {@link TermVectorsWriter}. */\n  private static void writeTermVectors(TermVectorsWriter writer, Fields vectors, FieldInfos fieldInfos) throws IOException {\n    if (vectors == null) {\n      writer.startDocument(0);\n      writer.finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    writer.startDocument(numFields);\n\n    String lastFieldName = null;\n\n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n\n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n\n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n\n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator();\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n\n      writer.startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator();\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n\n        writer.startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);\n          assert docsAndPositionsEnum != null;\n\n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n\n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            writer.addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        writer.finishTerm();\n      }\n      assert termCount == numTerms;\n      writer.finishField();\n    }\n    assert fieldCount == numFields;\n    writer.finishDocument();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"]},"commit2Childs":{"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}