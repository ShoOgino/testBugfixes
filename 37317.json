{"path":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","commits":[{"id":"d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626","date":1339522233,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect);\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0935c850ea562932997b72c69d93e345f21d7f45","date":1344711506,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f59fcfe7807d7be91d80ceb371aaca2255f5d6c6","date":1392642922,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = _TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = _TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = _TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"91d86ebcdb45ce6a1b2584e2603f76db47523d0a","date":1396466913,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      String pf = TestUtil.getPostingsFormat(\"dummy\");\n      boolean supportsOffsets = !doesntSupportOffsets.contains(pf);\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (supportsOffsets && offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS_ONLY); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n                if (offsetsAreCorrect) {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n                } else {\n                  ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n                }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":["995993f24c9f6feb42b49b71e1982cda8fa0b37c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ffa492a4fac1f68e46ffbb60d8bc41ee6bdd82c1","date":1415436729,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              System.out.println(\"add doc=\" + doc);\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"be3a54bda7c73e3b54027c6f7c96ebc0ebce25ed","date":1415436755,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              System.out.println(\"add doc=\" + doc);\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eeea025b4a7a8e8f70426ac4527ef481b3a86b72","date":1476199075,"type":3,"author":"yonik","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              FieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24a98f5fdd23e04f85819dbc63b47a12f7c44311","date":1482439157,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n\n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n\n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n\n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n\n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n        \n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n        \n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"995993f24c9f6feb42b49b71e1982cda8fa0b37c","date":1522116154,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean graphOffsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n\n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n\n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, graphOffsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n\n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n\n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":["2bb2842e561df4e8e9ad89010605fc86ac265465","d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","date":1522191940,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean graphOffsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n\n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n\n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, graphOffsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean offsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          if (offsetsAreCorrect) {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n          } else {\n            ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n          }\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n\n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n\n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, offsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec957ab3b0d9ea256564a995436d66bf57bba2","date":1580230551,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#checkRandomData(Random,Analyzer,int,int,boolean,boolean,boolean,RandomIndexWriter).mjava","sourceNew":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean graphOffsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    for (int i = 0; i < iterations; i++) {\n      String text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n\n      try {\n        checkAnalysisConsistency(random, a, useCharFilter, text, graphOffsetsAreCorrect, currentField);\n        if (iw != null) {\n          if (random.nextInt(7) == 0) {\n            // pile up a multivalued field\n            IndexableFieldType ft = field.fieldType();\n            currentField = new Field(\"dummy\", bogus, ft);\n            doc.add(currentField);\n          } else {\n            iw.addDocument(doc);\n            if (doc.getFields().size() > 1) {\n              // back to 1 field\n              currentField = field;\n              doc.removeFields(\"dummy\");\n              doc.add(currentField);\n            }\n          }\n        }\n      } catch (Throwable t) {\n        // TODO: really we should pass a random seed to\n        // checkAnalysisConsistency then print it here too:\n        System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n        Rethrow.rethrow(t);\n      }\n    }\n  }\n\n","sourceOld":"  private static void checkRandomData(Random random, Analyzer a, int iterations, int maxWordLength, boolean useCharFilter, boolean simple, boolean graphOffsetsAreCorrect, RandomIndexWriter iw) throws IOException {\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    Document doc = null;\n    Field field = null, currentField = null;\n    StringReader bogus = new StringReader(\"\");\n    if (iw != null) {\n      doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      if (random.nextBoolean()) {\n        ft.setStoreTermVectors(true);\n        ft.setStoreTermVectorOffsets(random.nextBoolean());\n        ft.setStoreTermVectorPositions(random.nextBoolean());\n        if (ft.storeTermVectorPositions()) {\n          ft.setStoreTermVectorPayloads(random.nextBoolean());\n        }\n      }\n      if (random.nextBoolean()) {\n        ft.setOmitNorms(true);\n      }\n      switch(random.nextInt(4)) {\n        case 0: ft.setIndexOptions(IndexOptions.DOCS); break;\n        case 1: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS); break;\n        case 2: ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS); break;\n        default:\n          ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      }\n      currentField = field = new Field(\"dummy\", bogus, ft);\n      doc.add(currentField);\n    }\n    \n    try {\n      for (int i = 0; i < iterations; i++) {\n        String text;\n\n        if (random.nextInt(10) == 7) {\n          // real data from linedocs\n          text = docs.nextDoc().get(\"body\");\n          if (text.length() > maxWordLength) {\n            \n            // Take a random slice from the text...:\n            int startPos = random.nextInt(text.length() - maxWordLength);\n            if (startPos > 0 && Character.isLowSurrogate(text.charAt(startPos))) {\n              // Take care not to split up a surrogate pair:\n              startPos--;\n              assert Character.isHighSurrogate(text.charAt(startPos));\n            }\n            int endPos = startPos + maxWordLength - 1;\n            if (Character.isHighSurrogate(text.charAt(endPos))) {\n              // Take care not to split up a surrogate pair:\n              endPos--;\n            }\n            text = text.substring(startPos, 1+endPos);\n          }\n        } else {\n          // synthetic\n          text = TestUtil.randomAnalysisString(random, maxWordLength, simple);\n        }\n\n        try {\n          checkAnalysisConsistency(random, a, useCharFilter, text, graphOffsetsAreCorrect, currentField);\n          if (iw != null) {\n            if (random.nextInt(7) == 0) {\n              // pile up a multivalued field\n              IndexableFieldType ft = field.fieldType();\n              currentField = new Field(\"dummy\", bogus, ft);\n              doc.add(currentField);\n            } else {\n              iw.addDocument(doc);\n              if (doc.getFields().size() > 1) {\n                // back to 1 field\n                currentField = field;\n                doc.removeFields(\"dummy\");\n                doc.add(currentField);\n              }\n            }\n          }\n        } catch (Throwable t) {\n          // TODO: really we should pass a random seed to\n          // checkAnalysisConsistency then print it here too:\n          System.err.println(\"TEST FAIL: useCharFilter=\" + useCharFilter + \" text='\" + escape(text) + \"'\");\n          Rethrow.rethrow(t);\n        }\n      }\n    } finally {\n      IOUtils.closeWhileHandlingException(docs);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"be3a54bda7c73e3b54027c6f7c96ebc0ebce25ed":["ffa492a4fac1f68e46ffbb60d8bc41ee6bdd82c1"],"5eb2511ababf862ea11e10761c70ee560cd84510":["6613659748fe4411a7dcf85266e55db1f95f7315","91d86ebcdb45ce6a1b2584e2603f76db47523d0a"],"eeea025b4a7a8e8f70426ac4527ef481b3a86b72":["be3a54bda7c73e3b54027c6f7c96ebc0ebce25ed"],"ffa492a4fac1f68e46ffbb60d8bc41ee6bdd82c1":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"f8ec957ab3b0d9ea256564a995436d66bf57bba2":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"91d86ebcdb45ce6a1b2584e2603f76db47523d0a":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["f59fcfe7807d7be91d80ceb371aaca2255f5d6c6"],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["24a98f5fdd23e04f85819dbc63b47a12f7c44311","995993f24c9f6feb42b49b71e1982cda8fa0b37c"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["91d86ebcdb45ce6a1b2584e2603f76db47523d0a"],"24a98f5fdd23e04f85819dbc63b47a12f7c44311":["eeea025b4a7a8e8f70426ac4527ef481b3a86b72"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["be3a54bda7c73e3b54027c6f7c96ebc0ebce25ed","eeea025b4a7a8e8f70426ac4527ef481b3a86b72"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","24a98f5fdd23e04f85819dbc63b47a12f7c44311"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626","0935c850ea562932997b72c69d93e345f21d7f45"],"995993f24c9f6feb42b49b71e1982cda8fa0b37c":["24a98f5fdd23e04f85819dbc63b47a12f7c44311"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f59fcfe7807d7be91d80ceb371aaca2255f5d6c6":["0935c850ea562932997b72c69d93e345f21d7f45"],"0935c850ea562932997b72c69d93e345f21d7f45":["d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626"],"d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626","0935c850ea562932997b72c69d93e345f21d7f45"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f8ec957ab3b0d9ea256564a995436d66bf57bba2"]},"commit2Childs":{"be3a54bda7c73e3b54027c6f7c96ebc0ebce25ed":["eeea025b4a7a8e8f70426ac4527ef481b3a86b72","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"5eb2511ababf862ea11e10761c70ee560cd84510":[],"ffa492a4fac1f68e46ffbb60d8bc41ee6bdd82c1":["be3a54bda7c73e3b54027c6f7c96ebc0ebce25ed"],"eeea025b4a7a8e8f70426ac4527ef481b3a86b72":["24a98f5fdd23e04f85819dbc63b47a12f7c44311","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"f8ec957ab3b0d9ea256564a995436d66bf57bba2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"91d86ebcdb45ce6a1b2584e2603f76db47523d0a":["5eb2511ababf862ea11e10761c70ee560cd84510","2bb2842e561df4e8e9ad89010605fc86ac265465"],"6613659748fe4411a7dcf85266e55db1f95f7315":["5eb2511ababf862ea11e10761c70ee560cd84510","91d86ebcdb45ce6a1b2584e2603f76db47523d0a"],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["f8ec957ab3b0d9ea256564a995436d66bf57bba2"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["ffa492a4fac1f68e46ffbb60d8bc41ee6bdd82c1"],"24a98f5fdd23e04f85819dbc63b47a12f7c44311":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","f03e4bed5023ec3ef93a771b8888cae991cf448d","995993f24c9f6feb42b49b71e1982cda8fa0b37c"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"995993f24c9f6feb42b49b71e1982cda8fa0b37c":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626"],"f59fcfe7807d7be91d80ceb371aaca2255f5d6c6":["6613659748fe4411a7dcf85266e55db1f95f7315"],"d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626":["c7869f64c874ebf7f317d22c00baf2b6857797a6","0935c850ea562932997b72c69d93e345f21d7f45","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"0935c850ea562932997b72c69d93e345f21d7f45":["c7869f64c874ebf7f317d22c00baf2b6857797a6","f59fcfe7807d7be91d80ceb371aaca2255f5d6c6","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","f03e4bed5023ec3ef93a771b8888cae991cf448d","c7869f64c874ebf7f317d22c00baf2b6857797a6","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}