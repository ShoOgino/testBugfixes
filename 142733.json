{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","commits":[{"id":"e2fe60a17a7a0cfd101b1169acf089221bc6c166","date":1412767493,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosReader#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final DocValuesType normsType = getDocValuesType(input, (byte) ((val >>> 4) & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, normsType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final DocValuesType normsType = getDocValuesType(input, (byte) ((val >>> 4) & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, normsType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosReader#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final DocValuesType normsType = getDocValuesType(input, (byte) ((val >>> 4) & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, normsType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final DocValuesType normsType = getDocValuesType(input, (byte) ((val >>> 4) & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, normsType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05da2d758a6089e737cdfc230e57a51b472b94b6","date":1413392310,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final DocValuesType normsType = getDocValuesType(input, (byte) ((val >>> 4) & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, normsType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84","date":1413458798,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final DocValuesType normsType = getDocValuesType(input, (byte) ((val >>> 4) & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, normsType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3184874f7f3aca850248483485b4995343066875","date":1413876758,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, CODEC_NAME, \n                                     FORMAT_START, \n                                     FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a22eafe3f72a4c2945eaad9547e6c78816978f4","date":1413956657,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, Lucene50FieldInfosFormat.EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean isIndexed = (bits & Lucene50FieldInfosFormat.IS_INDEXED) != 0;\n          boolean storeTermVector = (bits & Lucene50FieldInfosFormat.STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & Lucene50FieldInfosFormat.OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & Lucene50FieldInfosFormat.STORE_PAYLOADS) != 0;\n          final IndexOptions indexOptions;\n          if (!isIndexed) {\n            indexOptions = null;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_ONLY;\n          } else if ((bits & Lucene50FieldInfosFormat.OMIT_POSITIONS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS;\n          } else if ((bits & Lucene50FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n          } else {\n            indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n          }\n          \n          // DV Types are packed in one byte\n          byte val = input.readByte();\n          final DocValuesType docValuesType = getDocValuesType(input, (byte) (val & 0x0F));\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkSegmentHeader(input, CODEC_NAME, \n                                     FORMAT_START, \n                                     FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79700663e164dece87bed4adfd3e28bab6cb1385","date":1425241849,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc09d4e9b79dccc49261c15eb8f6974a7a5c0ec5","date":1425302892,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"299a2348fa24151d150182211b6208a38e5e3450","date":1425304608,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          final Map<String,String> attributes = input.readStringStringMap();\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, Collections.unmodifiableMap(attributes));\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f8973f28b29873ff0d7a016e562c9036ae649a9","date":1428098193,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ca792c26af46bd6c4a08d81117c60440cf6a7e3d","date":1445938295,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c850d2a2bc88f4751bf05e1ee6799940462331eb","date":1472140972,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a","date":1472163016,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        int format = CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes;\n          if (format >= FORMAT_SAFE_MAPS) {\n            attributes = input.readMapOfStrings();\n          } else {\n            attributes = Collections.unmodifiableMap(input.readStringStringMap());\n          }\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eeba0a4d0845889a402dd225793d62f009d029c9","date":1527938093,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, false);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab548c8f96022b4780f7500a30b19b4f4a5feeb6","date":1527940044,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, false);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7e4ca6dc9612ff741d8713743e2bccfae5eadac","date":1528093718,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, false);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, false);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, false);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, 0, false);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, false);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"683b2041fcb490acd2bfec6034c593b3cfb2098c","date":1596135595,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, 0, false);\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext context) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, segmentSuffix, EXTENSION);\n    try (ChecksumIndexInput input = directory.openChecksumInput(fileName, context)) {\n      Throwable priorE = null;\n      FieldInfo infos[] = null;\n      try {\n        CodecUtil.checkIndexHeader(input, Lucene50FieldInfosFormat.CODEC_NAME, \n                                     Lucene50FieldInfosFormat.FORMAT_START, \n                                     Lucene50FieldInfosFormat.FORMAT_CURRENT,\n                                     segmentInfo.getId(), segmentSuffix);\n        \n        final int size = input.readVInt(); //read in the size\n        infos = new FieldInfo[size];\n        \n        // previous field's attribute map, we share when possible:\n        Map<String,String> lastAttributes = Collections.emptyMap();\n        \n        for (int i = 0; i < size; i++) {\n          String name = input.readString();\n          final int fieldNumber = input.readVInt();\n          if (fieldNumber < 0) {\n            throw new CorruptIndexException(\"invalid field number for field: \" + name + \", fieldNumber=\" + fieldNumber, input);\n          }\n          byte bits = input.readByte();\n          boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;\n          boolean omitNorms = (bits & OMIT_NORMS) != 0;\n          boolean storePayloads = (bits & STORE_PAYLOADS) != 0;\n\n          final IndexOptions indexOptions = getIndexOptions(input, input.readByte());\n          \n          // DV Types are packed in one byte\n          final DocValuesType docValuesType = getDocValuesType(input, input.readByte());\n          final long dvGen = input.readLong();\n          Map<String,String> attributes = input.readMapOfStrings();\n\n          // just use the last field's map if its the same\n          if (attributes.equals(lastAttributes)) {\n            attributes = lastAttributes;\n          }\n          lastAttributes = attributes;\n          try {\n            infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, omitNorms, storePayloads, \n                                     indexOptions, docValuesType, dvGen, attributes, 0, 0, 0, false);\n            infos[i].checkConsistency();\n          } catch (IllegalStateException e) {\n            throw new CorruptIndexException(\"invalid fieldinfo for field: \" + name + \", fieldNumber=\" + fieldNumber, input, e);\n          }\n        }\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n      return new FieldInfos(infos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f6652c943595e92c187ee904c382863013eae28f":["b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238","fc09d4e9b79dccc49261c15eb8f6974a7a5c0ec5"],"ab548c8f96022b4780f7500a30b19b4f4a5feeb6":["eeba0a4d0845889a402dd225793d62f009d029c9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["ab548c8f96022b4780f7500a30b19b4f4a5feeb6"],"79700663e164dece87bed4adfd3e28bab6cb1385":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"299a2348fa24151d150182211b6208a38e5e3450":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238","fc09d4e9b79dccc49261c15eb8f6974a7a5c0ec5"],"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d","c850d2a2bc88f4751bf05e1ee6799940462331eb"],"05da2d758a6089e737cdfc230e57a51b472b94b6":["e2fe60a17a7a0cfd101b1169acf089221bc6c166"],"e2fe60a17a7a0cfd101b1169acf089221bc6c166":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84":["55980207f1977bd1463465de1659b821347e2fa8","05da2d758a6089e737cdfc230e57a51b472b94b6"],"55980207f1977bd1463465de1659b821347e2fa8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e2fe60a17a7a0cfd101b1169acf089221bc6c166"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84"],"3f8973f28b29873ff0d7a016e562c9036ae649a9":["fc09d4e9b79dccc49261c15eb8f6974a7a5c0ec5"],"3184874f7f3aca850248483485b4995343066875":["05da2d758a6089e737cdfc230e57a51b472b94b6"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d","e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":["3384e6013a93e4d11b7d75388693f8d0388602bf","3184874f7f3aca850248483485b4995343066875"],"fc09d4e9b79dccc49261c15eb8f6974a7a5c0ec5":["79700663e164dece87bed4adfd3e28bab6cb1385"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["3f8973f28b29873ff0d7a016e562c9036ae649a9"],"eeba0a4d0845889a402dd225793d62f009d029c9":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"c850d2a2bc88f4751bf05e1ee6799940462331eb":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["3184874f7f3aca850248483485b4995343066875","0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"683b2041fcb490acd2bfec6034c593b3cfb2098c":["f6652c943595e92c187ee904c382863013eae28f"],"f592209545c71895260367152601e9200399776d":["ab548c8f96022b4780f7500a30b19b4f4a5feeb6","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["683b2041fcb490acd2bfec6034c593b3cfb2098c"]},"commit2Childs":{"f6652c943595e92c187ee904c382863013eae28f":["683b2041fcb490acd2bfec6034c593b3cfb2098c"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"ab548c8f96022b4780f7500a30b19b4f4a5feeb6":["b7e4ca6dc9612ff741d8713743e2bccfae5eadac","f592209545c71895260367152601e9200399776d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e2fe60a17a7a0cfd101b1169acf089221bc6c166","55980207f1977bd1463465de1659b821347e2fa8"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["f6652c943595e92c187ee904c382863013eae28f","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"79700663e164dece87bed4adfd3e28bab6cb1385":["fc09d4e9b79dccc49261c15eb8f6974a7a5c0ec5"],"299a2348fa24151d150182211b6208a38e5e3450":[],"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a":["b70042a8a492f7054d480ccdd2be9796510d4327","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","eeba0a4d0845889a402dd225793d62f009d029c9"],"05da2d758a6089e737cdfc230e57a51b472b94b6":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84","3184874f7f3aca850248483485b4995343066875"],"e2fe60a17a7a0cfd101b1169acf089221bc6c166":["05da2d758a6089e737cdfc230e57a51b472b94b6","55980207f1977bd1463465de1659b821347e2fa8"],"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84":["3384e6013a93e4d11b7d75388693f8d0388602bf"],"55980207f1977bd1463465de1659b821347e2fa8":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"3f8973f28b29873ff0d7a016e562c9036ae649a9":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"3184874f7f3aca850248483485b4995343066875":["0a22eafe3f72a4c2945eaad9547e6c78816978f4","db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"fc09d4e9b79dccc49261c15eb8f6974a7a5c0ec5":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","299a2348fa24151d150182211b6208a38e5e3450","3f8973f28b29873ff0d7a016e562c9036ae649a9"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","c850d2a2bc88f4751bf05e1ee6799940462331eb"],"eeba0a4d0845889a402dd225793d62f009d029c9":["ab548c8f96022b4780f7500a30b19b4f4a5feeb6"],"c850d2a2bc88f4751bf05e1ee6799940462331eb":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","79700663e164dece87bed4adfd3e28bab6cb1385","299a2348fa24151d150182211b6208a38e5e3450"],"683b2041fcb490acd2bfec6034c593b3cfb2098c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b70042a8a492f7054d480ccdd2be9796510d4327","299a2348fa24151d150182211b6208a38e5e3450","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}