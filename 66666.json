{"path":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","commits":[{"id":"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","date":1346834651,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf8086c7e11dc41303ef1b8050bd355ddfaee76d","date":1350007219,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7492bcb52be51e55d596134b95b2e53cc4ffb91","date":1350223278,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.shutdown();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.shutdown();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.shutdown();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.shutdown();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbaae1c00d39df2c872bbe043af26d02d3818313","date":1409657064,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":null,"sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = TestUtil.alwaysPostingsFormat(new Pulsing41PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, DocsEnum.FLAG_NONE);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["c7492bcb52be51e55d596134b95b2e53cc4ffb91","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"fbaae1c00d39df2c872bbe043af26d02d3818313":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","cf8086c7e11dc41303ef1b8050bd355ddfaee76d"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fbaae1c00d39df2c872bbe043af26d02d3818313"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["db4fdbf3d262768eabc027cd8321edca0cd11fa8","c7492bcb52be51e55d596134b95b2e53cc4ffb91","cf8086c7e11dc41303ef1b8050bd355ddfaee76d"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","db4fdbf3d262768eabc027cd8321edca0cd11fa8","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"fbaae1c00d39df2c872bbe043af26d02d3818313":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","6613659748fe4411a7dcf85266e55db1f95f7315"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["fbaae1c00d39df2c872bbe043af26d02d3818313"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","db4fdbf3d262768eabc027cd8321edca0cd11fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}