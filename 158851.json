{"path":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","commits":[{"id":"7e4c214a1f904dde76f5611b56d4081533055b3b","date":1421938451,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],ReadersAndUpdates,SegmentReader,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        docsEnum = termsEnum.docs(segState.rld.getLiveDocs(), docsEnum, DocsEnum.FLAG_NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      ReadersAndUpdates rld, SegmentReader reader, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docsEnum = null;\n    \n    //System.out.println(Thread.currentThread().getName() + \" numericDVUpdate reader=\" + reader);\n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        docsEnum = termsEnum.docs(rld.getLiveDocs(), docsEnum, DocsEnum.FLAG_NONE);\n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, reader.maxDoc());\n        }\n        int doc;\n        while ((doc = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          //System.out.println(Thread.currentThread().getName() + \" numericDVUpdate term=\" + term + \" doc=\" + docID);\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        postingsEnum = termsEnum.postings(segState.rld.getLiveDocs(), postingsEnum, PostingsEnum.FLAG_NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        docsEnum = termsEnum.docs(segState.rld.getLiveDocs(), docsEnum, DocsEnum.FLAG_NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        postingsEnum = termsEnum.postings(segState.rld.getLiveDocs(), postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        postingsEnum = termsEnum.postings(segState.rld.getLiveDocs(), postingsEnum, PostingsEnum.FLAG_NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        postingsEnum = termsEnum.postings(segState.rld.getLiveDocs(), postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        postingsEnum = termsEnum.postings(segState.rld.getLiveDocs(), postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        postingsEnum = termsEnum.postings(segState.rld.getLiveDocs(), postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84c1ba52905cc7eaf624aac5e10414eccc0af92d","date":1464805673,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(List[DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(List<DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b8ee93140fd0efef7e101786e3ed5160a700b5f","date":1464820111,"type":5,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(List[DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(List<DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77","date":1464821470,"type":5,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(List[DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(List<DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f69e96b07e265f3e18957be540909b01fae36f8","date":1464859090,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(List[DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(List<DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyDocValuesUpdates(Iterable[#-extends-DocValuesUpdate],SegmentState,DocValuesFieldUpdates.Container).mjava","sourceNew":null,"sourceOld":"  // DocValues updates\n  private synchronized void applyDocValuesUpdates(Iterable<? extends DocValuesUpdate> updates, \n      SegmentState segState, DocValuesFieldUpdates.Container dvUpdatesContainer) throws IOException {\n    Fields fields = segState.reader.fields();\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum postingsEnum = null;\n    \n    for (DocValuesUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator();\n        } else {\n          termsEnum = null;\n        }\n      }\n\n      if (termsEnum == null) {\n        // no terms in this field\n        continue;\n      }\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        final Bits acceptDocs = segState.rld.getLiveDocs();\n        postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);\n\n        DocValuesFieldUpdates dvUpdates = dvUpdatesContainer.getUpdates(update.field, update.type);\n        if (dvUpdates == null) {\n          dvUpdates = dvUpdatesContainer.newUpdates(update.field, update.type, segState.reader.maxDoc());\n        }\n        int doc;\n        while ((doc = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          if (acceptDocs != null && acceptDocs.get(doc) == false) {\n            continue;\n          }\n          dvUpdates.add(doc, update.value);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1f69e96b07e265f3e18957be540909b01fae36f8":["0f4464508ee83288c8c4585b533f9faaa93aa314","84c1ba52905cc7eaf624aac5e10414eccc0af92d"],"7e4c214a1f904dde76f5611b56d4081533055b3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"84c1ba52905cc7eaf624aac5e10414eccc0af92d":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"5b8ee93140fd0efef7e101786e3ed5160a700b5f":["0f4464508ee83288c8c4585b533f9faaa93aa314","84c1ba52905cc7eaf624aac5e10414eccc0af92d"],"51f5280f31484820499077f41fcdfe92d527d9dc":["7e4c214a1f904dde76f5611b56d4081533055b3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0f4464508ee83288c8c4585b533f9faaa93aa314","1f69e96b07e265f3e18957be540909b01fae36f8"],"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77":["0f4464508ee83288c8c4585b533f9faaa93aa314","5b8ee93140fd0efef7e101786e3ed5160a700b5f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1f69e96b07e265f3e18957be540909b01fae36f8"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["1f69e96b07e265f3e18957be540909b01fae36f8","84c1ba52905cc7eaf624aac5e10414eccc0af92d","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7e4c214a1f904dde76f5611b56d4081533055b3b"],"1f69e96b07e265f3e18957be540909b01fae36f8":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7e4c214a1f904dde76f5611b56d4081533055b3b":["51f5280f31484820499077f41fcdfe92d527d9dc"],"84c1ba52905cc7eaf624aac5e10414eccc0af92d":["1f69e96b07e265f3e18957be540909b01fae36f8","5b8ee93140fd0efef7e101786e3ed5160a700b5f"],"5b8ee93140fd0efef7e101786e3ed5160a700b5f":["b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}