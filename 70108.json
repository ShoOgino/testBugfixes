{"path":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (state == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","sourceOld":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (state == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (state == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","sourceOld":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (state == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (state == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","sourceOld":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (state == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63131741120598595ba46620adaf3fad049ca291","date":1335567423,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","sourceOld":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (state == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","sourceOld":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","sourceOld":"  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d496ec5dd42f7b76312f7ba5ac6666f1ed0730d","date":1428726211,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = DEFAULT_RAM_BYTES_USED;\n      if (maxRamBytes != Long.MAX_VALUE) {\n        if (key != null && key instanceof Accountable) {\n          keySize = ((Accountable) key).ramBytesUsed();\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          if (key instanceof Accountable) {\n            Accountable aKey = (Accountable) key;\n            bytesToDecrement += aKey.ramBytesUsed();\n          } else {\n            bytesToDecrement += DEFAULT_RAM_BYTES_USED;\n          }\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n      return map.put(key,value);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc0fbfa191179ae7a0081ee1cf7da0464bcd8078","date":1469530061,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = DEFAULT_RAM_BYTES_USED;\n      if (maxRamBytes != Long.MAX_VALUE) {\n        if (key != null && key instanceof Accountable) {\n          keySize = ((Accountable) key).ramBytesUsed();\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          if (key instanceof Accountable) {\n            Accountable aKey = (Accountable) key;\n            bytesToDecrement += aKey.ramBytesUsed();\n          } else {\n            bytesToDecrement += DEFAULT_RAM_BYTES_USED;\n          }\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = DEFAULT_RAM_BYTES_USED;\n      if (maxRamBytes != Long.MAX_VALUE) {\n        if (key != null && key instanceof Accountable) {\n          keySize = ((Accountable) key).ramBytesUsed();\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          if (key instanceof Accountable) {\n            Accountable aKey = (Accountable) key;\n            bytesToDecrement += aKey.ramBytesUsed();\n          } else {\n            bytesToDecrement += DEFAULT_RAM_BYTES_USED;\n          }\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = DEFAULT_RAM_BYTES_USED;\n      if (maxRamBytes != Long.MAX_VALUE) {\n        if (key != null && key instanceof Accountable) {\n          keySize = ((Accountable) key).ramBytesUsed();\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          if (key instanceof Accountable) {\n            Accountable aKey = (Accountable) key;\n            bytesToDecrement += aKey.ramBytesUsed();\n          } else {\n            bytesToDecrement += DEFAULT_RAM_BYTES_USED;\n          }\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = DEFAULT_RAM_BYTES_USED;\n      if (maxRamBytes != Long.MAX_VALUE) {\n        if (key != null && key instanceof Accountable) {\n          keySize = ((Accountable) key).ramBytesUsed();\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          if (key instanceof Accountable) {\n            Accountable aKey = (Accountable) key;\n            bytesToDecrement += aKey.ramBytesUsed();\n          } else {\n            bytesToDecrement += DEFAULT_RAM_BYTES_USED;\n          }\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = DEFAULT_RAM_BYTES_USED;\n      if (maxRamBytes != Long.MAX_VALUE) {\n        if (key != null && key instanceof Accountable) {\n          keySize = ((Accountable) key).ramBytesUsed();\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          if (key instanceof Accountable) {\n            Accountable aKey = (Accountable) key;\n            bytesToDecrement += aKey.ramBytesUsed();\n          } else {\n            bytesToDecrement += DEFAULT_RAM_BYTES_USED;\n          }\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.incrementAndGet();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = DEFAULT_RAM_BYTES_USED;\n      if (maxRamBytes != Long.MAX_VALUE) {\n        if (key != null && key instanceof Accountable) {\n          keySize = ((Accountable) key).ramBytesUsed();\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          if (key instanceof Accountable) {\n            Accountable aKey = (Accountable) key;\n            bytesToDecrement += aKey.ramBytesUsed();\n          } else {\n            bytesToDecrement += DEFAULT_RAM_BYTES_USED;\n          }\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a71ca10e7131e1f01868c80d228f26a855e79dd0","date":1562166223,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      if (maxRamBytes != Long.MAX_VALUE) {\n        long keySize = 0;\n        if (key != null) {\n          keySize = RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          bytesToDecrement += RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = DEFAULT_RAM_BYTES_USED;\n      if (maxRamBytes != Long.MAX_VALUE) {\n        if (key != null && key instanceof Accountable) {\n          keySize = ((Accountable) key).ramBytesUsed();\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          if (key instanceof Accountable) {\n            Accountable aKey = (Accountable) key;\n            bytesToDecrement += aKey.ramBytesUsed();\n          } else {\n            bytesToDecrement += DEFAULT_RAM_BYTES_USED;\n          }\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce13e934d6cfdcc82d51e85de460cf9790e97566","date":1563877281,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    if (sizeLimit == Integer.MAX_VALUE && maxRamBytes == Long.MAX_VALUE) {\n      throw new IllegalStateException(\"Cache: \" + getName() + \" has neither size nor RAM limit!\");\n    }\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n      long valueSize = RamUsageEstimator.sizeOfObject(value, QUERY_DEFAULT_RAM_BYTES_USED);\n      ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      V old = map.put(key, value);\n      if (old != null) {\n        long bytesToDecrement = RamUsageEstimator.sizeOfObject(old, QUERY_DEFAULT_RAM_BYTES_USED);\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        bytesToDecrement += RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V value) {\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      if (maxRamBytes != Long.MAX_VALUE) {\n        long keySize = 0;\n        if (key != null) {\n          keySize = RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n        }\n        long valueSize = 0;\n        if (value != null) {\n          if (value instanceof Accountable) {\n            Accountable accountable = (Accountable) value;\n            valueSize = accountable.ramBytesUsed();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Cache: \"\n                + getName() + \" is configured with maxRamBytes=\" + RamUsageEstimator.humanReadableUnits(maxRamBytes)\n                + \" but its values do not implement org.apache.lucene.util.Accountable\");\n          }\n        }\n        ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      }\n      V old = map.put(key, value);\n      if (maxRamBytes != Long.MAX_VALUE && old != null) {\n        long bytesToDecrement = ((Accountable) old).ramBytesUsed();\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        if (key != null) {\n          bytesToDecrement += RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n        }\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e33a2e75ecee8b06fba2bd570c0fb9273962bc7","date":1565791119,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    if (maxSize == Integer.MAX_VALUE && maxRamBytes == Long.MAX_VALUE) {\n      throw new IllegalStateException(\"Cache: \" + getName() + \" has neither size nor RAM limit!\");\n    }\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n      long valueSize = RamUsageEstimator.sizeOfObject(value, QUERY_DEFAULT_RAM_BYTES_USED);\n      ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      V old = map.put(key, value);\n      if (old != null) {\n        long bytesToDecrement = RamUsageEstimator.sizeOfObject(old, QUERY_DEFAULT_RAM_BYTES_USED);\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        bytesToDecrement += RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V value) {\n    if (sizeLimit == Integer.MAX_VALUE && maxRamBytes == Long.MAX_VALUE) {\n      throw new IllegalStateException(\"Cache: \" + getName() + \" has neither size nor RAM limit!\");\n    }\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n      long valueSize = RamUsageEstimator.sizeOfObject(value, QUERY_DEFAULT_RAM_BYTES_USED);\n      ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      V old = map.put(key, value);\n      if (old != null) {\n        long bytesToDecrement = RamUsageEstimator.sizeOfObject(old, QUERY_DEFAULT_RAM_BYTES_USED);\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        bytesToDecrement += RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83","date":1568645407,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V value) {\n    if (maxSize == Integer.MAX_VALUE && maxRamBytes == Long.MAX_VALUE) {\n      throw new IllegalStateException(\"Cache: \" + getName() + \" has neither size nor RAM limit!\");\n    }\n    CacheValue<V> cacheValue = new CacheValue<>(value, timeSource.getEpochTimeNs());\n    return putCacheValue(key, cacheValue);\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V value) {\n    if (maxSize == Integer.MAX_VALUE && maxRamBytes == Long.MAX_VALUE) {\n      throw new IllegalStateException(\"Cache: \" + getName() + \" has neither size nor RAM limit!\");\n    }\n    synchronized (map) {\n      if (getState() == State.LIVE) {\n        stats.inserts.increment();\n      }\n\n      // increment local inserts regardless of state???\n      // it does make it more consistent with the current size...\n      inserts++;\n\n      // important to calc and add new ram bytes first so that removeEldestEntry can compare correctly\n      long keySize = RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n      long valueSize = RamUsageEstimator.sizeOfObject(value, QUERY_DEFAULT_RAM_BYTES_USED);\n      ramBytesUsed += keySize + valueSize + LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n      V old = map.put(key, value);\n      if (old != null) {\n        long bytesToDecrement = RamUsageEstimator.sizeOfObject(old, QUERY_DEFAULT_RAM_BYTES_USED);\n        // the key existed in the map but we added its size before the put, so let's back out\n        bytesToDecrement += LINKED_HASHTABLE_RAM_BYTES_PER_ENTRY;\n        bytesToDecrement += RamUsageEstimator.sizeOfObject(key, QUERY_DEFAULT_RAM_BYTES_USED);\n        ramBytesUsed -= bytesToDecrement;\n      }\n      return old;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d7d3943904804560937e6239effeebda0f920e4","date":1573762904,"type":4,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/search/LRUCache#put(K,V).mjava","sourceNew":null,"sourceOld":"  @Override\n  public V put(K key, V value) {\n    if (maxSize == Integer.MAX_VALUE && maxRamBytes == Long.MAX_VALUE) {\n      throw new IllegalStateException(\"Cache: \" + getName() + \" has neither size nor RAM limit!\");\n    }\n    CacheValue<V> cacheValue = new CacheValue<>(value, timeSource.getEpochTimeNs());\n    return putCacheValue(key, cacheValue);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["63131741120598595ba46620adaf3fad049ca291","7530de27b87b961b51f01bd1299b7004d46e8823"],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["0e33a2e75ecee8b06fba2bd570c0fb9273962bc7"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"4d7d3943904804560937e6239effeebda0f920e4":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"a71ca10e7131e1f01868c80d228f26a855e79dd0":["bc0fbfa191179ae7a0081ee1cf7da0464bcd8078"],"bc0fbfa191179ae7a0081ee1cf7da0464bcd8078":["9d496ec5dd42f7b76312f7ba5ac6666f1ed0730d"],"63131741120598595ba46620adaf3fad049ca291":["c26f00b574427b55127e869b935845554afde1fa"],"ce13e934d6cfdcc82d51e85de460cf9790e97566":["a71ca10e7131e1f01868c80d228f26a855e79dd0"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["9d496ec5dd42f7b76312f7ba5ac6666f1ed0730d","bc0fbfa191179ae7a0081ee1cf7da0464bcd8078"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9d496ec5dd42f7b76312f7ba5ac6666f1ed0730d":["7530de27b87b961b51f01bd1299b7004d46e8823"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7530de27b87b961b51f01bd1299b7004d46e8823":["63131741120598595ba46620adaf3fad049ca291"],"0e33a2e75ecee8b06fba2bd570c0fb9273962bc7":["ce13e934d6cfdcc82d51e85de460cf9790e97566"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["9d496ec5dd42f7b76312f7ba5ac6666f1ed0730d","bc0fbfa191179ae7a0081ee1cf7da0464bcd8078"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4d7d3943904804560937e6239effeebda0f920e4"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["4d7d3943904804560937e6239effeebda0f920e4"],"c26f00b574427b55127e869b935845554afde1fa":["63131741120598595ba46620adaf3fad049ca291"],"4d7d3943904804560937e6239effeebda0f920e4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a71ca10e7131e1f01868c80d228f26a855e79dd0":["ce13e934d6cfdcc82d51e85de460cf9790e97566"],"bc0fbfa191179ae7a0081ee1cf7da0464bcd8078":["a71ca10e7131e1f01868c80d228f26a855e79dd0","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"63131741120598595ba46620adaf3fad049ca291":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","7530de27b87b961b51f01bd1299b7004d46e8823"],"ce13e934d6cfdcc82d51e85de460cf9790e97566":["0e33a2e75ecee8b06fba2bd570c0fb9273962bc7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"9d496ec5dd42f7b76312f7ba5ac6666f1ed0730d":["bc0fbfa191179ae7a0081ee1cf7da0464bcd8078","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","9d496ec5dd42f7b76312f7ba5ac6666f1ed0730d"],"0e33a2e75ecee8b06fba2bd570c0fb9273962bc7":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a258fbb26824fd104ed795e5d9033d2d040049ee","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}