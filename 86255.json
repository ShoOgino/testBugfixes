{"path":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","commits":[{"id":"aeebe27bce18b879b80f68494c52cda1021b5705","date":1417792137,"type":0,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","pathOld":"/dev/null","sourceNew":"  /** If we have term vectors, we can highlight based on payloads */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, FIELD_TYPE_TV));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singleton(\"pos: 1\".getBytes(\"UTF-8\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      Scorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, null, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb","date":1420550360,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","sourceNew":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singleton(\"pos: 1\".getBytes(\"UTF-8\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, null, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","sourceOld":"  /** If we have term vectors, we can highlight based on payloads */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, FIELD_TYPE_TV));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singleton(\"pos: 1\".getBytes(\"UTF-8\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      Scorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, null, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","sourceNew":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singleton(\"pos: 1\".getBytes(\"UTF-8\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","sourceOld":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singleton(\"pos: 1\".getBytes(\"UTF-8\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, null, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a8dd51777c3f17c83f8aac170bd0f68a029d174","date":1442220758,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","sourceNew":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singletonList(new BytesRef(\"pos: 1\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","sourceOld":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singleton(\"pos: 1\".getBytes(\"UTF-8\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d77dafd89756a5161d244985903e3487ca109182","date":1548679743,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","sourceNew":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir1)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singletonList(new BytesRef(\"pos: 1\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","sourceOld":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singletonList(new BytesRef(\"pos: 1\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","date":1574619880,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","sourceNew":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir1)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singletonList(new BytesRef(\"pos: 1\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      @SuppressWarnings(\"deprecation\")\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","sourceOld":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir1)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singletonList(new BytesRef(\"pos: 1\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9c3baacabd473e8ecd6c4948aabacead49b88e","date":1574700980,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testPayloadQuery().mjava","sourceNew":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir1)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singletonList(new BytesRef(\"pos: 1\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","sourceOld":"  /** We can highlight based on payloads. It's supported both via term vectors and MemoryIndex since Lucene 5. */\n  public void testPayloadQuery() throws IOException, InvalidTokenOffsetsException {\n    final String text = \"random words and words\";//\"words\" at positions 1 & 4\n\n    Analyzer analyzer = new MockPayloadAnalyzer();//sets payload to \"pos: X\" (where X is position #)\n    try (IndexWriter writer = new IndexWriter(dir1, new IndexWriterConfig(analyzer))) {\n      writer.deleteAll();\n      Document doc = new Document();\n\n      doc.add(new Field(FIELD_NAME, text, fieldType));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n    try (IndexReader reader = DirectoryReader.open(dir1)) {\n      Query query = new SpanPayloadCheckQuery(new SpanTermQuery(new Term(FIELD_NAME, \"words\")),\n          Collections.singletonList(new BytesRef(\"pos: 1\")));//just match the first \"word\" occurrence\n      IndexSearcher searcher = newSearcher(reader);\n      QueryScorer scorer = new QueryScorer(query, searcher.getIndexReader(), FIELD_NAME);\n      scorer.setUsePayloads(true);\n      Highlighter h = new Highlighter(scorer);\n\n      TopDocs hits = searcher.search(query, 10);\n      assertEquals(1, hits.scoreDocs.length);\n      @SuppressWarnings(\"deprecation\")\n      TokenStream stream = TokenSources.getAnyTokenStream(searcher.getIndexReader(), 0, FIELD_NAME, analyzer);\n      if (random().nextBoolean()) {\n        stream = new CachingTokenFilter(stream);//conceals detection of TokenStreamFromTermVector\n      }\n      String result = h.getBestFragment(stream, text);\n      assertEquals(\"random <B>words</B> and words\", result);//only highlight first \"word\"\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8a8dd51777c3f17c83f8aac170bd0f68a029d174":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["d77dafd89756a5161d244985903e3487ca109182"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"d77dafd89756a5161d244985903e3487ca109182":["8a8dd51777c3f17c83f8aac170bd0f68a029d174"],"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb":["aeebe27bce18b879b80f68494c52cda1021b5705"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"aeebe27bce18b879b80f68494c52cda1021b5705":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"8a8dd51777c3f17c83f8aac170bd0f68a029d174":["d77dafd89756a5161d244985903e3487ca109182"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["8a8dd51777c3f17c83f8aac170bd0f68a029d174"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["aeebe27bce18b879b80f68494c52cda1021b5705"],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d77dafd89756a5161d244985903e3487ca109182":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"aeebe27bce18b879b80f68494c52cda1021b5705":["e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}