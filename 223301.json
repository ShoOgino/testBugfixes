{"path":"solr/core/src/test/org/apache/solr/util/hll/IntegrationTestGenerator#sparseFullRepresentationTest(ISchemaVersion).mjava","commits":[{"id":"6faa211c4af605e3cf078a76d200c1dc348973f5","date":1437043657,"type":0,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/util/hll/IntegrationTestGenerator#sparseFullRepresentationTest(ISchemaVersion).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Cumulatively unions \"underpopulated\" FULL HLLs into the\n     * accumulator to verify the correct behavior from the PostgreSQL implementation.\n     * The PostgreSQL implementation's representations of probabilistic HLLs should\n     * depend exclusively on the chosen SPARSE-to-FULL cutoff.\n     *\n     * Format: cumulative union\n     * Tests:\n     * - EMPTY U \"underpopulated\" FULL => SPARSE\n     * - SPARSE U \"underpopulated\" FULL => SPARSE\n     * - SPARSE U \"barely underpopulated\" FULL => FULL\n     */\n    private static void sparseFullRepresentationTest(final ISchemaVersion schemaVersion) throws IOException {\n        final FileWriter output = openOutput(schemaVersion, \"sparse_full_representation\", TestType.UNION);\n\n        final HLL emptyHLL1 = newHLL(HLLType.EMPTY);\n        final HLL emptyHLL2 = newHLL(HLLType.EMPTY);\n\n        cumulativeUnionLine(output, emptyHLL1, emptyHLL2, schemaVersion);\n\n        // NOTE:  In this test the sparseReference will be the \"expected\" value\n        //        from the C representation, since it doesn't choose representation\n        //        based on original encoding, but rather on the promotion rules\n        //        and the declared type of the \"receiving\" field.\n        //        It is the manually-constructed union result.\n\n        // \"underpopulated\" FULL U EMPTY => SPARSE\n        final HLL fullHLL = newHLL(HLLType.FULL);\n        fullHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));\n\n        final HLL sparseHLL = newHLL(HLLType.SPARSE);\n        sparseHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));\n\n        output.write(stringCardinality(fullHLL) + \",\" + toByteA(fullHLL, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n\n        // \"underpopulated\" FULL (small) U SPARSE (small) => SPARSE\n        final HLL fullHLL2 = newHLL(HLLType.FULL);\n        fullHLL2.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));\n\n        sparseHLL.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));\n\n        output.write(stringCardinality(fullHLL2) + \",\" + toByteA(fullHLL2, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n\n        // \"underpopulated\" FULL (just on edge) U SPARSE (small) => FULL\n        final HLL fullHLL3 = newHLL(HLLType.FULL);\n        for(int i=2; i<(SPARSE_THRESHOLD + 1); i++) {\n            fullHLL3.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));\n            sparseHLL.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));\n        }\n\n        output.write(stringCardinality(fullHLL3) + \",\" + toByteA(fullHLL3, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eee9a66ccba41a876431a55e209bff48f6c894f9","date":1437045967,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/util/hll/IntegrationTestGenerator#sparseFullRepresentationTest(ISchemaVersion).mjava","pathOld":"solr/core/src/test/org/apache/solr/util/hll/IntegrationTestGenerator#sparseFullRepresentationTest(ISchemaVersion).mjava","sourceNew":"    /**\n     * Cumulatively unions \"underpopulated\" FULL HLLs into the\n     * accumulator to verify the correct behavior from the PostgreSQL implementation.\n     * The PostgreSQL implementation's representations of probabilistic HLLs should\n     * depend exclusively on the chosen SPARSE-to-FULL cutoff.\n     *\n     * Format: cumulative union\n     * Tests:\n     * - EMPTY U \"underpopulated\" FULL => SPARSE\n     * - SPARSE U \"underpopulated\" FULL => SPARSE\n     * - SPARSE U \"barely underpopulated\" FULL => FULL\n     */\n    private static void sparseFullRepresentationTest(final ISchemaVersion schemaVersion) throws IOException {\n        final Writer output = openOutput(schemaVersion, \"sparse_full_representation\", TestType.UNION);\n\n        final HLL emptyHLL1 = newHLL(HLLType.EMPTY);\n        final HLL emptyHLL2 = newHLL(HLLType.EMPTY);\n\n        cumulativeUnionLine(output, emptyHLL1, emptyHLL2, schemaVersion);\n\n        // NOTE:  In this test the sparseReference will be the \"expected\" value\n        //        from the C representation, since it doesn't choose representation\n        //        based on original encoding, but rather on the promotion rules\n        //        and the declared type of the \"receiving\" field.\n        //        It is the manually-constructed union result.\n\n        // \"underpopulated\" FULL U EMPTY => SPARSE\n        final HLL fullHLL = newHLL(HLLType.FULL);\n        fullHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));\n\n        final HLL sparseHLL = newHLL(HLLType.SPARSE);\n        sparseHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));\n\n        output.write(stringCardinality(fullHLL) + \",\" + toByteA(fullHLL, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n\n        // \"underpopulated\" FULL (small) U SPARSE (small) => SPARSE\n        final HLL fullHLL2 = newHLL(HLLType.FULL);\n        fullHLL2.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));\n\n        sparseHLL.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));\n\n        output.write(stringCardinality(fullHLL2) + \",\" + toByteA(fullHLL2, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n\n        // \"underpopulated\" FULL (just on edge) U SPARSE (small) => FULL\n        final HLL fullHLL3 = newHLL(HLLType.FULL);\n        for(int i=2; i<(SPARSE_THRESHOLD + 1); i++) {\n            fullHLL3.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));\n            sparseHLL.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));\n        }\n\n        output.write(stringCardinality(fullHLL3) + \",\" + toByteA(fullHLL3, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n    }\n\n","sourceOld":"    /**\n     * Cumulatively unions \"underpopulated\" FULL HLLs into the\n     * accumulator to verify the correct behavior from the PostgreSQL implementation.\n     * The PostgreSQL implementation's representations of probabilistic HLLs should\n     * depend exclusively on the chosen SPARSE-to-FULL cutoff.\n     *\n     * Format: cumulative union\n     * Tests:\n     * - EMPTY U \"underpopulated\" FULL => SPARSE\n     * - SPARSE U \"underpopulated\" FULL => SPARSE\n     * - SPARSE U \"barely underpopulated\" FULL => FULL\n     */\n    private static void sparseFullRepresentationTest(final ISchemaVersion schemaVersion) throws IOException {\n        final FileWriter output = openOutput(schemaVersion, \"sparse_full_representation\", TestType.UNION);\n\n        final HLL emptyHLL1 = newHLL(HLLType.EMPTY);\n        final HLL emptyHLL2 = newHLL(HLLType.EMPTY);\n\n        cumulativeUnionLine(output, emptyHLL1, emptyHLL2, schemaVersion);\n\n        // NOTE:  In this test the sparseReference will be the \"expected\" value\n        //        from the C representation, since it doesn't choose representation\n        //        based on original encoding, but rather on the promotion rules\n        //        and the declared type of the \"receiving\" field.\n        //        It is the manually-constructed union result.\n\n        // \"underpopulated\" FULL U EMPTY => SPARSE\n        final HLL fullHLL = newHLL(HLLType.FULL);\n        fullHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));\n\n        final HLL sparseHLL = newHLL(HLLType.SPARSE);\n        sparseHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));\n\n        output.write(stringCardinality(fullHLL) + \",\" + toByteA(fullHLL, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n\n        // \"underpopulated\" FULL (small) U SPARSE (small) => SPARSE\n        final HLL fullHLL2 = newHLL(HLLType.FULL);\n        fullHLL2.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));\n\n        sparseHLL.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));\n\n        output.write(stringCardinality(fullHLL2) + \",\" + toByteA(fullHLL2, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n\n        // \"underpopulated\" FULL (just on edge) U SPARSE (small) => FULL\n        final HLL fullHLL3 = newHLL(HLLType.FULL);\n        for(int i=2; i<(SPARSE_THRESHOLD + 1); i++) {\n            fullHLL3.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));\n            sparseHLL.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));\n        }\n\n        output.write(stringCardinality(fullHLL3) + \",\" + toByteA(fullHLL3, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b5ee4c66244bdfcc4796a114519d47701b2c026","date":1437132013,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/util/hll/IntegrationTestGenerator#sparseFullRepresentationTest(ISchemaVersion).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Cumulatively unions \"underpopulated\" FULL HLLs into the\n     * accumulator to verify the correct behavior from the PostgreSQL implementation.\n     * The PostgreSQL implementation's representations of probabilistic HLLs should\n     * depend exclusively on the chosen SPARSE-to-FULL cutoff.\n     *\n     * Format: cumulative union\n     * Tests:\n     * - EMPTY U \"underpopulated\" FULL => SPARSE\n     * - SPARSE U \"underpopulated\" FULL => SPARSE\n     * - SPARSE U \"barely underpopulated\" FULL => FULL\n     */\n    private static void sparseFullRepresentationTest(final ISchemaVersion schemaVersion) throws IOException {\n        final Writer output = openOutput(schemaVersion, \"sparse_full_representation\", TestType.UNION);\n\n        final HLL emptyHLL1 = newHLL(HLLType.EMPTY);\n        final HLL emptyHLL2 = newHLL(HLLType.EMPTY);\n\n        cumulativeUnionLine(output, emptyHLL1, emptyHLL2, schemaVersion);\n\n        // NOTE:  In this test the sparseReference will be the \"expected\" value\n        //        from the C representation, since it doesn't choose representation\n        //        based on original encoding, but rather on the promotion rules\n        //        and the declared type of the \"receiving\" field.\n        //        It is the manually-constructed union result.\n\n        // \"underpopulated\" FULL U EMPTY => SPARSE\n        final HLL fullHLL = newHLL(HLLType.FULL);\n        fullHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));\n\n        final HLL sparseHLL = newHLL(HLLType.SPARSE);\n        sparseHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));\n\n        output.write(stringCardinality(fullHLL) + \",\" + toByteA(fullHLL, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n\n        // \"underpopulated\" FULL (small) U SPARSE (small) => SPARSE\n        final HLL fullHLL2 = newHLL(HLLType.FULL);\n        fullHLL2.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));\n\n        sparseHLL.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));\n\n        output.write(stringCardinality(fullHLL2) + \",\" + toByteA(fullHLL2, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n\n        // \"underpopulated\" FULL (just on edge) U SPARSE (small) => FULL\n        final HLL fullHLL3 = newHLL(HLLType.FULL);\n        for(int i=2; i<(SPARSE_THRESHOLD + 1); i++) {\n            fullHLL3.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));\n            sparseHLL.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));\n        }\n\n        output.write(stringCardinality(fullHLL3) + \",\" + toByteA(fullHLL3, schemaVersion) + \",\" + stringCardinality(sparseHLL) + \",\" + toByteA(sparseHLL, schemaVersion) + \"\\n\");\n        output.flush();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"eee9a66ccba41a876431a55e209bff48f6c894f9":["6faa211c4af605e3cf078a76d200c1dc348973f5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3b5ee4c66244bdfcc4796a114519d47701b2c026":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eee9a66ccba41a876431a55e209bff48f6c894f9"],"6faa211c4af605e3cf078a76d200c1dc348973f5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3b5ee4c66244bdfcc4796a114519d47701b2c026"]},"commit2Childs":{"eee9a66ccba41a876431a55e209bff48f6c894f9":["3b5ee4c66244bdfcc4796a114519d47701b2c026"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3b5ee4c66244bdfcc4796a114519d47701b2c026","6faa211c4af605e3cf078a76d200c1dc348973f5"],"3b5ee4c66244bdfcc4796a114519d47701b2c026":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6faa211c4af605e3cf078a76d200c1dc348973f5":["eee9a66ccba41a876431a55e209bff48f6c894f9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}