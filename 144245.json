{"path":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":null,"sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46ef60ed435c177f354fed8fc6a6537bcac2e6e9","date":1288529107,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":["b7326b9db90075ac88781359aefe6fccd60f9b8f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5871a631b6817f1cef161749ceffdc037e67558a","date":1291133429,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":["4d4f1b2c5601680b01c4bb95a43fe6fb73f03103"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7326b9db90075ac88781359aefe6fccd60f9b8f","date":1297897301,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","bugFix":["46ef60ed435c177f354fed8fc6a6537bcac2e6e9"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.put(row.get(entity.getPk()).toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      // Remove deleted rows from the delta rows\n      String deletedRowPk = row.get(entity.getPk()).toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Map<String, Map<String, Object>> deltaSet = new HashMap<String, Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    String pk = entity.getPk();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      deltaSet.put(pkValue.toString(), row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      deletedSet.add(row);\n      \n      Object pkValue = row.get(pk);\n      if (pkValue == null) {\n        pk = findMatchingPkColumn(pk, row);\n        pkValue = row.get(pk);\n      }\n\n      // Remove deleted rows from the delta rows\n      String deletedRowPk = pkValue.toString();\n      if (deltaSet.containsKey(deletedRowPk)) {\n        deltaSet.remove(deletedRowPk);\n      }\n\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet.values());\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    // Do not use entity.isDocRoot here because one of descendant entities may set rootEntity=\"true\"\n    return entity.parentEntity == null ?\n        myModifiedPks : new HashSet<Map<String, Object>>(parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"46ef60ed435c177f354fed8fc6a6537bcac2e6e9":["1da8d55113b689b06716246649de6f62430f15c0"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["3bb13258feba31ab676502787ab2e1779f129b7a","b7326b9db90075ac88781359aefe6fccd60f9b8f"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["b7326b9db90075ac88781359aefe6fccd60f9b8f","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"85a883878c0af761245ab048babc63d099f835f3":["1da8d55113b689b06716246649de6f62430f15c0","46ef60ed435c177f354fed8fc6a6537bcac2e6e9"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["1da8d55113b689b06716246649de6f62430f15c0","5871a631b6817f1cef161749ceffdc037e67558a"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"5871a631b6817f1cef161749ceffdc037e67558a":["46ef60ed435c177f354fed8fc6a6537bcac2e6e9"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["b7326b9db90075ac88781359aefe6fccd60f9b8f","b7326b9db90075ac88781359aefe6fccd60f9b8f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"b7326b9db90075ac88781359aefe6fccd60f9b8f":["5871a631b6817f1cef161749ceffdc037e67558a"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b7326b9db90075ac88781359aefe6fccd60f9b8f"],"3bb13258feba31ab676502787ab2e1779f129b7a":["85a883878c0af761245ab048babc63d099f835f3","5871a631b6817f1cef161749ceffdc037e67558a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"46ef60ed435c177f354fed8fc6a6537bcac2e6e9":["85a883878c0af761245ab048babc63d099f835f3","5871a631b6817f1cef161749ceffdc037e67558a"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"85a883878c0af761245ab048babc63d099f835f3":["3bb13258feba31ab676502787ab2e1779f129b7a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"1da8d55113b689b06716246649de6f62430f15c0":["46ef60ed435c177f354fed8fc6a6537bcac2e6e9","85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["c26f00b574427b55127e869b935845554afde1fa"],"5871a631b6817f1cef161749ceffdc037e67558a":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b7326b9db90075ac88781359aefe6fccd60f9b8f","3bb13258feba31ab676502787ab2e1779f129b7a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"3bb13258feba31ab676502787ab2e1779f129b7a":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"b7326b9db90075ac88781359aefe6fccd60f9b8f":["f1bdbf92da222965b46c0a942c3857ba56e5c638","c26f00b574427b55127e869b935845554afde1fa","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}