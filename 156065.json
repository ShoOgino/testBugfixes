{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","commits":[{"id":"3955a9511098c96b652734b2f2d4160d07cc2d63","date":1504780677,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    try (CloudSolrClient cloudSolrClient = new CloudSolrClient.Builder()\n        .withClusterStateProvider(new ZkClientClusterStateProvider(container.getZkController().getZkStateReader()))\n        .build()) {\n\n      SolrClientDataProvider dataProvider = new SolrClientDataProvider(cloudSolrClient);\n\n      for (String node : dataProvider.getNodes()) {\n        Map<String, ReplicaInfo> metricTags = new HashMap<>();\n        // coll, shard, replica\n        Map<String, Map<String, List<ReplicaInfo>>> infos = dataProvider.getReplicaInfo(node, Collections.emptyList());\n        infos.forEach((coll, shards) -> {\n          shards.forEach((sh, replicas) -> {\n            replicas.forEach(replica -> {\n              // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n              String replicaName = SolrCoreMetricManager.parseReplicaName(coll, replica.getCore());\n              if (replicaName == null) { // should never happen???\n                replicaName = replica.getName(); // which is actually coreNode name...\n              }\n              String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n              String tag = \"metrics:\" + registry\n                  + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n              metricTags.put(tag, replica);\n            });\n          });\n        });\n        Map<String, Object> rates = dataProvider.getNodeValues(node, metricTags.keySet());\n        rates.forEach((tag, rate) -> {\n          ReplicaInfo info = metricTags.get(tag);\n          if (info == null) {\n            log.warn(\"Missing replica info for response tag \" + tag);\n          } else {\n            Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n            List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n            info.getVariables().put(AutoScalingParams.RATE, rate);\n            perShard.add(info);\n            AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n            perNode.addAndGet((Double)rate);\n          }\n        });\n      }\n    } catch (IOException e) {\n      log.warn(\"Exception getting node values\", e);\n      return;\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cc58dbf9573e66a3054c7c372862b8e5a77a9da","date":1504796681,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    try (CloudSolrClient cloudSolrClient = new CloudSolrClient.Builder()\n        .withClusterStateProvider(new ZkClientClusterStateProvider(container.getZkController().getZkStateReader()))\n        .build()) {\n\n      SolrClientDataProvider dataProvider = new SolrClientDataProvider(cloudSolrClient);\n\n      for (String node : dataProvider.getNodes()) {\n        Map<String, ReplicaInfo> metricTags = new HashMap<>();\n        // coll, shard, replica\n        Map<String, Map<String, List<ReplicaInfo>>> infos = dataProvider.getReplicaInfo(node, Collections.emptyList());\n        infos.forEach((coll, shards) -> {\n          shards.forEach((sh, replicas) -> {\n            replicas.forEach(replica -> {\n              // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n              String replicaName = SolrCoreMetricManager.parseReplicaName(coll, replica.getCore());\n              if (replicaName == null) { // should never happen???\n                replicaName = replica.getName(); // which is actually coreNode name...\n              }\n              String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n              String tag = \"metrics:\" + registry\n                  + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n              metricTags.put(tag, replica);\n            });\n          });\n        });\n        Map<String, Object> rates = dataProvider.getNodeValues(node, metricTags.keySet());\n        rates.forEach((tag, rate) -> {\n          ReplicaInfo info = metricTags.get(tag);\n          if (info == null) {\n            log.warn(\"Missing replica info for response tag \" + tag);\n          } else {\n            Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n            List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n            info.getVariables().put(AutoScalingParams.RATE, rate);\n            perShard.add(info);\n            AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n            perNode.addAndGet((Double)rate);\n          }\n        });\n      }\n    } catch (IOException e) {\n      log.warn(\"Exception getting node values\", e);\n      return;\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, String> warmShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      final Object[] warmShard = new Object[2];\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (warmShard[0] == null) {\n          warmShard[0] = sh;\n          warmShard[1] = shardRate;\n        }\n        if (shardRate > (double)warmShard[1]) {\n          warmShard[0] = sh;\n          warmShard[1] = shardRate;\n        }\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n      warmShards.put(coll, (String)warmShard[0]);\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shRates) -> {\n      double total = shRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas, warmShards))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    try (CloudSolrClient cloudSolrClient = new CloudSolrClient.Builder()\n        .withClusterStateProvider(new ZkClientClusterStateProvider(container.getZkController().getZkStateReader()))\n        .build()) {\n\n      SolrClientDataProvider dataProvider = new SolrClientDataProvider(cloudSolrClient);\n\n      for (String node : dataProvider.getNodes()) {\n        Map<String, ReplicaInfo> metricTags = new HashMap<>();\n        // coll, shard, replica\n        Map<String, Map<String, List<ReplicaInfo>>> infos = dataProvider.getReplicaInfo(node, Collections.emptyList());\n        infos.forEach((coll, shards) -> {\n          shards.forEach((sh, replicas) -> {\n            replicas.forEach(replica -> {\n              // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n              String replicaName = SolrCoreMetricManager.parseReplicaName(coll, replica.getCore());\n              if (replicaName == null) { // should never happen???\n                replicaName = replica.getName(); // which is actually coreNode name...\n              }\n              String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n              String tag = \"metrics:\" + registry\n                  + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n              metricTags.put(tag, replica);\n            });\n          });\n        });\n        Map<String, Object> rates = dataProvider.getNodeValues(node, metricTags.keySet());\n        rates.forEach((tag, rate) -> {\n          ReplicaInfo info = metricTags.get(tag);\n          if (info == null) {\n            log.warn(\"Missing replica info for response tag \" + tag);\n          } else {\n            Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n            List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n            info.getVariables().put(AutoScalingParams.RATE, rate);\n            perShard.add(info);\n            AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n            perNode.addAndGet((Double)rate);\n          }\n        });\n      }\n    } catch (IOException e) {\n      log.warn(\"Exception getting node values\", e);\n      return;\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e412fed1b23292038553fbe85fe61cd7aa8472","date":1505751927,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    try (CloudSolrClient cloudSolrClient = new CloudSolrClient.Builder()\n        .withClusterStateProvider(new ZkClientClusterStateProvider(container.getZkController().getZkStateReader()))\n        .build()) {\n\n      SolrClientDataProvider dataProvider = new SolrClientDataProvider(cloudSolrClient);\n\n      for (String node : dataProvider.getNodes()) {\n        Map<String, ReplicaInfo> metricTags = new HashMap<>();\n        // coll, shard, replica\n        Map<String, Map<String, List<ReplicaInfo>>> infos = dataProvider.getReplicaInfo(node, Collections.emptyList());\n        infos.forEach((coll, shards) -> {\n          shards.forEach((sh, replicas) -> {\n            replicas.forEach(replica -> {\n              // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n              String replicaName = SolrCoreMetricManager.parseReplicaName(coll, replica.getCore());\n              if (replicaName == null) { // should never happen???\n                replicaName = replica.getName(); // which is actually coreNode name...\n              }\n              String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n              String tag = \"metrics:\" + registry\n                  + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n              metricTags.put(tag, replica);\n            });\n          });\n        });\n        Map<String, Object> rates = dataProvider.getNodeValues(node, metricTags.keySet());\n        rates.forEach((tag, rate) -> {\n          ReplicaInfo info = metricTags.get(tag);\n          if (info == null) {\n            log.warn(\"Missing replica info for response tag \" + tag);\n          } else {\n            Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n            List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n            info.getVariables().put(AutoScalingParams.RATE, rate);\n            perShard.add(info);\n            AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n            perNode.addAndGet((Double)rate);\n          }\n        });\n      }\n    } catch (IOException e) {\n      log.warn(\"Exception getting node values\", e);\n      return;\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    try (CloudSolrClient cloudSolrClient = new CloudSolrClient.Builder()\n        .withClusterStateProvider(new ZkClientClusterStateProvider(container.getZkController().getZkStateReader()))\n        .build()) {\n\n      SolrClientDataProvider dataProvider = new SolrClientDataProvider(cloudSolrClient);\n\n      for (String node : dataProvider.getNodes()) {\n        Map<String, ReplicaInfo> metricTags = new HashMap<>();\n        // coll, shard, replica\n        Map<String, Map<String, List<ReplicaInfo>>> infos = dataProvider.getReplicaInfo(node, Collections.emptyList());\n        infos.forEach((coll, shards) -> {\n          shards.forEach((sh, replicas) -> {\n            replicas.forEach(replica -> {\n              // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n              String replicaName = SolrCoreMetricManager.parseReplicaName(coll, replica.getCore());\n              if (replicaName == null) { // should never happen???\n                replicaName = replica.getName(); // which is actually coreNode name...\n              }\n              String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n              String tag = \"metrics:\" + registry\n                  + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n              metricTags.put(tag, replica);\n            });\n          });\n        });\n        Map<String, Object> rates = dataProvider.getNodeValues(node, metricTags.keySet());\n        rates.forEach((tag, rate) -> {\n          ReplicaInfo info = metricTags.get(tag);\n          if (info == null) {\n            log.warn(\"Missing replica info for response tag \" + tag);\n          } else {\n            Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n            List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n            info.getVariables().put(AutoScalingParams.RATE, rate);\n            perShard.add(info);\n            AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n            perNode.addAndGet((Double)rate);\n          }\n        });\n      }\n    } catch (IOException e) {\n      log.warn(\"Exception getting node values\", e);\n      return;\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, String> warmShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      final Object[] warmShard = new Object[2];\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (warmShard[0] == null) {\n          warmShard[0] = sh;\n          warmShard[1] = shardRate;\n        }\n        if (shardRate > (double)warmShard[1]) {\n          warmShard[0] = sh;\n          warmShard[1] = shardRate;\n        }\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n      warmShards.put(coll, (String)warmShard[0]);\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shRates) -> {\n      double total = shRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas, warmShards))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4f2ba631afa835c2dfd14555cf19ae7e73663c17","date":1505762504,"type":4,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":null,"sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    try (CloudSolrClient cloudSolrClient = new CloudSolrClient.Builder()\n        .withClusterStateProvider(new ZkClientClusterStateProvider(container.getZkController().getZkStateReader()))\n        .build()) {\n\n      SolrClientDataProvider dataProvider = new SolrClientDataProvider(cloudSolrClient);\n\n      for (String node : dataProvider.getNodes()) {\n        Map<String, ReplicaInfo> metricTags = new HashMap<>();\n        // coll, shard, replica\n        Map<String, Map<String, List<ReplicaInfo>>> infos = dataProvider.getReplicaInfo(node, Collections.emptyList());\n        infos.forEach((coll, shards) -> {\n          shards.forEach((sh, replicas) -> {\n            replicas.forEach(replica -> {\n              // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n              String replicaName = SolrCoreMetricManager.parseReplicaName(coll, replica.getCore());\n              if (replicaName == null) { // should never happen???\n                replicaName = replica.getName(); // which is actually coreNode name...\n              }\n              String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n              String tag = \"metrics:\" + registry\n                  + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n              metricTags.put(tag, replica);\n            });\n          });\n        });\n        Map<String, Object> rates = dataProvider.getNodeValues(node, metricTags.keySet());\n        rates.forEach((tag, rate) -> {\n          ReplicaInfo info = metricTags.get(tag);\n          if (info == null) {\n            log.warn(\"Missing replica info for response tag \" + tag);\n          } else {\n            Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n            List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n            info.getVariables().put(AutoScalingParams.RATE, rate);\n            perShard.add(info);\n            AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n            perNode.addAndGet((Double)rate);\n          }\n        });\n      }\n    } catch (IOException e) {\n      log.warn(\"Exception getting node values\", e);\n      return;\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3f354f2175f861ee625bb3c9572d53b77cd8545","date":1508405819,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7d7cf463e12b13965d63f133adc46a1c673d0c4e","date":1509636749,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    if (processor.process(new SearchRateEvent(getName(), now, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = timeSource.getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9ccfe45460d496c5e5e1b70396521dac842d966","date":1516798975,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43a787a75ad72a9bf26e8ff714d8b6d01f9eb441","date":1516881857,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4412883c12067d8a4e2a354aa8adc58c32be1d6","date":1521129281,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","date":1523453934,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43345f1452f9510f8aaadae6156fe0c834e7d957","date":1523483670,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info.getVariables().put(AutoScalingParams.RATE, rate);\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet((Double)rate);\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c0b90ab8b228b1f7a05d5ddfbe879ce962d8964a","date":1524514741,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    // collection, shard, list(replica + rate)\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    // node, rate\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    // this replication factor only considers replica types that are searchable\n    // collection, shard, RF\n    Map<String, Map<String, AtomicInteger>> searchableReplicationFactors = new HashMap<>();\n\n    ClusterState clusterState = null;\n    try {\n      clusterState = cloudManager.getClusterStateProvider().getClusterState();\n    } catch (IOException e) {\n      log.warn(\"Error getting ClusterState\", e);\n      return;\n    }\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        Map<String, AtomicInteger> replPerShard = searchableReplicationFactors.computeIfAbsent(coll, c -> new HashMap<>());\n        shards.forEach((sh, replicas) -> {\n          AtomicInteger repl = replPerShard.computeIfAbsent(sh, s -> new AtomicInteger());\n          replicas.forEach(replica -> {\n            // skip non-active replicas\n            if (replica.getState() != Replica.State.ACTIVE) {\n              return;\n            }\n            repl.incrementAndGet();\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry + \":\" + metric;\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    Map<String, Double> hotNodes = new HashMap<>();\n    Map<String, Double> coldNodes = new HashMap<>();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .forEach(entry -> {\n          if (entry.getValue().get() > aboveRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              hotNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else if (entry.getValue().get() < belowRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              coldNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            // (violation is only valid if it persists throughout waitFor)\n            lastNodeEvent.remove(entry.getKey());\n          }\n        });\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, Map<String, Double>> coldShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    List<ReplicaInfo> coldReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              String elapsedKey = r.getCollection() + \".\" + r.getCore();\n              if ((Double)r.getVariable(AutoScalingParams.RATE) > aboveRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  hotReplicas.add(r);\n                }\n              } else if ((Double)r.getVariable(AutoScalingParams.RATE) < belowRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  coldReplicas.add(r);\n                }\n              } else {\n                // no violation - clear waitForElapsed\n                lastReplicaEvent.remove(elapsedKey);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        String elapsedKey = coll + \".\" + sh;\n        if ((collections.isEmpty() || collections.contains(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          if (shardRate > aboveRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else if (shardRate < belowRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              coldShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            lastShardEvent.remove(elapsedKey);\n          }\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    Map<String, Double> coldCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (collections.isEmpty() || collections.contains(coll)) {\n        if (total > aboveRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            hotCollections.put(coll, total);\n          }\n        } else if (total < belowRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            coldCollections.put(coll, total);\n          }\n        } else {\n          // no violation - clear waitForElapsed\n          lastCollectionEvent.remove(coll);\n        }\n      }\n    });\n\n    if (hotCollections.isEmpty() &&\n        hotShards.isEmpty() &&\n        hotReplicas.isEmpty() &&\n        hotNodes.isEmpty() &&\n        coldCollections.isEmpty() &&\n        coldShards.isEmpty() &&\n        coldReplicas.isEmpty() &&\n        coldNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    coldShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n\n    calculateHotOps(ops, searchableReplicationFactors, hotNodes, hotCollections, hotShards, hotReplicas);\n    calculateColdOps(ops, clusterState, searchableReplicationFactors, coldNodes, coldCollections, coldShards, coldReplicas);\n\n    if (ops.isEmpty()) {\n      return;\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops,\n        hotNodes, hotCollections, hotShards, hotReplicas,\n        coldNodes, coldCollections, coldShards, coldReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      coldNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      coldCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      coldShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n      coldReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    Map<String, Integer> replicationFactors = new HashMap<>();\n\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        replicationFactors.computeIfAbsent(coll, c -> shards.size());\n        shards.forEach((sh, replicas) -> {\n          replicas.forEach(replica -> {\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry\n                + \":QUERY.\" + handler + \".requestTimes:1minRate\";\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Double> hotNodes = nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> entry.getValue().get() > rate)\n        .collect(Collectors.toMap(entry -> entry.getKey(), entry -> entry.getValue().get()));\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              if (waitForElapsed(r.getCollection() + \".\" + r.getCore(), now, lastReplicaEvent) &&\n                  ((Double)r.getVariable(AutoScalingParams.RATE) > rate)) {\n                hotReplicas.add(r);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        if (waitForElapsed(coll + \".\" + sh, now, lastShardEvent) &&\n            (shardRate > rate) &&\n            (collection.equals(Policy.ANY) || collection.equals(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (waitForElapsed(coll, now, lastCollectionEvent) &&\n          (total > rate) &&\n          (collection.equals(Policy.ANY) || collection.equals(coll))) {\n        hotCollections.put(coll, total);\n      }\n    });\n\n    if (hotCollections.isEmpty() && hotShards.isEmpty() && hotReplicas.isEmpty() && hotNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    // calculate the number of replicas to add to each hot shard, based on how much the rate was\n    // exceeded - but within limits.\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    if (hotShards.isEmpty() && hotCollections.isEmpty() && hotReplicas.isEmpty()) {\n      // move replicas around\n      hotNodes.forEach((n, r) -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.MOVEREPLICA, Suggester.Hint.SRC_NODE, n));\n      });\n    } else {\n      // add replicas\n      Map<String, Map<String, List<Pair<String, String>>>> hints = new HashMap<>();\n\n      hotShards.forEach((coll, shards) -> shards.forEach((s, r) -> {\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(coll, c -> new HashMap<>())\n            .computeIfAbsent(s, sh -> new ArrayList<>());\n        addHints(coll, s, r, replicationFactors.get(coll), perShard);\n      }));\n      hotReplicas.forEach(ri -> {\n        double r = (Double)ri.getVariable(AutoScalingParams.RATE);\n        // add only if not already accounted for in hotShards\n        List<Pair<String, String>> perShard = hints\n            .computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n            .computeIfAbsent(ri.getShard(), sh -> new ArrayList<>());\n        if (perShard.isEmpty()) {\n          addHints(ri.getCollection(), ri.getShard(), r, replicationFactors.get(ri.getCollection()), perShard);\n        }\n      });\n\n      hints.values().forEach(m -> m.values().forEach(lst -> lst.forEach(p -> {\n        ops.add(new TriggerEvent.Op(CollectionParams.CollectionAction.ADDREPLICA, Suggester.Hint.COLL_SHARD, p));\n      })));\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops, hotNodes, hotCollections, hotShards, hotReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"042b92cf48996255bedb0c3c4bf772d7e06e4dea","date":1534272102,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    // collection, shard, list(replica + rate)\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    // node, rate\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    // this replication factor only considers replica types that are searchable\n    // collection, shard, RF\n    Map<String, Map<String, AtomicInteger>> searchableReplicationFactors = new HashMap<>();\n\n    ClusterState clusterState = null;\n    try {\n      clusterState = cloudManager.getClusterStateProvider().getClusterState();\n    } catch (IOException e) {\n      log.warn(\"Error getting ClusterState\", e);\n      return;\n    }\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        Map<String, AtomicInteger> replPerShard = searchableReplicationFactors.computeIfAbsent(coll, c -> new HashMap<>());\n        shards.forEach((sh, replicas) -> {\n          AtomicInteger repl = replPerShard.computeIfAbsent(sh, s -> new AtomicInteger());\n          replicas.forEach(replica -> {\n            // skip non-active replicas\n            if (replica.getState() != Replica.State.ACTIVE) {\n              return;\n            }\n            repl.incrementAndGet();\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry + \":\" + metric;\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      if (log.isDebugEnabled()) {\n        log.debug(\"### rates for node \" + node);\n        rates.forEach((tag, rate) -> log.debug(\"###  \" + tag + \"\\t\" + rate));\n      }\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    if (log.isDebugEnabled()) {\n      collectionRates.forEach((coll, collRates) -> {\n        log.debug(\"## Collection: {}\", coll);\n        collRates.forEach((s, replicas) -> {\n          log.debug(\"##  - {}\", s);\n          replicas.forEach(ri -> log.debug(\"##     {}  {}\", ri.getCore(), ri.getVariable(AutoScalingParams.RATE)));\n        });\n      });\n    }\n    long now = cloudManager.getTimeSource().getTimeNs();\n    Map<String, Double> hotNodes = new HashMap<>();\n    Map<String, Double> coldNodes = new HashMap<>();\n\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .forEach(entry -> {\n          if (entry.getValue().get() > aboveNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              hotNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else if (entry.getValue().get() < belowNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              coldNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            // (violation is only valid if it persists throughout waitFor)\n            lastNodeEvent.remove(entry.getKey());\n          }\n        });\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, Map<String, Double>> coldShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    List<ReplicaInfo> coldReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double totalShardRate = replicaRates.stream()\n            .map(r -> {\n              String elapsedKey = r.getCollection() + \".\" + r.getCore();\n              if ((Double)r.getVariable(AutoScalingParams.RATE) > aboveRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  hotReplicas.add(r);\n                }\n              } else if ((Double)r.getVariable(AutoScalingParams.RATE) < belowRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  coldReplicas.add(r);\n                }\n              } else {\n                // no violation - clear waitForElapsed\n                lastReplicaEvent.remove(elapsedKey);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        // calculate average shard rate over all searchable replicas (see SOLR-12470)\n        double shardRate = totalShardRate / searchableReplicationFactors.get(coll).get(sh).doubleValue();\n        String elapsedKey = coll + \".\" + sh;\n        log.debug(\"-- {}: totalShardRate={}, shardRate={}\", elapsedKey, totalShardRate, shardRate);\n        if ((collections.isEmpty() || collections.contains(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          if (shardRate > aboveRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else if (shardRate < belowRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              coldShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n              log.debug(\"-- coldShard waitFor elapsed {}\", elapsedKey);\n            } else {\n              if (log.isDebugEnabled()) {\n                Long lastTime = lastShardEvent.computeIfAbsent(elapsedKey, s -> now);\n                long elapsed = TimeUnit.SECONDS.convert(now - lastTime, TimeUnit.NANOSECONDS);\n                log.debug(\"-- waitFor didn't elapse for {}, waitFor={}, elapsed={}\", elapsedKey, getWaitForSecond(), elapsed);\n              }\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            lastShardEvent.remove(elapsedKey);\n          }\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    Map<String, Double> coldCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (collections.isEmpty() || collections.contains(coll)) {\n        if (total > aboveRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            hotCollections.put(coll, total);\n          }\n        } else if (total < belowRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            coldCollections.put(coll, total);\n          }\n        } else {\n          // no violation - clear waitForElapsed\n          lastCollectionEvent.remove(coll);\n        }\n      }\n    });\n\n    if (hotCollections.isEmpty() &&\n        hotShards.isEmpty() &&\n        hotReplicas.isEmpty() &&\n        hotNodes.isEmpty() &&\n        coldCollections.isEmpty() &&\n        coldShards.isEmpty() &&\n        coldReplicas.isEmpty() &&\n        coldNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    coldShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    final Set<String> violations = new HashSet<>();\n\n    calculateHotOps(ops, violations, searchableReplicationFactors, hotNodes, hotCollections, hotShards, hotReplicas);\n    calculateColdOps(ops, violations, clusterState, searchableReplicationFactors, coldNodes, coldCollections, coldShards, coldReplicas);\n\n    if (ops.isEmpty()) {\n      return;\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops,\n        hotNodes, hotCollections, hotShards, hotReplicas,\n        coldNodes, coldCollections, coldShards, coldReplicas, violations))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      coldNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      coldCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      coldShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n      coldReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    // collection, shard, list(replica + rate)\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    // node, rate\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    // this replication factor only considers replica types that are searchable\n    // collection, shard, RF\n    Map<String, Map<String, AtomicInteger>> searchableReplicationFactors = new HashMap<>();\n\n    ClusterState clusterState = null;\n    try {\n      clusterState = cloudManager.getClusterStateProvider().getClusterState();\n    } catch (IOException e) {\n      log.warn(\"Error getting ClusterState\", e);\n      return;\n    }\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        Map<String, AtomicInteger> replPerShard = searchableReplicationFactors.computeIfAbsent(coll, c -> new HashMap<>());\n        shards.forEach((sh, replicas) -> {\n          AtomicInteger repl = replPerShard.computeIfAbsent(sh, s -> new AtomicInteger());\n          replicas.forEach(replica -> {\n            // skip non-active replicas\n            if (replica.getState() != Replica.State.ACTIVE) {\n              return;\n            }\n            repl.incrementAndGet();\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry + \":\" + metric;\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    Map<String, Double> hotNodes = new HashMap<>();\n    Map<String, Double> coldNodes = new HashMap<>();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .forEach(entry -> {\n          if (entry.getValue().get() > aboveRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              hotNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else if (entry.getValue().get() < belowRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              coldNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            // (violation is only valid if it persists throughout waitFor)\n            lastNodeEvent.remove(entry.getKey());\n          }\n        });\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, Map<String, Double>> coldShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    List<ReplicaInfo> coldReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double shardRate = replicaRates.stream()\n            .map(r -> {\n              String elapsedKey = r.getCollection() + \".\" + r.getCore();\n              if ((Double)r.getVariable(AutoScalingParams.RATE) > aboveRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  hotReplicas.add(r);\n                }\n              } else if ((Double)r.getVariable(AutoScalingParams.RATE) < belowRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  coldReplicas.add(r);\n                }\n              } else {\n                // no violation - clear waitForElapsed\n                lastReplicaEvent.remove(elapsedKey);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        String elapsedKey = coll + \".\" + sh;\n        if ((collections.isEmpty() || collections.contains(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          if (shardRate > aboveRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else if (shardRate < belowRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              coldShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            lastShardEvent.remove(elapsedKey);\n          }\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    Map<String, Double> coldCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (collections.isEmpty() || collections.contains(coll)) {\n        if (total > aboveRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            hotCollections.put(coll, total);\n          }\n        } else if (total < belowRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            coldCollections.put(coll, total);\n          }\n        } else {\n          // no violation - clear waitForElapsed\n          lastCollectionEvent.remove(coll);\n        }\n      }\n    });\n\n    if (hotCollections.isEmpty() &&\n        hotShards.isEmpty() &&\n        hotReplicas.isEmpty() &&\n        hotNodes.isEmpty() &&\n        coldCollections.isEmpty() &&\n        coldShards.isEmpty() &&\n        coldReplicas.isEmpty() &&\n        coldNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    coldShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n\n    calculateHotOps(ops, searchableReplicationFactors, hotNodes, hotCollections, hotShards, hotReplicas);\n    calculateColdOps(ops, clusterState, searchableReplicationFactors, coldNodes, coldCollections, coldShards, coldReplicas);\n\n    if (ops.isEmpty()) {\n      return;\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops,\n        hotNodes, hotCollections, hotShards, hotReplicas,\n        coldNodes, coldCollections, coldShards, coldReplicas))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      coldNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      coldCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      coldShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n      coldReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":["c3f354f2175f861ee625bb3c9572d53b77cd8545","c0b90ab8b228b1f7a05d5ddfbe879ce962d8964a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e35f2dde06b35aa9904949a3a93fabd090371077","date":1587906921,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    // collection, shard, list(replica + rate)\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    // node, rate\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    // this replication factor only considers replica types that are searchable\n    // collection, shard, RF\n    Map<String, Map<String, AtomicInteger>> searchableReplicationFactors = new HashMap<>();\n\n    ClusterState clusterState = null;\n    try {\n      clusterState = cloudManager.getClusterStateProvider().getClusterState();\n    } catch (IOException e) {\n      log.warn(\"Error getting ClusterState\", e);\n      return;\n    }\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        Map<String, AtomicInteger> replPerShard = searchableReplicationFactors.computeIfAbsent(coll, c -> new HashMap<>());\n        shards.forEach((sh, replicas) -> {\n          AtomicInteger repl = replPerShard.computeIfAbsent(sh, s -> new AtomicInteger());\n          replicas.forEach(replica -> {\n            // skip non-active replicas\n            if (replica.getState() != Replica.State.ACTIVE) {\n              return;\n            }\n            repl.incrementAndGet();\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry + \":\" + metric;\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      if (log.isDebugEnabled()) {\n        log.debug(\"### rates for node {}\", node);\n        rates.forEach((tag, rate) -> log.debug(\"###  \" + tag + \"\\t\" + rate)); // logOk\n      }\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag {}\", tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    if (log.isDebugEnabled()) {\n      collectionRates.forEach((coll, collRates) -> {\n        log.debug(\"## Collection: {}\", coll);\n        collRates.forEach((s, replicas) -> {\n          log.debug(\"##  - {}\", s);\n          replicas.forEach(ri -> log.debug(\"##     {}  {}\", ri.getCore(), ri.getVariable(AutoScalingParams.RATE))); //logOk\n        });\n      });\n    }\n    long now = cloudManager.getTimeSource().getTimeNs();\n    Map<String, Double> hotNodes = new HashMap<>();\n    Map<String, Double> coldNodes = new HashMap<>();\n\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .forEach(entry -> {\n          if (entry.getValue().get() > aboveNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              hotNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else if (entry.getValue().get() < belowNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              coldNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            // (violation is only valid if it persists throughout waitFor)\n            lastNodeEvent.remove(entry.getKey());\n          }\n        });\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, Map<String, Double>> coldShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    List<ReplicaInfo> coldReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double totalShardRate = replicaRates.stream()\n            .map(r -> {\n              String elapsedKey = r.getCollection() + \".\" + r.getCore();\n              if ((Double)r.getVariable(AutoScalingParams.RATE) > aboveRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  hotReplicas.add(r);\n                }\n              } else if ((Double)r.getVariable(AutoScalingParams.RATE) < belowRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  coldReplicas.add(r);\n                }\n              } else {\n                // no violation - clear waitForElapsed\n                lastReplicaEvent.remove(elapsedKey);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        // calculate average shard rate over all searchable replicas (see SOLR-12470)\n        double shardRate = totalShardRate / searchableReplicationFactors.get(coll).get(sh).doubleValue();\n        String elapsedKey = coll + \".\" + sh;\n        log.debug(\"-- {}: totalShardRate={}, shardRate={}\", elapsedKey, totalShardRate, shardRate);\n        if ((collections.isEmpty() || collections.contains(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          if (shardRate > aboveRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else if (shardRate < belowRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              coldShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n              log.debug(\"-- coldShard waitFor elapsed {}\", elapsedKey);\n            } else {\n              if (log.isDebugEnabled()) {\n                Long lastTime = lastShardEvent.computeIfAbsent(elapsedKey, s -> now);\n                long elapsed = TimeUnit.SECONDS.convert(now - lastTime, TimeUnit.NANOSECONDS);\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- waitFor didn't elapse for {}, waitFor={}, elapsed={}\", elapsedKey, getWaitForSecond(), elapsed);\n                }\n              }\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            lastShardEvent.remove(elapsedKey);\n          }\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    Map<String, Double> coldCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (collections.isEmpty() || collections.contains(coll)) {\n        if (total > aboveRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            hotCollections.put(coll, total);\n          }\n        } else if (total < belowRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            coldCollections.put(coll, total);\n          }\n        } else {\n          // no violation - clear waitForElapsed\n          lastCollectionEvent.remove(coll);\n        }\n      }\n    });\n\n    if (hotCollections.isEmpty() &&\n        hotShards.isEmpty() &&\n        hotReplicas.isEmpty() &&\n        hotNodes.isEmpty() &&\n        coldCollections.isEmpty() &&\n        coldShards.isEmpty() &&\n        coldReplicas.isEmpty() &&\n        coldNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    coldShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    final Set<String> violations = new HashSet<>();\n\n    calculateHotOps(ops, violations, searchableReplicationFactors, hotNodes, hotCollections, hotShards, hotReplicas);\n    calculateColdOps(ops, violations, clusterState, searchableReplicationFactors, coldNodes, coldCollections, coldShards, coldReplicas);\n\n    if (ops.isEmpty()) {\n      return;\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops,\n        hotNodes, hotCollections, hotShards, hotReplicas,\n        coldNodes, coldCollections, coldShards, coldReplicas, violations))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      coldNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      coldCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      coldShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n      coldReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    // collection, shard, list(replica + rate)\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    // node, rate\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    // this replication factor only considers replica types that are searchable\n    // collection, shard, RF\n    Map<String, Map<String, AtomicInteger>> searchableReplicationFactors = new HashMap<>();\n\n    ClusterState clusterState = null;\n    try {\n      clusterState = cloudManager.getClusterStateProvider().getClusterState();\n    } catch (IOException e) {\n      log.warn(\"Error getting ClusterState\", e);\n      return;\n    }\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        Map<String, AtomicInteger> replPerShard = searchableReplicationFactors.computeIfAbsent(coll, c -> new HashMap<>());\n        shards.forEach((sh, replicas) -> {\n          AtomicInteger repl = replPerShard.computeIfAbsent(sh, s -> new AtomicInteger());\n          replicas.forEach(replica -> {\n            // skip non-active replicas\n            if (replica.getState() != Replica.State.ACTIVE) {\n              return;\n            }\n            repl.incrementAndGet();\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry + \":\" + metric;\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      if (log.isDebugEnabled()) {\n        log.debug(\"### rates for node \" + node);\n        rates.forEach((tag, rate) -> log.debug(\"###  \" + tag + \"\\t\" + rate));\n      }\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag \" + tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    if (log.isDebugEnabled()) {\n      collectionRates.forEach((coll, collRates) -> {\n        log.debug(\"## Collection: {}\", coll);\n        collRates.forEach((s, replicas) -> {\n          log.debug(\"##  - {}\", s);\n          replicas.forEach(ri -> log.debug(\"##     {}  {}\", ri.getCore(), ri.getVariable(AutoScalingParams.RATE)));\n        });\n      });\n    }\n    long now = cloudManager.getTimeSource().getTimeNs();\n    Map<String, Double> hotNodes = new HashMap<>();\n    Map<String, Double> coldNodes = new HashMap<>();\n\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .forEach(entry -> {\n          if (entry.getValue().get() > aboveNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              hotNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else if (entry.getValue().get() < belowNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              coldNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            // (violation is only valid if it persists throughout waitFor)\n            lastNodeEvent.remove(entry.getKey());\n          }\n        });\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, Map<String, Double>> coldShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    List<ReplicaInfo> coldReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double totalShardRate = replicaRates.stream()\n            .map(r -> {\n              String elapsedKey = r.getCollection() + \".\" + r.getCore();\n              if ((Double)r.getVariable(AutoScalingParams.RATE) > aboveRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  hotReplicas.add(r);\n                }\n              } else if ((Double)r.getVariable(AutoScalingParams.RATE) < belowRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  coldReplicas.add(r);\n                }\n              } else {\n                // no violation - clear waitForElapsed\n                lastReplicaEvent.remove(elapsedKey);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        // calculate average shard rate over all searchable replicas (see SOLR-12470)\n        double shardRate = totalShardRate / searchableReplicationFactors.get(coll).get(sh).doubleValue();\n        String elapsedKey = coll + \".\" + sh;\n        log.debug(\"-- {}: totalShardRate={}, shardRate={}\", elapsedKey, totalShardRate, shardRate);\n        if ((collections.isEmpty() || collections.contains(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          if (shardRate > aboveRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else if (shardRate < belowRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              coldShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n              log.debug(\"-- coldShard waitFor elapsed {}\", elapsedKey);\n            } else {\n              if (log.isDebugEnabled()) {\n                Long lastTime = lastShardEvent.computeIfAbsent(elapsedKey, s -> now);\n                long elapsed = TimeUnit.SECONDS.convert(now - lastTime, TimeUnit.NANOSECONDS);\n                log.debug(\"-- waitFor didn't elapse for {}, waitFor={}, elapsed={}\", elapsedKey, getWaitForSecond(), elapsed);\n              }\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            lastShardEvent.remove(elapsedKey);\n          }\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    Map<String, Double> coldCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (collections.isEmpty() || collections.contains(coll)) {\n        if (total > aboveRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            hotCollections.put(coll, total);\n          }\n        } else if (total < belowRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            coldCollections.put(coll, total);\n          }\n        } else {\n          // no violation - clear waitForElapsed\n          lastCollectionEvent.remove(coll);\n        }\n      }\n    });\n\n    if (hotCollections.isEmpty() &&\n        hotShards.isEmpty() &&\n        hotReplicas.isEmpty() &&\n        hotNodes.isEmpty() &&\n        coldCollections.isEmpty() &&\n        coldShards.isEmpty() &&\n        coldReplicas.isEmpty() &&\n        coldNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    coldShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    final Set<String> violations = new HashSet<>();\n\n    calculateHotOps(ops, violations, searchableReplicationFactors, hotNodes, hotCollections, hotShards, hotReplicas);\n    calculateColdOps(ops, violations, clusterState, searchableReplicationFactors, coldNodes, coldCollections, coldShards, coldReplicas);\n\n    if (ops.isEmpty()) {\n      return;\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops,\n        hotNodes, hotCollections, hotShards, hotReplicas,\n        coldNodes, coldCollections, coldShards, coldReplicas, violations))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      coldNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      coldCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      coldShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n      coldReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd","date":1594731683,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    // collection, shard, list(replica + rate)\n    Map<String, Map<String, List<Replica>>> collectionRates = new HashMap<>();\n    // node, rate\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    // this replication factor only considers replica types that are searchable\n    // collection, shard, RF\n    Map<String, Map<String, AtomicInteger>> searchableReplicationFactors = new HashMap<>();\n\n    ClusterState clusterState = null;\n    try {\n      clusterState = cloudManager.getClusterStateProvider().getClusterState();\n    } catch (IOException e) {\n      log.warn(\"Error getting ClusterState\", e);\n      return;\n    }\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, Replica> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<Replica>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        Map<String, AtomicInteger> replPerShard = searchableReplicationFactors.computeIfAbsent(coll, c -> new HashMap<>());\n        shards.forEach((sh, replicas) -> {\n          AtomicInteger repl = replPerShard.computeIfAbsent(sh, s -> new AtomicInteger());\n          replicas.forEach(replica -> {\n            // skip non-active replicas\n            if (replica.getState() != Replica.State.ACTIVE) {\n              return;\n            }\n            repl.incrementAndGet();\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCoreName());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry + \":\" + metric;\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      if (log.isDebugEnabled()) {\n        log.debug(\"### rates for node {}\", node);\n        rates.forEach((tag, rate) -> log.debug(\"###  \" + tag + \"\\t\" + rate)); // logOk\n      }\n      rates.forEach((tag, rate) -> {\n        Replica info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag {}\", tag);\n        } else {\n          Map<String, List<Replica>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<Replica> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (Replica)info.clone();\n          info.getProperties().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    if (log.isDebugEnabled()) {\n      collectionRates.forEach((coll, collRates) -> {\n        log.debug(\"## Collection: {}\", coll);\n        collRates.forEach((s, replicas) -> {\n          log.debug(\"##  - {}\", s);\n          replicas.forEach(ri -> log.debug(\"##     {}  {}\", ri.getCoreName(), ri.get(AutoScalingParams.RATE))); //logOk\n        });\n      });\n    }\n    long now = cloudManager.getTimeSource().getTimeNs();\n    Map<String, Double> hotNodes = new HashMap<>();\n    Map<String, Double> coldNodes = new HashMap<>();\n\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .forEach(entry -> {\n          if (entry.getValue().get() > aboveNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              hotNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else if (entry.getValue().get() < belowNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              coldNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            // (violation is only valid if it persists throughout waitFor)\n            lastNodeEvent.remove(entry.getKey());\n          }\n        });\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, Map<String, Double>> coldShards = new HashMap<>();\n    List<Replica> hotReplicas = new ArrayList<>();\n    List<Replica> coldReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double totalShardRate = replicaRates.stream()\n            .map(r -> {\n              String elapsedKey = r.getCollection() + \".\" + r.getCoreName();\n              if ((Double)r.get(AutoScalingParams.RATE) > aboveRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  hotReplicas.add(r);\n                }\n              } else if ((Double)r.get(AutoScalingParams.RATE) < belowRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  coldReplicas.add(r);\n                }\n              } else {\n                // no violation - clear waitForElapsed\n                lastReplicaEvent.remove(elapsedKey);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.get(AutoScalingParams.RATE)).sum();\n        // calculate average shard rate over all searchable replicas (see SOLR-12470)\n        double shardRate = totalShardRate / searchableReplicationFactors.get(coll).get(sh).doubleValue();\n        String elapsedKey = coll + \".\" + sh;\n        log.debug(\"-- {}: totalShardRate={}, shardRate={}\", elapsedKey, totalShardRate, shardRate);\n        if ((collections.isEmpty() || collections.contains(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          if (shardRate > aboveRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else if (shardRate < belowRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              coldShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n              log.debug(\"-- coldShard waitFor elapsed {}\", elapsedKey);\n            } else {\n              if (log.isDebugEnabled()) {\n                Long lastTime = lastShardEvent.computeIfAbsent(elapsedKey, s -> now);\n                long elapsed = TimeUnit.SECONDS.convert(now - lastTime, TimeUnit.NANOSECONDS);\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- waitFor didn't elapse for {}, waitFor={}, elapsed={}\", elapsedKey, getWaitForSecond(), elapsed);\n                }\n              }\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            lastShardEvent.remove(elapsedKey);\n          }\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    Map<String, Double> coldCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.get(AutoScalingParams.RATE)).sum()).sum();\n      if (collections.isEmpty() || collections.contains(coll)) {\n        if (total > aboveRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            hotCollections.put(coll, total);\n          }\n        } else if (total < belowRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            coldCollections.put(coll, total);\n          }\n        } else {\n          // no violation - clear waitForElapsed\n          lastCollectionEvent.remove(coll);\n        }\n      }\n    });\n\n    if (hotCollections.isEmpty() &&\n        hotShards.isEmpty() &&\n        hotReplicas.isEmpty() &&\n        hotNodes.isEmpty() &&\n        coldCollections.isEmpty() &&\n        coldShards.isEmpty() &&\n        coldReplicas.isEmpty() &&\n        coldNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    coldShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCoreName());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCoreName());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    final Set<String> violations = new HashSet<>();\n\n    calculateHotOps(ops, violations, searchableReplicationFactors, hotNodes, hotCollections, hotShards, hotReplicas);\n    calculateColdOps(ops, violations, clusterState, searchableReplicationFactors, coldNodes, coldCollections, coldShards, coldReplicas);\n\n    if (ops.isEmpty()) {\n      return;\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops,\n        hotNodes, hotCollections, hotShards, hotReplicas,\n        coldNodes, coldCollections, coldShards, coldReplicas, violations))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      coldNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      coldCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      coldShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCoreName(), now));\n      coldReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCoreName(), now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    // collection, shard, list(replica + rate)\n    Map<String, Map<String, List<ReplicaInfo>>> collectionRates = new HashMap<>();\n    // node, rate\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    // this replication factor only considers replica types that are searchable\n    // collection, shard, RF\n    Map<String, Map<String, AtomicInteger>> searchableReplicationFactors = new HashMap<>();\n\n    ClusterState clusterState = null;\n    try {\n      clusterState = cloudManager.getClusterStateProvider().getClusterState();\n    } catch (IOException e) {\n      log.warn(\"Error getting ClusterState\", e);\n      return;\n    }\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, ReplicaInfo> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<ReplicaInfo>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        Map<String, AtomicInteger> replPerShard = searchableReplicationFactors.computeIfAbsent(coll, c -> new HashMap<>());\n        shards.forEach((sh, replicas) -> {\n          AtomicInteger repl = replPerShard.computeIfAbsent(sh, s -> new AtomicInteger());\n          replicas.forEach(replica -> {\n            // skip non-active replicas\n            if (replica.getState() != Replica.State.ACTIVE) {\n              return;\n            }\n            repl.incrementAndGet();\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCore());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry + \":\" + metric;\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      if (log.isDebugEnabled()) {\n        log.debug(\"### rates for node {}\", node);\n        rates.forEach((tag, rate) -> log.debug(\"###  \" + tag + \"\\t\" + rate)); // logOk\n      }\n      rates.forEach((tag, rate) -> {\n        ReplicaInfo info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag {}\", tag);\n        } else {\n          Map<String, List<ReplicaInfo>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<ReplicaInfo> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (ReplicaInfo)info.clone();\n          info.getVariables().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    if (log.isDebugEnabled()) {\n      collectionRates.forEach((coll, collRates) -> {\n        log.debug(\"## Collection: {}\", coll);\n        collRates.forEach((s, replicas) -> {\n          log.debug(\"##  - {}\", s);\n          replicas.forEach(ri -> log.debug(\"##     {}  {}\", ri.getCore(), ri.getVariable(AutoScalingParams.RATE))); //logOk\n        });\n      });\n    }\n    long now = cloudManager.getTimeSource().getTimeNs();\n    Map<String, Double> hotNodes = new HashMap<>();\n    Map<String, Double> coldNodes = new HashMap<>();\n\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .forEach(entry -> {\n          if (entry.getValue().get() > aboveNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              hotNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else if (entry.getValue().get() < belowNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              coldNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            // (violation is only valid if it persists throughout waitFor)\n            lastNodeEvent.remove(entry.getKey());\n          }\n        });\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, Map<String, Double>> coldShards = new HashMap<>();\n    List<ReplicaInfo> hotReplicas = new ArrayList<>();\n    List<ReplicaInfo> coldReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double totalShardRate = replicaRates.stream()\n            .map(r -> {\n              String elapsedKey = r.getCollection() + \".\" + r.getCore();\n              if ((Double)r.getVariable(AutoScalingParams.RATE) > aboveRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  hotReplicas.add(r);\n                }\n              } else if ((Double)r.getVariable(AutoScalingParams.RATE) < belowRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  coldReplicas.add(r);\n                }\n              } else {\n                // no violation - clear waitForElapsed\n                lastReplicaEvent.remove(elapsedKey);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum();\n        // calculate average shard rate over all searchable replicas (see SOLR-12470)\n        double shardRate = totalShardRate / searchableReplicationFactors.get(coll).get(sh).doubleValue();\n        String elapsedKey = coll + \".\" + sh;\n        log.debug(\"-- {}: totalShardRate={}, shardRate={}\", elapsedKey, totalShardRate, shardRate);\n        if ((collections.isEmpty() || collections.contains(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          if (shardRate > aboveRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else if (shardRate < belowRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              coldShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n              log.debug(\"-- coldShard waitFor elapsed {}\", elapsedKey);\n            } else {\n              if (log.isDebugEnabled()) {\n                Long lastTime = lastShardEvent.computeIfAbsent(elapsedKey, s -> now);\n                long elapsed = TimeUnit.SECONDS.convert(now - lastTime, TimeUnit.NANOSECONDS);\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- waitFor didn't elapse for {}, waitFor={}, elapsed={}\", elapsedKey, getWaitForSecond(), elapsed);\n                }\n              }\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            lastShardEvent.remove(elapsedKey);\n          }\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    Map<String, Double> coldCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.getVariable(AutoScalingParams.RATE)).sum()).sum();\n      if (collections.isEmpty() || collections.contains(coll)) {\n        if (total > aboveRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            hotCollections.put(coll, total);\n          }\n        } else if (total < belowRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            coldCollections.put(coll, total);\n          }\n        } else {\n          // no violation - clear waitForElapsed\n          lastCollectionEvent.remove(coll);\n        }\n      }\n    });\n\n    if (hotCollections.isEmpty() &&\n        hotShards.isEmpty() &&\n        hotReplicas.isEmpty() &&\n        hotNodes.isEmpty() &&\n        coldCollections.isEmpty() &&\n        coldShards.isEmpty() &&\n        coldReplicas.isEmpty() &&\n        coldNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    coldShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCore());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    final Set<String> violations = new HashSet<>();\n\n    calculateHotOps(ops, violations, searchableReplicationFactors, hotNodes, hotCollections, hotShards, hotReplicas);\n    calculateColdOps(ops, violations, clusterState, searchableReplicationFactors, coldNodes, coldCollections, coldShards, coldReplicas);\n\n    if (ops.isEmpty()) {\n      return;\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops,\n        hotNodes, hotCollections, hotShards, hotReplicas,\n        coldNodes, coldCollections, coldShards, coldReplicas, violations))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      coldNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      coldCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      coldShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n      coldReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCore(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/SearchRateTrigger#run().mjava","sourceNew":null,"sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    // collection, shard, list(replica + rate)\n    Map<String, Map<String, List<Replica>>> collectionRates = new HashMap<>();\n    // node, rate\n    Map<String, AtomicDouble> nodeRates = new HashMap<>();\n    // this replication factor only considers replica types that are searchable\n    // collection, shard, RF\n    Map<String, Map<String, AtomicInteger>> searchableReplicationFactors = new HashMap<>();\n\n    ClusterState clusterState = null;\n    try {\n      clusterState = cloudManager.getClusterStateProvider().getClusterState();\n    } catch (IOException e) {\n      log.warn(\"Error getting ClusterState\", e);\n      return;\n    }\n    for (String node : cloudManager.getClusterStateProvider().getLiveNodes()) {\n      Map<String, Replica> metricTags = new HashMap<>();\n      // coll, shard, replica\n      Map<String, Map<String, List<Replica>>> infos = cloudManager.getNodeStateProvider().getReplicaInfo(node, Collections.emptyList());\n      infos.forEach((coll, shards) -> {\n        Map<String, AtomicInteger> replPerShard = searchableReplicationFactors.computeIfAbsent(coll, c -> new HashMap<>());\n        shards.forEach((sh, replicas) -> {\n          AtomicInteger repl = replPerShard.computeIfAbsent(sh, s -> new AtomicInteger());\n          replicas.forEach(replica -> {\n            // skip non-active replicas\n            if (replica.getState() != Replica.State.ACTIVE) {\n              return;\n            }\n            repl.incrementAndGet();\n            // we have to translate to the metrics registry name, which uses \"_replica_nN\" as suffix\n            String replicaName = Utils.parseMetricsReplicaName(coll, replica.getCoreName());\n            if (replicaName == null) { // should never happen???\n              replicaName = replica.getName(); // which is actually coreNode name...\n            }\n            String registry = SolrCoreMetricManager.createRegistryName(true, coll, sh, replicaName, null);\n            String tag = \"metrics:\" + registry + \":\" + metric;\n            metricTags.put(tag, replica);\n          });\n        });\n      });\n      if (metricTags.isEmpty()) {\n        continue;\n      }\n      Map<String, Object> rates = cloudManager.getNodeStateProvider().getNodeValues(node, metricTags.keySet());\n      if (log.isDebugEnabled()) {\n        log.debug(\"### rates for node {}\", node);\n        rates.forEach((tag, rate) -> log.debug(\"###  \" + tag + \"\\t\" + rate)); // logOk\n      }\n      rates.forEach((tag, rate) -> {\n        Replica info = metricTags.get(tag);\n        if (info == null) {\n          log.warn(\"Missing replica info for response tag {}\", tag);\n        } else {\n          Map<String, List<Replica>> perCollection = collectionRates.computeIfAbsent(info.getCollection(), s -> new HashMap<>());\n          List<Replica> perShard = perCollection.computeIfAbsent(info.getShard(), s -> new ArrayList<>());\n          info = (Replica)info.clone();\n          info.getProperties().put(AutoScalingParams.RATE, ((Number)rate).doubleValue());\n          perShard.add(info);\n          AtomicDouble perNode = nodeRates.computeIfAbsent(node, s -> new AtomicDouble());\n          perNode.addAndGet(((Number)rate).doubleValue());\n        }\n      });\n    }\n\n    if (log.isDebugEnabled()) {\n      collectionRates.forEach((coll, collRates) -> {\n        log.debug(\"## Collection: {}\", coll);\n        collRates.forEach((s, replicas) -> {\n          log.debug(\"##  - {}\", s);\n          replicas.forEach(ri -> log.debug(\"##     {}  {}\", ri.getCoreName(), ri.get(AutoScalingParams.RATE))); //logOk\n        });\n      });\n    }\n    long now = cloudManager.getTimeSource().getTimeNs();\n    Map<String, Double> hotNodes = new HashMap<>();\n    Map<String, Double> coldNodes = new HashMap<>();\n\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    nodeRates.entrySet().stream()\n        .filter(entry -> node.equals(Policy.ANY) || node.equals(entry.getKey()))\n        .forEach(entry -> {\n          if (entry.getValue().get() > aboveNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              hotNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else if (entry.getValue().get() < belowNodeRate) {\n            if (waitForElapsed(entry.getKey(), now, lastNodeEvent)) {\n              coldNodes.put(entry.getKey(), entry.getValue().get());\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            // (violation is only valid if it persists throughout waitFor)\n            lastNodeEvent.remove(entry.getKey());\n          }\n        });\n\n    Map<String, Map<String, Double>> hotShards = new HashMap<>();\n    Map<String, Map<String, Double>> coldShards = new HashMap<>();\n    List<Replica> hotReplicas = new ArrayList<>();\n    List<Replica> coldReplicas = new ArrayList<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      shardRates.forEach((sh, replicaRates) -> {\n        double totalShardRate = replicaRates.stream()\n            .map(r -> {\n              String elapsedKey = r.getCollection() + \".\" + r.getCoreName();\n              if ((Double)r.get(AutoScalingParams.RATE) > aboveRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  hotReplicas.add(r);\n                }\n              } else if ((Double)r.get(AutoScalingParams.RATE) < belowRate) {\n                if (waitForElapsed(elapsedKey, now, lastReplicaEvent)) {\n                  coldReplicas.add(r);\n                }\n              } else {\n                // no violation - clear waitForElapsed\n                lastReplicaEvent.remove(elapsedKey);\n              }\n              return r;\n            })\n            .mapToDouble(r -> (Double)r.get(AutoScalingParams.RATE)).sum();\n        // calculate average shard rate over all searchable replicas (see SOLR-12470)\n        double shardRate = totalShardRate / searchableReplicationFactors.get(coll).get(sh).doubleValue();\n        String elapsedKey = coll + \".\" + sh;\n        log.debug(\"-- {}: totalShardRate={}, shardRate={}\", elapsedKey, totalShardRate, shardRate);\n        if ((collections.isEmpty() || collections.contains(coll)) &&\n            (shard.equals(Policy.ANY) || shard.equals(sh))) {\n          if (shardRate > aboveRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              hotShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n            }\n          } else if (shardRate < belowRate) {\n            if (waitForElapsed(elapsedKey, now, lastShardEvent)) {\n              coldShards.computeIfAbsent(coll, s -> new HashMap<>()).put(sh, shardRate);\n              log.debug(\"-- coldShard waitFor elapsed {}\", elapsedKey);\n            } else {\n              if (log.isDebugEnabled()) {\n                Long lastTime = lastShardEvent.computeIfAbsent(elapsedKey, s -> now);\n                long elapsed = TimeUnit.SECONDS.convert(now - lastTime, TimeUnit.NANOSECONDS);\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- waitFor didn't elapse for {}, waitFor={}, elapsed={}\", elapsedKey, getWaitForSecond(), elapsed);\n                }\n              }\n            }\n          } else {\n            // no violation - clear waitForElapsed\n            lastShardEvent.remove(elapsedKey);\n          }\n        }\n      });\n    });\n\n    Map<String, Double> hotCollections = new HashMap<>();\n    Map<String, Double> coldCollections = new HashMap<>();\n    collectionRates.forEach((coll, shardRates) -> {\n      double total = shardRates.entrySet().stream()\n          .mapToDouble(e -> e.getValue().stream()\n              .mapToDouble(r -> (Double)r.get(AutoScalingParams.RATE)).sum()).sum();\n      if (collections.isEmpty() || collections.contains(coll)) {\n        if (total > aboveRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            hotCollections.put(coll, total);\n          }\n        } else if (total < belowRate) {\n          if (waitForElapsed(coll, now, lastCollectionEvent)) {\n            coldCollections.put(coll, total);\n          }\n        } else {\n          // no violation - clear waitForElapsed\n          lastCollectionEvent.remove(coll);\n        }\n      }\n    });\n\n    if (hotCollections.isEmpty() &&\n        hotShards.isEmpty() &&\n        hotReplicas.isEmpty() &&\n        hotNodes.isEmpty() &&\n        coldCollections.isEmpty() &&\n        coldShards.isEmpty() &&\n        coldReplicas.isEmpty() &&\n        coldNodes.isEmpty()) {\n      return;\n    }\n\n    // generate event\n\n    // find the earliest time when a condition was exceeded\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldCollections.forEach((c, r) -> {\n      long time = lastCollectionEvent.get(c);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    coldShards.forEach((c, shards) -> {\n      shards.forEach((s, r) -> {\n        long time = lastShardEvent.get(c + \".\" + s);\n        if (eventTime.get() > time) {\n          eventTime.set(time);\n        }\n      });\n    });\n    hotReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCoreName());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldReplicas.forEach(r -> {\n      long time = lastReplicaEvent.get(r.getCollection() + \".\" + r.getCoreName());\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n    coldNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    final List<TriggerEvent.Op> ops = new ArrayList<>();\n    final Set<String> violations = new HashSet<>();\n\n    calculateHotOps(ops, violations, searchableReplicationFactors, hotNodes, hotCollections, hotShards, hotReplicas);\n    calculateColdOps(ops, violations, clusterState, searchableReplicationFactors, coldNodes, coldCollections, coldShards, coldReplicas);\n\n    if (ops.isEmpty()) {\n      return;\n    }\n\n    if (processor.process(new SearchRateEvent(getName(), eventTime.get(), ops,\n        hotNodes, hotCollections, hotShards, hotReplicas,\n        coldNodes, coldCollections, coldShards, coldReplicas, violations))) {\n      // update lastEvent times\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      coldNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n      hotCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      coldCollections.keySet().forEach(coll -> lastCollectionEvent.put(coll, now));\n      hotShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      coldShards.entrySet().forEach(e -> e.getValue()\n          .forEach((sh, rate) -> lastShardEvent.put(e.getKey() + \".\" + sh, now)));\n      hotReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCoreName(), now));\n      coldReplicas.forEach(r -> lastReplicaEvent.put(r.getCollection() + \".\" + r.getCoreName(), now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3955a9511098c96b652734b2f2d4160d07cc2d63":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3f504512a03d978990cbff30db0522b354e846db":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["c3f354f2175f861ee625bb3c9572d53b77cd8545","7d7cf463e12b13965d63f133adc46a1c673d0c4e"],"7d7cf463e12b13965d63f133adc46a1c673d0c4e":["c3f354f2175f861ee625bb3c9572d53b77cd8545"],"1cc58dbf9573e66a3054c7c372862b8e5a77a9da":["3955a9511098c96b652734b2f2d4160d07cc2d63"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["d4412883c12067d8a4e2a354aa8adc58c32be1d6","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"a4e412fed1b23292038553fbe85fe61cd7aa8472":["1cc58dbf9573e66a3054c7c372862b8e5a77a9da"],"43a787a75ad72a9bf26e8ff714d8b6d01f9eb441":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","d9ccfe45460d496c5e5e1b70396521dac842d966"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["c0b90ab8b228b1f7a05d5ddfbe879ce962d8964a"],"c0b90ab8b228b1f7a05d5ddfbe879ce962d8964a":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"c3f354f2175f861ee625bb3c9572d53b77cd8545":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["e35f2dde06b35aa9904949a3a93fabd090371077"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["43a787a75ad72a9bf26e8ff714d8b6d01f9eb441"],"e35f2dde06b35aa9904949a3a93fabd090371077":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"],"d9ccfe45460d496c5e5e1b70396521dac842d966":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"4f2ba631afa835c2dfd14555cf19ae7e73663c17":["a4e412fed1b23292038553fbe85fe61cd7aa8472"]},"commit2Childs":{"3955a9511098c96b652734b2f2d4160d07cc2d63":["1cc58dbf9573e66a3054c7c372862b8e5a77a9da"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"7d7cf463e12b13965d63f133adc46a1c673d0c4e":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"1cc58dbf9573e66a3054c7c372862b8e5a77a9da":["a4e412fed1b23292038553fbe85fe61cd7aa8472"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["c0b90ab8b228b1f7a05d5ddfbe879ce962d8964a"],"a4e412fed1b23292038553fbe85fe61cd7aa8472":["4f2ba631afa835c2dfd14555cf19ae7e73663c17"],"43a787a75ad72a9bf26e8ff714d8b6d01f9eb441":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["e35f2dde06b35aa9904949a3a93fabd090371077"],"c0b90ab8b228b1f7a05d5ddfbe879ce962d8964a":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"c3f354f2175f861ee625bb3c9572d53b77cd8545":["d523b8189b211dd1630166aa77b8c88bb48b3fcc","7d7cf463e12b13965d63f133adc46a1c673d0c4e"],"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["3f504512a03d978990cbff30db0522b354e846db"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3955a9511098c96b652734b2f2d4160d07cc2d63","c3f354f2175f861ee625bb3c9572d53b77cd8545"],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["43345f1452f9510f8aaadae6156fe0c834e7d957","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"e35f2dde06b35aa9904949a3a93fabd090371077":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["43a787a75ad72a9bf26e8ff714d8b6d01f9eb441","d9ccfe45460d496c5e5e1b70396521dac842d966"],"d9ccfe45460d496c5e5e1b70396521dac842d966":["43a787a75ad72a9bf26e8ff714d8b6d01f9eb441"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"4f2ba631afa835c2dfd14555cf19ae7e73663c17":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","4f2ba631afa835c2dfd14555cf19ae7e73663c17"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}