{"path":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","commits":[{"id":"aedcfb5ebceafe4a0285436fa86269ed6c926442","date":1271441603,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    for (int i = 0; i < random.nextInt(250); i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    for (int i = 0; i < random.nextInt(250); i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir, analyzer,\n        IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"febccbc33f56a77c1e8adb10e77c3e2d3f9c0d76","date":1273494417,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir, analyzer,\n        IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    for (int i = 0; i < random.nextInt(250); i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    for (int i = 0; i < random.nextInt(250); i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir, analyzer,\n        IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"163fe85a71d778fd2b7747f65ca27b54829e2e57","date":1279898785,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir, analyzer,\n        IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir, analyzer,\n        IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0e45742e10e8e3b98e854babe6dbb07a4197b71","date":1280230285,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250*_TestUtil.getRandomMultiplier());\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir, analyzer,\n        IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    MockRAMDirectory ramdir = new MockRAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    MockRAMDirectory ramdir = newDirectory(random);\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    MockRAMDirectory ramdir = new MockRAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","bugFix":null,"bugIntro":["9a835874e67543fc296ab80a78ba389811392393"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory(random);\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    MockRAMDirectory ramdir = newDirectory(random);\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory(random);\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","bugFix":null,"bugIntro":["9a835874e67543fc296ab80a78ba389811392393"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = newField(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = newField(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    RAMDirectory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = new Field(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = new Field(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    Field field2 = newField(\"term\", termField.toString(), Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat())));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodecProvider(_TestUtil.alwaysCodec(\"Standard\")));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a835874e67543fc296ab80a78ba389811392393","date":1332198923,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat())));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    \n    if (VERBOSE) {\n      System.out.println(\"Random MemoryIndex:\\n\" + memory.toString());\n      System.out.println(\"Same index as RAMDirectory: \" +\n        RamUsageEstimator.humanReadableUnits(RamUsageEstimator.sizeOf(ramdir)));\n      System.out.println();\n    } else {\n      assertTrue(memory.getMemorySize() > 0L);\n    }\n\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();    \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = newDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat())));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();\n  }\n\n","bugFix":["1f653cfcf159baeaafe5d01682a911e95bba4012","ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random().nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random().nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat())));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    \n    if (VERBOSE) {\n      System.out.println(\"Random MemoryIndex:\\n\" + memory.toString());\n      System.out.println(\"Same index as RAMDirectory: \" +\n        RamUsageEstimator.humanReadableUnits(RamUsageEstimator.sizeOf(ramdir)));\n      System.out.println();\n    } else {\n      assertTrue(memory.getMemorySize() > 0L);\n    }\n\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();    \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random.nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat())));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    \n    if (VERBOSE) {\n      System.out.println(\"Random MemoryIndex:\\n\" + memory.toString());\n      System.out.println(\"Same index as RAMDirectory: \" +\n        RamUsageEstimator.humanReadableUnits(RamUsageEstimator.sizeOf(ramdir)));\n      System.out.println();\n    } else {\n      assertTrue(memory.getMemorySize() > 0L);\n    }\n\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#assertAgainstRAMDirectory().mjava","sourceNew":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random().nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random().nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat())));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    \n    if (VERBOSE) {\n      System.out.println(\"Random MemoryIndex:\\n\" + memory.toString());\n      System.out.println(\"Same index as RAMDirectory: \" +\n        RamUsageEstimator.humanReadableUnits(RamUsageEstimator.sizeOf(ramdir)));\n      System.out.println();\n    } else {\n      assertTrue(memory.getMemorySize() > 0L);\n    }\n\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();    \n  }\n\n","sourceOld":"  /**\n   * Build a randomish document for both RAMDirectory and MemoryIndex,\n   * and run all the queries against it.\n   */\n  public void assertAgainstRAMDirectory() throws Exception {\n    StringBuilder fooField = new StringBuilder();\n    StringBuilder termField = new StringBuilder();\n \n    // add up to 250 terms to field \"foo\"\n    final int numFooTerms = random().nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numFooTerms; i++) {\n      fooField.append(\" \");\n      fooField.append(randomTerm());\n    }\n\n    // add up to 250 terms to field \"term\"\n    final int numTermTerms = random().nextInt(250 * RANDOM_MULTIPLIER);\n    for (int i = 0; i < numTermTerms; i++) {\n      termField.append(\" \");\n      termField.append(randomTerm());\n    }\n    \n    Directory ramdir = new RAMDirectory();\n    Analyzer analyzer = randomAnalyzer();\n    IndexWriter writer = new IndexWriter(ramdir,\n                                         new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer).setCodec(_TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat())));\n    Document doc = new Document();\n    Field field1 = newField(\"foo\", fooField.toString(), TextField.TYPE_UNSTORED);\n    Field field2 = newField(\"term\", termField.toString(), TextField.TYPE_UNSTORED);\n    doc.add(field1);\n    doc.add(field2);\n    writer.addDocument(doc);\n    writer.close();\n    \n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", fooField.toString(), analyzer);\n    memory.addField(\"term\", termField.toString(), analyzer);\n    \n    if (VERBOSE) {\n      System.out.println(\"Random MemoryIndex:\\n\" + memory.toString());\n      System.out.println(\"Same index as RAMDirectory: \" +\n        RamUsageEstimator.humanReadableUnits(RamUsageEstimator.sizeOf(ramdir)));\n      System.out.println();\n    } else {\n      assertTrue(memory.getMemorySize() > 0L);\n    }\n\n    assertAllQueries(memory, ramdir, analyzer);  \n    ramdir.close();    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e45742e10e8e3b98e854babe6dbb07a4197b71":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["febccbc33f56a77c1e8adb10e77c3e2d3f9c0d76","a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["febccbc33f56a77c1e8adb10e77c3e2d3f9c0d76","163fe85a71d778fd2b7747f65ca27b54829e2e57"],"163fe85a71d778fd2b7747f65ca27b54829e2e57":["febccbc33f56a77c1e8adb10e77c3e2d3f9c0d76"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3242a09f703274d3b9283f2064a1a33064b53a1b","132903c28af3aa6f67284b78de91c0f0a99488c2"],"febccbc33f56a77c1e8adb10e77c3e2d3f9c0d76":["aedcfb5ebceafe4a0285436fa86269ed6c926442"],"7b91922b55d15444d554721b352861d028eb8278":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"9a835874e67543fc296ab80a78ba389811392393":["7b91922b55d15444d554721b352861d028eb8278"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"aedcfb5ebceafe4a0285436fa86269ed6c926442":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["9a835874e67543fc296ab80a78ba389811392393"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"a0e45742e10e8e3b98e854babe6dbb07a4197b71":["3242a09f703274d3b9283f2064a1a33064b53a1b","1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"163fe85a71d778fd2b7747f65ca27b54829e2e57":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"febccbc33f56a77c1e8adb10e77c3e2d3f9c0d76":["3242a09f703274d3b9283f2064a1a33064b53a1b","4b103252dee6afa1b6d7a622c773d178788eb85a","163fe85a71d778fd2b7747f65ca27b54829e2e57"],"7b91922b55d15444d554721b352861d028eb8278":["9a835874e67543fc296ab80a78ba389811392393"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9a835874e67543fc296ab80a78ba389811392393":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"aedcfb5ebceafe4a0285436fa86269ed6c926442":["febccbc33f56a77c1e8adb10e77c3e2d3f9c0d76"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["aedcfb5ebceafe4a0285436fa86269ed6c926442"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7b91922b55d15444d554721b352861d028eb8278"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}