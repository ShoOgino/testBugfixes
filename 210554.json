{"path":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","pathOld":"src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    charPool = perThread.charPool;\n    bytePool = perThread.bytePool;\n    docState = perThread.docState;\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    charPool = perThread.charPool;\n    bytePool = perThread.bytePool;\n    docState = perThread.docState;\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9","date":1269379515,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    charPool = perThread.charPool;\n    bytePool = perThread.bytePool;\n    docState = perThread.docState;\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n    \n    //   +3: Posting is referenced by hash, which\n    //       targets 25-50% fill factor; approximate this\n    //       as 3X # pointers\n    bytesPerPosting = consumer.bytesPerPosting() + 3*DocumentsWriter.INT_NUM_BYTE;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    charPool = perThread.charPool;\n    bytePool = perThread.bytePool;\n    docState = perThread.docState;\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    postingsArray = consumer.createPostingsArray(postingsHashSize/2);\n    bytesUsed(postingsArray.size * postingsArray.bytesPerPosting());\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = perThread.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    charPool = perThread.charPool;\n    bytePool = perThread.bytePool;\n    docState = perThread.docState;\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n    \n    //   +3: Posting is referenced by hash, which\n    //       targets 25-50% fill factor; approximate this\n    //       as 3X # pointers\n    bytesPerPosting = consumer.bytesPerPosting() + 3*DocumentsWriter.INT_NUM_BYTE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f58dd714e47e4b20e7ddf69802a24d8278a50d3d","date":1270583819,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n    bytesUsed(postingsArray.size * postingsArray.bytesPerPosting());\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = perThread.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    postingsArray = consumer.createPostingsArray(postingsHashSize/2);\n    bytesUsed(postingsArray.size * postingsArray.bytesPerPosting());\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = perThread.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8dfd02cf03e7a1810924be21cddfdde6d265c14","date":1273590676,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = perThread.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n    bytesUsed(postingsArray.size * postingsArray.bytesPerPosting());\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = perThread.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c18273ea5b3974d2f30117f46f1ae416c28f727","date":1279708040,"type":5,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = termsHash.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = perThread.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","date":1286023472,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    termBytesRef = perThread.termBytesRef;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n\n    postingsHash = new int[postingsHashSize];\n    Arrays.fill(postingsHash, -1);\n    bytesUsed(postingsHashSize * RamUsageEstimator.NUM_BYTES_INT);\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    initPostingsArray();\n\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    utf8 = perThread.utf8;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3d07f1ae3b58102f36f3393c397d78ba4e547a4","date":1300715535,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    termBytesRef = perThread.termBytesRef;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    termBytesRef = perThread.termBytesRef;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":5,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHash,TermsHash,FieldInfo).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHash termsHash, final TermsHash nextTermsHash, final FieldInfo fieldInfo) {\n    intPool = termsHash.intPool;\n    bytePool = termsHash.bytePool;\n    termBytePool = termsHash.termBytePool;\n    docState = termsHash.docState;\n    this.termsHash = termsHash;\n    bytesUsed = termsHash.trackAllocations ? termsHash.docWriter.bytesUsed\n        : new AtomicLong();\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = termsHash.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts);\n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextTermsHash != null)\n      nextPerField = (TermsHashPerField) nextTermsHash.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":null,"sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/TermsHashPerField#TermsHashPerField(DocInverterPerField,TermsHashPerThread,TermsHashPerThread,FieldInfo).mjava","sourceNew":null,"sourceOld":"  public TermsHashPerField(DocInverterPerField docInverterPerField, final TermsHashPerThread perThread, final TermsHashPerThread nextPerThread, final FieldInfo fieldInfo) {\n    this.perThread = perThread;\n    intPool = perThread.intPool;\n    bytePool = perThread.bytePool;\n    termBytePool = perThread.termBytePool;\n    docState = perThread.docState;\n    bytesUsed =  perThread.termsHash.trackAllocations?perThread.termsHash.docWriter.bytesUsed:new AtomicLong();\n\n    fieldState = docInverterPerField.fieldState;\n    this.consumer = perThread.consumer.addField(this, fieldInfo);\n    PostingsBytesStartArray byteStarts = new PostingsBytesStartArray(this, bytesUsed);\n    bytesHash = new BytesRefHash(termBytePool, HASH_INIT_SIZE, byteStarts); \n    streamCount = consumer.getStreamCount();\n    numPostingInt = 2*streamCount;\n    this.fieldInfo = fieldInfo;\n    if (nextPerThread != null)\n      nextPerField = (TermsHashPerField) nextPerThread.addField(docInverterPerField, fieldInfo);\n    else\n      nextPerField = null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["f8dfd02cf03e7a1810924be21cddfdde6d265c14"],"6c18273ea5b3974d2f30117f46f1ae416c28f727":["f8dfd02cf03e7a1810924be21cddfdde6d265c14"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["b3d07f1ae3b58102f36f3393c397d78ba4e547a4","6c18273ea5b3974d2f30117f46f1ae416c28f727"],"f58dd714e47e4b20e7ddf69802a24d8278a50d3d":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","b3d07f1ae3b58102f36f3393c397d78ba4e547a4"],"a3776dccca01c11e7046323cfad46a3b4a471233":["b3d07f1ae3b58102f36f3393c397d78ba4e547a4","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f8dfd02cf03e7a1810924be21cddfdde6d265c14":["f58dd714e47e4b20e7ddf69802a24d8278a50d3d"],"b3d07f1ae3b58102f36f3393c397d78ba4e547a4":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392":["d619839baa8ce5503e496b94a9e42ad6f079293f","b3d07f1ae3b58102f36f3393c397d78ba4e547a4"],"6c18273ea5b3974d2f30117f46f1ae416c28f727":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["f58dd714e47e4b20e7ddf69802a24d8278a50d3d"],"f58dd714e47e4b20e7ddf69802a24d8278a50d3d":["f8dfd02cf03e7a1810924be21cddfdde6d265c14"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"f8dfd02cf03e7a1810924be21cddfdde6d265c14":["5d6c52f55ea3ba9a5b1d5a6dd17f79bc7d308392","6c18273ea5b3974d2f30117f46f1ae416c28f727"],"b3d07f1ae3b58102f36f3393c397d78ba4e547a4":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["741ed634ca00f7fcf06280bd2bf3f7eb9b605cc9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}