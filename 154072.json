{"path":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,DocValues).mjava","commits":[{"id":"d47326e0c6ce589b6962777df409aad0550940fa","date":1304584540,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,DocValues).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/docvalues/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,DocValues).mjava","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      DocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final DocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      DocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final DocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41e5bbad683f7546e96f08ffe8bc50cf447f2586","date":1307113213,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,DocValues).mjava","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      DocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final DocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"41e5bbad683f7546e96f08ffe8bc50cf447f2586":["d47326e0c6ce589b6962777df409aad0550940fa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d47326e0c6ce589b6962777df409aad0550940fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817","d47326e0c6ce589b6962777df409aad0550940fa"],"41e5bbad683f7546e96f08ffe8bc50cf447f2586":[],"d47326e0c6ce589b6962777df409aad0550940fa":["41e5bbad683f7546e96f08ffe8bc50cf447f2586"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["41e5bbad683f7546e96f08ffe8bc50cf447f2586","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}