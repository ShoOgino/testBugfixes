{"path":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","commits":[{"id":"3f20deebda1cf327549c84cb60464135abd31c71","date":1487004368,"type":0,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"/dev/null","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"116fdd6b9e04e18a6547a5650bc0afd3fda020aa","date":1487184909,"type":1,"author":"Joel Bernstein","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doSelectDistinct(SQLVisitor,int,String,String).mjava","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doSelectDistinct(SQLVisitor sqlVisitor,\n                                              int numWorkers,\n                                              String workerCollection,\n                                              String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.fields, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    if(metrics.length > 0) {\n      throw new IOException(\"Select Distinct queries cannot include aggregate functions.\");\n    }\n\n    String fl = fields(fieldSet);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(sqlVisitor.sorts, buckets, sqlVisitor.reverseColumnAliases);\n        // Because of the way adjustSorts works we know that each FieldComparator has a single\n        // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(sqlVisitor.limit > 0) {\n      tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b352170d31f8b9e7dc335bfa0c757a34b5ef0ce6","date":1489617105,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"94179096945a2e59d9d3c224f780c1d79f2d4b8f","date":1489651910,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab68488225b6a6c357dda72ed11dedca9914a192","date":1490013111,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01624b85de12fb02335810bdf325124e59040772","date":1490254940,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(SORT, sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6f4c5d3859373c3a74734e85efa122b17514e3e8","date":1490280013,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(SORT, sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f15af35d55d70c34451f9df5edeaeff6b31f8cbe","date":1519625627,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","sourceNew":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(SORT, sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      @SuppressWarnings(\"resource\")\n      final ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(SORT, sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8582f07e9350eaeb33bf6c4617b8c9895d99c839","date":1591307386,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/sql/SolrTable#handleSelectDistinctMapReduce(String,String,Properties,List[Map.Entry[String,Class]],String,List[Pair[String,String]],Bucket[],String).mjava","sourceNew":"  @SuppressWarnings({\"rawtypes\"})\n  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(SORT, sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      @SuppressWarnings(\"resource\")\n      final ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private TupleStream handleSelectDistinctMapReduce(final String zkHost,\n                                                    final String collection,\n                                                    final Properties properties,\n                                                    final List<Map.Entry<String, Class>> fields,\n                                                    final String query,\n                                                    final List<Pair<String, String>> orders,\n                                                    final Bucket[] buckets,\n                                                    final String limit) throws IOException{\n\n    int numWorkers = Integer.parseInt(properties.getProperty(\"numWorkers\", \"1\"));\n\n    String fl = getFields(fields);\n\n    String sort = null;\n    StreamEqualitor ecomp = null;\n    StreamComparator comp = null;\n\n    if(orders != null && orders.size() > 0) {\n      StreamComparator[] adjustedSorts = adjustSorts(orders, buckets);\n      // Because of the way adjustSorts works we know that each FieldComparator has a single\n      // field name. For this reason we can just look at the leftFieldName\n      FieldEqualitor[] fieldEqualitors = new FieldEqualitor[adjustedSorts.length];\n      StringBuilder buf = new StringBuilder();\n      for(int i=0; i<adjustedSorts.length; i++) {\n        FieldComparator fieldComparator = (FieldComparator)adjustedSorts[i];\n        fieldEqualitors[i] = new FieldEqualitor(fieldComparator.getLeftFieldName());\n        if(i>0) {\n          buf.append(\",\");\n        }\n        buf.append(fieldComparator.getLeftFieldName()).append(\" \").append(fieldComparator.getOrder().toString());\n      }\n\n      sort = buf.toString();\n\n      if(adjustedSorts.length == 1) {\n        ecomp = fieldEqualitors[0];\n        comp = adjustedSorts[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(fieldEqualitors);\n        comp = new MultipleFieldComparator(adjustedSorts);\n      }\n    } else {\n      StringBuilder sortBuf = new StringBuilder();\n      FieldEqualitor[] equalitors = new FieldEqualitor[buckets.length];\n      StreamComparator[] streamComparators = new StreamComparator[buckets.length];\n      for(int i=0; i<buckets.length; i++) {\n        equalitors[i] = new FieldEqualitor(buckets[i].toString());\n        streamComparators[i] = new FieldComparator(buckets[i].toString(), ComparatorOrder.ASCENDING);\n        if(i>0) {\n          sortBuf.append(',');\n        }\n        sortBuf.append(buckets[i].toString()).append(\" asc\");\n      }\n\n      sort = sortBuf.toString();\n\n      if(equalitors.length == 1) {\n        ecomp = equalitors[0];\n        comp = streamComparators[0];\n      } else {\n        ecomp = new MultipleFieldEqualitor(equalitors);\n        comp = new MultipleFieldComparator(streamComparators);\n      }\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, query);\n    params.set(CommonParams.WT, CommonParams.JAVABIN);\n    //Always use the /export handler for Distinct Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(SORT, sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new UniqueStream(cstream, ecomp);\n\n    if(numWorkers > 1) {\n      // Do the unique in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      @SuppressWarnings(\"resource\")\n      final ParallelStream parallelStream = new ParallelStream(zkHost, collection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"unique\", UniqueStream.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    if(limit != null) {\n      tupleStream = new LimitStream(tupleStream, Integer.parseInt(limit));\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b352170d31f8b9e7dc335bfa0c757a34b5ef0ce6":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"116fdd6b9e04e18a6547a5650bc0afd3fda020aa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3f20deebda1cf327549c84cb60464135abd31c71"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"94179096945a2e59d9d3c224f780c1d79f2d4b8f":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"3f20deebda1cf327549c84cb60464135abd31c71":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6f4c5d3859373c3a74734e85efa122b17514e3e8":["ab68488225b6a6c357dda72ed11dedca9914a192"],"f15af35d55d70c34451f9df5edeaeff6b31f8cbe":["01624b85de12fb02335810bdf325124e59040772"],"ab68488225b6a6c357dda72ed11dedca9914a192":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa","94179096945a2e59d9d3c224f780c1d79f2d4b8f"],"01624b85de12fb02335810bdf325124e59040772":["b352170d31f8b9e7dc335bfa0c757a34b5ef0ce6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8582f07e9350eaeb33bf6c4617b8c9895d99c839"],"8582f07e9350eaeb33bf6c4617b8c9895d99c839":["f15af35d55d70c34451f9df5edeaeff6b31f8cbe"]},"commit2Childs":{"b352170d31f8b9e7dc335bfa0c757a34b5ef0ce6":["01624b85de12fb02335810bdf325124e59040772"],"116fdd6b9e04e18a6547a5650bc0afd3fda020aa":["b352170d31f8b9e7dc335bfa0c757a34b5ef0ce6","94179096945a2e59d9d3c224f780c1d79f2d4b8f","ab68488225b6a6c357dda72ed11dedca9914a192"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa","3f20deebda1cf327549c84cb60464135abd31c71"],"94179096945a2e59d9d3c224f780c1d79f2d4b8f":["ab68488225b6a6c357dda72ed11dedca9914a192"],"3f20deebda1cf327549c84cb60464135abd31c71":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"6f4c5d3859373c3a74734e85efa122b17514e3e8":[],"f15af35d55d70c34451f9df5edeaeff6b31f8cbe":["8582f07e9350eaeb33bf6c4617b8c9895d99c839"],"ab68488225b6a6c357dda72ed11dedca9914a192":["6f4c5d3859373c3a74734e85efa122b17514e3e8"],"01624b85de12fb02335810bdf325124e59040772":["f15af35d55d70c34451f9df5edeaeff6b31f8cbe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"8582f07e9350eaeb33bf6c4617b8c9895d99c839":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["6f4c5d3859373c3a74734e85efa122b17514e3e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}