{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","commits":[{"id":"cf8086c7e11dc41303ef1b8050bd355ddfaee76d","date":1350007219,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8e747824826d8d95d8816040f55cfa32233c79c7","date":1350142290,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7492bcb52be51e55d596134b95b2e53cc4ffb91","date":1350223278,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#BlockPostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  public BlockPostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockPostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new BlockSkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                                  state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                                      state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                        state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                                  state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                                      state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                        state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                          state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                              state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99eb4a732d1a908f4636ace52928876136bf1896","date":1413829552,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                                  state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, Lucene41PostingsFormat.DOC_CODEC, Lucene41PostingsFormat.VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                                      state.context);\n        CodecUtil.writeHeader(posOut, Lucene41PostingsFormat.POS_CODEC, Lucene41PostingsFormat.VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                        state.context);\n          CodecUtil.writeHeader(payOut, Lucene41PostingsFormat.PAY_CODEC, Lucene41PostingsFormat.VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(Lucene41PostingsFormat.maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                                  state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                                      state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                        state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#Lucene41PostingsWriter(SegmentWriteState,float).mjava","sourceNew":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                                  state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, Lucene41PostingsFormat.DOC_CODEC, Lucene41PostingsFormat.VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                                      state.context);\n        CodecUtil.writeHeader(posOut, Lucene41PostingsFormat.POS_CODEC, Lucene41PostingsFormat.VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                        state.context);\n          CodecUtil.writeHeader(payOut, Lucene41PostingsFormat.PAY_CODEC, Lucene41PostingsFormat.VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(Lucene41PostingsFormat.maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","sourceOld":"  /** Creates a postings writer with the specified PackedInts overhead ratio */\n  // TODO: does this ctor even make sense?\n  public Lucene41PostingsWriter(SegmentWriteState state, float acceptableOverheadRatio) throws IOException {\n    super();\n\n    docOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.DOC_EXTENSION),\n                                                  state.context);\n    IndexOutput posOut = null;\n    IndexOutput payOut = null;\n    boolean success = false;\n    try {\n      CodecUtil.writeHeader(docOut, DOC_CODEC, VERSION_CURRENT);\n      forUtil = new ForUtil(acceptableOverheadRatio, docOut);\n      if (state.fieldInfos.hasProx()) {\n        posDeltaBuffer = new int[MAX_DATA_SIZE];\n        posOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.POS_EXTENSION),\n                                                      state.context);\n        CodecUtil.writeHeader(posOut, POS_CODEC, VERSION_CURRENT);\n\n        if (state.fieldInfos.hasPayloads()) {\n          payloadBytes = new byte[128];\n          payloadLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          payloadBytes = null;\n          payloadLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasOffsets()) {\n          offsetStartDeltaBuffer = new int[MAX_DATA_SIZE];\n          offsetLengthBuffer = new int[MAX_DATA_SIZE];\n        } else {\n          offsetStartDeltaBuffer = null;\n          offsetLengthBuffer = null;\n        }\n\n        if (state.fieldInfos.hasPayloads() || state.fieldInfos.hasOffsets()) {\n          payOut = state.directory.createOutput(IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene41PostingsFormat.PAY_EXTENSION),\n                                                        state.context);\n          CodecUtil.writeHeader(payOut, PAY_CODEC, VERSION_CURRENT);\n        }\n      } else {\n        posDeltaBuffer = null;\n        payloadLengthBuffer = null;\n        offsetStartDeltaBuffer = null;\n        offsetLengthBuffer = null;\n        payloadBytes = null;\n      }\n      this.payOut = payOut;\n      this.posOut = posOut;\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(docOut, posOut, payOut);\n      }\n    }\n\n    docDeltaBuffer = new int[MAX_DATA_SIZE];\n    freqBuffer = new int[MAX_DATA_SIZE];\n\n    // TODO: should we try skipping every 2/4 blocks...?\n    skipWriter = new Lucene41SkipWriter(maxSkipLevels,\n                                     BLOCK_SIZE, \n                                     state.segmentInfo.getDocCount(),\n                                     docOut,\n                                     posOut,\n                                     payOut);\n\n    encoded = new byte[MAX_ENCODED_SIZE];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["c7492bcb52be51e55d596134b95b2e53cc4ffb91","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8e747824826d8d95d8816040f55cfa32233c79c7"],"99eb4a732d1a908f4636ace52928876136bf1896":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["1f3b037cd083286b2af89f96e768f85dcd8072d6","99eb4a732d1a908f4636ace52928876136bf1896"],"8e747824826d8d95d8816040f55cfa32233c79c7":["cf8086c7e11dc41303ef1b8050bd355ddfaee76d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","99eb4a732d1a908f4636ace52928876136bf1896","db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6","db4fdbf3d262768eabc027cd8321edca0cd11fa8"],"99eb4a732d1a908f4636ace52928876136bf1896":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["8e747824826d8d95d8816040f55cfa32233c79c7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c7492bcb52be51e55d596134b95b2e53cc4ffb91","cf8086c7e11dc41303ef1b8050bd355ddfaee76d","db4fdbf3d262768eabc027cd8321edca0cd11fa8"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8e747824826d8d95d8816040f55cfa32233c79c7":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","db4fdbf3d262768eabc027cd8321edca0cd11fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}