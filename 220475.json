{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","commits":[{"id":"f00f1c5fad501b66705121feb623f8cfbb6712f9","date":1431347838,"type":0,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"/dev/null","sourceNew":"  private void testParallelMergeStream() throws Exception {\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\");\n    indexr(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\");\n    indexr(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\");\n    indexr(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\");\n    indexr(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\");\n    indexr(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\");\n\n    commit();\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withStreamFunction(\"search\", CloudSolrStream.class)\n        .withStreamFunction(\"unique\", UniqueStream.class)\n        .withStreamFunction(\"top\", RankStream.class)\n        .withStreamFunction(\"group\", ReducerStream.class)\n        .withStreamFunction(\"merge\", MergeStream.class)\n        .withStreamFunction(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n    del(\"*:*\");\n    commit();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3078cad1008b796c6d573b743c586fdf9ef5660a","date":1436019875,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  private void testParallelMergeStream() throws Exception {\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\");\n    indexr(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\");\n    indexr(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\");\n    indexr(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\");\n    indexr(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\");\n    indexr(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\");\n\n    commit();\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n    del(\"*:*\");\n    commit();\n  }\n\n","sourceOld":"  private void testParallelMergeStream() throws Exception {\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\");\n    indexr(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\");\n    indexr(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\");\n    indexr(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\");\n    indexr(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\");\n    indexr(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\");\n\n    commit();\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withStreamFunction(\"search\", CloudSolrStream.class)\n        .withStreamFunction(\"unique\", UniqueStream.class)\n        .withStreamFunction(\"top\", RankStream.class)\n        .withStreamFunction(\"group\", ReducerStream.class)\n        .withStreamFunction(\"merge\", MergeStream.class)\n        .withStreamFunction(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b940572a59da1b42b6c20ab5278155b12816807a","date":1462388874,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n  }\n\n","sourceOld":"  private void testParallelMergeStream() throws Exception {\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\");\n    indexr(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\");\n    indexr(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\");\n    indexr(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\");\n    indexr(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\");\n    indexr(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\");\n\n    commit();\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd78ba595fa6cdd7fff930f26d154d13a823fa47","date":1462400514,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n  }\n\n","sourceOld":"  private void testParallelMergeStream() throws Exception {\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\");\n    indexr(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\");\n    indexr(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\");\n    indexr(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\");\n    indexr(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\");\n    indexr(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\");\n\n    commit();\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73450c0955930295d34703e7ddbfc6973b7a121a","date":1462431925,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n  }\n\n","sourceOld":"  private void testParallelMergeStream() throws Exception {\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\");\n    indexr(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\");\n    indexr(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\");\n    indexr(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\");\n    indexr(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\");\n    indexr(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\");\n\n    commit();\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904","date":1462576651,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n  }\n\n","sourceOld":"  private void testParallelMergeStream() throws Exception {\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\");\n    indexr(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\");\n    indexr(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\");\n    indexr(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\");\n    indexr(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\");\n    indexr(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\");\n\n    commit();\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(collection1, merge(search(collection1, q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(collection1, q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3ac1075ab5d486199f24ec3a7c07dc9b74606161","date":1476897426,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2305f39a86a068f1cee6fc5fbdfb760b153ac138","date":1476906991,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0,1,2,3,4,7,6,8,9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9,8,6,4,3,2,1,0);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8c969f15cd04d31e520319c619a445ae21f02d72","date":1479263638,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1ef55e1fff7ff44354432770ad8bc19be1fcc75","date":1479266056,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTION);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTION, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTION + \", merge(search(\" + COLLECTION + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTION + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c405288c4553ffb50ab8ca5adbdde9881bcec4e4","date":1491938682,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    try {\n      //Test ascending\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i asc\\\")\");\n      pstream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 9);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n      //Test descending\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i desc\\\")\");\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 8);\n      assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    try {\n      //Test ascending\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i asc\\\")\");\n      pstream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 9);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n      //Test descending\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i desc\\\")\");\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 8);\n      assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    //Test ascending\n    ParallelStream pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i asc\\\")\");\n\n    List<Tuple> tuples = getTuples(pstream);\n\n\n\n    assert(tuples.size() == 9);\n    assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n    //Test descending\n\n    pstream = (ParallelStream)streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"a_i desc\\\")\");\n\n    tuples = getTuples(pstream);\n\n    assert(tuples.size() == 8);\n    assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf","date":1522951207,"type":5,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelMergeStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelMergeStream().mjava","sourceNew":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    try {\n      //Test ascending\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i asc\\\")\");\n      pstream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 9);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n      //Test descending\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i desc\\\")\");\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 8);\n      assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelMergeStream() throws Exception {\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\")\n        .add(id, \"5\", \"a_s\", \"hello0\", \"a_i\", \"10\", \"a_f\", \"0\")\n        .add(id, \"6\", \"a_s\", \"hello2\", \"a_i\", \"8\", \"a_f\", \"0\")\n        .add(id, \"7\", \"a_s\", \"hello3\", \"a_i\", \"7\", \"a_f\", \"3\")\n        .add(id, \"8\", \"a_s\", \"hello4\", \"a_i\", \"11\", \"a_f\", \"4\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"100\", \"a_f\", \"1\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory streamFactory = new StreamFactory().withCollectionZkHost(COLLECTIONORALIAS, zkHost)\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"unique\", UniqueStream.class)\n        .withFunctionName(\"top\", RankStream.class)\n        .withFunctionName(\"group\", ReducerStream.class)\n        .withFunctionName(\"merge\", MergeStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class);\n\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    try {\n      //Test ascending\n      ParallelStream pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 7 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i asc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i asc\\\"), workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i asc\\\")\");\n      pstream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(pstream);\n\n      assert (tuples.size() == 9);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 7, 6, 8, 9);\n\n      //Test descending\n\n      pstream = (ParallelStream) streamFactory.constructStream(\"parallel(\" + COLLECTIONORALIAS + \", merge(search(\" + COLLECTIONORALIAS + \", q=\\\"id:(4 1 8 9)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), search(\" + COLLECTIONORALIAS + \", q=\\\"id:(0 2 3 6)\\\", fl=\\\"id,a_s,a_i\\\", sort=\\\"a_i desc\\\", partitionKeys=\\\"a_i\\\"), on=\\\"a_i desc\\\"), workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"a_i desc\\\")\");\n      pstream.setStreamContext(streamContext);\n      tuples = getTuples(pstream);\n\n      assert (tuples.size() == 8);\n      assertOrder(tuples, 9, 8, 6, 4, 3, 2, 1, 0);\n    } finally {\n      solrClientCache.close();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f00f1c5fad501b66705121feb623f8cfbb6712f9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["8c969f15cd04d31e520319c619a445ae21f02d72"],"3078cad1008b796c6d573b743c586fdf9ef5660a":["f00f1c5fad501b66705121feb623f8cfbb6712f9"],"73450c0955930295d34703e7ddbfc6973b7a121a":["3078cad1008b796c6d573b743c586fdf9ef5660a","b940572a59da1b42b6c20ab5278155b12816807a"],"c405288c4553ffb50ab8ca5adbdde9881bcec4e4":["8c969f15cd04d31e520319c619a445ae21f02d72"],"b940572a59da1b42b6c20ab5278155b12816807a":["3078cad1008b796c6d573b743c586fdf9ef5660a"],"3ac1075ab5d486199f24ec3a7c07dc9b74606161":["73450c0955930295d34703e7ddbfc6973b7a121a"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["bd78ba595fa6cdd7fff930f26d154d13a823fa47","2305f39a86a068f1cee6fc5fbdfb760b153ac138"],"2305f39a86a068f1cee6fc5fbdfb760b153ac138":["73450c0955930295d34703e7ddbfc6973b7a121a","3ac1075ab5d486199f24ec3a7c07dc9b74606161"],"bd78ba595fa6cdd7fff930f26d154d13a823fa47":["3078cad1008b796c6d573b743c586fdf9ef5660a","b940572a59da1b42b6c20ab5278155b12816807a"],"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904":["3078cad1008b796c6d573b743c586fdf9ef5660a","73450c0955930295d34703e7ddbfc6973b7a121a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","8c969f15cd04d31e520319c619a445ae21f02d72"],"8c969f15cd04d31e520319c619a445ae21f02d72":["2305f39a86a068f1cee6fc5fbdfb760b153ac138"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["c405288c4553ffb50ab8ca5adbdde9881bcec4e4"]},"commit2Childs":{"f00f1c5fad501b66705121feb623f8cfbb6712f9":["3078cad1008b796c6d573b743c586fdf9ef5660a"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":[],"3078cad1008b796c6d573b743c586fdf9ef5660a":["73450c0955930295d34703e7ddbfc6973b7a121a","b940572a59da1b42b6c20ab5278155b12816807a","bd78ba595fa6cdd7fff930f26d154d13a823fa47","a8ed5da4b0191db6bc7f77f9feb35da6bd76f904"],"73450c0955930295d34703e7ddbfc6973b7a121a":["3ac1075ab5d486199f24ec3a7c07dc9b74606161","2305f39a86a068f1cee6fc5fbdfb760b153ac138","a8ed5da4b0191db6bc7f77f9feb35da6bd76f904"],"c405288c4553ffb50ab8ca5adbdde9881bcec4e4":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"b940572a59da1b42b6c20ab5278155b12816807a":["73450c0955930295d34703e7ddbfc6973b7a121a","bd78ba595fa6cdd7fff930f26d154d13a823fa47"],"3ac1075ab5d486199f24ec3a7c07dc9b74606161":["2305f39a86a068f1cee6fc5fbdfb760b153ac138"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"2305f39a86a068f1cee6fc5fbdfb760b153ac138":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","8c969f15cd04d31e520319c619a445ae21f02d72"],"bd78ba595fa6cdd7fff930f26d154d13a823fa47":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f00f1c5fad501b66705121feb623f8cfbb6712f9"],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":[],"8c969f15cd04d31e520319c619a445ae21f02d72":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","c405288c4553ffb50ab8ca5adbdde9881bcec4e4","a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","a8ed5da4b0191db6bc7f77f9feb35da6bd76f904","a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}