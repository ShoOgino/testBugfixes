{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","commits":[{"id":"622a708571e534680618b3c5e0c28ac539a47776","date":1517406892,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum).mjava","sourceNew":"    void write(BytesRef text, TermsEnum termsEnum, NormsProducer norms) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen, norms);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        pendingTerms = Arrays.copyOf(pendingTerms, ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n        for(int i=pendingCount;i<pendingTerms.length;i++) {\n          pendingTerms[i] = new TermEntry();\n        }\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    void write(BytesRef text, TermsEnum termsEnum) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        pendingTerms = Arrays.copyOf(pendingTerms, ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n        for(int i=pendingCount;i<pendingTerms.length;i++) {\n          pendingTerms[i] = new TermEntry();\n        }\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9798d0818e7a880546802b509792d3f3d57babd2","date":1528358901,"type":3,"author":"Nhat Nguyen","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","sourceNew":"    void write(BytesRef text, TermsEnum termsEnum, NormsProducer norms) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen, norms);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      pendingTerms = ArrayUtil.grow(pendingTerms, pendingCount + 1);\n      for (int i = pendingCount; i < pendingTerms.length; i++) {\n        pendingTerms[i] = new TermEntry();\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    void write(BytesRef text, TermsEnum termsEnum, NormsProducer norms) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen, norms);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        pendingTerms = Arrays.copyOf(pendingTerms, ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n        for(int i=pendingCount;i<pendingTerms.length;i++) {\n          pendingTerms[i] = new TermEntry();\n        }\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","sourceNew":"    void write(BytesRef text, TermsEnum termsEnum, NormsProducer norms) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen, norms);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      pendingTerms = ArrayUtil.grow(pendingTerms, pendingCount + 1);\n      for (int i = pendingCount; i < pendingTerms.length; i++) {\n        pendingTerms[i] = new TermEntry();\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    void write(BytesRef text, TermsEnum termsEnum, NormsProducer norms) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen, norms);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        pendingTerms = Arrays.copyOf(pendingTerms, ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n        for(int i=pendingCount;i<pendingTerms.length;i++) {\n          pendingTerms[i] = new TermEntry();\n        }\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/BlockTermsWriter.TermsWriter#write(BytesRef,TermsEnum,NormsProducer).mjava","sourceNew":"    void write(BytesRef text, TermsEnum termsEnum, NormsProducer norms) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen, norms);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      pendingTerms = ArrayUtil.grow(pendingTerms, pendingCount + 1);\n      for (int i = pendingCount; i < pendingTerms.length; i++) {\n        pendingTerms[i] = new TermEntry();\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","sourceOld":"    void write(BytesRef text, TermsEnum termsEnum, NormsProducer norms) throws IOException {\n\n      BlockTermState state = postingsWriter.writeTerm(text, termsEnum, docsSeen, norms);\n      if (state == null) {\n        // No docs for this term:\n        return;\n      }\n      sumDocFreq += state.docFreq;\n      sumTotalTermFreq += state.totalTermFreq;\n\n      assert state.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      TermStats stats = new TermStats(state.docFreq, state.totalTermFreq);\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        pendingTerms = Arrays.copyOf(pendingTerms, ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF));\n        for(int i=pendingCount;i<pendingTerms.length;i++) {\n          pendingTerms[i] = new TermEntry();\n        }\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.state = state;\n\n      pendingCount++;\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["622a708571e534680618b3c5e0c28ac539a47776","9798d0818e7a880546802b509792d3f3d57babd2"],"622a708571e534680618b3c5e0c28ac539a47776":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9798d0818e7a880546802b509792d3f3d57babd2":["622a708571e534680618b3c5e0c28ac539a47776"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9798d0818e7a880546802b509792d3f3d57babd2"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["622a708571e534680618b3c5e0c28ac539a47776","9798d0818e7a880546802b509792d3f3d57babd2"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["622a708571e534680618b3c5e0c28ac539a47776"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"622a708571e534680618b3c5e0c28ac539a47776":["b70042a8a492f7054d480ccdd2be9796510d4327","9798d0818e7a880546802b509792d3f3d57babd2","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"9798d0818e7a880546802b509792d3f3d57babd2":["b70042a8a492f7054d480ccdd2be9796510d4327","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}