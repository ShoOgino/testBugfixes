{"path":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","sourceNew":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++)\n            sumSize += size(infos.info(j+i));\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","sourceOld":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++)\n            sumSize += size(infos.info(j+i));\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","sourceNew":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentInfoPerCommit> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i));\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","sourceOld":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++)\n            sumSize += size(infos.info(j+i));\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","sourceNew":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentInfoPerCommit> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i));\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","sourceOld":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++)\n            sumSize += size(infos.info(j+i));\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","sourceNew":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i));\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","sourceOld":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentInfoPerCommit> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i));\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"67bcec391f8e94564afde5a0f0e6538d07a96255","date":1393593793,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","sourceNew":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos, infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i));\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","sourceOld":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i));\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","bugFix":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"027bee21e09164c9ee230395405076d1e0034b30","date":1401521821,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int,IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","sourceNew":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last, IndexWriter writer) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos, infos.info(0), writer)) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i), writer);\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1), writer) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","sourceOld":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos, infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i));\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","9d153abcf92dc5329d98571a8c3035df9bd80648"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9d153abcf92dc5329d98571a8c3035df9bd80648":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"027bee21e09164c9ee230395405076d1e0034b30":["67bcec391f8e94564afde5a0f0e6538d07a96255"],"67bcec391f8e94564afde5a0f0e6538d07a96255":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["027bee21e09164c9ee230395405076d1e0034b30"]},"commit2Childs":{"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["67bcec391f8e94564afde5a0f0e6538d07a96255"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","9d153abcf92dc5329d98571a8c3035df9bd80648"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"027bee21e09164c9ee230395405076d1e0034b30":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"67bcec391f8e94564afde5a0f0e6538d07a96255":["027bee21e09164c9ee230395405076d1e0034b30"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}