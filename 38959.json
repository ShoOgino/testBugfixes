{"path":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean).mjava","commits":[{"id":"20f6b7cff3771384f27af0f059795d7e64aff6b9","date":1425498309,"type":1,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SnapPuller#fetchLatestIndex(SolrCore,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws IOException, InterruptedException {\n    successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n        \n        if (isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n              reloadCore = true;\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n        if (reloadCore) {\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      try {\n        if (!successfulInstall) {\n          try {\n            logReplicationTimeAndConfFiles(null, successfulInstall);\n          } catch(Exception e) {\n            LOG.error(\"caught\", e);\n          }\n        }\n        filesToDownload = filesDownloaded = confFilesDownloaded = confFilesToDownload = null;\n        replicationStartTime = 0;\n        dirFileFetcher = null;\n        localFileFetcher = null;\n        if (fsyncService != null && !fsyncService.isShutdown()) fsyncService\n            .shutdownNow();\n        fsyncService = null;\n        stop = false;\n        fsyncException = null;\n      } finally {\n        if (deleteTmpIdxDir && tmpIndexDir != null) {\n          try {\n            core.getDirectoryFactory().doneWithDirectory(tmpIndexDir);\n            core.getDirectoryFactory().remove(tmpIndexDir);\n          } catch (IOException e) {\n            SolrException.log(LOG, \"Error removing directory \" + tmpIndexDir, e);\n          }\n        }\n        \n        if (tmpIndexDir != null) {\n          core.getDirectoryFactory().release(tmpIndexDir);\n        }\n        \n        if (indexDir != null) {\n          core.getDirectoryFactory().release(indexDir);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws IOException, InterruptedException {\n    successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n        \n        if (isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"SnapPuller unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"SnapPuller slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n              reloadCore = true;\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n        if (reloadCore) {\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      try {\n        if (!successfulInstall) {\n          try {\n            logReplicationTimeAndConfFiles(null, successfulInstall);\n          } catch(Exception e) {\n            LOG.error(\"caught\", e);\n          }\n        }\n        filesToDownload = filesDownloaded = confFilesDownloaded = confFilesToDownload = null;\n        replicationStartTime = 0;\n        dirFileFetcher = null;\n        localFileFetcher = null;\n        if (fsyncService != null && !fsyncService.isShutdown()) fsyncService\n            .shutdownNow();\n        fsyncService = null;\n        stop = false;\n        fsyncException = null;\n      } finally {\n        if (deleteTmpIdxDir && tmpIndexDir != null) {\n          try {\n            core.getDirectoryFactory().doneWithDirectory(tmpIndexDir);\n            core.getDirectoryFactory().remove(tmpIndexDir);\n          } catch (IOException e) {\n            SolrException.log(LOG, \"Error removing directory \" + tmpIndexDir, e);\n          }\n        }\n        \n        if (tmpIndexDir != null) {\n          core.getDirectoryFactory().release(tmpIndexDir);\n        }\n        \n        if (indexDir != null) {\n          core.getDirectoryFactory().release(indexDir);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c94d2661bc1c14426980ec7882e951fdcff08d0","date":1427167177,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean).mjava","sourceNew":"  boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws IOException, InterruptedException {\n    return fetchLatestIndex(core, forceReplication, false);\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws IOException, InterruptedException {\n    successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n        \n        if (isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n              reloadCore = true;\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n        if (reloadCore) {\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      try {\n        if (!successfulInstall) {\n          try {\n            logReplicationTimeAndConfFiles(null, successfulInstall);\n          } catch(Exception e) {\n            LOG.error(\"caught\", e);\n          }\n        }\n        filesToDownload = filesDownloaded = confFilesDownloaded = confFilesToDownload = null;\n        replicationStartTime = 0;\n        dirFileFetcher = null;\n        localFileFetcher = null;\n        if (fsyncService != null && !fsyncService.isShutdown()) fsyncService\n            .shutdownNow();\n        fsyncService = null;\n        stop = false;\n        fsyncException = null;\n      } finally {\n        if (deleteTmpIdxDir && tmpIndexDir != null) {\n          try {\n            core.getDirectoryFactory().doneWithDirectory(tmpIndexDir);\n            core.getDirectoryFactory().remove(tmpIndexDir);\n          } catch (IOException e) {\n            SolrException.log(LOG, \"Error removing directory \" + tmpIndexDir, e);\n          }\n        }\n        \n        if (tmpIndexDir != null) {\n          core.getDirectoryFactory().release(tmpIndexDir);\n        }\n        \n        if (indexDir != null) {\n          core.getDirectoryFactory().release(indexDir);\n        }\n      }\n    }\n  }\n\n","bugFix":["ad3c006a1d6ec52c49f33c62a3678bf5023d9baf","190779ba7de3fda15afd1bbafbc383720a4b0966","bd9ddb59e9d33950773d186a8b726b5610ae3aad","4dcfb92697fbd03e488cf9e5155514e3270d0fc3","2a77b0d8787d127be70f6c4055937ee9c0d4ee3b","8dd517686f746fb280a35ebadd0abf38e864fb41","1b7910b51406c081814c946331386da674f26aa5","c01638f4dd94981c1d3d52c4f7991246a5a24aba","1c8719b2c0b382be11f5b193b6fc14bc310e906b","be4d0855f94432c9a580ae7750c6f842d604a3e4","9f5e2ce7174b645aee7b07eab55640cf0b28916b","b1615f6fc540ecd5dea7b03d2bac9a18bba69d5c","8d50ba1695a40ff11a41bbfc1ad45c7bfd6a5738","d9405f486872f1e416304dfe389741f4ee2f8a4d","0fa112cb510d1bdb66c944fe9ba78679974d3c14","1eda2abfda9da3ca2bc5c5872d6b8c0f4948f674","058801f8673d53a5abac8088204860ec29a40f0d","b3c2c17185ad7fb0aa9b81dbd9d0395debbc4519","08bcaef9e931052e4ca24133a89cc6aefaf61829","2c007e7c4cf8c55bc2a5884e315123afaaeec87f","dea8e36e8c36d610840396c282a5affe3f722f4e","4897c5b415f476d84ec970a19c41510645887526","20f6b7cff3771384f27af0f059795d7e64aff6b9","66c64e8cfded6a585100e6430238faaf416f3fea","d8a3067239133ceb0117bc3d48356169cf03894f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean).mjava","pathOld":"/dev/null","sourceNew":"  boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws IOException, InterruptedException {\n    return fetchLatestIndex(core, forceReplication, false);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b13106276bb5ea342253dbf6aae7b675adb38d3","date":1428054414,"type":4,"author":"Varun Thacker","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean).mjava","sourceNew":null,"sourceOld":"  boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws IOException, InterruptedException {\n    return fetchLatestIndex(core, forceReplication, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","date":1428091986,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean).mjava","sourceNew":null,"sourceOld":"  boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws IOException, InterruptedException {\n    return fetchLatestIndex(core, forceReplication, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6c94d2661bc1c14426980ec7882e951fdcff08d0"],"20f6b7cff3771384f27af0f059795d7e64aff6b9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["20f6b7cff3771384f27af0f059795d7e64aff6b9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","7b13106276bb5ea342253dbf6aae7b675adb38d3"],"7b13106276bb5ea342253dbf6aae7b675adb38d3":["6c94d2661bc1c14426980ec7882e951fdcff08d0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b13106276bb5ea342253dbf6aae7b675adb38d3"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c"],"20f6b7cff3771384f27af0f059795d7e64aff6b9":["6c94d2661bc1c14426980ec7882e951fdcff08d0"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","7b13106276bb5ea342253dbf6aae7b675adb38d3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","20f6b7cff3771384f27af0f059795d7e64aff6b9"],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":[],"7b13106276bb5ea342253dbf6aae7b675adb38d3":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}