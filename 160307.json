{"path":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","commits":[{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","pathOld":"/dev/null","sourceNew":"  DocumentsWriter(Directory directory, IndexWriter writer) throws IOException {\n    this.directory = directory;\n    this.writer = writer;\n\n    postingsFreeList = new Posting[0];\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be","date":1204801324,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","sourceNew":"  DocumentsWriter(Directory directory, IndexWriter writer) throws IOException {\n    this.directory = directory;\n    this.writer = writer;\n    flushedDocCount = writer.docCount();\n    postingsFreeList = new Posting[0];\n  }\n\n","sourceOld":"  DocumentsWriter(Directory directory, IndexWriter writer) throws IOException {\n    this.directory = directory;\n    this.writer = writer;\n\n    postingsFreeList = new Posting[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5350389bf83287111f7760b9e3db3af8e3648474","date":1216372812,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","sourceNew":"  DocumentsWriter(Directory directory, IndexWriter writer) throws IOException {\n    this.directory = directory;\n    this.writer = writer;\n    this.similarity = writer.getSimilarity();\n    flushedDocCount = writer.maxDoc();\n\n    /*\n      This is the current indexing chain:\n\n      DocConsumer / DocConsumerPerThread\n        --> code: DocFieldProcessor / DocFieldProcessorPerThread\n          --> DocFieldConsumer / DocFieldConsumerPerThread / DocFieldConsumerPerField\n            --> code: DocFieldConsumers / DocFieldConsumersPerThread / DocFieldConsumersPerField\n              --> code: DocInverter / DocInverterPerThread / DocInverterPerField\n                --> InvertedDocConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField\n                  --> code: TermsHash / TermsHashPerThread / TermsHashPerField\n                    --> TermsHashConsumer / TermsHashConsumerPerThread / TermsHashConsumerPerField\n                      --> code: FreqProxTermsWriter / FreqProxTermsWriterPerThread / FreqProxTermsWriterPerField\n                      --> code: TermVectorsTermsWriter / TermVectorsTermsWriterPerThread / TermVectorsTermsWriterPerField\n                --> InvertedDocEndConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField\n                  --> code: NormsWriter / NormsWriterPerThread / NormsWriterPerField\n              --> code: StoredFieldsWriter / StoredFieldsWriterPerThread / StoredFieldsWriterPerField\n    */\n\n    // TODO FI: this should be something the user can pass in\n    // Build up indexing chain:\n    final TermsHashConsumer termVectorsWriter = new TermVectorsTermsWriter(this);\n    final TermsHashConsumer freqProxWriter = new FreqProxTermsWriter();\n\n    final InvertedDocConsumer  termsHash = new TermsHash(this, true, freqProxWriter,\n                                                         new TermsHash(this, false, termVectorsWriter, null));\n    final NormsWriter normsWriter = new NormsWriter();\n    final DocInverter docInverter = new DocInverter(termsHash, normsWriter);\n    final StoredFieldsWriter fieldsWriter = new StoredFieldsWriter(this);\n    final DocFieldConsumers docFieldConsumers = new DocFieldConsumers(docInverter, fieldsWriter);\n    consumer = new DocFieldProcessor(this, docFieldConsumers);\n  }\n\n","sourceOld":"  DocumentsWriter(Directory directory, IndexWriter writer) throws IOException {\n    this.directory = directory;\n    this.writer = writer;\n    flushedDocCount = writer.docCount();\n    postingsFreeList = new Posting[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"902ba79f4590a41c663c447756d2e5041cbbdda9","date":1217956662,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","sourceNew":"  DocumentsWriter(Directory directory, IndexWriter writer) throws IOException {\n    this.directory = directory;\n    this.writer = writer;\n    this.similarity = writer.getSimilarity();\n    flushedDocCount = writer.maxDoc();\n\n    /*\n      This is the current indexing chain:\n\n      DocConsumer / DocConsumerPerThread\n        --> code: DocFieldProcessor / DocFieldProcessorPerThread\n          --> DocFieldConsumer / DocFieldConsumerPerThread / DocFieldConsumerPerField\n            --> code: DocFieldConsumers / DocFieldConsumersPerThread / DocFieldConsumersPerField\n              --> code: DocInverter / DocInverterPerThread / DocInverterPerField\n                --> InvertedDocConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField\n                  --> code: TermsHash / TermsHashPerThread / TermsHashPerField\n                    --> TermsHashConsumer / TermsHashConsumerPerThread / TermsHashConsumerPerField\n                      --> code: FreqProxTermsWriter / FreqProxTermsWriterPerThread / FreqProxTermsWriterPerField\n                      --> code: TermVectorsTermsWriter / TermVectorsTermsWriterPerThread / TermVectorsTermsWriterPerField\n                --> InvertedDocEndConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField\n                  --> code: NormsWriter / NormsWriterPerThread / NormsWriterPerField\n              --> code: StoredFieldsWriter / StoredFieldsWriterPerThread / StoredFieldsWriterPerField\n    */\n\n    // TODO FI: this should be something the user can pass in\n    // Build up indexing chain:\n    final TermsHashConsumer termVectorsWriter = new TermVectorsTermsWriter(this);\n    final TermsHashConsumer freqProxWriter = new FreqProxTermsWriter();\n\n    final InvertedDocConsumer  termsHash = new TermsHash(this, true, freqProxWriter,\n                                                         new TermsHash(this, false, termVectorsWriter, null));\n    final NormsWriter normsWriter = new NormsWriter();\n    final DocInverter docInverter = new DocInverter(termsHash, normsWriter);\n    final StoredFieldsWriter fieldsWriter = new StoredFieldsWriter(this);\n    final DocFieldConsumers docFieldConsumers = new DocFieldConsumers(docInverter, fieldsWriter);\n    consumer = docFieldProcessor = new DocFieldProcessor(this, docFieldConsumers);\n  }\n\n","sourceOld":"  DocumentsWriter(Directory directory, IndexWriter writer) throws IOException {\n    this.directory = directory;\n    this.writer = writer;\n    this.similarity = writer.getSimilarity();\n    flushedDocCount = writer.maxDoc();\n\n    /*\n      This is the current indexing chain:\n\n      DocConsumer / DocConsumerPerThread\n        --> code: DocFieldProcessor / DocFieldProcessorPerThread\n          --> DocFieldConsumer / DocFieldConsumerPerThread / DocFieldConsumerPerField\n            --> code: DocFieldConsumers / DocFieldConsumersPerThread / DocFieldConsumersPerField\n              --> code: DocInverter / DocInverterPerThread / DocInverterPerField\n                --> InvertedDocConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField\n                  --> code: TermsHash / TermsHashPerThread / TermsHashPerField\n                    --> TermsHashConsumer / TermsHashConsumerPerThread / TermsHashConsumerPerField\n                      --> code: FreqProxTermsWriter / FreqProxTermsWriterPerThread / FreqProxTermsWriterPerField\n                      --> code: TermVectorsTermsWriter / TermVectorsTermsWriterPerThread / TermVectorsTermsWriterPerField\n                --> InvertedDocEndConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField\n                  --> code: NormsWriter / NormsWriterPerThread / NormsWriterPerField\n              --> code: StoredFieldsWriter / StoredFieldsWriterPerThread / StoredFieldsWriterPerField\n    */\n\n    // TODO FI: this should be something the user can pass in\n    // Build up indexing chain:\n    final TermsHashConsumer termVectorsWriter = new TermVectorsTermsWriter(this);\n    final TermsHashConsumer freqProxWriter = new FreqProxTermsWriter();\n\n    final InvertedDocConsumer  termsHash = new TermsHash(this, true, freqProxWriter,\n                                                         new TermsHash(this, false, termVectorsWriter, null));\n    final NormsWriter normsWriter = new NormsWriter();\n    final DocInverter docInverter = new DocInverter(termsHash, normsWriter);\n    final StoredFieldsWriter fieldsWriter = new StoredFieldsWriter(this);\n    final DocFieldConsumers docFieldConsumers = new DocFieldConsumers(docInverter, fieldsWriter);\n    consumer = new DocFieldProcessor(this, docFieldConsumers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"96609ea54585d552d1498d27226f664b5e88d337","date":1223921531,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#DocumentsWriter(Directory,IndexWriter).mjava","sourceNew":null,"sourceOld":"  DocumentsWriter(Directory directory, IndexWriter writer) throws IOException {\n    this.directory = directory;\n    this.writer = writer;\n    this.similarity = writer.getSimilarity();\n    flushedDocCount = writer.maxDoc();\n\n    /*\n      This is the current indexing chain:\n\n      DocConsumer / DocConsumerPerThread\n        --> code: DocFieldProcessor / DocFieldProcessorPerThread\n          --> DocFieldConsumer / DocFieldConsumerPerThread / DocFieldConsumerPerField\n            --> code: DocFieldConsumers / DocFieldConsumersPerThread / DocFieldConsumersPerField\n              --> code: DocInverter / DocInverterPerThread / DocInverterPerField\n                --> InvertedDocConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField\n                  --> code: TermsHash / TermsHashPerThread / TermsHashPerField\n                    --> TermsHashConsumer / TermsHashConsumerPerThread / TermsHashConsumerPerField\n                      --> code: FreqProxTermsWriter / FreqProxTermsWriterPerThread / FreqProxTermsWriterPerField\n                      --> code: TermVectorsTermsWriter / TermVectorsTermsWriterPerThread / TermVectorsTermsWriterPerField\n                --> InvertedDocEndConsumer / InvertedDocConsumerPerThread / InvertedDocConsumerPerField\n                  --> code: NormsWriter / NormsWriterPerThread / NormsWriterPerField\n              --> code: StoredFieldsWriter / StoredFieldsWriterPerThread / StoredFieldsWriterPerField\n    */\n\n    // TODO FI: this should be something the user can pass in\n    // Build up indexing chain:\n    final TermsHashConsumer termVectorsWriter = new TermVectorsTermsWriter(this);\n    final TermsHashConsumer freqProxWriter = new FreqProxTermsWriter();\n\n    final InvertedDocConsumer  termsHash = new TermsHash(this, true, freqProxWriter,\n                                                         new TermsHash(this, false, termVectorsWriter, null));\n    final NormsWriter normsWriter = new NormsWriter();\n    final DocInverter docInverter = new DocInverter(termsHash, normsWriter);\n    final StoredFieldsWriter fieldsWriter = new StoredFieldsWriter(this);\n    final DocFieldConsumers docFieldConsumers = new DocFieldConsumers(docInverter, fieldsWriter);\n    consumer = docFieldProcessor = new DocFieldProcessor(this, docFieldConsumers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"96609ea54585d552d1498d27226f664b5e88d337":["902ba79f4590a41c663c447756d2e5041cbbdda9"],"902ba79f4590a41c663c447756d2e5041cbbdda9":["5350389bf83287111f7760b9e3db3af8e3648474"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"5350389bf83287111f7760b9e3db3af8e3648474":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["96609ea54585d552d1498d27226f664b5e88d337"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"96609ea54585d552d1498d27226f664b5e88d337":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"902ba79f4590a41c663c447756d2e5041cbbdda9":["96609ea54585d552d1498d27226f664b5e88d337"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["5350389bf83287111f7760b9e3db3af8e3648474"],"5350389bf83287111f7760b9e3db3af8e3648474":["902ba79f4590a41c663c447756d2e5041cbbdda9"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}