{"path":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","commits":[{"id":"2c705a0d590cf911e7c942df49563ca2ea176e22","date":1526916174,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","pathOld":"/dev/null","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: some docs may have no value in a field\n        final int numValsThisDoc = TestUtil.nextInt(random(), 0, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c5ec3c464e62e57df598ba20e010313bf6d5d7b4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1bd47e89c87cf4ff6e6c91af7f383ee810968fc3","date":1531457318,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: we ensure every doc has at least one value in each field\n        // that way, if a term is returned for a parent there there is garunteed to be at least one\n        // one term in the child facet as well.\n        //\n        // otherwise, we'd face the risk of a single shardX returning parentTermX as a top term for\n        // the parent facet, but having no child terms -- meanwhile on refinement another shardY that\n        // did *not* returned parentTermX in phase#1, could return some *new* child terms under\n        // parentTermX, but their stats would not include the bgCount from shardX.\n        //\n        // in normal operation, this is an edge case that isn't a big deal because the ratios &\n        // relatedness scores are statistically approximate, but for the purpose of this test where\n        // we verify correctness via exactness we need all shards to contribute to the SKG statistics\n        final int numValsThisDoc = TestUtil.nextInt(random(), 1, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: some docs may have no value in a field\n        final int numValsThisDoc = TestUtil.nextInt(random(), 0, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: we ensure every doc has at least one value in each field\n        // that way, if a term is returned for a parent there there is garunteed to be at least one\n        // one term in the child facet as well.\n        //\n        // otherwise, we'd face the risk of a single shardX returning parentTermX as a top term for\n        // the parent facet, but having no child terms -- meanwhile on refinement another shardY that\n        // did *not* returned parentTermX in phase#1, could return some *new* child terms under\n        // parentTermX, but their stats would not include the bgCount from shardX.\n        //\n        // in normal operation, this is an edge case that isn't a big deal because the ratios &\n        // relatedness scores are statistically approximate, but for the purpose of this test where\n        // we verify correctness via exactness we need all shards to contribute to the SKG statistics\n        final int numValsThisDoc = TestUtil.nextInt(random(), 1, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: some docs may have no value in a field\n        final int numValsThisDoc = TestUtil.nextInt(random(), 0, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: we ensure every doc has at least one value in each field\n        // that way, if a term is returned for a parent there there is garunteed to be at least one\n        // one term in the child facet as well.\n        //\n        // otherwise, we'd face the risk of a single shardX returning parentTermX as a top term for\n        // the parent facet, but having no child terms -- meanwhile on refinement another shardY that\n        // did *not* returned parentTermX in phase#1, could return some *new* child terms under\n        // parentTermX, but their stats would not include the bgCount from shardX.\n        //\n        // in normal operation, this is an edge case that isn't a big deal because the ratios &\n        // relatedness scores are statistically approximate, but for the purpose of this test where\n        // we verify correctness via exactness we need all shards to contribute to the SKG statistics\n        final int numValsThisDoc = TestUtil.nextInt(random(), 1, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: some docs may have no value in a field\n        final int numValsThisDoc = TestUtil.nextInt(random(), 0, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92910727264a23a47b7a6c94b0f75d655537b9ea","date":1540414655,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/facet/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudJSONFacetSKG#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: we ensure every doc has at least one value in each field\n        // that way, if a term is returned for a parent there there is garunteed to be at least one\n        // one term in the child facet as well.\n        //\n        // otherwise, we'd face the risk of a single shardX returning parentTermX as a top term for\n        // the parent facet, but having no child terms -- meanwhile on refinement another shardY that\n        // did *not* returned parentTermX in phase#1, could return some *new* child terms under\n        // parentTermX, but their stats would not include the bgCount from shardX.\n        //\n        // in normal operation, this is an edge case that isn't a big deal because the ratios &\n        // relatedness scores are statistically approximate, but for the purpose of this test where\n        // we verify correctness via exactness we need all shards to contribute to the SKG statistics\n        final int numValsThisDoc = TestUtil.nextInt(random(), 1, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    // sanity check constants\n    assertTrue(\"bad test constants: some suffixes will never be tested\",\n               (STR_FIELD_SUFFIXES.length < MAX_FIELD_NUM) && (INT_FIELD_SUFFIXES.length < MAX_FIELD_NUM));\n    \n    // we need DVs on point fields to compute stats & facets\n    if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n    \n    // multi replicas should not matter...\n    final int repFactor = usually() ? 1 : 2;\n    // ... but we definitely want to test multiple shards\n    final int numShards = TestUtil.nextInt(random(), 1, (usually() ? 2 :3));\n    final int numNodes = (numShards * repFactor);\n   \n    final String configName = DEBUG_LABEL + \"_config-set\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(numNodes).addConfig(configName, configDir).configure();\n    \n    Map<String, String> collectionProperties = new LinkedHashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema_latest.xml\");\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, numShards, repFactor)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n\n    waitForRecoveriesToFinish(CLOUD_CLIENT);\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      CLIENTS.add(getHttpSolrClient(jetty.getBaseUrl() + \"/\" + COLLECTION_NAME + \"/\"));\n    }\n\n    final int numDocs = atLeast(100);\n    for (int id = 0; id < numDocs; id++) {\n      SolrInputDocument doc = sdoc(\"id\", \"\"+id);\n      for (int fieldNum = 0; fieldNum < MAX_FIELD_NUM; fieldNum++) {\n        // NOTE: we ensure every doc has at least one value in each field\n        // that way, if a term is returned for a parent there there is garunteed to be at least one\n        // one term in the child facet as well.\n        //\n        // otherwise, we'd face the risk of a single shardX returning parentTermX as a top term for\n        // the parent facet, but having no child terms -- meanwhile on refinement another shardY that\n        // did *not* returned parentTermX in phase#1, could return some *new* child terms under\n        // parentTermX, but their stats would not include the bgCount from shardX.\n        //\n        // in normal operation, this is an edge case that isn't a big deal because the ratios &\n        // relatedness scores are statistically approximate, but for the purpose of this test where\n        // we verify correctness via exactness we need all shards to contribute to the SKG statistics\n        final int numValsThisDoc = TestUtil.nextInt(random(), 1, (usually() ? 5 : 10));\n        for (int v = 0; v < numValsThisDoc; v++) {\n          final String fieldValue = randFieldValue(fieldNum);\n          \n          // for each fieldNum, there are actaully two fields: one string, and one integer\n          doc.addField(field(STR_FIELD_SUFFIXES, fieldNum), fieldValue);\n          doc.addField(field(INT_FIELD_SUFFIXES, fieldNum), fieldValue);\n        }\n      }\n      CLOUD_CLIENT.add(doc);\n      if (random().nextInt(100) < 1) {\n        CLOUD_CLIENT.commit();  // commit 1% of the time to create new segments\n      }\n      if (random().nextInt(100) < 5) {\n        CLOUD_CLIENT.add(doc);  // duplicate the doc 5% of the time to create deleted docs\n      }\n    }\n    CLOUD_CLIENT.commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"2c705a0d590cf911e7c942df49563ca2ea176e22":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["2c705a0d590cf911e7c942df49563ca2ea176e22","1bd47e89c87cf4ff6e6c91af7f383ee810968fc3"],"1bd47e89c87cf4ff6e6c91af7f383ee810968fc3":["2c705a0d590cf911e7c942df49563ca2ea176e22"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"92910727264a23a47b7a6c94b0f75d655537b9ea":["1bd47e89c87cf4ff6e6c91af7f383ee810968fc3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["92910727264a23a47b7a6c94b0f75d655537b9ea"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["2c705a0d590cf911e7c942df49563ca2ea176e22","1bd47e89c87cf4ff6e6c91af7f383ee810968fc3"]},"commit2Childs":{"2c705a0d590cf911e7c942df49563ca2ea176e22":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","1bd47e89c87cf4ff6e6c91af7f383ee810968fc3","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"1bd47e89c87cf4ff6e6c91af7f383ee810968fc3":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","92910727264a23a47b7a6c94b0f75d655537b9ea","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2c705a0d590cf911e7c942df49563ca2ea176e22"],"92910727264a23a47b7a6c94b0f75d655537b9ea":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}