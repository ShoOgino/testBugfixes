{"path":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(AttributeFactory,Reader,UserDictionary,boolean,Mode).mjava","commits":[{"id":"13927d699a111b970c38bc3eec00837464c3ede6","date":1363322510,"type":0,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(AttributeFactory,Reader,UserDictionary,boolean,Mode).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   *\n   * @param factory the AttributeFactory to use\n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer\n      (AttributeFactory factory, Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(factory, input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader();\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader();\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0","date":1379858263,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(AttributeFactory,Reader,UserDictionary,boolean,Mode).mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(AttributeFactory,Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   *\n   * @param factory the AttributeFactory to use\n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer\n      (AttributeFactory factory, Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(factory, input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader();\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader();\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(this.input);\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   *\n   * @param factory the AttributeFactory to use\n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer\n      (AttributeFactory factory, Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(factory, input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader();\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader();\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(null); // best effort NPE consumers that don't call reset()\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(AttributeFactory,UserDictionary,boolean,Mode).mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#JapaneseTokenizer(AttributeFactory,Reader,UserDictionary,boolean,Mode).mjava","sourceNew":"  /**\n   * Create a new JapaneseTokenizer.\n   *\n   * @param factory the AttributeFactory to use\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer\n      (AttributeFactory factory, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(factory);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader();\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader();\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(this.input);\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","sourceOld":"  /**\n   * Create a new JapaneseTokenizer.\n   *\n   * @param factory the AttributeFactory to use\n   * @param input Reader containing text\n   * @param userDictionary Optional: if non-null, user dictionary.\n   * @param discardPunctuation true if punctuation tokens should be dropped from the output.\n   * @param mode tokenization mode.\n   */\n  public JapaneseTokenizer\n      (AttributeFactory factory, Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {\n    super(factory, input);\n    dictionary = TokenInfoDictionary.getInstance();\n    fst = dictionary.getFST();\n    unkDictionary = UnknownDictionary.getInstance();\n    characterDefinition = unkDictionary.getCharacterDefinition();\n    this.userDictionary = userDictionary;\n    costs = ConnectionCosts.getInstance();\n    fstReader = fst.getBytesReader();\n    if (userDictionary != null) {\n      userFST = userDictionary.getFST();\n      userFSTReader = userFST.getBytesReader();\n    } else {\n      userFST = null;\n      userFSTReader = null;\n    }\n    this.discardPunctuation = discardPunctuation;\n    switch(mode){\n      case SEARCH:\n        searchMode = true;\n        extendedMode = false;\n        outputCompounds = true;\n        break;\n      case EXTENDED:\n        searchMode = true;\n        extendedMode = true;\n        outputCompounds = false;\n        break;\n      default:\n        searchMode = false;\n        extendedMode = false;\n        outputCompounds = false;\n        break;\n    }\n    buffer.reset(this.input);\n\n    resetState();\n\n    dictionaryMap.put(Type.KNOWN, dictionary);\n    dictionaryMap.put(Type.UNKNOWN, unkDictionary);\n    dictionaryMap.put(Type.USER, userDictionary);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0":["13927d699a111b970c38bc3eec00837464c3ede6"],"13927d699a111b970c38bc3eec00837464c3ede6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["df1b735b811bfe6055a98336ee8dfd1e43cf2dc0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"]},"commit2Childs":{"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"13927d699a111b970c38bc3eec00837464c3ede6":["df1b735b811bfe6055a98336ee8dfd1e43cf2dc0"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["13927d699a111b970c38bc3eec00837464c3ede6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}