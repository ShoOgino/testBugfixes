{"path":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","commits":[{"id":"fb8457dd0880f5547d70dbf40ea4f1c5e7787798","date":1363378339,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        SortedSetDocValues segValues = matchingDocs.context.reader().getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = matchingDocs.context.reader().maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d1f7dc2d5ba61f478d9439f5b6afe27c8809422a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d1f7dc2d5ba61f478d9439f5b6afe27c8809422a","date":1365621037,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","sourceNew":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        SortedSetDocValues segValues = matchingDocs.context.reader().getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = matchingDocs.context.reader().maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        SortedSetDocValues segValues = matchingDocs.context.reader().getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = matchingDocs.context.reader().maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","bugFix":["fb8457dd0880f5547d70dbf40ea4f1c5e7787798"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c557e6f970bbfb1e81bf6b491874ed620a4bb5","date":1373906832,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","sourceNew":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        AtomicReader reader = matchingDocs.context.reader();\n\n        // LUCENE-5090: make sure the provided reader context \"matches\"\n        // the top-level reader passed to the\n        // SortedSetDocValuesReaderState, else cryptic\n        // AIOOBE can happen:\n        if (ReaderUtil.getTopLevelContext(matchingDocs.context).reader() != state.origReader) {\n          throw new IllegalStateException(\"the SortedSetDocValuesReaderState provided to this class does not match the reader being searched; you must create a new SortedSetDocValuesReaderState every time you open a new IndexReader\");\n        }\n        \n        SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = reader.maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        SortedSetDocValues segValues = matchingDocs.context.reader().getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = matchingDocs.context.reader().maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","sourceNew":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        AtomicReader reader = matchingDocs.context.reader();\n\n        // LUCENE-5090: make sure the provided reader context \"matches\"\n        // the top-level reader passed to the\n        // SortedSetDocValuesReaderState, else cryptic\n        // AIOOBE can happen:\n        if (ReaderUtil.getTopLevelContext(matchingDocs.context).reader() != state.origReader) {\n          throw new IllegalStateException(\"the SortedSetDocValuesReaderState provided to this class does not match the reader being searched; you must create a new SortedSetDocValuesReaderState every time you open a new IndexReader\");\n        }\n        \n        SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = reader.maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        SortedSetDocValues segValues = matchingDocs.context.reader().getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = matchingDocs.context.reader().maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6249cba93d7ad1bf6f5a225c34fbe3d547ed9f49","date":1375103250,"type":4,"author":"Shai Erera","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","sourceNew":null,"sourceOld":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        AtomicReader reader = matchingDocs.context.reader();\n\n        // LUCENE-5090: make sure the provided reader context \"matches\"\n        // the top-level reader passed to the\n        // SortedSetDocValuesReaderState, else cryptic\n        // AIOOBE can happen:\n        if (ReaderUtil.getTopLevelContext(matchingDocs.context).reader() != state.origReader) {\n          throw new IllegalStateException(\"the SortedSetDocValuesReaderState provided to this class does not match the reader being searched; you must create a new SortedSetDocValuesReaderState every time you open a new IndexReader\");\n        }\n        \n        SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = reader.maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":4,"author":"Han Jiang","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesAccumulator#getAggregator().mjava","sourceNew":null,"sourceOld":"  @Override\n  public FacetsAggregator getAggregator() {\n\n    return new FacetsAggregator() {\n\n      @Override\n      public void aggregate(MatchingDocs matchingDocs, CategoryListParams clp, FacetArrays facetArrays) throws IOException {\n\n        AtomicReader reader = matchingDocs.context.reader();\n\n        // LUCENE-5090: make sure the provided reader context \"matches\"\n        // the top-level reader passed to the\n        // SortedSetDocValuesReaderState, else cryptic\n        // AIOOBE can happen:\n        if (ReaderUtil.getTopLevelContext(matchingDocs.context).reader() != state.origReader) {\n          throw new IllegalStateException(\"the SortedSetDocValuesReaderState provided to this class does not match the reader being searched; you must create a new SortedSetDocValuesReaderState every time you open a new IndexReader\");\n        }\n        \n        SortedSetDocValues segValues = reader.getSortedSetDocValues(field);\n        if (segValues == null) {\n          return;\n        }\n\n        final int[] counts = facetArrays.getIntArray();\n        final int maxDoc = reader.maxDoc();\n        assert maxDoc == matchingDocs.bits.length();\n\n        if (dv instanceof MultiSortedSetDocValues) {\n          MultiDocValues.OrdinalMap ordinalMap = ((MultiSortedSetDocValues) dv).mapping;\n          int segOrd = matchingDocs.context.ord;\n\n          int numSegOrds = (int) segValues.getValueCount();\n\n          if (matchingDocs.totalHits < numSegOrds/10) {\n            // Remap every ord to global ord as we iterate:\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, term)]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n          } else {\n\n            // First count in seg-ord space:\n            final int[] segCounts = new int[numSegOrds];\n            int doc = 0;\n            while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n              segValues.setDocument(doc);\n              int term = (int) segValues.nextOrd();\n              while (term != SortedSetDocValues.NO_MORE_ORDS) {\n                segCounts[term]++;\n                term = (int) segValues.nextOrd();\n              }\n              ++doc;\n            }\n\n            // Then, migrate to global ords:\n            for(int ord=0;ord<numSegOrds;ord++) {\n              int count = segCounts[ord];\n              if (count != 0) {\n                counts[(int) ordinalMap.getGlobalOrd(segOrd, ord)] += count;\n              }\n            }\n          }\n        } else {\n          // No ord mapping (e.g., single segment index):\n          // just aggregate directly into counts:\n\n          int doc = 0;\n          while (doc < maxDoc && (doc = matchingDocs.bits.nextSetBit(doc)) != -1) {\n            segValues.setDocument(doc);\n            int term = (int) segValues.nextOrd();\n            while (term != SortedSetDocValues.NO_MORE_ORDS) {\n              counts[term]++;\n              term = (int) segValues.nextOrd();\n            }\n            ++doc;\n          }\n        }\n      }\n\n      @Override\n      public void rollupValues(FacetRequest fr, int ordinal, int[] children, int[] siblings, FacetArrays facetArrays) {\n        // Nothing to do here: we only support flat (dim +\n        // label) facets, and in accumulate we sum up the\n        // count for the dimension.\n      }\n\n      @Override\n      public boolean requiresDocScores() {\n        return false;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"37a0f60745e53927c4c876cfe5b5a58170f0646c":["d1f7dc2d5ba61f478d9439f5b6afe27c8809422a","a3c557e6f970bbfb1e81bf6b491874ed620a4bb5"],"a3c557e6f970bbfb1e81bf6b491874ed620a4bb5":["d1f7dc2d5ba61f478d9439f5b6afe27c8809422a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d1f7dc2d5ba61f478d9439f5b6afe27c8809422a":["fb8457dd0880f5547d70dbf40ea4f1c5e7787798"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["37a0f60745e53927c4c876cfe5b5a58170f0646c"],"fb8457dd0880f5547d70dbf40ea4f1c5e7787798":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6249cba93d7ad1bf6f5a225c34fbe3d547ed9f49":["a3c557e6f970bbfb1e81bf6b491874ed620a4bb5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6249cba93d7ad1bf6f5a225c34fbe3d547ed9f49"]},"commit2Childs":{"37a0f60745e53927c4c876cfe5b5a58170f0646c":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"a3c557e6f970bbfb1e81bf6b491874ed620a4bb5":["37a0f60745e53927c4c876cfe5b5a58170f0646c","6249cba93d7ad1bf6f5a225c34fbe3d547ed9f49"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fb8457dd0880f5547d70dbf40ea4f1c5e7787798"],"d1f7dc2d5ba61f478d9439f5b6afe27c8809422a":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a3c557e6f970bbfb1e81bf6b491874ed620a4bb5"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"fb8457dd0880f5547d70dbf40ea4f1c5e7787798":["d1f7dc2d5ba61f478d9439f5b6afe27c8809422a"],"6249cba93d7ad1bf6f5a225c34fbe3d547ed9f49":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}