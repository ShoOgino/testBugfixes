{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","commits":[{"id":"144725940ce5c83d189b7327223aceafdc0ebd39","date":1371765308,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"/dev/null","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1);\n    suggester.build(new TermFreqArrayIterator(new TermFreq[] {new TermFreq(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"/dev/null","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1);\n    suggester.build(new TermFreqArrayIterator(new TermFreq[] {new TermFreq(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ada2f7352a7f964fe49bccd13227c4ec38563d39","date":1381659982,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1);\n    suggester.build(new TermFreqPayloadArrayIterator(new TermFreqPayload[] {new TermFreqPayload(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1);\n    suggester.build(new TermFreqArrayIterator(new TermFreq[] {new TermFreq(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1);\n    suggester.build(new TermFreqPayloadArrayIterator(new TermFreqPayload[] {new TermFreqPayload(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4e0095ef720d1b8e7406847147af69f19af3ab6","date":1383131477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, false);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33f87fe6faf49dfc1e66f45e841e24838c2f725c","date":1383142987,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, false);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n    a.close();\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n    a.close();\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"867e3d9153fb761456b54a9dcce566e1545c5ef6","date":1444903098,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e859719dc778fb66d3d21e7be08cd408fc2bde98","date":1446717611,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) {\n            }\n          };\n        }\n      };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n    IOUtils.close(a, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fac252ef8e3d0bbff9303ffbf675e824a729dfaf","date":1537347776,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testTooManyExpansions().mjava","sourceNew":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(r -> {}, new CannedTokenStream(\n            new Token(\"a\", 0, 1),\n            new Token(\"b\", 0, 0, 1)));\n      }\n    };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void testTooManyExpansions() throws Exception {\n\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            @Override\n            public TokenStream getTokenStream() {\n              Token a = new Token(\"a\", 0, 1);\n              a.setPositionIncrement(1);\n              Token b = new Token(\"b\", 0, 1);\n              b.setPositionIncrement(0);\n              return new CannedTokenStream(new Token[] {a, b});\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) {\n            }\n          };\n        }\n      };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, 1, true);\n    suggester.build(new InputArrayIterator(new Input[] {new Input(\"a\", 1)}));\n    assertEquals(\"[a/1]\", suggester.lookup(\"a\", false, 1).toString());\n    IOUtils.close(a, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","144725940ce5c83d189b7327223aceafdc0ebd39"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["33f87fe6faf49dfc1e66f45e841e24838c2f725c"],"33f87fe6faf49dfc1e66f45e841e24838c2f725c":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["867e3d9153fb761456b54a9dcce566e1545c5ef6"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","a56958d7f71a28824f20031ffbb2e13502a0274e"],"144725940ce5c83d189b7327223aceafdc0ebd39":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fac252ef8e3d0bbff9303ffbf675e824a729dfaf":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a56958d7f71a28824f20031ffbb2e13502a0274e":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fac252ef8e3d0bbff9303ffbf675e824a729dfaf"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["144725940ce5c83d189b7327223aceafdc0ebd39"]},"commit2Childs":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"33f87fe6faf49dfc1e66f45e841e24838c2f725c":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["fac252ef8e3d0bbff9303ffbf675e824a729dfaf"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"144725940ce5c83d189b7327223aceafdc0ebd39":["37a0f60745e53927c4c876cfe5b5a58170f0646c","ada2f7352a7f964fe49bccd13227c4ec38563d39"],"fac252ef8e3d0bbff9303ffbf675e824a729dfaf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["37a0f60745e53927c4c876cfe5b5a58170f0646c","144725940ce5c83d189b7327223aceafdc0ebd39"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","867e3d9153fb761456b54a9dcce566e1545c5ef6"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["33f87fe6faf49dfc1e66f45e841e24838c2f725c"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}