{"path":"sandbox/contributions/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","commits":[{"id":"4215168c7c026cd898f2d98bb6aa5b0df9856696","date":1092688246,"type":0,"author":"Daniel Naber","isMerge":false,"pathNew":"sandbox/contributions/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"/dev/null","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":5,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"sandbox/contributions/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"043c298cb215f13ba7b9b81d20760704e8f93d66":["4215168c7c026cd898f2d98bb6aa5b0df9856696"],"4215168c7c026cd898f2d98bb6aa5b0df9856696":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["043c298cb215f13ba7b9b81d20760704e8f93d66"]},"commit2Childs":{"043c298cb215f13ba7b9b81d20760704e8f93d66":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4215168c7c026cd898f2d98bb6aa5b0df9856696":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4215168c7c026cd898f2d98bb6aa5b0df9856696"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}