{"path":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#shingleFilterTest(int,Token[],Token[],int[],String[]).mjava","commits":[{"id":"dd745d580729e528151b58aeda87ef82f1b95c9b","date":1248369082,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#shingleFilterTest(int,Token[],Token[],int[],String[]).mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#shingleFilterTest(int,Token[],Token[],int[],String[]).mjava","sourceNew":"  protected void shingleFilterTest(int maxSize, Token[] tokensToShingle, Token[] tokensToCompare,\n                                   int[] positionIncrements, String[] types)\n    throws IOException {\n\n    TokenStream filter = new ShingleFilter(new TestTokenStream(tokensToShingle), maxSize);\n    int i = 0;\n    final Token reusableToken = new Token();\n    for (Token nextToken = filter.next(reusableToken); nextToken != null; nextToken = filter.next(reusableToken)) {\n      String termText = nextToken.term();\n      String goldText = tokensToCompare[i].term();\n      assertEquals(\"Wrong termText\", goldText, termText);\n      assertEquals(\"Wrong startOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].startOffset(), nextToken.startOffset());\n      assertEquals(\"Wrong endOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].endOffset(), nextToken.endOffset());\n      assertEquals(\"Wrong positionIncrement for token \\\"\" + termText + \"\\\"\",\n          positionIncrements[i], nextToken.getPositionIncrement());\n      assertEquals(\"Wrong type for token \\\"\" + termText + \"\\\"\", types[i], nextToken.type());\n      i++;\n    }\n  }\n\n","sourceOld":"  protected void shingleFilterTest(int maxSize, Token[] tokensToShingle, Token[] tokensToCompare,\n                                   int[] positionIncrements, String[] types)\n    throws IOException {\n\n    TokenStream filter = new ShingleFilter(new TestTokenStream(tokensToShingle), maxSize);\n    int i = 0;\n    final Token reusableToken = new Token();\n    for (Token nextToken = filter.next(reusableToken); nextToken != null; nextToken = filter.next(reusableToken)) {\n      String termText = nextToken.term();\n      String goldText = tokensToCompare[i].term();\n      assertEquals(\"Wrong termText\", goldText, termText);\n      assertEquals(\"Wrong startOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].startOffset(), nextToken.startOffset());\n      assertEquals(\"Wrong endOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].endOffset(), nextToken.endOffset());\n      assertEquals(\"Wrong positionIncrement for token \\\"\" + termText + \"\\\"\",\n          positionIncrements[i], nextToken.getPositionIncrement());\n      assertEquals(\"Wrong type for token \\\"\" + termText + \"\\\"\", types[i], nextToken.type());\n      i++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0dda87e5ad7246b25d0da56a16ead95360499d86","date":1249273990,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#shingleFilterTest(int,Token[],Token[],int[],String[]).mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#shingleFilterTest(int,Token[],Token[],int[],String[]).mjava","sourceNew":"  protected void shingleFilterTest(int maxSize, Token[] tokensToShingle, Token[] tokensToCompare,\n                                   int[] positionIncrements, String[] types)\n    throws IOException {\n\n    TokenStream filter = new ShingleFilter(new TestTokenStream(tokensToShingle), maxSize);\n    TermAttribute termAtt = (TermAttribute) filter.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) filter.addAttribute(OffsetAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) filter.addAttribute(PositionIncrementAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) filter.addAttribute(TypeAttribute.class);\n\n    int i = 0;\n    while (filter.incrementToken()) {\n      String termText = termAtt.term();\n      String goldText = tokensToCompare[i].term();\n      assertEquals(\"Wrong termText\", goldText, termText);\n      assertEquals(\"Wrong startOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].startOffset(), offsetAtt.startOffset());\n      assertEquals(\"Wrong endOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].endOffset(), offsetAtt.endOffset());\n      assertEquals(\"Wrong positionIncrement for token \\\"\" + termText + \"\\\"\",\n          positionIncrements[i], posIncrAtt.getPositionIncrement());\n      assertEquals(\"Wrong type for token \\\"\" + termText + \"\\\"\", types[i], typeAtt.type());\n      i++;\n    }\n  }\n\n","sourceOld":"  protected void shingleFilterTest(int maxSize, Token[] tokensToShingle, Token[] tokensToCompare,\n                                   int[] positionIncrements, String[] types)\n    throws IOException {\n\n    TokenStream filter = new ShingleFilter(new TestTokenStream(tokensToShingle), maxSize);\n    int i = 0;\n    final Token reusableToken = new Token();\n    for (Token nextToken = filter.next(reusableToken); nextToken != null; nextToken = filter.next(reusableToken)) {\n      String termText = nextToken.term();\n      String goldText = tokensToCompare[i].term();\n      assertEquals(\"Wrong termText\", goldText, termText);\n      assertEquals(\"Wrong startOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].startOffset(), nextToken.startOffset());\n      assertEquals(\"Wrong endOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].endOffset(), nextToken.endOffset());\n      assertEquals(\"Wrong positionIncrement for token \\\"\" + termText + \"\\\"\",\n          positionIncrements[i], nextToken.getPositionIncrement());\n      assertEquals(\"Wrong type for token \\\"\" + termText + \"\\\"\", types[i], nextToken.type());\n      i++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4","date":1252476174,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#shingleFilterTest(int,Token[],Token[],int[],String[],boolean).mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest#shingleFilterTest(int,Token[],Token[],int[],String[]).mjava","sourceNew":"  protected void shingleFilterTest(int maxSize, Token[] tokensToShingle, Token[] tokensToCompare,\n                                   int[] positionIncrements, String[] types,\n                                   boolean outputUnigrams)\n    throws IOException {\n\n    ShingleFilter filter = new ShingleFilter(new TestTokenStream(tokensToShingle), maxSize);\n    filter.setOutputUnigrams(outputUnigrams);\n\n    TermAttribute termAtt = (TermAttribute) filter.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) filter.addAttribute(OffsetAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) filter.addAttribute(PositionIncrementAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) filter.addAttribute(TypeAttribute.class);\n\n    int i = 0;\n    while (filter.incrementToken()) {\n      assertTrue(\"ShingleFilter outputted more tokens than expected\", i < tokensToCompare.length);\n      String termText = termAtt.term();\n      String goldText = tokensToCompare[i].term();\n      assertEquals(\"Wrong termText\", goldText, termText);\n      assertEquals(\"Wrong startOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].startOffset(), offsetAtt.startOffset());\n      assertEquals(\"Wrong endOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].endOffset(), offsetAtt.endOffset());\n      assertEquals(\"Wrong positionIncrement for token \\\"\" + termText + \"\\\"\",\n          positionIncrements[i], posIncrAtt.getPositionIncrement());\n      assertEquals(\"Wrong type for token \\\"\" + termText + \"\\\"\", types[i], typeAtt.type());\n      i++;\n    }\n    assertEquals(\"ShingleFilter outputted wrong # of tokens. (# output = \" + i + \"; # expected =\" + tokensToCompare.length + \")\",\n                 tokensToCompare.length, i);\n  }\n\n","sourceOld":"  protected void shingleFilterTest(int maxSize, Token[] tokensToShingle, Token[] tokensToCompare,\n                                   int[] positionIncrements, String[] types)\n    throws IOException {\n\n    TokenStream filter = new ShingleFilter(new TestTokenStream(tokensToShingle), maxSize);\n    TermAttribute termAtt = (TermAttribute) filter.addAttribute(TermAttribute.class);\n    OffsetAttribute offsetAtt = (OffsetAttribute) filter.addAttribute(OffsetAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) filter.addAttribute(PositionIncrementAttribute.class);\n    TypeAttribute typeAtt = (TypeAttribute) filter.addAttribute(TypeAttribute.class);\n\n    int i = 0;\n    while (filter.incrementToken()) {\n      String termText = termAtt.term();\n      String goldText = tokensToCompare[i].term();\n      assertEquals(\"Wrong termText\", goldText, termText);\n      assertEquals(\"Wrong startOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].startOffset(), offsetAtt.startOffset());\n      assertEquals(\"Wrong endOffset for token \\\"\" + termText + \"\\\"\",\n          tokensToCompare[i].endOffset(), offsetAtt.endOffset());\n      assertEquals(\"Wrong positionIncrement for token \\\"\" + termText + \"\\\"\",\n          positionIncrements[i], posIncrAtt.getPositionIncrement());\n      assertEquals(\"Wrong type for token \\\"\" + termText + \"\\\"\", types[i], typeAtt.type());\n      i++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0dda87e5ad7246b25d0da56a16ead95360499d86":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4":["0dda87e5ad7246b25d0da56a16ead95360499d86"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4"]},"commit2Childs":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["0dda87e5ad7246b25d0da56a16ead95360499d86"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"0dda87e5ad7246b25d0da56a16ead95360499d86":["f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4"],"f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}