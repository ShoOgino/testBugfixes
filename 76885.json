{"path":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","commits":[{"id":"0e7bc21595222ae4f75509300fbb7726691f387f","date":1464078795,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","pathOld":"/dev/null","sourceNew":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615370d2b876c3435773b5174df2e2242ad7981a","date":1495117651,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10, new Sort(SortField.FIELD_DOC, SortField.FIELD_SCORE));\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10, new Sort(SortField.FIELD_DOC, SortField.FIELD_SCORE));\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10, new Sort(SortField.FIELD_DOC, SortField.FIELD_SCORE));\n    assertEquals(2, hits.totalHits.value);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10, new Sort(SortField.FIELD_DOC, SortField.FIELD_SCORE));\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7","date":1552575873,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public void visit(QueryVisitor visitor) {\n\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10, new Sort(SortField.FIELD_DOC, SortField.FIELD_SCORE));\n    assertEquals(2, hits.totalHits.value);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10, new Sort(SortField.FIELD_DOC, SortField.FIELD_SCORE));\n    assertEquals(2, hits.totalHits.value);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e9017cf144952056066919f1ebc7897ff9bd71b1":["0e7bc21595222ae4f75509300fbb7726691f387f","615370d2b876c3435773b5174df2e2242ad7981a"],"615370d2b876c3435773b5174df2e2242ad7981a":["0e7bc21595222ae4f75509300fbb7726691f387f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0e7bc21595222ae4f75509300fbb7726691f387f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["615370d2b876c3435773b5174df2e2242ad7981a"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0e7bc21595222ae4f75509300fbb7726691f387f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["83788ad129a5154d5c6562c4e8ce3db48793aada"]},"commit2Childs":{"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"615370d2b876c3435773b5174df2e2242ad7981a":["e9017cf144952056066919f1ebc7897ff9bd71b1","83788ad129a5154d5c6562c4e8ce3db48793aada"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0e7bc21595222ae4f75509300fbb7726691f387f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"0e7bc21595222ae4f75509300fbb7726691f387f":["e9017cf144952056066919f1ebc7897ff9bd71b1","615370d2b876c3435773b5174df2e2242ad7981a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}