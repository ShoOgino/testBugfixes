{"path":"lucene/core/src/test/org/apache/lucene/analysis/TestStopFilter#testEndStopword().mjava","commits":[{"id":"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","date":1465936684,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestStopFilter#testEndStopword().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter#testEndStopword().mjava","sourceNew":"  // LUCENE-3849: make sure after .end() we see the \"ending\" posInc\n  public void testEndStopword() throws Exception {\n    CharArraySet stopSet = StopFilter.makeStopSet(\"of\");\n    final MockTokenizer in = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n    in.setReader(new StringReader(\"test of\"));\n    StopFilter stpf = new StopFilter(in, stopSet);\n    assertTokenStreamContents(stpf, new String[] { \"test\" },\n                              new int[] {0},\n                              new int[] {4},\n                              null,\n                              new int[] {1},\n                              null,\n                              7,\n                              1,\n                              null,\n                              true);    \n  }\n\n","sourceOld":"  // LUCENE-3849: make sure after .end() we see the \"ending\" posInc\n  public void testEndStopword() throws Exception {\n    CharArraySet stopSet = StopFilter.makeStopSet(\"of\");\n    final MockTokenizer in = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n    in.setReader(new StringReader(\"test of\"));\n    StopFilter stpf = new StopFilter(in, stopSet);\n    assertTokenStreamContents(stpf, new String[] { \"test\" },\n                              new int[] {0},\n                              new int[] {4},\n                              null,\n                              new int[] {1},\n                              null,\n                              7,\n                              1,\n                              null,\n                              true);    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestStopFilter#testEndStopword().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter#testEndStopword().mjava","sourceNew":"  // LUCENE-3849: make sure after .end() we see the \"ending\" posInc\n  public void testEndStopword() throws Exception {\n    CharArraySet stopSet = StopFilter.makeStopSet(\"of\");\n    final MockTokenizer in = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n    in.setReader(new StringReader(\"test of\"));\n    StopFilter stpf = new StopFilter(in, stopSet);\n    assertTokenStreamContents(stpf, new String[] { \"test\" },\n                              new int[] {0},\n                              new int[] {4},\n                              null,\n                              new int[] {1},\n                              null,\n                              7,\n                              1,\n                              null,\n                              true);    \n  }\n\n","sourceOld":"  // LUCENE-3849: make sure after .end() we see the \"ending\" posInc\n  public void testEndStopword() throws Exception {\n    CharArraySet stopSet = StopFilter.makeStopSet(\"of\");\n    final MockTokenizer in = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n    in.setReader(new StringReader(\"test of\"));\n    StopFilter stpf = new StopFilter(in, stopSet);\n    assertTokenStreamContents(stpf, new String[] { \"test\" },\n                              new int[] {0},\n                              new int[] {4},\n                              null,\n                              new int[] {1},\n                              null,\n                              7,\n                              1,\n                              null,\n                              true);    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"afc5b4b2446e392448f36ae4f5a164540f2ccb65","date":1513355058,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestStopFilter#testEndStopword().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestStopFilter#testEndStopword().mjava","sourceNew":"  // LUCENE-3849: make sure after .end() we see the \"ending\" posInc\n  public void testEndStopword() throws Exception {\n    CharArraySet stopSet = StopFilter.makeStopSet(\"of\");\n    final MockTokenizer in = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n    in.setReader(new StringReader(\"test of\"));\n    StopFilter stpf = new StopFilter(in, stopSet);\n    assertTokenStreamContents(stpf, new String[] { \"test\" },\n                              new int[] {0},\n                              new int[] {4},\n                              null,\n                              new int[] {1},\n                              null,\n                              7,\n                              1,\n                              null,\n                              true,\n                              null);\n  }\n\n","sourceOld":"  // LUCENE-3849: make sure after .end() we see the \"ending\" posInc\n  public void testEndStopword() throws Exception {\n    CharArraySet stopSet = StopFilter.makeStopSet(\"of\");\n    final MockTokenizer in = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n    in.setReader(new StringReader(\"test of\"));\n    StopFilter stpf = new StopFilter(in, stopSet);\n    assertTokenStreamContents(stpf, new String[] { \"test\" },\n                              new int[] {0},\n                              new int[] {4},\n                              null,\n                              new int[] {1},\n                              null,\n                              7,\n                              1,\n                              null,\n                              true);    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb5529b83dfe8f452a536b7afe14b0f26b33033c","date":1544111330,"type":3,"author":"Diego Ceccarelli","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestStopFilter#testEndStopword().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestStopFilter#testEndStopword().mjava","sourceNew":"  // LUCENE-3849: make sure after .end() we see the \"ending\" posInc\n  public void testEndStopword() throws Exception {\n    CharArraySet stopSet = StopFilter.makeStopSet(\"of\");\n    final MockTokenizer in = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n    in.setReader(new StringReader(\"test of\"));\n    StopFilter stopfilter = new StopFilter(in, stopSet);\n    assertTokenStreamContents(stopfilter, new String[] { \"test\" },\n                              new int[] {0},\n                              new int[] {4},\n                              null,\n                              new int[] {1},\n                              null,\n                              7,\n                              1,\n                              null,\n                              true,\n                              null);\n  }\n\n","sourceOld":"  // LUCENE-3849: make sure after .end() we see the \"ending\" posInc\n  public void testEndStopword() throws Exception {\n    CharArraySet stopSet = StopFilter.makeStopSet(\"of\");\n    final MockTokenizer in = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n    in.setReader(new StringReader(\"test of\"));\n    StopFilter stpf = new StopFilter(in, stopSet);\n    assertTokenStreamContents(stpf, new String[] { \"test\" },\n                              new int[] {0},\n                              new int[] {4},\n                              null,\n                              new int[] {1},\n                              null,\n                              7,\n                              1,\n                              null,\n                              true,\n                              null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"cb5529b83dfe8f452a536b7afe14b0f26b33033c":["afc5b4b2446e392448f36ae4f5a164540f2ccb65"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b266fe0ac2172d4ad87cff12bd9bf9f8c8247345"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cb5529b83dfe8f452a536b7afe14b0f26b33033c"],"afc5b4b2446e392448f36ae4f5a164540f2ccb65":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345"]},"commit2Childs":{"cb5529b83dfe8f452a536b7afe14b0f26b33033c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","afc5b4b2446e392448f36ae4f5a164540f2ccb65"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"afc5b4b2446e392448f36ae4f5a164540f2ccb65":["cb5529b83dfe8f452a536b7afe14b0f26b33033c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}