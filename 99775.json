{"path":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","commits":[{"id":"cbf497fc92342be81ff184a144dfa7c96264116b","date":1275079529,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"/dev/null","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d302ba328993a5b449c2e0b3b5e15ae53e45879","date":1281609097,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory(rand);\n    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"91ca06ab0564c3d6a522d3b7ab91e83b168e3099","date":1282686932,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory(rand);\n    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);\n\n    MergeScheduler ms = writer.w.getMergeScheduler();\n    ConcurrentMergeScheduler cms;\n    if (ms instanceof ConcurrentMergeScheduler) {\n      cms = (ConcurrentMergeScheduler) ms;\n    } else {\n      cms = null;\n    }\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    if (cms != null) {\n      cms.sync();\n    }\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory(rand);\n    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93b552aba60d85b5b96fadcf4824bb350147fb8f","date":1282733672,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory(rand);\n    RandomIndexWriter writer = new RandomIndexWriter(rand, dir,\n                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory(rand);\n    RandomIndexWriter writer = new RandomIndexWriter(rand, dir);\n\n    MergeScheduler ms = writer.w.getMergeScheduler();\n    ConcurrentMergeScheduler cms;\n    if (ms instanceof ConcurrentMergeScheduler) {\n      cms = (ConcurrentMergeScheduler) ms;\n    } else {\n      cms = null;\n    }\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    if (cms != null) {\n      cms.sync();\n    }\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    if (cms != null) {\n      cms.sync();\n    }\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory(rand);\n    RandomIndexWriter writer = new RandomIndexWriter(rand, dir,\n                                                     newIndexWriterConfig(rand, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"296e4ed69ccbda3c7b5fdb86c7acaa43c9074e01","date":1286712181,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = writer.w.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a186ae8733084223c22044e935e4ef848a143d1","date":1289694819,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n    // asserts below requires no unexpected merges:\n    ((LogMergePolicy) writer.w.getMergePolicy()).setMergeFactor(10);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c498d3f8d75170b121f5eda2c6210ac5beb5d411","date":1289726298,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n    // asserts below requires no unexpected merges:\n    ((LogMergePolicy) writer.w.getMergePolicy()).setMergeFactor(10);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n    // asserts below requires no unexpected merges:\n    ((LogMergePolicy) writer.w.getMergePolicy()).setMergeFactor(10);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));\n    // asserts below requires no unexpected merges:\n    ((LogMergePolicy) writer.w.getMergePolicy()).setMergeFactor(10);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    IndexReader newReader = refreshReader(reader);\n    assertTrue(reader != newReader);\n    reader = newReader;\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb378f8bdee16a26810e086303a4a86b4930ea12","date":1296410797,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","date":1297940445,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher = new IndexSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = new IndexSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1bb50752d43a65ef1b623eabdb8e865983d3cd6","date":1304257984,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    IndexSearcher searcher = newSearcher(reader);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43369d257d14f61a881aa609962ef95e8a334d3a","date":1318786064,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    reader = refreshReader(reader);\n    assertTrue(reader != oldReader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6620df8541b174097b1133a4fc370adb2e570524","date":1319544675,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // ignore deletions\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.IGNORE);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    ConstantScoreQuery constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n\n    // force cache to regenerate:\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.RECACHE);\n\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(missCount+1, filter.missCount);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n\n    // apply deletions dynamically\n    filter = new CachingWrapperFilter(startFilter, CachingWrapperFilter.DeletesMode.DYNAMIC);\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // doesn't count as a miss\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not optimize\n    // away our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher.close();\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    searcher.close();\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc0528274cde759b2d3f75b55794edeae6093533","date":1323799309,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4ceb6a6c707ada1df8bde804e25c98668e699a18","date":1323800602,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that its there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    int missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader = reader;\n\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    IndexReader oldReader2 = reader;\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n    assertTrue(oldReader2 != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a2ec9a9068164200de82395f0e8537a9d9302f3f","date":1327856476,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    IndexReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"6620df8541b174097b1133a4fc370adb2e570524":["43369d257d14f61a881aa609962ef95e8a334d3a"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["29ef99d61cda9641b6250bf9567329a6e65f901d","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["6620df8541b174097b1133a4fc370adb2e570524"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"0d302ba328993a5b449c2e0b3b5e15ae53e45879":["cbf497fc92342be81ff184a144dfa7c96264116b"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["cbf497fc92342be81ff184a144dfa7c96264116b","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"296e4ed69ccbda3c7b5fdb86c7acaa43c9074e01":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"bc0528274cde759b2d3f75b55794edeae6093533":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["93b552aba60d85b5b96fadcf4824bb350147fb8f"],"a2ec9a9068164200de82395f0e8537a9d9302f3f":["bc0528274cde759b2d3f75b55794edeae6093533"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["3bb13258feba31ab676502787ab2e1779f129b7a","790e1fde4caa765b3faaad3fbcd25c6973450336"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["c1bb50752d43a65ef1b623eabdb8e865983d3cd6"],"93b552aba60d85b5b96fadcf4824bb350147fb8f":["91ca06ab0564c3d6a522d3b7ab91e83b168e3099"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"4ceb6a6c707ada1df8bde804e25c98668e699a18":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","bc0528274cde759b2d3f75b55794edeae6093533"],"2a186ae8733084223c22044e935e4ef848a143d1":["296e4ed69ccbda3c7b5fdb86c7acaa43c9074e01"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["0d302ba328993a5b449c2e0b3b5e15ae53e45879"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["296e4ed69ccbda3c7b5fdb86c7acaa43c9074e01","2a186ae8733084223c22044e935e4ef848a143d1"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["f1bdbf92da222965b46c0a942c3857ba56e5c638","c1bb50752d43a65ef1b623eabdb8e865983d3cd6"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"43369d257d14f61a881aa609962ef95e8a334d3a":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"c1bb50752d43a65ef1b623eabdb8e865983d3cd6":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["bc0528274cde759b2d3f75b55794edeae6093533","a2ec9a9068164200de82395f0e8537a9d9302f3f"],"cbf497fc92342be81ff184a144dfa7c96264116b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"91ca06ab0564c3d6a522d3b7ab91e83b168e3099":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a3776dccca01c11e7046323cfad46a3b4a471233":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","c1bb50752d43a65ef1b623eabdb8e865983d3cd6"],"3bb13258feba31ab676502787ab2e1779f129b7a":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["2a186ae8733084223c22044e935e4ef848a143d1"]},"commit2Childs":{"6620df8541b174097b1133a4fc370adb2e570524":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["4ceb6a6c707ada1df8bde804e25c98668e699a18"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["296e4ed69ccbda3c7b5fdb86c7acaa43c9074e01"],"0d302ba328993a5b449c2e0b3b5e15ae53e45879":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3":["f1bdbf92da222965b46c0a942c3857ba56e5c638","f2c5f0cb44df114db4228c8f77861714b5cabaea","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"296e4ed69ccbda3c7b5fdb86c7acaa43c9074e01":["2a186ae8733084223c22044e935e4ef848a143d1","c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"bc0528274cde759b2d3f75b55794edeae6093533":["a2ec9a9068164200de82395f0e8537a9d9302f3f","4ceb6a6c707ada1df8bde804e25c98668e699a18","5cab9a86bd67202d20b6adc463008c8e982b070a"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["962d04139994fce5193143ef35615499a9a96d78","c1bb50752d43a65ef1b623eabdb8e865983d3cd6"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","bc0528274cde759b2d3f75b55794edeae6093533"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"a2ec9a9068164200de82395f0e8537a9d9302f3f":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cbf497fc92342be81ff184a144dfa7c96264116b"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["43369d257d14f61a881aa609962ef95e8a334d3a"],"93b552aba60d85b5b96fadcf4824bb350147fb8f":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"4ceb6a6c707ada1df8bde804e25c98668e699a18":[],"2a186ae8733084223c22044e935e4ef848a143d1":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["91ca06ab0564c3d6a522d3b7ab91e83b168e3099"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["3bb13258feba31ab676502787ab2e1779f129b7a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"962d04139994fce5193143ef35615499a9a96d78":[],"43369d257d14f61a881aa609962ef95e8a334d3a":["6620df8541b174097b1133a4fc370adb2e570524"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"c1bb50752d43a65ef1b623eabdb8e865983d3cd6":["1509f151d7692d84fae414b2b799ac06ba60fcb4","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"cbf497fc92342be81ff184a144dfa7c96264116b":["0d302ba328993a5b449c2e0b3b5e15ae53e45879","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","29ef99d61cda9641b6250bf9567329a6e65f901d"],"91ca06ab0564c3d6a522d3b7ab91e83b168e3099":["93b552aba60d85b5b96fadcf4824bb350147fb8f"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"3bb13258feba31ab676502787ab2e1779f129b7a":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","eb378f8bdee16a26810e086303a4a86b4930ea12","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4ceb6a6c707ada1df8bde804e25c98668e699a18","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}