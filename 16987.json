{"path":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","commits":[{"id":"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4","date":1442407411,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = MultiSpansWrapper.wrap(is.getIndexReader(), snq, SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    Spans spans = MultiSpansWrapper.wrap(is.getIndexReader(), snq, SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          Collection<byte[]> payloads = collector.getPayloads();\n          for (final byte [] payload : payloads) {\n            payloadSet.add(new String(payload, StandardCharsets.UTF_8));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader));\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(reader);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = MultiSpansWrapper.wrap(is.getIndexReader(), snq, SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":["790e1fde4caa765b3faaad3fbcd25c6973450336","29aea3139c4326c0501d75d51059855463220279"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ecdeda0f97b09b83f431ef8c6e8a2ae4695270a1","date":1457861702,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader));\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"02e175abd2c4c1611c5a9647486ae8ba249a94c1","date":1468327116,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false, 1f).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false, 1f).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false, 1f).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/payloads/TestPayloadSpans#testShrinkToAfterShortestMatch().mjava","sourceNew":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, ScoreMode.COMPLETE_NO_SCORES, 1f).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testShrinkToAfterShortestMatch() throws IOException {\n    Directory directory = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory,\n                                                     newIndexWriterConfig(new TestPayloadAnalyzer()));\n\n    Document doc = new Document();\n    doc.add(new TextField(\"content\", new StringReader(\"a b c d e f g h i j a k\")));\n    writer.addDocument(doc);\n\n    IndexReader reader = writer.getReader();\n    IndexSearcher is = newSearcher(getOnlyLeafReader(reader), false);\n    writer.close();\n\n    SpanTermQuery stq1 = new SpanTermQuery(new Term(\"content\", \"a\"));\n    SpanTermQuery stq2 = new SpanTermQuery(new Term(\"content\", \"k\"));\n    SpanQuery[] sqs = { stq1, stq2 };\n    SpanNearQuery snq = new SpanNearQuery(sqs, 1, true);\n    VerifyingCollector collector = new VerifyingCollector();\n    Spans spans = snq.createWeight(is, false, 1f).getSpans(is.getIndexReader().leaves().get(0), SpanWeight.Postings.PAYLOADS);\n\n    TopDocs topDocs = is.search(snq, 1);\n    Set<String> payloadSet = new HashSet<>();\n    for (int i = 0; i < topDocs.scoreDocs.length; i++) {\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          collector.reset();\n          spans.collect(collector);\n          for (final BytesRef payload : collector.payloads) {\n            payloadSet.add(Term.toString(payload));\n          }\n        }\n      }\n    }\n    assertEquals(2, payloadSet.size());\n    assertTrue(payloadSet.contains(\"a:Noise:10\"));\n    assertTrue(payloadSet.contains(\"k:Noise:11\"));\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["eeab49258a6aca6c7e96aaf189f1794fe6ddebe4"],"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["ecdeda0f97b09b83f431ef8c6e8a2ae4695270a1"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"ecdeda0f97b09b83f431ef8c6e8a2ae4695270a1":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["ecdeda0f97b09b83f431ef8c6e8a2ae4695270a1","02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["417142ff08fda9cf0b72d5133e63097a166c6458"],"417142ff08fda9cf0b72d5133e63097a166c6458":["02e175abd2c4c1611c5a9647486ae8ba249a94c1","9fc47cb7b4346802411bb432f501ed0673d7119e"]},"commit2Childs":{"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["ecdeda0f97b09b83f431ef8c6e8a2ae4695270a1"],"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["eeab49258a6aca6c7e96aaf189f1794fe6ddebe4"],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["9fc47cb7b4346802411bb432f501ed0673d7119e","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","417142ff08fda9cf0b72d5133e63097a166c6458"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"ecdeda0f97b09b83f431ef8c6e8a2ae4695270a1":["02e175abd2c4c1611c5a9647486ae8ba249a94c1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"417142ff08fda9cf0b72d5133e63097a166c6458":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}