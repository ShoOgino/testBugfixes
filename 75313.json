{"path":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader#PrefixCodedTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int).mjava","commits":[{"id":"99cf56f3a650b908f7017a72f9d23940418f8a52","date":1284891529,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader#PrefixCodedTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader#StandardTermsDictReader(StandardTermsIndexReader,Directory,FieldInfos,String,StandardPostingsReader,int,Comparator[BytesRef],int).mjava","sourceNew":"  public PrefixCodedTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", PrefixCodedTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final TermsIndexReaderBase.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory dir, FieldInfos fieldInfos, String segment, StandardPostingsReader postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", StandardCodec.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final StandardTermsIndexReader.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16c697f6ca5cdc82f918f753317a4ac9c70d259f","date":1289840486,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader#PrefixCodedTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader#PrefixCodedTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int).mjava","sourceNew":"  public PrefixCodedTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, PrefixCodedTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final TermsIndexReaderBase.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public PrefixCodedTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", PrefixCodedTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final TermsIndexReaderBase.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ab1f5591dc05f1f2b5407d809c9699f75554a32","date":1290008586,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader#PrefixCodedTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader#PrefixCodedTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,Comparator[BytesRef],int).mjava","sourceNew":"  public PrefixCodedTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize, String codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, PrefixCodedTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final TermsIndexReaderBase.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public PrefixCodedTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                                 Comparator<BytesRef> termComp, int termsCacheSize)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,TermState>(termsCacheSize);\n\n    this.termComp = termComp;\n    \n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\", PrefixCodedTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readInt();\n        final long numTerms = in.readLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readLong();\n        final TermsIndexReaderBase.FieldReader fieldIndexReader;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        fieldIndexReader = indexReader.getField(fieldInfo);\n        if (numTerms > 0) {\n          assert !fields.containsKey(fieldInfo.name);\n          fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"16c697f6ca5cdc82f918f753317a4ac9c70d259f":["99cf56f3a650b908f7017a72f9d23940418f8a52"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["99cf56f3a650b908f7017a72f9d23940418f8a52","16c697f6ca5cdc82f918f753317a4ac9c70d259f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"99cf56f3a650b908f7017a72f9d23940418f8a52":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["16c697f6ca5cdc82f918f753317a4ac9c70d259f"]},"commit2Childs":{"16c697f6ca5cdc82f918f753317a4ac9c70d259f":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["99cf56f3a650b908f7017a72f9d23940418f8a52"],"99cf56f3a650b908f7017a72f9d23940418f8a52":["16c697f6ca5cdc82f918f753317a4ac9c70d259f","9ab1f5591dc05f1f2b5407d809c9699f75554a32"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}