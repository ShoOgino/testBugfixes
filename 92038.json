{"path":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","commits":[{"id":"73d216e8a31fcc28595d9f9518b2f081d9379789","date":1333813682,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"/dev/null","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      boolean success = false;\n      while (!success) {\n        try {\n          // TODO: check Reader+Version,Version+Reader too\n          // also look for other variants and handle them special\n          int idx = random.nextInt(tokenizers.length);\n          try {\n            Constructor c = tokenizers[idx].getConstructor(Version.class, Reader.class);\n            spec.tokenizer = (Tokenizer) c.newInstance(TEST_VERSION_CURRENT, reader);\n          } catch (NoSuchMethodException e) {\n            Constructor c = tokenizers[idx].getConstructor(Reader.class);\n            spec.tokenizer = (Tokenizer) c.newInstance(reader);\n          }\n          spec.toString = tokenizers[idx].toString();\n          success = true;\n        } catch (Exception e) {\n          // ignore\n        }\n      }\n      return spec;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a75004531a9cdf4ad1c7a295d1c822057af45b87","date":1333836028,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      boolean success = false;\n      while (!success) {\n        try {\n          // TODO: check Reader+Version,Version+Reader too\n          // also look for other variants and handle them special\n          int idx = random.nextInt(tokenizers.size());\n          try {\n            Constructor<? extends Tokenizer> c = tokenizers.get(idx).getConstructor(Version.class, Reader.class);\n            spec.tokenizer = c.newInstance(TEST_VERSION_CURRENT, reader);\n          } catch (NoSuchMethodException e) {\n            Constructor<? extends Tokenizer> c = tokenizers.get(idx).getConstructor(Reader.class);\n            spec.tokenizer = c.newInstance(reader);\n          }\n          spec.toString = tokenizers.get(idx).toString();\n          success = true;\n        } catch (Exception e) {\n          // ignore\n        }\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      boolean success = false;\n      while (!success) {\n        try {\n          // TODO: check Reader+Version,Version+Reader too\n          // also look for other variants and handle them special\n          int idx = random.nextInt(tokenizers.length);\n          try {\n            Constructor c = tokenizers[idx].getConstructor(Version.class, Reader.class);\n            spec.tokenizer = (Tokenizer) c.newInstance(TEST_VERSION_CURRENT, reader);\n          } catch (NoSuchMethodException e) {\n            Constructor c = tokenizers[idx].getConstructor(Reader.class);\n            spec.tokenizer = (Tokenizer) c.newInstance(reader);\n          }\n          spec.toString = tokenizers[idx].toString();\n          success = true;\n        } catch (Exception e) {\n          // ignore\n        }\n      }\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a92b21feea3b1b4d7ad5a06439333c4f757318f","date":1333977928,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      boolean success = false;\n      while (!success) {\n        try {\n          final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n          final Object args[] = newTokenizerArgs(random, reader, ctor.getParameterTypes());\n          spec.tokenizer = ctor.newInstance(args);\n          spec.toString =  ctor.getDeclaringClass().getName() + (\"(\" + Arrays.toString(args) + \")\");\n          success = true;\n        } catch (InvocationTargetException ite) {\n          final Throwable cause = ite.getCause();\n          if (cause instanceof IllegalArgumentException ||\n              cause instanceof UnsupportedOperationException) {\n            // thats ok, ignore\n            if (VERBOSE) {\n              System.err.println(\"Ignoring IAE/UOE from ctor:\");\n              cause.printStackTrace(System.err);\n            }\n          } else {\n            Rethrow.rethrow(cause);\n          }\n        } catch (IllegalAccessException iae) {\n          Rethrow.rethrow(iae);\n        } catch (InstantiationException ie) {\n          Rethrow.rethrow(ie);\n        }\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      boolean success = false;\n      while (!success) {\n        try {\n          // TODO: check Reader+Version,Version+Reader too\n          // also look for other variants and handle them special\n          int idx = random.nextInt(tokenizers.size());\n          try {\n            Constructor<? extends Tokenizer> c = tokenizers.get(idx).getConstructor(Version.class, Reader.class);\n            spec.tokenizer = c.newInstance(TEST_VERSION_CURRENT, reader);\n          } catch (NoSuchMethodException e) {\n            Constructor<? extends Tokenizer> c = tokenizers.get(idx).getConstructor(Reader.class);\n            spec.tokenizer = c.newInstance(reader);\n          }\n          spec.toString = tokenizers.get(idx).toString();\n          success = true;\n        } catch (Exception e) {\n          // ignore\n        }\n      }\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d1f4dc85b409fc5f00183c0cafb53ab47621e5eb","date":1333990334,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final Object args[] = newTokenizerArgs(random, reader, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      boolean success = false;\n      while (!success) {\n        try {\n          final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n          final Object args[] = newTokenizerArgs(random, reader, ctor.getParameterTypes());\n          spec.tokenizer = ctor.newInstance(args);\n          spec.toString =  ctor.getDeclaringClass().getName() + (\"(\" + Arrays.toString(args) + \")\");\n          success = true;\n        } catch (InvocationTargetException ite) {\n          final Throwable cause = ite.getCause();\n          if (cause instanceof IllegalArgumentException ||\n              cause instanceof UnsupportedOperationException) {\n            // thats ok, ignore\n            if (VERBOSE) {\n              System.err.println(\"Ignoring IAE/UOE from ctor:\");\n              cause.printStackTrace(System.err);\n            }\n          } else {\n            Rethrow.rethrow(cause);\n          }\n        } catch (IllegalAccessException iae) {\n          Rethrow.rethrow(iae);\n        } catch (InstantiationException ie) {\n          Rethrow.rethrow(ie);\n        }\n      }\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a1f75de0fcbd527904ffc7e6c2865045cb7a587","date":1333992759,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (spec.tokenizer == null) {\n          assert wrapper.readSomething == false;\n        }\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final Object args[] = newTokenizerArgs(random, reader, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"32eaa30f04d4e9274c2258b8bc03861ca5e06679","date":1333994007,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (spec.tokenizer == null) {\n          assertFalse(ctor.getDeclaringClass().getName() + \" has read something in ctor but failed with UOE/IAE\", wrapper.readSomething);\n        }\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (spec.tokenizer == null) {\n          assert wrapper.readSomething == false;\n        }\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"888c2d6bca1edd8d9293631d6e1d188b036e0f05","date":1334076894,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (brokenOffsetsComponents.contains(ctor.getDeclaringClass())) {\n          spec.offsetsAreCorrect = false;\n        }\n        if (spec.tokenizer == null) {\n          assertFalse(ctor.getDeclaringClass().getName() + \" has read something in ctor but failed with UOE/IAE\", wrapper.readSomething);\n        }\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (spec.tokenizer == null) {\n          assertFalse(ctor.getDeclaringClass().getName() + \" has read something in ctor but failed with UOE/IAE\", wrapper.readSomething);\n        }\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e","date":1334174049,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (brokenOffsetsComponents.contains(ctor.getDeclaringClass())) {\n          spec.offsetsAreCorrect = false;\n        }\n        if (spec.tokenizer == null) {\n          assertFalse(ctor.getDeclaringClass().getName() + \" has read something in ctor but failed with UOE/IAE\", wrapper.readSomething);\n        }\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      boolean success = false;\n      while (!success) {\n        try {\n          // TODO: check Reader+Version,Version+Reader too\n          // also look for other variants and handle them special\n          int idx = random.nextInt(tokenizers.size());\n          try {\n            Constructor<? extends Tokenizer> c = tokenizers.get(idx).getConstructor(Version.class, Reader.class);\n            spec.tokenizer = c.newInstance(TEST_VERSION_CURRENT, reader);\n          } catch (NoSuchMethodException e) {\n            Constructor<? extends Tokenizer> c = tokenizers.get(idx).getConstructor(Reader.class);\n            spec.tokenizer = c.newInstance(reader);\n          }\n          spec.toString = tokenizers.get(idx).toString();\n          success = true;\n        } catch (Exception e) {\n          // ignore\n        }\n      }\n      return spec;\n    }\n\n","bugFix":["a75004531a9cdf4ad1c7a295d1c822057af45b87","73d216e8a31fcc28595d9f9518b2f081d9379789"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"64c6c5ffc98eb03d746c9ad07bdc3cc4a9d9cba7","date":1334539915,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (spec.tokenizer != null) {\n          if (brokenOffsetsComponents.contains(ctor.getDeclaringClass())) {\n            spec.offsetsAreCorrect = false;\n          }\n          spec.toString = descr.toString();\n        } else {\n          assertFalse(ctor.getDeclaringClass().getName() + \" has read something in ctor but failed with UOE/IAE\", wrapper.readSomething);\n        }\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (brokenOffsetsComponents.contains(ctor.getDeclaringClass())) {\n          spec.offsetsAreCorrect = false;\n        }\n        if (spec.tokenizer == null) {\n          assertFalse(ctor.getDeclaringClass().getName() + \" has read something in ctor but failed with UOE/IAE\", wrapper.readSomething);\n        }\n        spec.toString = descr.toString();\n      }\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newTokenizer(Random,Reader).mjava","sourceNew":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (spec.tokenizer != null) {\n          if (brokenOffsetsComponents.contains(ctor.getDeclaringClass())) {\n            spec.offsetsAreCorrect = false;\n          }\n          spec.toString = descr.toString();\n        } else {\n          assertFalse(ctor.getDeclaringClass().getName() + \" has read something in ctor but failed with UOE/IAE\", wrapper.readSomething);\n        }\n      }\n      return spec;\n    }\n\n","sourceOld":"    // create a new random tokenizer from classpath\n    private TokenizerSpec newTokenizer(Random random, Reader reader) {\n      TokenizerSpec spec = new TokenizerSpec();\n      while (spec.tokenizer == null) {\n        final Constructor<? extends Tokenizer> ctor = tokenizers.get(random.nextInt(tokenizers.size()));\n        final StringBuilder descr = new StringBuilder();\n        final CheckThatYouDidntReadAnythingReaderWrapper wrapper = new CheckThatYouDidntReadAnythingReaderWrapper(reader);\n        final Object args[] = newTokenizerArgs(random, wrapper, ctor.getParameterTypes());\n        spec.tokenizer = createComponent(ctor, args, descr);\n        if (spec.tokenizer != null) {\n          if (brokenOffsetsComponents.contains(ctor.getDeclaringClass())) {\n            spec.offsetsAreCorrect = false;\n          }\n          spec.toString = descr.toString();\n        } else {\n          assertFalse(ctor.getDeclaringClass().getName() + \" has read something in ctor but failed with UOE/IAE\", wrapper.readSomething);\n        }\n      }\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"888c2d6bca1edd8d9293631d6e1d188b036e0f05":["32eaa30f04d4e9274c2258b8bc03861ca5e06679"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["64c6c5ffc98eb03d746c9ad07bdc3cc4a9d9cba7"],"d1f4dc85b409fc5f00183c0cafb53ab47621e5eb":["5a92b21feea3b1b4d7ad5a06439333c4f757318f"],"a75004531a9cdf4ad1c7a295d1c822057af45b87":["73d216e8a31fcc28595d9f9518b2f081d9379789"],"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e":["a75004531a9cdf4ad1c7a295d1c822057af45b87","888c2d6bca1edd8d9293631d6e1d188b036e0f05"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"32eaa30f04d4e9274c2258b8bc03861ca5e06679":["2a1f75de0fcbd527904ffc7e6c2865045cb7a587"],"64c6c5ffc98eb03d746c9ad07bdc3cc4a9d9cba7":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"2a1f75de0fcbd527904ffc7e6c2865045cb7a587":["d1f4dc85b409fc5f00183c0cafb53ab47621e5eb"],"5a92b21feea3b1b4d7ad5a06439333c4f757318f":["a75004531a9cdf4ad1c7a295d1c822057af45b87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"73d216e8a31fcc28595d9f9518b2f081d9379789":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"888c2d6bca1edd8d9293631d6e1d188b036e0f05":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d1f4dc85b409fc5f00183c0cafb53ab47621e5eb":["2a1f75de0fcbd527904ffc7e6c2865045cb7a587"],"a75004531a9cdf4ad1c7a295d1c822057af45b87":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e","5a92b21feea3b1b4d7ad5a06439333c4f757318f"],"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e":["64c6c5ffc98eb03d746c9ad07bdc3cc4a9d9cba7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["73d216e8a31fcc28595d9f9518b2f081d9379789"],"32eaa30f04d4e9274c2258b8bc03861ca5e06679":["888c2d6bca1edd8d9293631d6e1d188b036e0f05"],"64c6c5ffc98eb03d746c9ad07bdc3cc4a9d9cba7":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"5a92b21feea3b1b4d7ad5a06439333c4f757318f":["d1f4dc85b409fc5f00183c0cafb53ab47621e5eb"],"2a1f75de0fcbd527904ffc7e6c2865045cb7a587":["32eaa30f04d4e9274c2258b8bc03861ca5e06679"],"73d216e8a31fcc28595d9f9518b2f081d9379789":["a75004531a9cdf4ad1c7a295d1c822057af45b87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}