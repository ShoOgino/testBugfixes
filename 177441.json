{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","commits":[{"id":"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf","date":1522951207,"type":1,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108","date":1533256859,"type":3,"author":"Erick","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233","date":1543335722,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\", qt=\\\"/export\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"parallelDestinationCollection\", 2, 2);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\", qt=\\\"/export\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\", qt=\\\"/export\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":["b940572a59da1b42b6c20ab5278155b12816807a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d35c84fdef07284c122012ca4000d3b7285a66e","date":1545962630,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","sourceNew":"  @Test\n  // commented out on: 24-Dec-2018   @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"parallelDestinationCollection\", 2, 2);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\", qt=\\\"/export\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"parallelDestinationCollection\", 2, 2);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\", qt=\\\"/export\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a1cae9aea470e88146567017129e8280d21ca76","date":1563504024,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"parallelDestinationCollection\", 2, 2);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\", qt=\\\"/export\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  // commented out on: 24-Dec-2018   @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(\"parallelDestinationCollection\", 2, 2);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n    \n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n    \n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n      .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n      .withCollectionZkHost(\"parallelDestinationCollection\", cluster.getZkServer().getZkAddress())\n      .withFunctionName(\"search\", CloudSolrStream.class)\n      .withFunctionName(\"update\", UpdateStream.class)\n      .withFunctionName(\"parallel\", ParallelStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"update(parallelDestinationCollection, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\", qt=\\\"/export\\\"))\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      cluster.getSolrClient().commit(\"parallelDestinationCollection\");\n\n      //Ensure that all UpdateStream tuples indicate the correct number of copied/indexed docs\n      long count = 0;\n\n      for (Tuple tuple : tuples) {\n        count += tuple.getLong(\"batchIndexed\");\n      }\n\n      assert (count == 5);\n\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8a1cae9aea470e88146567017129e8280d21ca76":["8d35c84fdef07284c122012ca4000d3b7285a66e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8a1cae9aea470e88146567017129e8280d21ca76"],"8d35c84fdef07284c122012ca4000d3b7285a66e":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["8d35c84fdef07284c122012ca4000d3b7285a66e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"8a1cae9aea470e88146567017129e8280d21ca76":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108"],"b73cc5cc718a5ccdc940b7e3ecbf17e6c145d233":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"8d35c84fdef07284c122012ca4000d3b7285a66e":["8a1cae9aea470e88146567017129e8280d21ca76"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}