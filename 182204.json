{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","commits":[{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lock();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), c -> new HashMap<>()).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), name -> new HashMap<>()).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), rn -> new ArrayList<>()).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0c5018985f5ddacff38d20cd4b39cf3c885fa234","date":1547081878,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","sourceNew":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lock();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), Utils.NEW_HASHMAP_FUN).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), Utils.NEW_HASHMAP_FUN).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), Utils.NEW_ARRAYLIST_FUN).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lock();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), c -> new HashMap<>()).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), name -> new HashMap<>()).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), rn -> new ArrayList<>()).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"66b87d86427dfa19b2ef36b66de83aa9655cea33","date":1552627668,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","sourceNew":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lock();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), Utils.NEW_HASHMAP_FUN).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), Utils.NEW_HASHMAP_FUN).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lock();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), Utils.NEW_HASHMAP_FUN).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), Utils.NEW_HASHMAP_FUN).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), Utils.NEW_ARRAYLIST_FUN).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76ebb8ccd9ce24bddddc5bec621183fdec375769","date":1552676813,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","sourceNew":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lockInterruptibly();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), Utils.NEW_HASHMAP_FUN).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), Utils.NEW_HASHMAP_FUN).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lock();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), Utils.NEW_HASHMAP_FUN).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), Utils.NEW_HASHMAP_FUN).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":5,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSetClusterState(ClusterState).mjava","sourceNew":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lockInterruptibly();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), Utils.NEW_HASHMAP_FUN).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), Utils.NEW_HASHMAP_FUN).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Initialize from an existing cluster state\n   * @param initialState initial cluster state\n   */\n  public void simSetClusterState(ClusterState initialState) throws Exception {\n    lock.lockInterruptibly();\n    try {\n      collProperties.clear();\n      sliceProperties.clear();\n      nodeReplicaMap.clear();\n      liveNodes.clear();\n      for (String nodeId : stateManager.listData(ZkStateReader.LIVE_NODES_ZKNODE)) {\n        if (stateManager.hasData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.LIVE_NODES_ZKNODE + \"/\" + nodeId, -1);\n        }\n        if (stateManager.hasData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId)) {\n          stateManager.removeData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + nodeId, -1);\n        }\n      }\n      liveNodes.addAll(initialState.getLiveNodes());\n      for (String nodeId : liveNodes.get()) {\n        createEphemeralLiveNode(nodeId);\n      }\n      initialState.forEachCollection(dc -> {\n        collProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>()).putAll(dc.getProperties());\n        opDelays.computeIfAbsent(dc.getName(), Utils.NEW_HASHMAP_FUN).putAll(defaultOpDelays);\n        dc.getSlices().forEach(s -> {\n          sliceProperties.computeIfAbsent(dc.getName(), name -> new ConcurrentHashMap<>())\n              .computeIfAbsent(s.getName(), Utils.NEW_HASHMAP_FUN).putAll(s.getProperties());\n          s.getReplicas().forEach(r -> {\n            ReplicaInfo ri = new ReplicaInfo(r.getName(), r.getCoreName(), dc.getName(), s.getName(), r.getType(), r.getNodeName(), r.getProperties());\n            if (liveNodes.get().contains(r.getNodeName())) {\n              nodeReplicaMap.computeIfAbsent(r.getNodeName(), Utils.NEW_SYNCHRONIZED_ARRAYLIST_FUN).add(ri);\n            }\n          });\n        });\n      });\n      collectionsStatesRef.set(null);\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"76ebb8ccd9ce24bddddc5bec621183fdec375769":["66b87d86427dfa19b2ef36b66de83aa9655cea33"],"0c5018985f5ddacff38d20cd4b39cf3c885fa234":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"66b87d86427dfa19b2ef36b66de83aa9655cea33":["0c5018985f5ddacff38d20cd4b39cf3c885fa234"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["76ebb8ccd9ce24bddddc5bec621183fdec375769"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"]},"commit2Childs":{"76ebb8ccd9ce24bddddc5bec621183fdec375769":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"0c5018985f5ddacff38d20cd4b39cf3c885fa234":["66b87d86427dfa19b2ef36b66de83aa9655cea33"],"66b87d86427dfa19b2ef36b66de83aa9655cea33":["76ebb8ccd9ce24bddddc5bec621183fdec375769"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["0c5018985f5ddacff38d20cd4b39cf3c885fa234"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}