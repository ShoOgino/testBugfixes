{"path":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","commits":[{"id":"7391c1f4ab1a6817de8a262f5c1b3de3cf190785","date":1222335791,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"/dev/null","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["657efdf11c7dcb2c658d94a4cc2570cbf8a88ee7","433ef5e0ff3fa18d549774f572b36aae2ae64232"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e196053d22b13893cdca90c9e794fce0acaa5b30","date":1225305050,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bd80c1e3e248c89bf83612023f71b946f1e64194","date":1232102891,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          final byte[] b = new byte[reader.maxDoc()];\n          reader.norms(fieldName, b, 0);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["657efdf11c7dcb2c658d94a4cc2570cbf8a88ee7","433ef5e0ff3fa18d549774f572b36aae2ae64232"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"657efdf11c7dcb2c658d94a4cc2570cbf8a88ee7","date":1232104284,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        final byte[] b = new byte[reader.maxDoc()];\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          reader.norms(fieldName, b, 0);\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          final byte[] b = new byte[reader.maxDoc()];\n          reader.norms(fieldName, b, 0);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":["bd80c1e3e248c89bf83612023f71b946f1e64194","7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"bugIntro":["433ef5e0ff3fa18d549774f572b36aae2ae64232"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a825553898ef252fc32587f6f03e8e3102b79d7","date":1235822479,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        final byte[] b = new byte[reader.maxDoc()];\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          reader.norms(fieldName, b, 0);\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        final int maxDoc = reader.maxDoc();\n\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            if (doc >= maxDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        final byte[] b = new byte[reader.maxDoc()];\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          reader.norms(fieldName, b, 0);\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["433ef5e0ff3fa18d549774f572b36aae2ae64232"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e8e18c40b99c99721d4ee99fc33b6c299311da32","date":1241864501,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        final byte[] b = new byte[reader.maxDoc()];\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          reader.norms(fieldName, b, 0);\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        final int maxDoc = reader.maxDoc();\n\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            if (doc >= maxDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        final byte[] b = new byte[reader.maxDoc()];\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          reader.norms(fieldName, b, 0);\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        final int maxDoc = reader.maxDoc();\n\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            if (doc >= maxDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3ab91f3bb602daf6393fa7f78b11afd3400d669","date":1243282044,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        final byte[] b = new byte[reader.maxDoc()];\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          reader.norms(fieldName, b, 0);\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        final int maxDoc = reader.maxDoc();\n\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            if (doc >= maxDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        final byte[] b = new byte[reader.maxDoc()];\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          reader.norms(fieldName, b, 0);\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        final int maxDoc = reader.maxDoc();\n\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            if (doc >= maxDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"433ef5e0ff3fa18d549774f572b36aae2ae64232","date":1246039802,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        // Test getFieldNames()\n        if (infoStream != null) {\n          infoStream.print(\"    test: fields..............\");\n        }         \n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        \n        // Test Field Norms\n        segInfoStat.fieldNormStatus = testFieldNorms(fieldNames, reader);\n\n        // Test the Term Index\n        segInfoStat.termIndexStatus = testTermIndex(info, reader);\n\n        // Test Stored Fields\n        segInfoStat.storedFieldStatus = testStoredFields(info, reader, nf);\n\n        // Test Term Vectors\n        segInfoStat.termVectorStatus = testTermVectors(info, reader, nf);\n\n        // Rethrow the first exception we encountered\n        //  This will cause stats for failed segments to be incremented properly\n        if (segInfoStat.fieldNormStatus.error != null) {\n          throw new RuntimeException(\"Field Norm test failed\");\n        } else if (segInfoStat.termIndexStatus.error != null) {\n          throw new RuntimeException(\"Term Index test failed\");\n        } else if (segInfoStat.storedFieldStatus.error != null) {\n          throw new RuntimeException(\"Stored Field test failed\");\n        } else if (segInfoStat.termVectorStatus.error != null) {\n          throw new RuntimeException(\"Term Vector test failed\");\n        }\n\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        if (infoStream != null)\n          infoStream.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        final byte[] b = new byte[reader.maxDoc()];\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          reader.norms(fieldName, b, 0);\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        if (infoStream != null)\n          infoStream.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        final int maxDoc = reader.maxDoc();\n\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            if (doc >= maxDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        if (infoStream != null)\n          infoStream.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":["657efdf11c7dcb2c658d94a4cc2570cbf8a88ee7","bd80c1e3e248c89bf83612023f71b946f1e64194","5a825553898ef252fc32587f6f03e8e3102b79d7","7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1","date":1255502337,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        // Test getFieldNames()\n        if (infoStream != null) {\n          infoStream.print(\"    test: fields..............\");\n        }         \n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        \n        // Test Field Norms\n        segInfoStat.fieldNormStatus = testFieldNorms(fieldNames, reader);\n\n        // Test the Term Index\n        segInfoStat.termIndexStatus = testTermIndex(info, reader);\n\n        // Test Stored Fields\n        segInfoStat.storedFieldStatus = testStoredFields(info, reader, nf);\n\n        // Test Term Vectors\n        segInfoStat.termVectorStatus = testTermVectors(info, reader, nf);\n\n        // Rethrow the first exception we encountered\n        //  This will cause stats for failed segments to be incremented properly\n        if (segInfoStat.fieldNormStatus.error != null) {\n          throw new RuntimeException(\"Field Norm test failed\");\n        } else if (segInfoStat.termIndexStatus.error != null) {\n          throw new RuntimeException(\"Term Index test failed\");\n        } else if (segInfoStat.storedFieldStatus.error != null) {\n          throw new RuntimeException(\"Stored Field test failed\");\n        } else if (segInfoStat.termVectorStatus.error != null) {\n          throw new RuntimeException(\"Term Vector test failed\");\n        }\n\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        // Test getFieldNames()\n        if (infoStream != null) {\n          infoStream.print(\"    test: fields..............\");\n        }         \n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        \n        // Test Field Norms\n        segInfoStat.fieldNormStatus = testFieldNorms(fieldNames, reader);\n\n        // Test the Term Index\n        segInfoStat.termIndexStatus = testTermIndex(info, reader);\n\n        // Test Stored Fields\n        segInfoStat.storedFieldStatus = testStoredFields(info, reader, nf);\n\n        // Test Term Vectors\n        segInfoStat.termVectorStatus = testTermVectors(info, reader, nf);\n\n        // Rethrow the first exception we encountered\n        //  This will cause stats for failed segments to be incremented properly\n        if (segInfoStat.fieldNormStatus.error != null) {\n          throw new RuntimeException(\"Field Norm test failed\");\n        } else if (segInfoStat.termIndexStatus.error != null) {\n          throw new RuntimeException(\"Term Index test failed\");\n        } else if (segInfoStat.storedFieldStatus.error != null) {\n          throw new RuntimeException(\"Stored Field test failed\");\n        } else if (segInfoStat.termVectorStatus.error != null) {\n          throw new RuntimeException(\"Term Vector test failed\");\n        }\n\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b4e40ecf6eb9bff831572fe33a2758f9ef1e0dcc","date":1255773182,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        // Test getFieldNames()\n        if (infoStream != null) {\n          infoStream.print(\"    test: fields..............\");\n        }         \n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        \n        // Test Field Norms\n        segInfoStat.fieldNormStatus = testFieldNorms(fieldNames, reader);\n\n        // Test the Term Index\n        segInfoStat.termIndexStatus = testTermIndex(info, reader);\n\n        // Test Stored Fields\n        segInfoStat.storedFieldStatus = testStoredFields(info, reader, nf);\n\n        // Test Term Vectors\n        segInfoStat.termVectorStatus = testTermVectors(info, reader, nf);\n\n        // Rethrow the first exception we encountered\n        //  This will cause stats for failed segments to be incremented properly\n        if (segInfoStat.fieldNormStatus.error != null) {\n          throw new RuntimeException(\"Field Norm test failed\");\n        } else if (segInfoStat.termIndexStatus.error != null) {\n          throw new RuntimeException(\"Term Index test failed\");\n        } else if (segInfoStat.storedFieldStatus.error != null) {\n          throw new RuntimeException(\"Stored Field test failed\");\n        } else if (segInfoStat.termVectorStatus.error != null) {\n          throw new RuntimeException(\"Term Vector test failed\");\n        }\n\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add((SegmentInfo) info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        // Test getFieldNames()\n        if (infoStream != null) {\n          infoStream.print(\"    test: fields..............\");\n        }         \n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        \n        // Test Field Norms\n        segInfoStat.fieldNormStatus = testFieldNorms(fieldNames, reader);\n\n        // Test the Term Index\n        segInfoStat.termIndexStatus = testTermIndex(info, reader);\n\n        // Test Stored Fields\n        segInfoStat.storedFieldStatus = testStoredFields(info, reader, nf);\n\n        // Test Term Vectors\n        segInfoStat.termVectorStatus = testTermVectors(info, reader, nf);\n\n        // Rethrow the first exception we encountered\n        //  This will cause stats for failed segments to be incremented properly\n        if (segInfoStat.fieldNormStatus.error != null) {\n          throw new RuntimeException(\"Field Norm test failed\");\n        } else if (segInfoStat.termIndexStatus.error != null) {\n          throw new RuntimeException(\"Term Index test failed\");\n        } else if (segInfoStat.storedFieldStatus.error != null) {\n          throw new RuntimeException(\"Stored Field test failed\");\n        } else if (segInfoStat.termVectorStatus.error != null) {\n          throw new RuntimeException(\"Term Vector test failed\");\n        }\n\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f011f01db72fa6f556a9a0843944ecee2de4aaa8","date":1255806907,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List[String]).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#checkIndex(List).mjava","sourceNew":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List<String> onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      for (String s : onlySegments) {\n        if (infoStream != null)\n          infoStream.print(\" \" + s);\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map<String,String> diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        // Test getFieldNames()\n        if (infoStream != null) {\n          infoStream.print(\"    test: fields..............\");\n        }         \n        Collection<String> fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        \n        // Test Field Norms\n        segInfoStat.fieldNormStatus = testFieldNorms(fieldNames, reader);\n\n        // Test the Term Index\n        segInfoStat.termIndexStatus = testTermIndex(info, reader);\n\n        // Test Stored Fields\n        segInfoStat.storedFieldStatus = testStoredFields(info, reader, nf);\n\n        // Test Term Vectors\n        segInfoStat.termVectorStatus = testTermVectors(info, reader, nf);\n\n        // Rethrow the first exception we encountered\n        //  This will cause stats for failed segments to be incremented properly\n        if (segInfoStat.fieldNormStatus.error != null) {\n          throw new RuntimeException(\"Field Norm test failed\");\n        } else if (segInfoStat.termIndexStatus.error != null) {\n          throw new RuntimeException(\"Term Index test failed\");\n        } else if (segInfoStat.storedFieldStatus.error != null) {\n          throw new RuntimeException(\"Stored Field test failed\");\n        } else if (segInfoStat.termVectorStatus.error != null) {\n          throw new RuntimeException(\"Term Vector test failed\");\n        }\n\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add((SegmentInfo) info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns a {@link Status} instance detailing\n   *  the state of the index.\n   * \n   *  @param onlySegments list of specific segment names to check\n   *\n   *  <p>As this method checks every byte in the specified\n   *  segments, on a large index it can take quite a long\n   *  time to run.\n   *\n   *  <p><b>WARNING</b>: make sure\n   *  you only call this when the index is not opened by any\n   *  writer. */\n  public Status checkIndex(List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    Status result = new Status();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      if (infoStream != null)\n        t.printStackTrace(infoStream);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_USER_DATA)\n        sFormat = \"FORMAT_USER_DATA [Lucene 2.9]\";\n      else if (format == SegmentInfos.FORMAT_DIAGNOSTICS)\n        sFormat = \"FORMAT_DIAGNOSTICS [Lucene 2.9]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n    result.userData = sis.getUserData();\n    String userDataString;\n    if (sis.getUserData().size() > 0) {\n      userDataString = \" userData=\" + sis.getUserData();\n    } else {\n      userDataString = \"\";\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat + userDataString);\n\n    if (onlySegments != null) {\n      result.partial = true;\n      if (infoStream != null)\n        infoStream.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        if (infoStream != null)\n          infoStream.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      Status.SegmentInfoStatus segInfoStat = new Status.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n        Map diagnostics = info.getDiagnostics();\n        segInfoStat.diagnostics = diagnostics;\n        if (diagnostics.size() > 0) {\n          msg(\"    diagnostics = \" + diagnostics);\n        }\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n        }\n        if (infoStream != null)\n          infoStream.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n        segInfoStat.openReaderPassed = true;\n\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (reader.deletedDocs.count() != info.getDelCount()) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (reader.deletedDocs.count() > reader.maxDoc()) {\n            throw new RuntimeException(\"too many deleted docs: maxDoc()=\" + reader.maxDoc() + \" vs deletedDocs.count()=\" + reader.deletedDocs.count());\n          }\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0) {\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n        if (reader.maxDoc() != info.docCount)\n          throw new RuntimeException(\"SegmentReader.maxDoc() \" + reader.maxDoc() + \" != SegmentInfos.docCount \" + info.docCount);\n\n        // Test getFieldNames()\n        if (infoStream != null) {\n          infoStream.print(\"    test: fields..............\");\n        }         \n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        \n        // Test Field Norms\n        segInfoStat.fieldNormStatus = testFieldNorms(fieldNames, reader);\n\n        // Test the Term Index\n        segInfoStat.termIndexStatus = testTermIndex(info, reader);\n\n        // Test Stored Fields\n        segInfoStat.storedFieldStatus = testStoredFields(info, reader, nf);\n\n        // Test Term Vectors\n        segInfoStat.termVectorStatus = testTermVectors(info, reader, nf);\n\n        // Rethrow the first exception we encountered\n        //  This will cause stats for failed segments to be incremented properly\n        if (segInfoStat.fieldNormStatus.error != null) {\n          throw new RuntimeException(\"Field Norm test failed\");\n        } else if (segInfoStat.termIndexStatus.error != null) {\n          throw new RuntimeException(\"Term Index test failed\");\n        } else if (segInfoStat.storedFieldStatus.error != null) {\n          throw new RuntimeException(\"Stored Field test failed\");\n        } else if (segInfoStat.termVectorStatus.error != null) {\n          throw new RuntimeException(\"Term Vector test failed\");\n        }\n\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        comment = \"fixIndex() would remove reference to this segment\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        if (infoStream != null)\n          t.printStackTrace(infoStream);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add((SegmentInfo) info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"657efdf11c7dcb2c658d94a4cc2570cbf8a88ee7":["bd80c1e3e248c89bf83612023f71b946f1e64194"],"b4e40ecf6eb9bff831572fe33a2758f9ef1e0dcc":["be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1"],"f011f01db72fa6f556a9a0843944ecee2de4aaa8":["b4e40ecf6eb9bff831572fe33a2758f9ef1e0dcc"],"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1":["433ef5e0ff3fa18d549774f572b36aae2ae64232"],"e196053d22b13893cdca90c9e794fce0acaa5b30":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"433ef5e0ff3fa18d549774f572b36aae2ae64232":["d3ab91f3bb602daf6393fa7f78b11afd3400d669"],"7391c1f4ab1a6817de8a262f5c1b3de3cf190785":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e8e18c40b99c99721d4ee99fc33b6c299311da32":["5a825553898ef252fc32587f6f03e8e3102b79d7"],"5a825553898ef252fc32587f6f03e8e3102b79d7":["657efdf11c7dcb2c658d94a4cc2570cbf8a88ee7"],"d3ab91f3bb602daf6393fa7f78b11afd3400d669":["e8e18c40b99c99721d4ee99fc33b6c299311da32"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bd80c1e3e248c89bf83612023f71b946f1e64194":["e196053d22b13893cdca90c9e794fce0acaa5b30"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f011f01db72fa6f556a9a0843944ecee2de4aaa8"]},"commit2Childs":{"657efdf11c7dcb2c658d94a4cc2570cbf8a88ee7":["5a825553898ef252fc32587f6f03e8e3102b79d7"],"b4e40ecf6eb9bff831572fe33a2758f9ef1e0dcc":["f011f01db72fa6f556a9a0843944ecee2de4aaa8"],"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1":["b4e40ecf6eb9bff831572fe33a2758f9ef1e0dcc"],"f011f01db72fa6f556a9a0843944ecee2de4aaa8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e196053d22b13893cdca90c9e794fce0acaa5b30":["bd80c1e3e248c89bf83612023f71b946f1e64194"],"433ef5e0ff3fa18d549774f572b36aae2ae64232":["be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1"],"7391c1f4ab1a6817de8a262f5c1b3de3cf190785":["e196053d22b13893cdca90c9e794fce0acaa5b30"],"e8e18c40b99c99721d4ee99fc33b6c299311da32":["d3ab91f3bb602daf6393fa7f78b11afd3400d669"],"5a825553898ef252fc32587f6f03e8e3102b79d7":["e8e18c40b99c99721d4ee99fc33b6c299311da32"],"d3ab91f3bb602daf6393fa7f78b11afd3400d669":["433ef5e0ff3fa18d549774f572b36aae2ae64232"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"bd80c1e3e248c89bf83612023f71b946f1e64194":["657efdf11c7dcb2c658d94a4cc2570cbf8a88ee7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}