{"path":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","commits":[{"id":"13ba39c40de7bda3b305a362bceb7a788e31df23","date":1075988755,"type":0,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"/dev/null","sourceNew":"  public void testStopList() {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertTrue(stream != null);\n    Token token = null;\n    try {\n      while ((token = stream.next()) != null)\n      {\n        String text = token.termText();\n        assertTrue(stopWordsSet.contains(text) == false);\n      }\n    } catch (IOException e) {\n      assertTrue(false);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd","c39363fefe2d7f6a6d50ce8e8b758c17a257c58e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"89550d25407cfe6619fc426d7602304f48a0f861","date":1120080682,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    Token token = null;\n    while ((token = stream.next()) != null) {\n      String text = token.termText();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","sourceOld":"  public void testStopList() {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertTrue(stream != null);\n    Token token = null;\n    try {\n      while ((token = stream.next()) != null)\n      {\n        String text = token.termText();\n        assertTrue(stopWordsSet.contains(text) == false);\n      }\n    } catch (IOException e) {\n      assertTrue(false);\n    }\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"693d6573b6621fc1265316fc6b042c24235c81d8","date":1199049557,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    Token token = null;\n    while ((token = stream.next()) != null) {\n      String text = token.termText();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,token.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    Token token = null;\n    while ((token = stream.next()) != null) {\n      String text = token.termText();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    final Token reusableToken = new Token();\n    for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n      String text = nextToken.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,nextToken.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    Token token = null;\n    while ((token = stream.next()) != null) {\n      String text = token.termText();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,token.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223","date":1227051709,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    final Token reusableToken = new Token();\n    for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n      String text = nextToken.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,nextToken.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9","date":1256127131,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(stopWordsSet, false);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer((String[])stopWordsSet.toArray(new String[3]));\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba1116b3450a9c1642c89445d131b37344055245","date":1256329517,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(stopWordsSet, false);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // by default stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e450c7d50c2fc84c963d0d7ade9d3217d868064d","date":1259932067,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set stopWordsSet = new HashSet();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":["c39363fefe2d7f6a6d50ce8e8b758c17a257c58e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.term();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["693d6573b6621fc1265316fc6b042c24235c81d8"],"89550d25407cfe6619fc426d7602304f48a0f861":["13ba39c40de7bda3b305a362bceb7a788e31df23"],"13ba39c40de7bda3b305a362bceb7a788e31df23":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"693d6573b6621fc1265316fc6b042c24235c81d8":["89550d25407cfe6619fc426d7602304f48a0f861"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["ba1116b3450a9c1642c89445d131b37344055245"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"ba1116b3450a9c1642c89445d131b37344055245":["4b41b991de69ba7b72d5e90cfcee25699a1a7fc9"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"89550d25407cfe6619fc426d7602304f48a0f861":["693d6573b6621fc1265316fc6b042c24235c81d8"],"13ba39c40de7bda3b305a362bceb7a788e31df23":["89550d25407cfe6619fc426d7602304f48a0f861"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["13ba39c40de7bda3b305a362bceb7a788e31df23"],"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9":["ba1116b3450a9c1642c89445d131b37344055245"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["4b41b991de69ba7b72d5e90cfcee25699a1a7fc9"],"693d6573b6621fc1265316fc6b042c24235c81d8":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ba1116b3450a9c1642c89445d131b37344055245":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}