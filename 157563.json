{"path":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","commits":[{"id":"ca792c26af46bd6c4a08d81117c60440cf6a7e3d","date":1445938295,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasDimensionalValues()) {\n        dimensionalReader = codec.dimensionalFormat().fieldsReader(segmentReadState);\n      } else {\n        dimensionalReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cab7a79353f33d1a94cd307bf33aa5148601ebe6","date":1453391888,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointReader = codec.pointFormat().fieldsReader(segmentReadState);\n      } else {\n        pointReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasDimensionalValues()) {\n        dimensionalReader = codec.dimensionalFormat().fieldsReader(segmentReadState);\n      } else {\n        dimensionalReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4522ffca5a1f420c6a02198c9332d7c596a30ca5","4522ffca5a1f420c6a02198c9332d7c596a30ca5","4522ffca5a1f420c6a02198c9332d7c596a30ca5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4522ffca5a1f420c6a02198c9332d7c596a30ca5","date":1457270822,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointReader = codec.pointFormat().fieldsReader(segmentReadState);\n      } else {\n        pointReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"89d414c6c8de88bce9988e1445ffded7c10121bc","date":1481575617,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379ac53fe9f85e4560f02f2ff25f97eb7b5694a1","date":1486776053,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790693f23f4e88a59fbb25e47cc25f6d493b03cb","date":1553077690,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,boolean,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, boolean openedFromWriter, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, openedFromWriter, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bec68e7c41fed133827595747d853cad504e481e","date":1583501052,"type":1,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(Directory,SegmentCommitInfo,boolean,IOContext).mjava","sourceNew":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","sourceOld":"  SegmentCoreReaders(Directory dir, SegmentCommitInfo si, boolean openedFromWriter, IOContext context) throws IOException {\n\n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) it's the cfsdir, otherwise it's the segment's directory.\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = codec.compoundFormat().getCompoundReader(dir, si.info, context);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n\n      segment = si.info.name;\n\n      coreFieldInfos = codec.fieldInfosFormat().read(cfsDir, si.info, \"\", context);\n      \n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, coreFieldInfos, openedFromWriter, context);\n      final PostingsFormat format = codec.postingsFormat();\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (coreFieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, coreFieldInfos, context);\n\n      if (coreFieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, coreFieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      if (coreFieldInfos.hasPointValues()) {\n        pointsReader = codec.pointsFormat().fieldsReader(segmentReadState);\n      } else {\n        pointsReader = null;\n      }\n      success = true;\n    } catch (EOFException | FileNotFoundException e) {\n      throw new CorruptIndexException(\"Problem reading index from \" + dir, dir.toString(), e);\n    } catch (NoSuchFileException e) {\n      throw new CorruptIndexException(\"Problem reading index.\", e.getFile(), e);\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["28288370235ed02234a64753cdbf0c6ec096304a"],"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["379ac53fe9f85e4560f02f2ff25f97eb7b5694a1"],"bec68e7c41fed133827595747d853cad504e481e":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"379ac53fe9f85e4560f02f2ff25f97eb7b5694a1":["89d414c6c8de88bce9988e1445ffded7c10121bc"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["379ac53fe9f85e4560f02f2ff25f97eb7b5694a1","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["379ac53fe9f85e4560f02f2ff25f97eb7b5694a1","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"4522ffca5a1f420c6a02198c9332d7c596a30ca5":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9856095f7afb5a607bf5e65077615ed91273508c":["4522ffca5a1f420c6a02198c9332d7c596a30ca5","89d414c6c8de88bce9988e1445ffded7c10121bc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bec68e7c41fed133827595747d853cad504e481e"],"89d414c6c8de88bce9988e1445ffded7c10121bc":["4522ffca5a1f420c6a02198c9332d7c596a30ca5"]},"commit2Childs":{"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["bec68e7c41fed133827595747d853cad504e481e"],"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["4522ffca5a1f420c6a02198c9332d7c596a30ca5"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"bec68e7c41fed133827595747d853cad504e481e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"379ac53fe9f85e4560f02f2ff25f97eb7b5694a1":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"4522ffca5a1f420c6a02198c9332d7c596a30ca5":["9856095f7afb5a607bf5e65077615ed91273508c","89d414c6c8de88bce9988e1445ffded7c10121bc"],"ca792c26af46bd6c4a08d81117c60440cf6a7e3d":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"9856095f7afb5a607bf5e65077615ed91273508c":[],"89d414c6c8de88bce9988e1445ffded7c10121bc":["379ac53fe9f85e4560f02f2ff25f97eb7b5694a1","9856095f7afb5a607bf5e65077615ed91273508c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","9856095f7afb5a607bf5e65077615ed91273508c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}