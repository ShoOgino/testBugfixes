{"path":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#writeValues(FieldInfo,DocValuesProducer).mjava","commits":[{"id":"03e17b020972a0d6e8d6823f545571a66646a167","date":1547847724,"type":1,"author":"Toke Eskildsen","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#writeValues(FieldInfo,DocValuesProducer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#writeValues(FieldInfo,DocValuesProducer).mjava","sourceNew":"  private long[] writeValues(FieldInfo field, DocValuesProducer valuesProducer) throws IOException {\n    SortedNumericDocValues values = valuesProducer.getSortedNumeric(field);\n    int numDocsWithValue = 0;\n    MinMaxTracker minMax = new MinMaxTracker();\n    MinMaxTracker blockMinMax = new MinMaxTracker();\n    long gcd = 0;\n    Set<Long> uniqueValues = new HashSet<>();\n    for (int doc = values.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = values.nextDoc()) {\n      for (int i = 0, count = values.docValueCount(); i < count; ++i) {\n        long v = values.nextValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (minMax.numValues != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minMax.min);\n          }\n        }\n\n        minMax.update(v);\n        blockMinMax.update(v);\n        if (blockMinMax.numValues == NUMERIC_BLOCK_SIZE) {\n          blockMinMax.nextBlock();\n        }\n\n        if (uniqueValues != null\n            && uniqueValues.add(v)\n            && uniqueValues.size() > 256) {\n          uniqueValues = null;\n        }\n      }\n\n      numDocsWithValue++;\n    }\n\n    minMax.finish();\n    blockMinMax.finish();\n\n    final long numValues = minMax.numValues;\n    long min = minMax.min;\n    final long max = minMax.max;\n    assert blockMinMax.spaceInBits <= minMax.spaceInBits;\n\n    if (numDocsWithValue == 0) {\n      meta.writeLong(-2);\n      meta.writeLong(0L);\n    } else if (numDocsWithValue == maxDoc) {\n      meta.writeLong(-1);\n      meta.writeLong(0L);\n    } else {\n      long offset = data.getFilePointer();\n      meta.writeLong(offset);\n      values = valuesProducer.getSortedNumeric(field);\n      IndexedDISI.writeBitSet(values, data);\n      meta.writeLong(data.getFilePointer() - offset);\n    }\n\n    meta.writeLong(numValues);\n    final int numBitsPerValue;\n    boolean doBlocks = false;\n    Map<Long, Integer> encode = null;\n    if (min >= max) {\n      numBitsPerValue = 0;\n      meta.writeInt(-1);\n    } else {\n      if (uniqueValues != null\n          && uniqueValues.size() > 1\n          && DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1) < DirectWriter.unsignedBitsRequired((max - min) / gcd)) {\n        numBitsPerValue = DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1);\n        final Long[] sortedUniqueValues = uniqueValues.toArray(new Long[0]);\n        Arrays.sort(sortedUniqueValues);\n        meta.writeInt(sortedUniqueValues.length);\n        for (Long v : sortedUniqueValues) {\n          meta.writeLong(v);\n        }\n        encode = new HashMap<>();\n        for (int i = 0; i < sortedUniqueValues.length; ++i) {\n          encode.put(sortedUniqueValues[i], i);\n        }\n        min = 0;\n        gcd = 1;\n      } else {\n        uniqueValues = null;\n        // we do blocks if that appears to save 10+% storage\n        doBlocks = minMax.spaceInBits > 0 && (double) blockMinMax.spaceInBits / minMax.spaceInBits <= 0.9;\n        if (doBlocks) {\n          numBitsPerValue = 0xFF;\n          meta.writeInt(-2 - NUMERIC_BLOCK_SHIFT);\n        } else {\n          numBitsPerValue = DirectWriter.unsignedBitsRequired((max - min) / gcd);\n          if (gcd == 1 && min > 0\n              && DirectWriter.unsignedBitsRequired(max) == DirectWriter.unsignedBitsRequired(max - min)) {\n            min = 0;\n          }\n          meta.writeInt(-1);\n        }\n      }\n    }\n\n    meta.writeByte((byte) numBitsPerValue);\n    meta.writeLong(min);\n    meta.writeLong(gcd);\n    long startOffset = data.getFilePointer();\n    meta.writeLong(startOffset);\n    if (doBlocks) {\n      writeValuesMultipleBlocks(valuesProducer.getSortedNumeric(field), gcd);\n    } else if (numBitsPerValue != 0) {\n      writeValuesSingleBlock(valuesProducer.getSortedNumeric(field), numValues, numBitsPerValue, min, gcd, encode);\n    }\n    meta.writeLong(data.getFilePointer() - startOffset);\n\n    return new long[] {numDocsWithValue, numValues};\n  }\n\n","sourceOld":"  private long[] writeValues(FieldInfo field, DocValuesProducer valuesProducer) throws IOException {\n    SortedNumericDocValues values = valuesProducer.getSortedNumeric(field);\n    int numDocsWithValue = 0;\n    MinMaxTracker minMax = new MinMaxTracker();\n    MinMaxTracker blockMinMax = new MinMaxTracker();\n    long gcd = 0;\n    Set<Long> uniqueValues = new HashSet<>();\n    for (int doc = values.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = values.nextDoc()) {\n      for (int i = 0, count = values.docValueCount(); i < count; ++i) {\n        long v = values.nextValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (minMax.numValues != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minMax.min);\n          }\n        }\n\n        minMax.update(v);\n        blockMinMax.update(v);\n        if (blockMinMax.numValues == NUMERIC_BLOCK_SIZE) {\n          blockMinMax.nextBlock();\n        }\n\n        if (uniqueValues != null\n            && uniqueValues.add(v)\n            && uniqueValues.size() > 256) {\n          uniqueValues = null;\n        }\n      }\n\n      numDocsWithValue++;\n    }\n\n    minMax.finish();\n    blockMinMax.finish();\n\n    final long numValues = minMax.numValues;\n    long min = minMax.min;\n    final long max = minMax.max;\n    assert blockMinMax.spaceInBits <= minMax.spaceInBits;\n\n    if (numDocsWithValue == 0) {\n      meta.writeLong(-2);\n      meta.writeLong(0L);\n    } else if (numDocsWithValue == maxDoc) {\n      meta.writeLong(-1);\n      meta.writeLong(0L);\n    } else {\n      long offset = data.getFilePointer();\n      meta.writeLong(offset);\n      values = valuesProducer.getSortedNumeric(field);\n      IndexedDISI.writeBitSet(values, data);\n      meta.writeLong(data.getFilePointer() - offset);\n    }\n\n    meta.writeLong(numValues);\n    final int numBitsPerValue;\n    boolean doBlocks = false;\n    Map<Long, Integer> encode = null;\n    if (min >= max) {\n      numBitsPerValue = 0;\n      meta.writeInt(-1);\n    } else {\n      if (uniqueValues != null\n          && uniqueValues.size() > 1\n          && DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1) < DirectWriter.unsignedBitsRequired((max - min) / gcd)) {\n        numBitsPerValue = DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1);\n        final Long[] sortedUniqueValues = uniqueValues.toArray(new Long[0]);\n        Arrays.sort(sortedUniqueValues);\n        meta.writeInt(sortedUniqueValues.length);\n        for (Long v : sortedUniqueValues) {\n          meta.writeLong(v);\n        }\n        encode = new HashMap<>();\n        for (int i = 0; i < sortedUniqueValues.length; ++i) {\n          encode.put(sortedUniqueValues[i], i);\n        }\n        min = 0;\n        gcd = 1;\n      } else {\n        uniqueValues = null;\n        // we do blocks if that appears to save 10+% storage\n        doBlocks = minMax.spaceInBits > 0 && (double) blockMinMax.spaceInBits / minMax.spaceInBits <= 0.9;\n        if (doBlocks) {\n          numBitsPerValue = 0xFF;\n          meta.writeInt(-2 - NUMERIC_BLOCK_SHIFT);\n        } else {\n          numBitsPerValue = DirectWriter.unsignedBitsRequired((max - min) / gcd);\n          if (gcd == 1 && min > 0\n              && DirectWriter.unsignedBitsRequired(max) == DirectWriter.unsignedBitsRequired(max - min)) {\n            min = 0;\n          }\n          meta.writeInt(-1);\n        }\n      }\n    }\n\n    meta.writeByte((byte) numBitsPerValue);\n    meta.writeLong(min);\n    meta.writeLong(gcd);\n    long startOffset = data.getFilePointer();\n    meta.writeLong(startOffset);\n    if (doBlocks) {\n      writeValuesMultipleBlocks(valuesProducer.getSortedNumeric(field), gcd);\n    } else if (numBitsPerValue != 0) {\n      writeValuesSingleBlock(valuesProducer.getSortedNumeric(field), numValues, numBitsPerValue, min, gcd, encode);\n    }\n    meta.writeLong(data.getFilePointer() - startOffset);\n\n    return new long[] {numDocsWithValue, numValues};\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c89f1ef80a9432f4eabaeda9a1e135cd72e60836","date":1547972642,"type":1,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#writeValues(FieldInfo,DocValuesProducer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#writeValues(FieldInfo,DocValuesProducer).mjava","sourceNew":"  private long[] writeValues(FieldInfo field, DocValuesProducer valuesProducer) throws IOException {\n    SortedNumericDocValues values = valuesProducer.getSortedNumeric(field);\n    int numDocsWithValue = 0;\n    MinMaxTracker minMax = new MinMaxTracker();\n    MinMaxTracker blockMinMax = new MinMaxTracker();\n    long gcd = 0;\n    Set<Long> uniqueValues = new HashSet<>();\n    for (int doc = values.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = values.nextDoc()) {\n      for (int i = 0, count = values.docValueCount(); i < count; ++i) {\n        long v = values.nextValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (minMax.numValues != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minMax.min);\n          }\n        }\n\n        minMax.update(v);\n        blockMinMax.update(v);\n        if (blockMinMax.numValues == NUMERIC_BLOCK_SIZE) {\n          blockMinMax.nextBlock();\n        }\n\n        if (uniqueValues != null\n            && uniqueValues.add(v)\n            && uniqueValues.size() > 256) {\n          uniqueValues = null;\n        }\n      }\n\n      numDocsWithValue++;\n    }\n\n    minMax.finish();\n    blockMinMax.finish();\n\n    final long numValues = minMax.numValues;\n    long min = minMax.min;\n    final long max = minMax.max;\n    assert blockMinMax.spaceInBits <= minMax.spaceInBits;\n\n    if (numDocsWithValue == 0) {\n      meta.writeLong(-2);\n      meta.writeLong(0L);\n    } else if (numDocsWithValue == maxDoc) {\n      meta.writeLong(-1);\n      meta.writeLong(0L);\n    } else {\n      long offset = data.getFilePointer();\n      meta.writeLong(offset);\n      values = valuesProducer.getSortedNumeric(field);\n      IndexedDISI.writeBitSet(values, data);\n      meta.writeLong(data.getFilePointer() - offset);\n    }\n\n    meta.writeLong(numValues);\n    final int numBitsPerValue;\n    boolean doBlocks = false;\n    Map<Long, Integer> encode = null;\n    if (min >= max) {\n      numBitsPerValue = 0;\n      meta.writeInt(-1);\n    } else {\n      if (uniqueValues != null\n          && uniqueValues.size() > 1\n          && DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1) < DirectWriter.unsignedBitsRequired((max - min) / gcd)) {\n        numBitsPerValue = DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1);\n        final Long[] sortedUniqueValues = uniqueValues.toArray(new Long[0]);\n        Arrays.sort(sortedUniqueValues);\n        meta.writeInt(sortedUniqueValues.length);\n        for (Long v : sortedUniqueValues) {\n          meta.writeLong(v);\n        }\n        encode = new HashMap<>();\n        for (int i = 0; i < sortedUniqueValues.length; ++i) {\n          encode.put(sortedUniqueValues[i], i);\n        }\n        min = 0;\n        gcd = 1;\n      } else {\n        uniqueValues = null;\n        // we do blocks if that appears to save 10+% storage\n        doBlocks = minMax.spaceInBits > 0 && (double) blockMinMax.spaceInBits / minMax.spaceInBits <= 0.9;\n        if (doBlocks) {\n          numBitsPerValue = 0xFF;\n          meta.writeInt(-2 - NUMERIC_BLOCK_SHIFT);\n        } else {\n          numBitsPerValue = DirectWriter.unsignedBitsRequired((max - min) / gcd);\n          if (gcd == 1 && min > 0\n              && DirectWriter.unsignedBitsRequired(max) == DirectWriter.unsignedBitsRequired(max - min)) {\n            min = 0;\n          }\n          meta.writeInt(-1);\n        }\n      }\n    }\n\n    meta.writeByte((byte) numBitsPerValue);\n    meta.writeLong(min);\n    meta.writeLong(gcd);\n    long startOffset = data.getFilePointer();\n    meta.writeLong(startOffset);\n    if (doBlocks) {\n      writeValuesMultipleBlocks(valuesProducer.getSortedNumeric(field), gcd);\n    } else if (numBitsPerValue != 0) {\n      writeValuesSingleBlock(valuesProducer.getSortedNumeric(field), numValues, numBitsPerValue, min, gcd, encode);\n    }\n    meta.writeLong(data.getFilePointer() - startOffset);\n\n    return new long[] {numDocsWithValue, numValues};\n  }\n\n","sourceOld":"  private long[] writeValues(FieldInfo field, DocValuesProducer valuesProducer) throws IOException {\n    SortedNumericDocValues values = valuesProducer.getSortedNumeric(field);\n    int numDocsWithValue = 0;\n    MinMaxTracker minMax = new MinMaxTracker();\n    MinMaxTracker blockMinMax = new MinMaxTracker();\n    long gcd = 0;\n    Set<Long> uniqueValues = new HashSet<>();\n    for (int doc = values.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = values.nextDoc()) {\n      for (int i = 0, count = values.docValueCount(); i < count; ++i) {\n        long v = values.nextValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (minMax.numValues != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minMax.min);\n          }\n        }\n\n        minMax.update(v);\n        blockMinMax.update(v);\n        if (blockMinMax.numValues == NUMERIC_BLOCK_SIZE) {\n          blockMinMax.nextBlock();\n        }\n\n        if (uniqueValues != null\n            && uniqueValues.add(v)\n            && uniqueValues.size() > 256) {\n          uniqueValues = null;\n        }\n      }\n\n      numDocsWithValue++;\n    }\n\n    minMax.finish();\n    blockMinMax.finish();\n\n    final long numValues = minMax.numValues;\n    long min = minMax.min;\n    final long max = minMax.max;\n    assert blockMinMax.spaceInBits <= minMax.spaceInBits;\n\n    if (numDocsWithValue == 0) {\n      meta.writeLong(-2);\n      meta.writeLong(0L);\n    } else if (numDocsWithValue == maxDoc) {\n      meta.writeLong(-1);\n      meta.writeLong(0L);\n    } else {\n      long offset = data.getFilePointer();\n      meta.writeLong(offset);\n      values = valuesProducer.getSortedNumeric(field);\n      IndexedDISI.writeBitSet(values, data);\n      meta.writeLong(data.getFilePointer() - offset);\n    }\n\n    meta.writeLong(numValues);\n    final int numBitsPerValue;\n    boolean doBlocks = false;\n    Map<Long, Integer> encode = null;\n    if (min >= max) {\n      numBitsPerValue = 0;\n      meta.writeInt(-1);\n    } else {\n      if (uniqueValues != null\n          && uniqueValues.size() > 1\n          && DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1) < DirectWriter.unsignedBitsRequired((max - min) / gcd)) {\n        numBitsPerValue = DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1);\n        final Long[] sortedUniqueValues = uniqueValues.toArray(new Long[0]);\n        Arrays.sort(sortedUniqueValues);\n        meta.writeInt(sortedUniqueValues.length);\n        for (Long v : sortedUniqueValues) {\n          meta.writeLong(v);\n        }\n        encode = new HashMap<>();\n        for (int i = 0; i < sortedUniqueValues.length; ++i) {\n          encode.put(sortedUniqueValues[i], i);\n        }\n        min = 0;\n        gcd = 1;\n      } else {\n        uniqueValues = null;\n        // we do blocks if that appears to save 10+% storage\n        doBlocks = minMax.spaceInBits > 0 && (double) blockMinMax.spaceInBits / minMax.spaceInBits <= 0.9;\n        if (doBlocks) {\n          numBitsPerValue = 0xFF;\n          meta.writeInt(-2 - NUMERIC_BLOCK_SHIFT);\n        } else {\n          numBitsPerValue = DirectWriter.unsignedBitsRequired((max - min) / gcd);\n          if (gcd == 1 && min > 0\n              && DirectWriter.unsignedBitsRequired(max) == DirectWriter.unsignedBitsRequired(max - min)) {\n            min = 0;\n          }\n          meta.writeInt(-1);\n        }\n      }\n    }\n\n    meta.writeByte((byte) numBitsPerValue);\n    meta.writeLong(min);\n    meta.writeLong(gcd);\n    long startOffset = data.getFilePointer();\n    meta.writeLong(startOffset);\n    if (doBlocks) {\n      writeValuesMultipleBlocks(valuesProducer.getSortedNumeric(field), gcd);\n    } else if (numBitsPerValue != 0) {\n      writeValuesSingleBlock(valuesProducer.getSortedNumeric(field), numValues, numBitsPerValue, min, gcd, encode);\n    }\n    meta.writeLong(data.getFilePointer() - startOffset);\n\n    return new long[] {numDocsWithValue, numValues};\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57cb6df494f10aeb3fab477b1ce4a9187455a227","date":1574155024,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#writeValues(FieldInfo,DocValuesProducer).mjava","sourceNew":null,"sourceOld":"  private long[] writeValues(FieldInfo field, DocValuesProducer valuesProducer) throws IOException {\n    SortedNumericDocValues values = valuesProducer.getSortedNumeric(field);\n    int numDocsWithValue = 0;\n    MinMaxTracker minMax = new MinMaxTracker();\n    MinMaxTracker blockMinMax = new MinMaxTracker();\n    long gcd = 0;\n    Set<Long> uniqueValues = new HashSet<>();\n    for (int doc = values.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = values.nextDoc()) {\n      for (int i = 0, count = values.docValueCount(); i < count; ++i) {\n        long v = values.nextValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (minMax.numValues != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minMax.min);\n          }\n        }\n\n        minMax.update(v);\n        blockMinMax.update(v);\n        if (blockMinMax.numValues == NUMERIC_BLOCK_SIZE) {\n          blockMinMax.nextBlock();\n        }\n\n        if (uniqueValues != null\n            && uniqueValues.add(v)\n            && uniqueValues.size() > 256) {\n          uniqueValues = null;\n        }\n      }\n\n      numDocsWithValue++;\n    }\n\n    minMax.finish();\n    blockMinMax.finish();\n\n    final long numValues = minMax.numValues;\n    long min = minMax.min;\n    final long max = minMax.max;\n    assert blockMinMax.spaceInBits <= minMax.spaceInBits;\n\n    if (numDocsWithValue == 0) {\n      meta.writeLong(-2);\n      meta.writeLong(0L);\n    } else if (numDocsWithValue == maxDoc) {\n      meta.writeLong(-1);\n      meta.writeLong(0L);\n    } else {\n      long offset = data.getFilePointer();\n      meta.writeLong(offset);\n      values = valuesProducer.getSortedNumeric(field);\n      IndexedDISI.writeBitSet(values, data);\n      meta.writeLong(data.getFilePointer() - offset);\n    }\n\n    meta.writeLong(numValues);\n    final int numBitsPerValue;\n    boolean doBlocks = false;\n    Map<Long, Integer> encode = null;\n    if (min >= max) {\n      numBitsPerValue = 0;\n      meta.writeInt(-1);\n    } else {\n      if (uniqueValues != null\n          && uniqueValues.size() > 1\n          && DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1) < DirectWriter.unsignedBitsRequired((max - min) / gcd)) {\n        numBitsPerValue = DirectWriter.unsignedBitsRequired(uniqueValues.size() - 1);\n        final Long[] sortedUniqueValues = uniqueValues.toArray(new Long[0]);\n        Arrays.sort(sortedUniqueValues);\n        meta.writeInt(sortedUniqueValues.length);\n        for (Long v : sortedUniqueValues) {\n          meta.writeLong(v);\n        }\n        encode = new HashMap<>();\n        for (int i = 0; i < sortedUniqueValues.length; ++i) {\n          encode.put(sortedUniqueValues[i], i);\n        }\n        min = 0;\n        gcd = 1;\n      } else {\n        uniqueValues = null;\n        // we do blocks if that appears to save 10+% storage\n        doBlocks = minMax.spaceInBits > 0 && (double) blockMinMax.spaceInBits / minMax.spaceInBits <= 0.9;\n        if (doBlocks) {\n          numBitsPerValue = 0xFF;\n          meta.writeInt(-2 - NUMERIC_BLOCK_SHIFT);\n        } else {\n          numBitsPerValue = DirectWriter.unsignedBitsRequired((max - min) / gcd);\n          if (gcd == 1 && min > 0\n              && DirectWriter.unsignedBitsRequired(max) == DirectWriter.unsignedBitsRequired(max - min)) {\n            min = 0;\n          }\n          meta.writeInt(-1);\n        }\n      }\n    }\n\n    meta.writeByte((byte) numBitsPerValue);\n    meta.writeLong(min);\n    meta.writeLong(gcd);\n    long startOffset = data.getFilePointer();\n    meta.writeLong(startOffset);\n    if (doBlocks) {\n      writeValuesMultipleBlocks(valuesProducer.getSortedNumeric(field), gcd);\n    } else if (numBitsPerValue != 0) {\n      writeValuesSingleBlock(valuesProducer.getSortedNumeric(field), numValues, numBitsPerValue, min, gcd, encode);\n    }\n    meta.writeLong(data.getFilePointer() - startOffset);\n\n    return new long[] {numDocsWithValue, numValues};\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03e17b020972a0d6e8d6823f545571a66646a167":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","03e17b020972a0d6e8d6823f545571a66646a167"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"57cb6df494f10aeb3fab477b1ce4a9187455a227":["03e17b020972a0d6e8d6823f545571a66646a167"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57cb6df494f10aeb3fab477b1ce4a9187455a227"]},"commit2Childs":{"03e17b020972a0d6e8d6823f545571a66646a167":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","57cb6df494f10aeb3fab477b1ce4a9187455a227"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["03e17b020972a0d6e8d6823f545571a66646a167","c89f1ef80a9432f4eabaeda9a1e135cd72e60836"],"57cb6df494f10aeb3fab477b1ce4a9187455a227":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}