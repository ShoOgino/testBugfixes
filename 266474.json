{"path":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else {\n        final Query result;\n        if (col.pendingTerms.isEmpty()) {\n          result = new BooleanQuery(true);\n        } else {\n          BooleanQuery bq = new BooleanQuery(true);\n          for(Term term : col.pendingTerms) {\n            TermQuery tq = new TermQuery(term);\n            bq.add(tq, BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n        }\n        query.incTotalNumberOfTerms(col.pendingTerms.size());\n        return result;\n      }\n    }\n\n","sourceOld":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else {\n        final Query result;\n        if (col.pendingTerms.isEmpty()) {\n          result = new BooleanQuery(true);\n        } else {\n          BooleanQuery bq = new BooleanQuery(true);\n          for(Term term : col.pendingTerms) {\n            TermQuery tq = new TermQuery(term);\n            bq.add(tq, BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n        }\n        query.incTotalNumberOfTerms(col.pendingTerms.size());\n        return result;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4f29ba80b723649f5feb7e37afe1a558dd2c1304","date":1278318805,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, query.field, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (col.termCount == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final PagedBytes.Reader bytesReader = col.pendingTerms.freeze(false);\n        try {\n          final BooleanQuery bq = new BooleanQuery(true);\n          final Term placeholderTerm = new Term(query.field);\n          long start = col.startOffset;\n          for(int i = 0; i < col.termCount; i++) {\n            final BytesRef bytes = new BytesRef();\n            start = bytesReader.fillUsingLengthPrefix3(bytes, start);\n            bq.add(new TermQuery(placeholderTerm.createTerm(bytes)), BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n          query.incTotalNumberOfTerms(col.termCount);\n          return result;\n        } finally {\n          bytesReader.close();\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else {\n        final Query result;\n        if (col.pendingTerms.isEmpty()) {\n          result = new BooleanQuery(true);\n        } else {\n          BooleanQuery bq = new BooleanQuery(true);\n          for(Term term : col.pendingTerms) {\n            TermQuery tq = new TermQuery(term);\n            bq.add(tq, BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n        }\n        query.incTotalNumberOfTerms(col.pendingTerms.size());\n        return result;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, query.field, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (col.termCount == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final PagedBytes.Reader bytesReader = col.pendingTerms.freeze(false);\n        try {\n          final BooleanQuery bq = new BooleanQuery(true);\n          final Term placeholderTerm = new Term(query.field);\n          long start = col.startOffset;\n          for(int i = 0; i < col.termCount; i++) {\n            final BytesRef bytes = new BytesRef();\n            start = bytesReader.fillUsingLengthPrefix3(bytes, start);\n            bq.add(new TermQuery(placeholderTerm.createTerm(bytes)), BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n          query.incTotalNumberOfTerms(col.termCount);\n          return result;\n        } finally {\n          bytesReader.close();\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else {\n        final Query result;\n        if (col.pendingTerms.isEmpty()) {\n          result = new BooleanQuery(true);\n        } else {\n          BooleanQuery bq = new BooleanQuery(true);\n          for(Term term : col.pendingTerms) {\n            TermQuery tq = new TermQuery(term);\n            bq.add(tq, BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n        }\n        query.incTotalNumberOfTerms(col.pendingTerms.size());\n        return result;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33a8b1f99104f4144f210f5d068411c297cd7163","date":1287152748,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      final int size = col.pendingTerms.size();\n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (size == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final BooleanQuery bq = new BooleanQuery(true);\n        final Term placeholderTerm = new Term(query.field);\n        final BytesRefHash pendingTerms = col.pendingTerms;\n        final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n        for(int i = 0; i < size; i++) {\n          // docFreq is not used for constant score here, we pass 1\n          // to explicitely set a fake value, so it's not calculated\n          bq.add(new TermQuery(\n            placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1\n          ), BooleanClause.Occur.SHOULD);\n        }\n        // Strip scores\n        final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n        result.setBoost(query.getBoost());\n        query.incTotalNumberOfTerms(size);\n        return result;\n      }\n    }\n\n","sourceOld":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, query.field, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (col.termCount == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final PagedBytes.Reader bytesReader = col.pendingTerms.freeze(false);\n        try {\n          final BooleanQuery bq = new BooleanQuery(true);\n          final Term placeholderTerm = new Term(query.field);\n          long start = col.startOffset;\n          for(int i = 0; i < col.termCount; i++) {\n            final BytesRef bytes = new BytesRef();\n            start = bytesReader.fillUsingLengthPrefix3(bytes, start);\n            bq.add(new TermQuery(placeholderTerm.createTerm(bytes)), BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n          query.incTotalNumberOfTerms(col.termCount);\n          return result;\n        } finally {\n          bytesReader.close();\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ecea1664e8617d82eca3b8055a3c37cb4da8511","date":1287578668,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      final int size = col.pendingTerms.size();\n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (size == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final BooleanQuery bq = new BooleanQuery(true);\n        final Term placeholderTerm = new Term(query.field);\n        final BytesRefHash pendingTerms = col.pendingTerms;\n        final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n        for(int i = 0; i < size; i++) {\n          // docFreq is not used for constant score here, we pass 1\n          // to explicitely set a fake value, so it's not calculated\n          bq.add(new TermQuery(\n            placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1\n          ), BooleanClause.Occur.SHOULD);\n        }\n        // Strip scores\n        final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n        result.setBoost(query.getBoost());\n        query.incTotalNumberOfTerms(size);\n        return result;\n      }\n    }\n\n","sourceOld":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, query.field, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (col.termCount == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final PagedBytes.Reader bytesReader = col.pendingTerms.freeze(false);\n        try {\n          final BooleanQuery bq = new BooleanQuery(true);\n          final Term placeholderTerm = new Term(query.field);\n          long start = col.startOffset;\n          for(int i = 0; i < col.termCount; i++) {\n            final BytesRef bytes = new BytesRef();\n            start = bytesReader.fillUsingLengthPrefix3(bytes, start);\n            bq.add(new TermQuery(placeholderTerm.createTerm(bytes)), BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n          query.incTotalNumberOfTerms(col.termCount);\n          return result;\n        } finally {\n          bytesReader.close();\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"744486748bc5bee772100e49230e5bca39bac99a","date":1289776426,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      final int size = col.pendingTerms.size();\n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (size == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final BooleanQuery bq = new BooleanQuery(true);\n        final Term placeholderTerm = new Term(query.field);\n        final BytesRefHash pendingTerms = col.pendingTerms;\n        final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n        for(int i = 0; i < size; i++) {\n          // docFreq is not used for constant score here, we pass 1\n          // to explicitely set a fake value, so it's not calculated\n          bq.add(new TermQuery(\n            placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1\n          ), BooleanClause.Occur.SHOULD);\n        }\n        // Strip scores\n        final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n        result.setBoost(query.getBoost());\n        query.incTotalNumberOfTerms(size);\n        return result;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ab1f5591dc05f1f2b5407d809c9699f75554a32","date":1290008586,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      final int size = col.pendingTerms.size();\n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (size == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final BooleanQuery bq = new BooleanQuery(true);\n        final Term placeholderTerm = new Term(query.field);\n        final BytesRefHash pendingTerms = col.pendingTerms;\n        final int sort[] = pendingTerms.sort(col.termsEnum.getComparator());\n        for(int i = 0; i < size; i++) {\n          // docFreq is not used for constant score here, we pass 1\n          // to explicitely set a fake value, so it's not calculated\n          bq.add(new TermQuery(\n            placeholderTerm.createTerm(pendingTerms.get(sort[i], new BytesRef())), 1\n          ), BooleanClause.Occur.SHOULD);\n        }\n        // Strip scores\n        final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n        result.setBoost(query.getBoost());\n        query.incTotalNumberOfTerms(size);\n        return result;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/MultiTermQuery.ConstantScoreAutoRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n\n      // Get the enum and start visiting terms.  If we\n      // exhaust the enum before hitting either of the\n      // cutoffs, we use ConstantBooleanQueryRewrite; else,\n      // ConstantFilterRewrite:\n      final int docCountCutoff = (int) ((docCountPercent / 100.) * reader.maxDoc());\n      final int termCountLimit = Math.min(BooleanQuery.getMaxClauseCount(), termCountCutoff);\n\n      final CutOffTermCollector col = new CutOffTermCollector(reader, query.field, docCountCutoff, termCountLimit);\n      collectTerms(reader, query, col);\n      \n      if (col.hasCutOff) {\n        return CONSTANT_SCORE_FILTER_REWRITE.rewrite(reader, query);\n      } else if (col.termCount == 0) {\n        return new BooleanQuery(true);\n      } else {\n        final PagedBytes.Reader bytesReader = col.pendingTerms.freeze(false);\n        try {\n          final BooleanQuery bq = new BooleanQuery(true);\n          final Term placeholderTerm = new Term(query.field);\n          long start = col.startOffset;\n          for(int i = 0; i < col.termCount; i++) {\n            final BytesRef bytes = new BytesRef();\n            start = bytesReader.fillUsingLengthPrefix3(bytes, start);\n            bq.add(new TermQuery(placeholderTerm.createTerm(bytes)), BooleanClause.Occur.SHOULD);\n          }\n          // Strip scores\n          final Query result = new ConstantScoreQuery(new QueryWrapperFilter(bq));\n          result.setBoost(query.getBoost());\n          query.incTotalNumberOfTerms(col.termCount);\n          return result;\n        } finally {\n          bytesReader.close();\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"33a8b1f99104f4144f210f5d068411c297cd7163":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["4ecea1664e8617d82eca3b8055a3c37cb4da8511","744486748bc5bee772100e49230e5bca39bac99a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5f4e87790277826a2aea119328600dfb07761f32":["9454a6510e2db155fb01faa5c049b06ece95fab9","4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5f4e87790277826a2aea119328600dfb07761f32","744486748bc5bee772100e49230e5bca39bac99a"],"4ecea1664e8617d82eca3b8055a3c37cb4da8511":["4f29ba80b723649f5feb7e37afe1a558dd2c1304","33a8b1f99104f4144f210f5d068411c297cd7163"],"744486748bc5bee772100e49230e5bca39bac99a":["33a8b1f99104f4144f210f5d068411c297cd7163"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["744486748bc5bee772100e49230e5bca39bac99a"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"33a8b1f99104f4144f210f5d068411c297cd7163":["4ecea1664e8617d82eca3b8055a3c37cb4da8511","744486748bc5bee772100e49230e5bca39bac99a"],"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["33a8b1f99104f4144f210f5d068411c297cd7163","5f4e87790277826a2aea119328600dfb07761f32","4ecea1664e8617d82eca3b8055a3c37cb4da8511"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"5f4e87790277826a2aea119328600dfb07761f32":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"4ecea1664e8617d82eca3b8055a3c37cb4da8511":["9ab1f5591dc05f1f2b5407d809c9699f75554a32"],"744486748bc5bee772100e49230e5bca39bac99a":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["4f29ba80b723649f5feb7e37afe1a558dd2c1304","5f4e87790277826a2aea119328600dfb07761f32"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}