{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b832cbed6eb3d54a8bb9339296bdda8eeb53014","date":1279708040,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public long updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        long sequenceID = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n        return sequenceID;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null) {\n            message(\"hit exception updating document\");\n          }\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null) {\n              deleter.deleteNewFiles(files);\n            }\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n    \n    return -1;\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"334c1175813aea771a71728cd2c4ee4754fd0603","date":1279710173,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public long updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        long sequenceID = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n        return sequenceID;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null) {\n            message(\"hit exception updating document\");\n          }\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null) {\n              deleter.deleteNewFiles(files);\n            }\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n    \n    return -1;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8fe956d65251358d755c56f14fe8380644790e47","date":1279711318,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public long updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        long sequenceID = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n        return sequenceID;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null) {\n            message(\"hit exception updating document\");\n          }\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null) {\n              deleter.deleteNewFiles(files);\n            }\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n    \n    return -1;\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ef87af8c7bd0f8429622b83aa74202383f2e757","date":1280262785,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public long updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        long sequenceID = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n        return sequenceID;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null) {\n            message(\"hit exception updating document\");\n          }\n          \n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null) {\n              deleter.deleteNewFiles(files);\n            }\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n    \n    return -1;\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public long updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        long sequenceID = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n        return sequenceID;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null) {\n            message(\"hit exception updating document\");\n          }\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null) {\n              deleter.deleteNewFiles(files);\n            }\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n    \n    return -1;\n  }\n\n","bugFix":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null) {\n            message(\"hit exception updating document\");\n          }\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            if (docWriter != null) {\n              final Collection<String> files = docWriter.abortedFiles();\n              if (files != null) {\n                deleter.deleteNewFiles(files);\n              }\n            }\n          }\n        }\n      }\n      if (doFlush) {\n        flush(true, false, false);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n      if (doFlush) {\n        flush(true, false);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null) {\n            message(\"hit exception updating document\");\n          }\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            if (docWriter != null) {\n              final Collection<String> files = docWriter.abortedFiles();\n              if (files != null) {\n                deleter.deleteNewFiles(files);\n              }\n            }\n          }\n        }\n      }\n      if (doFlush) {\n        flush(true, false, false);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n      if (doFlush) {\n        flush(true, false);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public long updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        long sequenceID = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n        return sequenceID;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null) {\n            message(\"hit exception updating document\");\n          }\n          \n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null) {\n              deleter.deleteNewFiles(files);\n            }\n          }\n        }\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n    \n    return -1;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff78505662c0b741e2663a9f38a4889c12a32c9f","date":1294908561,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    boolean maybeMerge = false;\n    try {\n      boolean success = false;\n      try {\n        maybeMerge = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n\n    if (maybeMerge) {\n      maybeMerge();\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      try {\n        docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3161e3ffcf20c09a22504a589d4d9bd273e11e33","date":1295142360,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean maybeMerge = false;\n      try {\n        maybeMerge = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n\n      if (maybeMerge) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    boolean maybeMerge = false;\n    try {\n      boolean success = false;\n      try {\n        maybeMerge = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n\n    if (maybeMerge) {\n      maybeMerge();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1b1414bb9669ffe06a89e46b889729f2e2588081","date":1304006610,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean maybeMerge = false;\n      try {\n        maybeMerge = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n\n      if (maybeMerge) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n      if (doFlush) {\n        flush(true, false);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n      if (doFlush) {\n        flush(true, false);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n      if (doFlush) {\n        flush(true, false);\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Iterable[#-extends-IndexableField],Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Iterable<? extends IndexableField> doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean success = false;\n      boolean anySegmentFlushed = false;\n      try {\n        anySegmentFlushed = docWriter.updateDocument(doc, analyzer, term);\n        success = true;\n      } finally {\n        if (!success && infoStream != null)\n          message(\"hit exception updating document\");\n      }\n\n      if (anySegmentFlushed) {\n        maybeMerge();\n      }\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ff78505662c0b741e2663a9f38a4889c12a32c9f":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["334c1175813aea771a71728cd2c4ee4754fd0603"],"1b1414bb9669ffe06a89e46b889729f2e2588081":["3161e3ffcf20c09a22504a589d4d9bd273e11e33"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","1b1414bb9669ffe06a89e46b889729f2e2588081"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["334c1175813aea771a71728cd2c4ee4754fd0603","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"334c1175813aea771a71728cd2c4ee4754fd0603":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5ef87af8c7bd0f8429622b83aa74202383f2e757","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3161e3ffcf20c09a22504a589d4d9bd273e11e33":["ff78505662c0b741e2663a9f38a4889c12a32c9f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8fe956d65251358d755c56f14fe8380644790e47":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"5ef87af8c7bd0f8429622b83aa74202383f2e757":["8fe956d65251358d755c56f14fe8380644790e47"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"ff78505662c0b741e2663a9f38a4889c12a32c9f":["3161e3ffcf20c09a22504a589d4d9bd273e11e33"],"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"1b1414bb9669ffe06a89e46b889729f2e2588081":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"334c1175813aea771a71728cd2c4ee4754fd0603":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["ff78505662c0b741e2663a9f38a4889c12a32c9f"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["334c1175813aea771a71728cd2c4ee4754fd0603"],"3161e3ffcf20c09a22504a589d4d9bd273e11e33":["1b1414bb9669ffe06a89e46b889729f2e2588081"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8fe956d65251358d755c56f14fe8380644790e47":["5ef87af8c7bd0f8429622b83aa74202383f2e757"],"5ef87af8c7bd0f8429622b83aa74202383f2e757":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","ab5cb6a74aefb78aa0569857970b9151dfe2e787","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","a3776dccca01c11e7046323cfad46a3b4a471233"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014","8fe956d65251358d755c56f14fe8380644790e47"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}