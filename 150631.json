{"path":"src/java/org/apache/solr/schema/TrieField#init(IndexSchema,Map[String,String]).mjava","commits":[{"id":"1d6ca4f6b8a27a0523251c56d0abeb659ef5c1b0","date":1236796963,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/TrieField#init(IndexSchema,Map[String,String]).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    String p = args.remove(\"precisionStep\");\n    if (p != null) {\n      precisionStep = Integer.parseInt(p);\n    }\n    String t = args.remove(\"type\");\n    if (t == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"));\n    } else {\n      try {\n        type = TrieTypes.valueOf(t.toUpperCase());\n      } catch (IllegalArgumentException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"), e);\n      }\n    }\n\n    CharFilterFactory[] filterFactories = new CharFilterFactory[0];\n    TokenFilterFactory[] tokenFilterFactories = new TokenFilterFactory[0];\n    analyzer = new TokenizerChain(filterFactories, new TrieIndexTokenizerFactory(type, precisionStep), tokenFilterFactories);\n    queryAnalyzer = new TokenizerChain(filterFactories, new TrieQueryTokenizerFactory(type), tokenFilterFactories);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["99c9d8533c954f661481ae44273622957dbf572f","99c9d8533c954f661481ae44273622957dbf572f","99c9d8533c954f661481ae44273622957dbf572f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e77721aaf23393f6ea7926045ae6f8efea0ce8e","date":1247678464,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/TrieField#init(IndexSchema,Map[String,String]).mjava","pathOld":"src/java/org/apache/solr/schema/TrieField#init(IndexSchema,Map[String,String]).mjava","sourceNew":"  @Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    String p = args.remove(\"precisionStep\");\n    if (p != null) {\n      precisionStep = Integer.parseInt(p);\n    }\n    String t = args.remove(\"type\");\n    if (t == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"));\n    } else {\n      try {\n        type = TrieTypes.valueOf(t.toUpperCase());\n      } catch (IllegalArgumentException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"), e);\n      }\n    }\n    \n    CharFilterFactory[] filterFactories = new CharFilterFactory[0];\n    TokenFilterFactory[] tokenFilterFactories = new TokenFilterFactory[0];\n    analyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, precisionStep), tokenFilterFactories);\n    // for query time we only need one token, so we use the biggest possible precisionStep:\n    queryAnalyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, Integer.MAX_VALUE), tokenFilterFactories);\n  }\n\n","sourceOld":"  @Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    String p = args.remove(\"precisionStep\");\n    if (p != null) {\n      precisionStep = Integer.parseInt(p);\n    }\n    String t = args.remove(\"type\");\n    if (t == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"));\n    } else {\n      try {\n        type = TrieTypes.valueOf(t.toUpperCase());\n      } catch (IllegalArgumentException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"), e);\n      }\n    }\n\n    CharFilterFactory[] filterFactories = new CharFilterFactory[0];\n    TokenFilterFactory[] tokenFilterFactories = new TokenFilterFactory[0];\n    analyzer = new TokenizerChain(filterFactories, new TrieIndexTokenizerFactory(type, precisionStep), tokenFilterFactories);\n    queryAnalyzer = new TokenizerChain(filterFactories, new TrieQueryTokenizerFactory(type), tokenFilterFactories);\n  }\n\n","bugFix":null,"bugIntro":["99c9d8533c954f661481ae44273622957dbf572f","99c9d8533c954f661481ae44273622957dbf572f","99c9d8533c954f661481ae44273622957dbf572f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dbc0ca7104fa6f1d7cc24b05ed50b39ddb7cfa8c","date":1249333745,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/TrieField#init(IndexSchema,Map[String,String]).mjava","pathOld":"src/java/org/apache/solr/schema/TrieField#init(IndexSchema,Map[String,String]).mjava","sourceNew":"  @Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    String p = args.remove(\"precisionStep\");\n    if (p != null) {\n       precisionStepArg = Integer.parseInt(p);\n    }\n    // normalize the precisionStep\n    precisionStep = precisionStepArg;\n    if (precisionStep<=0 || precisionStep>=64) precisionStep=Integer.MAX_VALUE;\n    String t = args.remove(\"type\");\n\n    if (t != null) {\n      try {\n        type = TrieTypes.valueOf(t.toUpperCase());\n      } catch (IllegalArgumentException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"), e);\n      }\n    }\n  \n    \n    CharFilterFactory[] filterFactories = new CharFilterFactory[0];\n    TokenFilterFactory[] tokenFilterFactories = new TokenFilterFactory[0];\n    analyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, precisionStep), tokenFilterFactories);\n    // for query time we only need one token, so we use the biggest possible precisionStep:\n    queryAnalyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, Integer.MAX_VALUE), tokenFilterFactories);\n  }\n\n","sourceOld":"  @Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    String p = args.remove(\"precisionStep\");\n    if (p != null) {\n      precisionStep = Integer.parseInt(p);\n    }\n    String t = args.remove(\"type\");\n    if (t == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n              \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"));\n    } else {\n      try {\n        type = TrieTypes.valueOf(t.toUpperCase());\n      } catch (IllegalArgumentException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"), e);\n      }\n    }\n    \n    CharFilterFactory[] filterFactories = new CharFilterFactory[0];\n    TokenFilterFactory[] tokenFilterFactories = new TokenFilterFactory[0];\n    analyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, precisionStep), tokenFilterFactories);\n    // for query time we only need one token, so we use the biggest possible precisionStep:\n    queryAnalyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, Integer.MAX_VALUE), tokenFilterFactories);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/schema/TrieField#init(IndexSchema,Map[String,String]).mjava","pathOld":"src/java/org/apache/solr/schema/TrieField#init(IndexSchema,Map[String,String]).mjava","sourceNew":"  @Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    String p = args.remove(\"precisionStep\");\n    if (p != null) {\n       precisionStepArg = Integer.parseInt(p);\n    }\n    // normalize the precisionStep\n    precisionStep = precisionStepArg;\n    if (precisionStep<=0 || precisionStep>=64) precisionStep=Integer.MAX_VALUE;\n    String t = args.remove(\"type\");\n\n    if (t != null) {\n      try {\n        type = TrieTypes.valueOf(t.toUpperCase());\n      } catch (IllegalArgumentException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"), e);\n      }\n    }\n  \n    \n    CharFilterFactory[] filterFactories = new CharFilterFactory[0];\n    TokenFilterFactory[] tokenFilterFactories = new TokenFilterFactory[0];\n    analyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, precisionStep), tokenFilterFactories);\n    // for query time we only need one token, so we use the biggest possible precisionStep:\n    queryAnalyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, Integer.MAX_VALUE), tokenFilterFactories);\n  }\n\n","sourceOld":"  @Override\n  protected void init(IndexSchema schema, Map<String, String> args) {\n    String p = args.remove(\"precisionStep\");\n    if (p != null) {\n       precisionStepArg = Integer.parseInt(p);\n    }\n    // normalize the precisionStep\n    precisionStep = precisionStepArg;\n    if (precisionStep<=0 || precisionStep>=64) precisionStep=Integer.MAX_VALUE;\n    String t = args.remove(\"type\");\n\n    if (t != null) {\n      try {\n        type = TrieTypes.valueOf(t.toUpperCase());\n      } catch (IllegalArgumentException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Invalid type specified in schema.xml for field: \" + args.get(\"name\"), e);\n      }\n    }\n  \n    \n    CharFilterFactory[] filterFactories = new CharFilterFactory[0];\n    TokenFilterFactory[] tokenFilterFactories = new TokenFilterFactory[0];\n    analyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, precisionStep), tokenFilterFactories);\n    // for query time we only need one token, so we use the biggest possible precisionStep:\n    queryAnalyzer = new TokenizerChain(filterFactories, new TrieTokenizerFactory(type, Integer.MAX_VALUE), tokenFilterFactories);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1e77721aaf23393f6ea7926045ae6f8efea0ce8e":["1d6ca4f6b8a27a0523251c56d0abeb659ef5c1b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"dbc0ca7104fa6f1d7cc24b05ed50b39ddb7cfa8c":["1e77721aaf23393f6ea7926045ae6f8efea0ce8e"],"1d6ca4f6b8a27a0523251c56d0abeb659ef5c1b0":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"ad94625fb8d088209f46650c8097196fec67f00c":["dbc0ca7104fa6f1d7cc24b05ed50b39ddb7cfa8c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"1e77721aaf23393f6ea7926045ae6f8efea0ce8e":["dbc0ca7104fa6f1d7cc24b05ed50b39ddb7cfa8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["1d6ca4f6b8a27a0523251c56d0abeb659ef5c1b0"],"dbc0ca7104fa6f1d7cc24b05ed50b39ddb7cfa8c":["ad94625fb8d088209f46650c8097196fec67f00c"],"1d6ca4f6b8a27a0523251c56d0abeb659ef5c1b0":["1e77721aaf23393f6ea7926045ae6f8efea0ce8e"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}