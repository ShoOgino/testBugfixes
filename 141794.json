{"path":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","commits":[{"id":"762c80e29fe0c3bb83aabe2e64af6379273cec7b","date":1484347562,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","pathOld":"/dev/null","sourceNew":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = FSDirectory.open(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    w.addIndexes(dir);\n    w.close();\n    // OK: addIndexes(Directory...) also keeps version as 6.3.0, so offsets not checked:\n    TestUtil.checkIndex(tmpDir);\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    w.addIndexes(codecReaders);\n    w.close();\n\n    // NOT OK: broken offsets were copied into a 7.0 segment:\n    ByteArrayOutputStream output = new ByteArrayOutputStream(1024);    \n    RuntimeException re = expectThrows(RuntimeException.class, () -> {TestUtil.checkIndex(tmpDir2, false, true, output);});\n    assertEquals(\"term [66 6f 6f]: doc 0: pos 1: startOffset 7 < lastStartOffset 10; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\", re.getMessage());\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e6d90ae30e3829bfba7468f805c109e4898b0639","date":1484392861,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","sourceNew":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    w.addIndexes(dir);\n    w.close();\n    // OK: addIndexes(Directory...) also keeps version as 6.3.0, so offsets not checked:\n    TestUtil.checkIndex(tmpDir);\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    w.addIndexes(codecReaders);\n    reader.close();\n    w.close();\n\n    // NOT OK: broken offsets were copied into a 7.0 segment:\n    ByteArrayOutputStream output = new ByteArrayOutputStream(1024);    \n    RuntimeException re = expectThrows(RuntimeException.class, () -> {TestUtil.checkIndex(tmpDir2, false, true, output);});\n    assertEquals(\"term [66 6f 6f]: doc 0: pos 1: startOffset 7 < lastStartOffset 10; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\", re.getMessage());\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = FSDirectory.open(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    w.addIndexes(dir);\n    w.close();\n    // OK: addIndexes(Directory...) also keeps version as 6.3.0, so offsets not checked:\n    TestUtil.checkIndex(tmpDir);\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    w.addIndexes(codecReaders);\n    w.close();\n\n    // NOT OK: broken offsets were copied into a 7.0 segment:\n    ByteArrayOutputStream output = new ByteArrayOutputStream(1024);    \n    RuntimeException re = expectThrows(RuntimeException.class, () -> {TestUtil.checkIndex(tmpDir2, false, true, output);});\n    assertEquals(\"term [66 6f 6f]: doc 0: pos 1: startOffset 7 < lastStartOffset 10; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\", re.getMessage());\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"507e7decdf00981d09a74632ea30299a4ce6ba72","date":1484600874,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","pathOld":"/dev/null","sourceNew":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    w.addIndexes(dir);\n    w.close();\n    // OK: addIndexes(Directory...) also keeps version as 6.3.0, so offsets not checked:\n    TestUtil.checkIndex(tmpDir);\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    w.addIndexes(codecReaders);\n    reader.close();\n    w.close();\n\n    // NOT OK: broken offsets were copied into a 7.0 segment:\n    ByteArrayOutputStream output = new ByteArrayOutputStream(1024);    \n    RuntimeException re = expectThrows(RuntimeException.class, () -> {TestUtil.checkIndex(tmpDir2, false, true, output);});\n    assertEquals(\"term [66 6f 6f]: doc 0: pos 1: startOffset 7 < lastStartOffset 10; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\", re.getMessage());\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d97ba94eef1fc33c5451259a7aa2ac682646c1af","date":1488285427,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","sourceNew":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    IndexWriter finalW = w;\n    IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> finalW.addIndexes(dir));\n    assertTrue(e.getMessage(), e.getMessage().startsWith(\"Cannot use addIndexes(Directory) with indexes that have been created by a different Lucene version.\"));\n    w.close();\n    // OK: addIndexes(Directory...) refuses to execute if the index creation version is different so broken offsets are not carried over\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    w.addIndexes(codecReaders);\n    reader.close();\n    w.close();\n\n    // NOT OK: broken offsets were copied into a 7.0 segment:\n    ByteArrayOutputStream output = new ByteArrayOutputStream(1024);    \n    RuntimeException re = expectThrows(RuntimeException.class, () -> {TestUtil.checkIndex(tmpDir2, false, true, output);});\n    assertEquals(\"term [66 6f 6f]: doc 0: pos 1: startOffset 7 < lastStartOffset 10; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\", re.getMessage());\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    w.addIndexes(dir);\n    w.close();\n    // OK: addIndexes(Directory...) also keeps version as 6.3.0, so offsets not checked:\n    TestUtil.checkIndex(tmpDir);\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    w.addIndexes(codecReaders);\n    reader.close();\n    w.close();\n\n    // NOT OK: broken offsets were copied into a 7.0 segment:\n    ByteArrayOutputStream output = new ByteArrayOutputStream(1024);    \n    RuntimeException re = expectThrows(RuntimeException.class, () -> {TestUtil.checkIndex(tmpDir2, false, true, output);});\n    assertEquals(\"term [66 6f 6f]: doc 0: pos 1: startOffset 7 < lastStartOffset 10; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\", re.getMessage());\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","sourceNew":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    IndexWriter finalW = w;\n    IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> finalW.addIndexes(dir));\n    assertTrue(e.getMessage(), e.getMessage().startsWith(\"Cannot use addIndexes(Directory) with indexes that have been created by a different Lucene version.\"));\n    w.close();\n    // OK: addIndexes(Directory...) refuses to execute if the index creation version is different so broken offsets are not carried over\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    IndexWriter finalW2 = w;\n    e = expectThrows(IllegalArgumentException.class, () -> finalW2.addIndexes(codecReaders));\n    assertEquals(\"Cannot merge a segment that has been created with major version 6 into this index which has been created by major version 7\", e.getMessage());\n    reader.close();\n    w.close();\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    IndexWriter finalW = w;\n    IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> finalW.addIndexes(dir));\n    assertTrue(e.getMessage(), e.getMessage().startsWith(\"Cannot use addIndexes(Directory) with indexes that have been created by a different Lucene version.\"));\n    w.close();\n    // OK: addIndexes(Directory...) refuses to execute if the index creation version is different so broken offsets are not carried over\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    w.addIndexes(codecReaders);\n    reader.close();\n    w.close();\n\n    // NOT OK: broken offsets were copied into a 7.0 segment:\n    ByteArrayOutputStream output = new ByteArrayOutputStream(1024);    \n    RuntimeException re = expectThrows(RuntimeException.class, () -> {TestUtil.checkIndex(tmpDir2, false, true, output);});\n    assertEquals(\"term [66 6f 6f]: doc 0: pos 1: startOffset 7 < lastStartOffset 10; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\", re.getMessage());\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","sourceNew":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    IndexWriter finalW = w;\n    IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> finalW.addIndexes(dir));\n    assertTrue(e.getMessage(), e.getMessage().startsWith(\"Cannot use addIndexes(Directory) with indexes that have been created by a different Lucene version.\"));\n    w.close();\n    // OK: addIndexes(Directory...) refuses to execute if the index creation version is different so broken offsets are not carried over\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    IndexWriter finalW2 = w;\n    e = expectThrows(IllegalArgumentException.class, () -> finalW2.addIndexes(codecReaders));\n    assertEquals(\"Cannot merge a segment that has been created with major version 6 into this index which has been created by major version 7\", e.getMessage());\n    reader.close();\n    w.close();\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    IndexWriter finalW = w;\n    IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> finalW.addIndexes(dir));\n    assertTrue(e.getMessage(), e.getMessage().startsWith(\"Cannot use addIndexes(Directory) with indexes that have been created by a different Lucene version.\"));\n    w.close();\n    // OK: addIndexes(Directory...) refuses to execute if the index creation version is different so broken offsets are not carried over\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    w.addIndexes(codecReaders);\n    reader.close();\n    w.close();\n\n    // NOT OK: broken offsets were copied into a 7.0 segment:\n    ByteArrayOutputStream output = new ByteArrayOutputStream(1024);    \n    RuntimeException re = expectThrows(RuntimeException.class, () -> {TestUtil.checkIndex(tmpDir2, false, true, output);});\n    assertEquals(\"term [66 6f 6f]: doc 0: pos 1: startOffset 7 < lastStartOffset 10; consider using the FixBrokenOffsets tool in Lucene's backward-codecs module to correct your index\", re.getMessage());\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c77cd17559fe8804f9a6d1e2e494617de0ed2d7","date":1499083945,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","sourceNew":null,"sourceOld":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    IndexWriter finalW = w;\n    IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> finalW.addIndexes(dir));\n    assertTrue(e.getMessage(), e.getMessage().startsWith(\"Cannot use addIndexes(Directory) with indexes that have been created by a different Lucene version.\"));\n    w.close();\n    // OK: addIndexes(Directory...) refuses to execute if the index creation version is different so broken offsets are not carried over\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    IndexWriter finalW2 = w;\n    e = expectThrows(IllegalArgumentException.class, () -> finalW2.addIndexes(codecReaders));\n    assertEquals(\"Cannot merge a segment that has been created with major version 6 into this index which has been created by major version 7\", e.getMessage());\n    reader.close();\n    w.close();\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc018b79379c67835b40b1259cd3dc931df60944","date":1499109112,"type":4,"author":"Anshum Gupta","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","sourceNew":null,"sourceOld":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    IndexWriter finalW = w;\n    IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> finalW.addIndexes(dir));\n    assertTrue(e.getMessage(), e.getMessage().startsWith(\"Cannot use addIndexes(Directory) with indexes that have been created by a different Lucene version.\"));\n    w.close();\n    // OK: addIndexes(Directory...) refuses to execute if the index creation version is different so broken offsets are not carried over\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    IndexWriter finalW2 = w;\n    e = expectThrows(IllegalArgumentException.class, () -> finalW2.addIndexes(codecReaders));\n    assertEquals(\"Cannot merge a segment that has been created with major version 6 into this index which has been created by major version 7\", e.getMessage());\n    reader.close();\n    w.close();\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30c8e5574b55d57947e989443dfde611646530ee","date":1499131153,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestFixBrokenOffsets#testFixBrokenOffsetsIndex().mjava","sourceNew":null,"sourceOld":"  public void testFixBrokenOffsetsIndex() throws IOException {\n    InputStream resource = getClass().getResourceAsStream(\"index.630.brokenoffsets.zip\");\n    assertNotNull(\"Broken offsets index not found\", resource);\n    Path path = createTempDir(\"brokenoffsets\");\n    TestUtil.unzip(resource, path);\n    Directory dir = newFSDirectory(path);\n\n    // OK: index is 6.3.0 so offsets not checked:\n    TestUtil.checkIndex(dir);\n    \n    MockDirectoryWrapper tmpDir = newMockDirectory();\n    tmpDir.setCheckIndexOnClose(false);\n    IndexWriter w = new IndexWriter(tmpDir, new IndexWriterConfig());\n    IndexWriter finalW = w;\n    IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> finalW.addIndexes(dir));\n    assertTrue(e.getMessage(), e.getMessage().startsWith(\"Cannot use addIndexes(Directory) with indexes that have been created by a different Lucene version.\"));\n    w.close();\n    // OK: addIndexes(Directory...) refuses to execute if the index creation version is different so broken offsets are not carried over\n    tmpDir.close();\n\n    final MockDirectoryWrapper tmpDir2 = newMockDirectory();\n    tmpDir2.setCheckIndexOnClose(false);\n    w = new IndexWriter(tmpDir2, new IndexWriterConfig());\n    DirectoryReader reader = DirectoryReader.open(dir);\n    List<LeafReaderContext> leaves = reader.leaves();\n    CodecReader[] codecReaders = new CodecReader[leaves.size()];\n    for(int i=0;i<leaves.size();i++) {\n      codecReaders[i] = (CodecReader) leaves.get(i).reader();\n    }\n    IndexWriter finalW2 = w;\n    e = expectThrows(IllegalArgumentException.class, () -> finalW2.addIndexes(codecReaders));\n    assertEquals(\"Cannot merge a segment that has been created with major version 6 into this index which has been created by major version 7\", e.getMessage());\n    reader.close();\n    w.close();\n    tmpDir2.close();\n\n    // Now run the tool and confirm the broken offsets are fixed:\n    Path path2 = createTempDir(\"fixedbrokenoffsets\").resolve(\"subdir\");\n    FixBrokenOffsets.main(new String[] {path.toString(), path2.toString()});\n    Directory tmpDir3 = FSDirectory.open(path2);\n    TestUtil.checkIndex(tmpDir3);\n    tmpDir3.close();\n    \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"762c80e29fe0c3bb83aabe2e64af6379273cec7b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cc018b79379c67835b40b1259cd3dc931df60944":["31741cf1390044e38a2ec3127cf302ba841bfd75","5c77cd17559fe8804f9a6d1e2e494617de0ed2d7"],"30c8e5574b55d57947e989443dfde611646530ee":["92212fd254551a0b1156aafc3a1a6ed1a43932ad","cc018b79379c67835b40b1259cd3dc931df60944"],"e6d90ae30e3829bfba7468f805c109e4898b0639":["762c80e29fe0c3bb83aabe2e64af6379273cec7b"],"d97ba94eef1fc33c5451259a7aa2ac682646c1af":["e6d90ae30e3829bfba7468f805c109e4898b0639"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["d97ba94eef1fc33c5451259a7aa2ac682646c1af"],"507e7decdf00981d09a74632ea30299a4ce6ba72":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e6d90ae30e3829bfba7468f805c109e4898b0639"],"5c77cd17559fe8804f9a6d1e2e494617de0ed2d7":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cc018b79379c67835b40b1259cd3dc931df60944"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["d97ba94eef1fc33c5451259a7aa2ac682646c1af"]},"commit2Childs":{"762c80e29fe0c3bb83aabe2e64af6379273cec7b":["e6d90ae30e3829bfba7468f805c109e4898b0639"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["762c80e29fe0c3bb83aabe2e64af6379273cec7b","507e7decdf00981d09a74632ea30299a4ce6ba72"],"cc018b79379c67835b40b1259cd3dc931df60944":["30c8e5574b55d57947e989443dfde611646530ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"30c8e5574b55d57947e989443dfde611646530ee":[],"e6d90ae30e3829bfba7468f805c109e4898b0639":["d97ba94eef1fc33c5451259a7aa2ac682646c1af","507e7decdf00981d09a74632ea30299a4ce6ba72"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["30c8e5574b55d57947e989443dfde611646530ee"],"d97ba94eef1fc33c5451259a7aa2ac682646c1af":["92212fd254551a0b1156aafc3a1a6ed1a43932ad","31741cf1390044e38a2ec3127cf302ba841bfd75"],"507e7decdf00981d09a74632ea30299a4ce6ba72":[],"5c77cd17559fe8804f9a6d1e2e494617de0ed2d7":["cc018b79379c67835b40b1259cd3dc931df60944"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["cc018b79379c67835b40b1259cd3dc931df60944","5c77cd17559fe8804f9a6d1e2e494617de0ed2d7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["30c8e5574b55d57947e989443dfde611646530ee","507e7decdf00981d09a74632ea30299a4ce6ba72","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}