{"path":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","commits":[{"id":"abb23fcc2461782ab204e61213240feb77d355aa","date":1422029612,"type":1,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#doTest().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"344b0840364d990b29b97467bfcc766ff8325d11","date":1501574100,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":["e4daf0e37630dc4d06c6bcf53c19bfb09e0ba6dd"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"20c968c14aace7cf49843bf2c1fafc7fd3845659","date":1533133859,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null, false);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2ffc8d70d9f57a62a24c3dd15b66e353de935054","date":1533178472,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null, false);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null, false);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      leaderJetty.jetty.stop();\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      deadJetty.jetty.start(); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null, false);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      chaosMonkey.killJetty(leaderJetty);\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      ChaosMonkey.start(deadJetty.jetty); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null, false);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      leaderJetty.jetty.stop();\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90, TimeUnit.SECONDS);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      deadJetty.jetty.start(); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null, false);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    waitForThingsToLevelOut(15);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n    final Set<String> documentIds = ConcurrentHashMap.newKeySet(1024);\n\n    Thread indexThread = null;\n    OverseerRestarter killer = null;\n    Thread killerThread = null;\n    final SolrClient solrClient = clients.get(0);\n\n    try {\n      del(\"*:*\");\n      for (int id = 0; id < 100; id++) {\n        indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n      }\n      commit();\n\n      indexThread = new Thread() {\n        @Override\n        public void run() {\n          int max = atLeast(401);\n          for (int id = 101; id < max; id++) {\n            try {\n              indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id, documentIds);\n              Thread.sleep(atLeast(25));\n            } catch (Exception e) {\n              log.error(\"Exception while adding doc\", e);\n            }\n          }\n        }\n      };\n      indexThread.start();\n\n      // kill the leader\n      CloudJettyRunner leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      leaderJetty.jetty.stop();\n\n      Thread.sleep(2000);\n\n      waitForThingsToLevelOut(90);\n\n      Thread.sleep(1000);\n      checkShardConsistency(false, true);\n\n      CloudJettyRunner deadJetty = leaderJetty;\n\n      // TODO: Check total docs ?\n      // long cloudClientDocs = cloudClient.query(new\n      // SolrQuery(\"*:*\")).getResults().getNumFound();\n\n      // Wait until new leader is elected\n      while (deadJetty == leaderJetty) {\n        updateMappingsFromZk(this.jettys, this.clients);\n        leaderJetty = shardToLeaderJetty.get(\"shard1\");\n      }\n\n      // bring back dead node\n      deadJetty.jetty.start(); // he is not the leader anymore\n\n      waitTillRecovered();\n\n      // Kill the overseer\n      // TODO: Actually kill the Overseer instance\n      killer = new OverseerRestarter(zkServer.getZkAddress());\n      killerThread = new Thread(killer);\n      killerThread.start();\n      killCounter.incrementAndGet();\n\n      splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, null, null, false);\n\n      log.info(\"Layout after split: \\n\");\n      printLayout();\n\n      // distributed commit on all shards\n    } finally {\n      if (indexThread != null)\n        indexThread.join();\n      if (solrClient != null)\n        solrClient.commit();\n      if (killer != null) {\n        killer.run = false;\n        if (killerThread != null) {\n          killerThread.join();\n        }\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas, documentIds);\n\n    // todo - can't call waitForThingsToLevelOut because it looks for\n    // jettys of all shards\n    // and the new sub-shards don't have any.\n    waitForRecoveriesToFinish(true);\n    // waitForThingsToLevelOut(15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["abb23fcc2461782ab204e61213240feb77d355aa","344b0840364d990b29b97467bfcc766ff8325d11"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["2ffc8d70d9f57a62a24c3dd15b66e353de935054"],"abb23fcc2461782ab204e61213240feb77d355aa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"344b0840364d990b29b97467bfcc766ff8325d11":["abb23fcc2461782ab204e61213240feb77d355aa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"2ffc8d70d9f57a62a24c3dd15b66e353de935054":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["344b0840364d990b29b97467bfcc766ff8325d11"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["add1e7dd742ea533ff4318cea83ca0a1f669f662"]},"commit2Childs":{"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"abb23fcc2461782ab204e61213240feb77d355aa":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","344b0840364d990b29b97467bfcc766ff8325d11"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"344b0840364d990b29b97467bfcc766ff8325d11":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","20c968c14aace7cf49843bf2c1fafc7fd3845659"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["abb23fcc2461782ab204e61213240feb77d355aa"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2ffc8d70d9f57a62a24c3dd15b66e353de935054":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["2ffc8d70d9f57a62a24c3dd15b66e353de935054"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}