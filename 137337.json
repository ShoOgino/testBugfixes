{"path":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#setMaxDocBytesToAnalyze(int).mjava","commits":[{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#setMaxDocBytesToAnalyze(int).mjava","pathOld":"sandbox/contributions/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#setMaxDocBytesToAnalyze(int).mjava","sourceNew":"\t/**\n\t * @param byteCount the maximum number of bytes to be tokenized per doc\n\t * (This can improve performance with large documents)\n\t */\n\tpublic void setMaxDocBytesToAnalyze(int byteCount)\n\t{\n\t\tmaxDocBytesToAnalyze = byteCount;\n\t}\n\n","sourceOld":"\t/**\n\t * @param byteCount the maximum number of bytes to be tokenized per doc\n\t * (This can improve performance with large documents)\n\t */\n\tpublic void setMaxDocBytesToAnalyze(int byteCount)\n\t{\n\t\tmaxDocBytesToAnalyze = byteCount;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a710e1326e4ffd9966ad8e37ba4e5f720778c5d9","date":1201613713,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#setMaxDocBytesToAnalyze(int).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#setMaxDocBytesToAnalyze(int).mjava","sourceNew":"\t/**\n\t * @param byteCount the maximum number of bytes to be tokenized per doc\n\t * (This can improve performance with large documents)\n   *\n   * @deprecated See {@link #setMaxDocCharsToAnalyze(int)}, since this value has always counted chars\n\t */\n\tpublic void setMaxDocBytesToAnalyze(int byteCount)\n\t{\n\t\tmaxDocCharsToAnalyze = byteCount;\n\t}\n\n","sourceOld":"\t/**\n\t * @param byteCount the maximum number of bytes to be tokenized per doc\n\t * (This can improve performance with large documents)\n\t */\n\tpublic void setMaxDocBytesToAnalyze(int byteCount)\n\t{\n\t\tmaxDocBytesToAnalyze = byteCount;\n\t}\n\n","bugFix":["db2e1c87dfa9ca908febe5b39f6dd3dee2fbe9e2"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2aa9553aad4bb588f33e036ce51485a850a2917","date":1257895368,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter#setMaxDocBytesToAnalyze(int).mjava","sourceNew":null,"sourceOld":"\t/**\n\t * @param byteCount the maximum number of bytes to be tokenized per doc\n\t * (This can improve performance with large documents)\n   *\n   * @deprecated See {@link #setMaxDocCharsToAnalyze(int)}, since this value has always counted chars\n\t */\n\tpublic void setMaxDocBytesToAnalyze(int byteCount)\n\t{\n\t\tmaxDocCharsToAnalyze = byteCount;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f2aa9553aad4bb588f33e036ce51485a850a2917":["a710e1326e4ffd9966ad8e37ba4e5f720778c5d9"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a710e1326e4ffd9966ad8e37ba4e5f720778c5d9":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f2aa9553aad4bb588f33e036ce51485a850a2917"]},"commit2Childs":{"f2aa9553aad4bb588f33e036ce51485a850a2917":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["a710e1326e4ffd9966ad8e37ba4e5f720778c5d9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"a710e1326e4ffd9966ad8e37ba4e5f720778c5d9":["f2aa9553aad4bb588f33e036ce51485a850a2917"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}