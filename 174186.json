{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d19974432be9aed28ee7dca73bdf01d139e763a9","date":1342822166,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    final int termIndexInterval = writer.getConfig().getTermIndexInterval();\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    // Import to use same term index interval else a\n    // smaller one here could increase the disk usage and\n    // cause a false failure:\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setTermIndexInterval(termIndexInterval).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.shutdown();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.shutdown();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.shutdown();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.shutdown();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(10).setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.shutdown();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND).setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.shutdown();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.shutdown();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.shutdown();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e02c236171fb81c2cbf0b1d1e188e90c2ee8af92","date":1411368491,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage)\", maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    MockDirectoryWrapper dir = newMockDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage\");\n    }\n    long startDiskUsage = 0;\n    String[] files = dir.listAll();\n    for(int i=0;i<files.length;i++) {\n      startDiskUsage += dir.fileLength(files[i]);\n      if (VERBOSE) {\n        System.out.println(files[i] + \": \" + dir.fileLength(files[i]));\n      }\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    writer.forceMerge(1);\n    writer.close();\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \" + startDiskUsage + \" bytes; max temp usage was \" + maxDiskUsage + \" but should have been \" + (4*startDiskUsage) + \" (= 4X starting usage)\",\n               maxDiskUsage <= 4*startDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["30766374cfdb9f7a09a8ff617a4859604982b05e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"577531718b186fa4937d3aaf91050f413295c2cd","date":1427860013,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage)\", maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fa2f5292dd18968c87a154a7ef217664be7f1302","date":1427860545,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage)\", maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["30766374cfdb9f7a09a8ff617a4859604982b05e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"49f5332fbcc2cf46175c46590184a39eadb17fc1","date":1427860953,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"aff95b4aa04cf5901d134745f3e55a6a23d49b94","date":1427861009,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"30766374cfdb9f7a09a8ff617a4859604982b05e","date":1428006183,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":["fa2f5292dd18968c87a154a7ef217664be7f1302","e02c236171fb81c2cbf0b1d1e188e90c2ee8af92"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","date":1428091986,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been \" + (3 * maxStartFinalDiskUsage)\n        + \" (= 3X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 3 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bfe104fc023fadc9e709f8d17403d2cc61133fe","date":1454446396,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterForceMerge#testForceMergeTempSpaceUsage().mjava","sourceNew":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure forceMerge doesn't use any more than 1X\n   * starting index size as its temporary free space\n   * required.\n   */\n  public void testForceMergeTempSpaceUsage() throws IOException {\n\n    final MockDirectoryWrapper dir = newMockDirectory();\n    dir.setEnableVirusScanner(false);\n    // don't use MockAnalyzer, variable length payloads can cause merge to make things bigger,\n    // since things are optimized for fixed length case. this is a problem for MemoryPF's encoding.\n    // (it might have other problems too)\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.WHITESPACE, true));\n      }\n    };\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(analyzer)\n                                                 .setMaxBufferedDocs(10)\n                                                 .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config1=\" + writer.getConfig());\n    }\n\n    for(int j=0;j<500;j++) {\n      TestIndexWriter.addDocWithIndex(writer, j);\n    }\n    // force one extra segment w/ different doc store so\n    // we see the doc stores get merged\n    writer.commit();\n    TestIndexWriter.addDocWithIndex(writer, 500);\n    writer.close();\n\n    long startDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      startDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: start disk usage = \" + startDiskUsage);\n    }\n    String startListing = listFiles(dir);\n\n    dir.resetMaxUsedSizeInBytes();\n    dir.setTrackDiskUsage(true);\n\n    writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                    .setOpenMode(OpenMode.APPEND)\n                                    .setMergePolicy(newLogMergePolicy()));\n    \n    if (VERBOSE) {\n      System.out.println(\"TEST: config2=\" + writer.getConfig());\n    }\n\n    writer.forceMerge(1);\n    writer.close();\n\n    long finalDiskUsage = 0;\n    for (String f : dir.listAll()) {\n      finalDiskUsage += dir.fileLength(f);\n      if (VERBOSE) {\n        System.out.println(f + \": \" + dir.fileLength(f));\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"TEST: final disk usage = \" + finalDiskUsage);\n    }\n\n    // The result of the merged index is often smaller, but sometimes it could\n    // be bigger (compression slightly changes, Codec changes etc.). Therefore\n    // we compare the temp space used to the max of the initial and final index\n    // size\n    long maxStartFinalDiskUsage = Math.max(startDiskUsage, finalDiskUsage);\n    long maxDiskUsage = dir.getMaxUsedSizeInBytes();\n    assertTrue(\"forceMerge used too much temporary space: starting usage was \"\n        + startDiskUsage + \" bytes; final usage was \" + finalDiskUsage\n        + \" bytes; max temp usage was \" + maxDiskUsage\n        + \" but should have been at most \" + (4 * maxStartFinalDiskUsage)\n        + \" (= 4X starting usage), BEFORE=\" + startListing + \"AFTER=\" + listFiles(dir), maxDiskUsage <= 4 * maxStartFinalDiskUsage);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"577531718b186fa4937d3aaf91050f413295c2cd":["e02c236171fb81c2cbf0b1d1e188e90c2ee8af92"],"aff95b4aa04cf5901d134745f3e55a6a23d49b94":["577531718b186fa4937d3aaf91050f413295c2cd","49f5332fbcc2cf46175c46590184a39eadb17fc1"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"fa2f5292dd18968c87a154a7ef217664be7f1302":["e02c236171fb81c2cbf0b1d1e188e90c2ee8af92"],"a45bec74b98f6fc05f52770cfb425739e6563960":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5a207d19eac354d649c3f0e2cce070017c78125e":["30766374cfdb9f7a09a8ff617a4859604982b05e","b470f36a9372c97283360b1304eacbde22df6c0d"],"e02c236171fb81c2cbf0b1d1e188e90c2ee8af92":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["30766374cfdb9f7a09a8ff617a4859604982b05e","b470f36a9372c97283360b1304eacbde22df6c0d"],"aba371508186796cc6151d8223a5b4e16d02e26e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","d19974432be9aed28ee7dca73bdf01d139e763a9"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"b470f36a9372c97283360b1304eacbde22df6c0d":["30766374cfdb9f7a09a8ff617a4859604982b05e","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"49f5332fbcc2cf46175c46590184a39eadb17fc1":["fa2f5292dd18968c87a154a7ef217664be7f1302"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":["aff95b4aa04cf5901d134745f3e55a6a23d49b94","30766374cfdb9f7a09a8ff617a4859604982b05e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["30766374cfdb9f7a09a8ff617a4859604982b05e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["a45bec74b98f6fc05f52770cfb425739e6563960"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","d19974432be9aed28ee7dca73bdf01d139e763a9"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5a207d19eac354d649c3f0e2cce070017c78125e"],"30766374cfdb9f7a09a8ff617a4859604982b05e":["49f5332fbcc2cf46175c46590184a39eadb17fc1"]},"commit2Childs":{"577531718b186fa4937d3aaf91050f413295c2cd":["aff95b4aa04cf5901d134745f3e55a6a23d49b94"],"aff95b4aa04cf5901d134745f3e55a6a23d49b94":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"fa2f5292dd18968c87a154a7ef217664be7f1302":["49f5332fbcc2cf46175c46590184a39eadb17fc1"],"a45bec74b98f6fc05f52770cfb425739e6563960":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5a207d19eac354d649c3f0e2cce070017c78125e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e02c236171fb81c2cbf0b1d1e188e90c2ee8af92":["577531718b186fa4937d3aaf91050f413295c2cd","fa2f5292dd18968c87a154a7ef217664be7f1302"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"d19974432be9aed28ee7dca73bdf01d139e763a9":["a45bec74b98f6fc05f52770cfb425739e6563960","aba371508186796cc6151d8223a5b4e16d02e26e","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"49f5332fbcc2cf46175c46590184a39eadb17fc1":["aff95b4aa04cf5901d134745f3e55a6a23d49b94","30766374cfdb9f7a09a8ff617a4859604982b05e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["e02c236171fb81c2cbf0b1d1e188e90c2ee8af92"],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["b470f36a9372c97283360b1304eacbde22df6c0d"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["aba371508186796cc6151d8223a5b4e16d02e26e","d19974432be9aed28ee7dca73bdf01d139e763a9","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"30766374cfdb9f7a09a8ff617a4859604982b05e":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3","b470f36a9372c97283360b1304eacbde22df6c0d","6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","aba371508186796cc6151d8223a5b4e16d02e26e","6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}