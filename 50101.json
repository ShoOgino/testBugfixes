{"path":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testDocSortOptimization().mjava","commits":[{"id":"e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241","date":1599588987,"type":0,"author":"Mayya Sharipova","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testDocSortOptimization().mjava","pathOld":"/dev/null","sourceNew":"  public void testDocSortOptimization() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n    final int numDocs = atLeast(100);\n    int seg = 1;\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = new Document();\n      doc.add(new LongPoint(\"lf\", i));\n      doc.add(new StoredField(\"slf\", i));\n      doc.add(new StringField(\"tf\", \"seg\" + seg, Field.Store.YES));\n      writer.addDocument(doc);\n      if ((i > 0) && (i % 50 == 0)) {\n        writer.commit();\n        seg++;\n      }\n    }\n    final IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    final int numHits = 3;\n    final int totalHitsThreshold = 3;\n    final Sort sort = new Sort(FIELD_DOC);\n\n    // sort by _doc should skip all non-competitive documents\n    {\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(numHits, topDocs.scoreDocs.length);\n      for (int i = 0; i < numHits; i++) {\n        assertEquals(i, topDocs.scoreDocs[i].doc);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < 10); // assert that very few docs were collected\n    }\n\n    // sort by _doc with a bool query should skip all non-competitive documents\n    {\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      int lowerRange = 40;\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      bq.add(LongPoint.newRangeQuery(\"lf\", lowerRange, Long.MAX_VALUE), BooleanClause.Occur.MUST);\n      bq.add(new TermQuery(new Term(\"tf\", \"seg1\")), BooleanClause.Occur.MUST);\n      searcher.search(bq.build(), collector);\n\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(numHits, topDocs.scoreDocs.length);\n      for (int i = 0; i < numHits; i++) {\n        Document d = searcher.doc(topDocs.scoreDocs[i].doc);\n        assertEquals(Integer.toString(i + lowerRange), d.get(\"slf\"));\n        assertEquals(\"seg1\", d.get(\"tf\"));\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < 10); // assert that very few docs were collected\n    }\n\n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e977a403f93a917f75266c88727eadb89e4f64fc","date":1600866583,"type":3,"author":"Mayya Sharipova","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testDocSortOptimization().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testDocSortOptimization().mjava","sourceNew":"  public void testDocSortOptimization() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n    final int numDocs = atLeast(100);\n    int seg = 1;\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = new Document();\n      doc.add(new LongPoint(\"lf\", i));\n      doc.add(new StoredField(\"slf\", i));\n      doc.add(new StringField(\"tf\", \"seg\" + seg, Field.Store.YES));\n      writer.addDocument(doc);\n      if ((i > 0) && (i % 50 == 0)) {\n        writer.flush();\n        seg++;\n      }\n    }\n    final IndexReader reader = DirectoryReader.open(writer);\n    writer.close();\n\n    final int numHits = 3;\n    final int totalHitsThreshold = 3;\n    final Sort sort = new Sort(FIELD_DOC);\n\n    // sort by _doc should skip all non-competitive documents\n    {\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      IndexSearcher searcher = newSearcher(reader);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(numHits, topDocs.scoreDocs.length);\n      for (int i = 0; i < numHits; i++) {\n        assertEquals(i, topDocs.scoreDocs[i].doc);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < 10); // assert that very few docs were collected\n    }\n\n    // sort by _doc with a bool query should skip all non-competitive documents\n    {\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      int lowerRange = 40;\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      bq.add(LongPoint.newRangeQuery(\"lf\", lowerRange, Long.MAX_VALUE), BooleanClause.Occur.MUST);\n      bq.add(new TermQuery(new Term(\"tf\", \"seg1\")), BooleanClause.Occur.MUST);\n      IndexSearcher searcher = newSearcher(reader);\n      searcher.search(bq.build(), collector);\n\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(numHits, topDocs.scoreDocs.length);\n      for (int i = 0; i < numHits; i++) {\n        Document d = searcher.doc(topDocs.scoreDocs[i].doc);\n        assertEquals(Integer.toString(i + lowerRange), d.get(\"slf\"));\n        assertEquals(\"seg1\", d.get(\"tf\"));\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < 10); // assert that very few docs were collected\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocSortOptimization() throws IOException {\n    final Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n    final int numDocs = atLeast(100);\n    int seg = 1;\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = new Document();\n      doc.add(new LongPoint(\"lf\", i));\n      doc.add(new StoredField(\"slf\", i));\n      doc.add(new StringField(\"tf\", \"seg\" + seg, Field.Store.YES));\n      writer.addDocument(doc);\n      if ((i > 0) && (i % 50 == 0)) {\n        writer.commit();\n        seg++;\n      }\n    }\n    final IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    final int numHits = 3;\n    final int totalHitsThreshold = 3;\n    final Sort sort = new Sort(FIELD_DOC);\n\n    // sort by _doc should skip all non-competitive documents\n    {\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(numHits, topDocs.scoreDocs.length);\n      for (int i = 0; i < numHits; i++) {\n        assertEquals(i, topDocs.scoreDocs[i].doc);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < 10); // assert that very few docs were collected\n    }\n\n    // sort by _doc with a bool query should skip all non-competitive documents\n    {\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      int lowerRange = 40;\n      BooleanQuery.Builder bq = new BooleanQuery.Builder();\n      bq.add(LongPoint.newRangeQuery(\"lf\", lowerRange, Long.MAX_VALUE), BooleanClause.Occur.MUST);\n      bq.add(new TermQuery(new Term(\"tf\", \"seg1\")), BooleanClause.Occur.MUST);\n      searcher.search(bq.build(), collector);\n\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(numHits, topDocs.scoreDocs.length);\n      for (int i = 0; i < numHits; i++) {\n        Document d = searcher.doc(topDocs.scoreDocs[i].doc);\n        assertEquals(Integer.toString(i + lowerRange), d.get(\"slf\"));\n        assertEquals(\"seg1\", d.get(\"tf\"));\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < 10); // assert that very few docs were collected\n    }\n\n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e977a403f93a917f75266c88727eadb89e4f64fc":["e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e977a403f93a917f75266c88727eadb89e4f64fc"],"e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"e977a403f93a917f75266c88727eadb89e4f64fc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241"],"e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241":["e977a403f93a917f75266c88727eadb89e4f64fc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}