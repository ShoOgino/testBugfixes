{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexWriter#writeBlock().mjava","commits":[{"id":"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69","date":1352818449,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexWriter#writeBlock().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexWriter#writeBlock().mjava","sourceNew":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n    }\n    writer.finish();\n  }\n\n","sourceOld":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n    }\n    writer.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexWriter#writeBlock().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexWriter#writeBlock().mjava","sourceNew":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n    }\n    writer.finish();\n  }\n\n","sourceOld":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n    }\n    writer.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1995eb2e4c2ebf223c9eeefc5cbab3992bc1530b","date":1397228189,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexWriter#writeBlock().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexWriter#writeBlock().mjava","sourceNew":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= zigZagEncode(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= zigZagEncode(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n    }\n    writer.finish();\n  }\n\n","sourceOld":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= moveSignToLowOrderBit(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(moveSignToLowOrderBit(delta)) <= writer.bitsPerValue();\n      writer.add(moveSignToLowOrderBit(delta));\n    }\n    writer.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70a4487b07c49a1861c05720e04624826ecbe9fa","date":1580924108,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsIndexWriter#writeBlock().mjava","sourceNew":null,"sourceOld":"  private void writeBlock() throws IOException {\n    assert blockChunks > 0;\n    fieldsIndexOut.writeVInt(blockChunks);\n\n    // The trick here is that we only store the difference from the average start\n    // pointer or doc base, this helps save bits per value.\n    // And in order to prevent a few chunks that would be far from the average to\n    // raise the number of bits per value for all of them, we only encode blocks\n    // of 1024 chunks at once\n    // See LUCENE-4512\n\n    // doc bases\n    final int avgChunkDocs;\n    if (blockChunks == 1) {\n      avgChunkDocs = 0;\n    } else {\n      avgChunkDocs = Math.round((float) (blockDocs - docBaseDeltas[blockChunks - 1]) / (blockChunks - 1));\n    }\n    fieldsIndexOut.writeVInt(totalDocs - blockDocs); // docBase\n    fieldsIndexOut.writeVInt(avgChunkDocs);\n    int docBase = 0;\n    long maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final int delta = docBase - avgChunkDocs * i;\n      maxDelta |= zigZagEncode(delta);\n      docBase += docBaseDeltas[i];\n    }\n\n    final int bitsPerDocBase = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerDocBase);\n    PackedInts.Writer writer = PackedInts.getWriterNoHeader(fieldsIndexOut,\n        PackedInts.Format.PACKED, blockChunks, bitsPerDocBase, 1);\n    docBase = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      final long delta = docBase - avgChunkDocs * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n      docBase += docBaseDeltas[i];\n    }\n    writer.finish();\n\n    // start pointers\n    fieldsIndexOut.writeVLong(firstStartPointer);\n    final long avgChunkSize;\n    if (blockChunks == 1) {\n      avgChunkSize = 0;\n    } else {\n      avgChunkSize = (maxStartPointer - firstStartPointer) / (blockChunks - 1);\n    }\n    fieldsIndexOut.writeVLong(avgChunkSize);\n    long startPointer = 0;\n    maxDelta = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      maxDelta |= zigZagEncode(delta);\n    }\n\n    final int bitsPerStartPointer = PackedInts.bitsRequired(maxDelta);\n    fieldsIndexOut.writeVInt(bitsPerStartPointer);\n    writer = PackedInts.getWriterNoHeader(fieldsIndexOut, PackedInts.Format.PACKED,\n        blockChunks, bitsPerStartPointer, 1);\n    startPointer = 0;\n    for (int i = 0; i < blockChunks; ++i) {\n      startPointer += startPointerDeltas[i];\n      final long delta = startPointer - avgChunkSize * i;\n      assert PackedInts.bitsRequired(zigZagEncode(delta)) <= writer.bitsPerValue();\n      writer.add(zigZagEncode(delta));\n    }\n    writer.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70a4487b07c49a1861c05720e04624826ecbe9fa":["1995eb2e4c2ebf223c9eeefc5cbab3992bc1530b"],"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"1995eb2e4c2ebf223c9eeefc5cbab3992bc1530b":["5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69"]},"commit2Childs":{"70a4487b07c49a1861c05720e04624826ecbe9fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69":["407687e67faf6e1f02a211ca078d8e3eed631027","1995eb2e4c2ebf223c9eeefc5cbab3992bc1530b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69","407687e67faf6e1f02a211ca078d8e3eed631027"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"1995eb2e4c2ebf223c9eeefc5cbab3992bc1530b":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}