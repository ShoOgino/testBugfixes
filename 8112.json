{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    MockDirectoryWrapper dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random, new RAMDirectory(dir1, newIOContext(random)));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    final Collection<String> openDeletedFiles = dir1.getOpenDeletedFiles();\n    assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    MockDirectoryWrapper dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random, new RAMDirectory(dir1, newIOContext(random)));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    final Collection<String> openDeletedFiles = dir1.getOpenDeletedFiles();\n    assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    MockDirectoryWrapper dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    final Collection<String> openDeletedFiles = dir1.getOpenDeletedFiles();\n    assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    MockDirectoryWrapper dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random, new RAMDirectory(dir1, newIOContext(random)));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    final Collection<String> openDeletedFiles = dir1.getOpenDeletedFiles();\n    assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":["302be0cc5e6a28ebcebcac98aa81a92be2e94370"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d19974432be9aed28ee7dca73bdf01d139e763a9","date":1342822166,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    MockDirectoryWrapper dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    final Collection<String> openDeletedFiles = dir1.getOpenDeletedFiles();\n    assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":["1ec890fad2ea96317f4429e0aa0085bb25673641","8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"bugIntro":["527cc14542789f47d75da436cb4287d1ab887e34"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    MockDirectoryWrapper dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    final Collection<String> openDeletedFiles = dir1.getOpenDeletedFiles();\n    assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    MockDirectoryWrapper dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    final Collection<String> openDeletedFiles = dir1.getOpenDeletedFiles();\n    assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0fcdcf196523675146a4df3193e91413533857ab","date":1390686560,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    final Thread[] threads = new Thread[numThreads];\n    for(int i=0;i<numThreads;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<numThreads;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":["a37d7952ff54064a735708748444570f9963683e"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"527cc14542789f47d75da436cb4287d1ab887e34","date":1391705548,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.shutdown();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.shutdown();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.shutdown();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.shutdown();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"aee6e14aa025a22ed06b7e38e12bcc15ec251fbd","date":1417101195,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final int count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final float SECONDS = 0.5f;\n\n    final long endTime = (long) (System.currentTimeMillis() + 1000.*SECONDS);\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            do {\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(System.currentTimeMillis() < endTime);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(System.currentTimeMillis() < endTime) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n      }\n      Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n      IndexSearcher searcher = newSearcher(r);\n      final int count = searcher.search(q, 10).totalHits;\n      assertTrue(count >= lastCount);\n      lastCount = count;\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":["f8f3dce1d4820d9634c1a6a46cd50ac13cf0f5a6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"302be0cc5e6a28ebcebcac98aa81a92be2e94370","date":1423848654,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final int count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), new RAMDirectory(dir1, newIOContext(random())));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final int count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8f3dce1d4820d9634c1a6a46cd50ac13cf0f5a6","date":1498031702,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final int count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":["790e1fde4caa765b3faaad3fbcd25c6973450336","c4ff8864209d2e972cb4393600c26082f9a6533d","aee6e14aa025a22ed06b7e38e12bcc15ec251fbd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final int count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    int lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final int count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final int count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.search(q, 10).totalHits.value;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.search(q, 10).totalHits.value;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.search(q, 10).totalHits;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.search(q, 10).totalHits;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d82f2f7ad0b5fdfd0dcb7a59bbcc834853180f1f","date":1533501662,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.count(q);\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.count(q);\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.search(q, 10).totalHits.value;\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.search(q, 10).totalHits.value;\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f354ba79a5a3e8491ec2953f14f365a02c058ac","date":1598293148,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testDuringAddIndexes().mjava","sourceNew":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random())).setMaxFullFlushMergeWaitMillis(0)\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.count(q);\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.count(q);\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","sourceOld":"  // Stress test reopen during addIndexes\n  @Nightly\n  public void testDuringAddIndexes() throws Exception {\n    Directory dir1 = getAssertNoDeletesDirectory(newDirectory());\n    final IndexWriter writer = new IndexWriter(\n        dir1,\n        newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy(2))\n    );\n\n    // create the index\n    createIndexNoClose(false, \"test\", writer);\n    writer.commit();\n\n    final Directory[] dirs = new Directory[10];\n    for (int i=0;i<10;i++) {\n      dirs[i] = new MockDirectoryWrapper(random(), TestUtil.ramCopyOf(dir1));\n    }\n\n    DirectoryReader r = writer.getReader();\n\n    final int numIterations = 10;\n    final List<Throwable> excs = Collections.synchronizedList(new ArrayList<Throwable>());\n\n    // Only one thread can addIndexes at a time, because\n    // IndexWriter acquires a write lock in each directory:\n    final Thread[] threads = new Thread[1];\n    final AtomicBoolean threadDone = new AtomicBoolean(false);\n    for(int i=0;i<threads.length;i++) {\n      threads[i] = new Thread() {\n          @Override\n          public void run() {\n            int count = 0;\n            do {\n              count++;\n              try {\n                writer.addIndexes(dirs);\n                writer.maybeMerge();\n              } catch (Throwable t) {\n                excs.add(t);\n                throw new RuntimeException(t);\n              }\n            } while(count < numIterations);\n            threadDone.set(true);\n          }\n        };\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    long lastCount = 0;\n    while(threadDone.get() == false) {\n      DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n      if (r2 != null) {\n        r.close();\n        r = r2;\n        Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n        IndexSearcher searcher = newSearcher(r);\n        final long count = searcher.count(q);\n        assertTrue(count >= lastCount);\n        lastCount = count;\n      }\n    }\n\n    for(int i=0;i<threads.length;i++) {\n      threads[i].join();\n    }\n    // final check\n    DirectoryReader r2 = DirectoryReader.openIfChanged(r);\n    if (r2 != null) {\n      r.close();\n      r = r2;\n    }\n    Query q = new TermQuery(new Term(\"indexname\", \"test\"));\n    IndexSearcher searcher = newSearcher(r);\n    final long count = searcher.count(q);\n    assertTrue(count >= lastCount);\n\n    assertEquals(0, excs.size());\n    r.close();\n    if (dir1 instanceof MockDirectoryWrapper) {\n      final Collection<String> openDeletedFiles = ((MockDirectoryWrapper)dir1).getOpenDeletedFiles();\n      assertEquals(\"openDeleted=\" + openDeletedFiles, 0, openDeletedFiles.size());\n    }\n\n    writer.close();\n\n    dir1.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"527cc14542789f47d75da436cb4287d1ab887e34":["0fcdcf196523675146a4df3193e91413533857ab"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f8f3dce1d4820d9634c1a6a46cd50ac13cf0f5a6":["302be0cc5e6a28ebcebcac98aa81a92be2e94370"],"aee6e14aa025a22ed06b7e38e12bcc15ec251fbd":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["302be0cc5e6a28ebcebcac98aa81a92be2e94370","f8f3dce1d4820d9634c1a6a46cd50ac13cf0f5a6"],"28288370235ed02234a64753cdbf0c6ec096304a":["302be0cc5e6a28ebcebcac98aa81a92be2e94370","f8f3dce1d4820d9634c1a6a46cd50ac13cf0f5a6"],"d82f2f7ad0b5fdfd0dcb7a59bbcc834853180f1f":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"aba371508186796cc6151d8223a5b4e16d02e26e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","d19974432be9aed28ee7dca73bdf01d139e763a9"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["527cc14542789f47d75da436cb4287d1ab887e34"],"0fcdcf196523675146a4df3193e91413533857ab":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","d19974432be9aed28ee7dca73bdf01d139e763a9"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["28288370235ed02234a64753cdbf0c6ec096304a"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3f354ba79a5a3e8491ec2953f14f365a02c058ac":["d82f2f7ad0b5fdfd0dcb7a59bbcc834853180f1f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f354ba79a5a3e8491ec2953f14f365a02c058ac"],"302be0cc5e6a28ebcebcac98aa81a92be2e94370":["aee6e14aa025a22ed06b7e38e12bcc15ec251fbd"]},"commit2Childs":{"527cc14542789f47d75da436cb4287d1ab887e34":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"f8f3dce1d4820d9634c1a6a46cd50ac13cf0f5a6":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"aee6e14aa025a22ed06b7e38e12bcc15ec251fbd":["302be0cc5e6a28ebcebcac98aa81a92be2e94370"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"d82f2f7ad0b5fdfd0dcb7a59bbcc834853180f1f":["3f354ba79a5a3e8491ec2953f14f365a02c058ac"],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"d19974432be9aed28ee7dca73bdf01d139e763a9":["aba371508186796cc6151d8223a5b4e16d02e26e","0fcdcf196523675146a4df3193e91413533857ab","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["aee6e14aa025a22ed06b7e38e12bcc15ec251fbd"],"0fcdcf196523675146a4df3193e91413533857ab":["527cc14542789f47d75da436cb4287d1ab887e34"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":[],"83788ad129a5154d5c6562c4e8ce3db48793aada":["d82f2f7ad0b5fdfd0dcb7a59bbcc834853180f1f"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["aba371508186796cc6151d8223a5b4e16d02e26e","d19974432be9aed28ee7dca73bdf01d139e763a9","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"3f354ba79a5a3e8491ec2953f14f365a02c058ac":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"302be0cc5e6a28ebcebcac98aa81a92be2e94370":["f8f3dce1d4820d9634c1a6a46cd50ac13cf0f5a6","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}