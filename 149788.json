{"path":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dfd4d352ddf04b37253ad97ce1aad1448253f0f7","date":1310173878,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63639dd66fd5bd9b90bc24dd596ae01575f27cc4","date":1310237454,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"91a3609ac9a09ca0c8eee1b765401bbdacaceaf8","date":1310355420,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3a0403b45dfe384fae4a1b6e96c3265d000c498","date":1321445981,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"dfd4d352ddf04b37253ad97ce1aad1448253f0f7":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"91a3609ac9a09ca0c8eee1b765401bbdacaceaf8":["dfd4d352ddf04b37253ad97ce1aad1448253f0f7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["91a3609ac9a09ca0c8eee1b765401bbdacaceaf8"],"63639dd66fd5bd9b90bc24dd596ae01575f27cc4":["9454a6510e2db155fb01faa5c049b06ece95fab9","dfd4d352ddf04b37253ad97ce1aad1448253f0f7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"dfd4d352ddf04b37253ad97ce1aad1448253f0f7":["91a3609ac9a09ca0c8eee1b765401bbdacaceaf8","63639dd66fd5bd9b90bc24dd596ae01575f27cc4"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["b89678825b68eccaf09e6ab71675fc0b0af1e099","93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"91a3609ac9a09ca0c8eee1b765401bbdacaceaf8":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["0e7c2454a6a8237bfd0e953f5b940838408c9055","93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"63639dd66fd5bd9b90bc24dd596ae01575f27cc4":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["dfd4d352ddf04b37253ad97ce1aad1448253f0f7","63639dd66fd5bd9b90bc24dd596ae01575f27cc4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","63639dd66fd5bd9b90bc24dd596ae01575f27cc4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}