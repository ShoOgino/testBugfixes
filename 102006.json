{"path":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","commits":[{"id":"7bb889a868ab9d608bde8136f42ed7234a3a927b","date":1359393528,"type":0,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    final AbstractAnalysisFactory instance;\n    try {\n     instance = clazz.newInstance();\n    } catch (Exception e) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n    }\n    Version luceneMatchVersion = null;\n    Map<String,String> argMap = new HashMap<String,String>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                if (argName.equalsIgnoreCase(\"luceneMatchVersion\")) {\n                  try {\n                    luceneMatchVersion = Version.parseLeniently(argValue);\n                  } catch (IllegalArgumentException e) {\n                    throw new RuntimeException\n                        (\"Line #\" + lineno(stok) + \": Unrecognized luceneMatchVersion '\" + argValue + \"'\", e);\n                  }\n                } else {\n                  argMap.put(argName, argValue);\n                }\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n\n      instance.setLuceneMatchVersion\n          (null == luceneMatchVersion ? Version.LUCENE_CURRENT : luceneMatchVersion);\n      instance.init(argMap);\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"de522d9303bd67c8473a269a1319125d1f3700e0","date":1359477856,"type":0,"author":"Adrien Grand","isMerge":true,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    final AbstractAnalysisFactory instance;\n    try {\n     instance = clazz.newInstance();\n    } catch (Exception e) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n    }\n    Version luceneMatchVersion = null;\n    Map<String,String> argMap = new HashMap<String,String>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                if (argName.equalsIgnoreCase(\"luceneMatchVersion\")) {\n                  try {\n                    luceneMatchVersion = Version.parseLeniently(argValue);\n                  } catch (IllegalArgumentException e) {\n                    throw new RuntimeException\n                        (\"Line #\" + lineno(stok) + \": Unrecognized luceneMatchVersion '\" + argValue + \"'\", e);\n                  }\n                } else {\n                  argMap.put(argName, argValue);\n                }\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n\n      instance.setLuceneMatchVersion\n          (null == luceneMatchVersion ? Version.LUCENE_CURRENT : luceneMatchVersion);\n      instance.init(argMap);\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fda45bae072048ea73bab14187426f7d45a4cb08","date":1363505550,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    final AbstractAnalysisFactory instance;\n    try {\n     instance = clazz.newInstance();\n    } catch (Exception e) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n    }\n    Version luceneMatchVersion = null;\n    Map<String,String> argMap = new HashMap<String,String>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                if (argName.equalsIgnoreCase(\"luceneMatchVersion\")) {\n                  try {\n                    luceneMatchVersion = Version.parseLeniently(argValue);\n                  } catch (IllegalArgumentException e) {\n                    throw new RuntimeException\n                        (\"Line #\" + lineno(stok) + \": Unrecognized luceneMatchVersion '\" + argValue + \"'\", e);\n                  }\n                } else {\n                  argMap.put(argName, argValue);\n                }\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n\n      instance.setLuceneMatchVersion\n          (null == luceneMatchVersion ? Version.LUCENE_CURRENT : luceneMatchVersion);\n      instance.init(argMap);\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        if ( ! baseDir.isDirectory()) {\n          baseDir = new File(\".\").getAbsoluteFile();\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    final AbstractAnalysisFactory instance;\n    try {\n     instance = clazz.newInstance();\n    } catch (Exception e) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n    }\n    Version luceneMatchVersion = null;\n    Map<String,String> argMap = new HashMap<String,String>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                if (argName.equalsIgnoreCase(\"luceneMatchVersion\")) {\n                  try {\n                    luceneMatchVersion = Version.parseLeniently(argValue);\n                  } catch (IllegalArgumentException e) {\n                    throw new RuntimeException\n                        (\"Line #\" + lineno(stok) + \": Unrecognized luceneMatchVersion '\" + argValue + \"'\", e);\n                  }\n                } else {\n                  argMap.put(argName, argValue);\n                }\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n\n      instance.setLuceneMatchVersion\n          (null == luceneMatchVersion ? Version.LUCENE_CURRENT : luceneMatchVersion);\n      instance.init(argMap);\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57da959ec15bb701bd1d1bf3c613b69009ff4bfd","date":1364833800,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<String,String>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LUCENE_CURRENT.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        if ( ! baseDir.isDirectory()) {\n          baseDir = new File(\".\").getAbsoluteFile();\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    final AbstractAnalysisFactory instance;\n    try {\n     instance = clazz.newInstance();\n    } catch (Exception e) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n    }\n    Version luceneMatchVersion = null;\n    Map<String,String> argMap = new HashMap<String,String>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                if (argName.equalsIgnoreCase(\"luceneMatchVersion\")) {\n                  try {\n                    luceneMatchVersion = Version.parseLeniently(argValue);\n                  } catch (IllegalArgumentException e) {\n                    throw new RuntimeException\n                        (\"Line #\" + lineno(stok) + \": Unrecognized luceneMatchVersion '\" + argValue + \"'\", e);\n                  }\n                } else {\n                  argMap.put(argName, argValue);\n                }\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n\n      instance.setLuceneMatchVersion\n          (null == luceneMatchVersion ? Version.LUCENE_CURRENT : luceneMatchVersion);\n      instance.init(argMap);\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        if ( ! baseDir.isDirectory()) {\n          baseDir = new File(\".\").getAbsoluteFile();\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LUCENE_CURRENT.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        if ( ! baseDir.isDirectory()) {\n          baseDir = new File(\".\").getAbsoluteFile();\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<String,String>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LUCENE_CURRENT.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        if ( ! baseDir.isDirectory()) {\n          baseDir = new File(\".\").getAbsoluteFile();\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"057a1793765d068ea9302f1a29e21734ee58d41e","date":1408130117,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        if ( ! baseDir.isDirectory()) {\n          baseDir = new File(\".\").getAbsoluteFile();\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LUCENE_CURRENT.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        if ( ! baseDir.isDirectory()) {\n          baseDir = new File(\".\").getAbsoluteFile();\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        Path baseDir = Paths.get(getRunData().getConfig().get(\"work.dir\", \"work\"));\n        if (!Files.isDirectory(baseDir)) {\n          baseDir = Paths.get(\".\");\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        File baseDir = new File(getRunData().getConfig().get(\"work.dir\", \"work\")).getAbsoluteFile();\n        if ( ! baseDir.isDirectory()) {\n          baseDir = new File(\".\").getAbsoluteFile();\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dc707eb4c159b3029aac235f5f36bb3c7b58ee4","date":1439660917,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  @SuppressWarnings(\"fallthrough\")\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        Path baseDir = Paths.get(getRunData().getConfig().get(\"work.dir\", \"work\"));\n        if (!Files.isDirectory(baseDir)) {\n          baseDir = Paths.get(\".\");\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        Path baseDir = Paths.get(getRunData().getConfig().get(\"work.dir\", \"work\"));\n        if (!Files.isDirectory(baseDir)) {\n          baseDir = Paths.get(\".\");\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","date":1574619880,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  @SuppressWarnings({\"fallthrough\", \"deprecation\"})\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        Path baseDir = Paths.get(getRunData().getConfig().get(\"work.dir\", \"work\"));\n        if (!Files.isDirectory(baseDir)) {\n          baseDir = Paths.get(\".\");\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  @SuppressWarnings(\"fallthrough\")\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        Path baseDir = Paths.get(getRunData().getConfig().get(\"work.dir\", \"work\"));\n        if (!Files.isDirectory(baseDir)) {\n          baseDir = Paths.get(\".\");\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9c3baacabd473e8ecd6c4948aabacead49b88e","date":1574700980,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","pathOld":"lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask#createAnalysisPipelineComponent(StreamTokenizer,Class[#-extends-AbstractAnalysisFactory]).mjava","sourceNew":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  @SuppressWarnings(\"fallthrough\")\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        Path baseDir = Paths.get(getRunData().getConfig().get(\"work.dir\", \"work\"));\n        if (!Files.isDirectory(baseDir)) {\n          baseDir = Paths.get(\".\");\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","sourceOld":"  /**\n   * Instantiates the given analysis factory class after pulling params from\n   * the given stream tokenizer, then stores the result in the appropriate\n   * pipeline component list.\n   *\n   * @param stok stream tokenizer from which to draw analysis factory params\n   * @param clazz analysis factory class to instantiate\n   */\n  @SuppressWarnings({\"fallthrough\", \"deprecation\"})\n  private void createAnalysisPipelineComponent\n      (StreamTokenizer stok, Class<? extends AbstractAnalysisFactory> clazz) {\n    Map<String,String> argMap = new HashMap<>();\n    boolean parenthetical = false;\n    try {\n      WHILE_LOOP: while (stok.nextToken() != StreamTokenizer.TT_EOF) {\n        switch (stok.ttype) {\n          case ',': {\n            if (parenthetical) {\n              // Do nothing\n              break;\n            } else {\n              // Finished reading this analysis factory configuration\n              break WHILE_LOOP;\n            }\n          }\n          case '(': {\n            if (parenthetical) {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected opening parenthesis.\");\n            }\n            parenthetical = true;\n            break;\n          }\n          case ')': {\n            if (parenthetical) {\n              parenthetical = false;\n            } else {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Unexpected closing parenthesis.\");\n            }\n            break;\n          }\n          case StreamTokenizer.TT_WORD: {\n            if ( ! parenthetical) {\n              throw new RuntimeException(\"Line #\" + lineno(stok) + \": Unexpected token '\" + stok.sval + \"'\");\n            }\n            String argName = stok.sval;\n            stok.nextToken();\n            if (stok.ttype != ':') {\n              throw new RuntimeException\n                  (\"Line #\" + lineno(stok) + \": Missing ':' after '\" + argName + \"' param to \" + clazz.getSimpleName());\n            }\n            stok.nextToken();\n            String argValue = stok.sval;\n            switch (stok.ttype) {\n              case StreamTokenizer.TT_NUMBER: {\n                  argValue = Double.toString(stok.nval);\n                  // Drop the \".0\" from numbers, for integer arguments\n                  argValue = TRAILING_DOT_ZERO_PATTERN.matcher(argValue).replaceFirst(\"\");\n                  // Intentional fall-through\n              }\n              case '\"':\n              case '\\'':\n              case StreamTokenizer.TT_WORD: {\n                argMap.put(argName, argValue);\n                break;\n              }\n              case StreamTokenizer.TT_EOF: {\n                throw new RuntimeException(\"Unexpected EOF: \" + stok.toString());\n              }\n              default: {\n                throw new RuntimeException\n                    (\"Line #\" + lineno(stok) + \": Unexpected token: \" + stok.toString());\n              }\n            }\n          }\n        }\n      }\n      if (!argMap.containsKey(\"luceneMatchVersion\")) {\n        argMap.put(\"luceneMatchVersion\", Version.LATEST.toString());\n      }\n      final AbstractAnalysisFactory instance;\n      try {\n        instance = clazz.getConstructor(Map.class).newInstance(argMap);\n      } catch (Exception e) {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n      if (instance instanceof ResourceLoaderAware) {\n        Path baseDir = Paths.get(getRunData().getConfig().get(\"work.dir\", \"work\"));\n        if (!Files.isDirectory(baseDir)) {\n          baseDir = Paths.get(\".\");\n        }\n        ((ResourceLoaderAware)instance).inform(new FilesystemResourceLoader(baseDir));\n      }\n      if (CharFilterFactory.class.isAssignableFrom(clazz)) {\n        charFilterFactories.add((CharFilterFactory)instance);\n      } else if (TokenizerFactory.class.isAssignableFrom(clazz)) {\n        tokenizerFactory = (TokenizerFactory)instance;\n      } else if (TokenFilterFactory.class.isAssignableFrom(clazz)) {\n        tokenFilterFactories.add((TokenFilterFactory)instance);\n      }\n    } catch (RuntimeException e) {\n      if (e.getMessage().startsWith(\"Line #\")) {\n        throw (e);\n      } else {\n        throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", e);\n      }\n    } catch (Throwable t) {\n      throw new RuntimeException(\"Line #\" + lineno(stok) + \": \", t);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["57da959ec15bb701bd1d1bf3c613b69009ff4bfd"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["3dc707eb4c159b3029aac235f5f36bb3c7b58ee4"],"fda45bae072048ea73bab14187426f7d45a4cb08":["7bb889a868ab9d608bde8136f42ed7234a3a927b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"7bb889a868ab9d608bde8136f42ed7234a3a927b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3dc707eb4c159b3029aac235f5f36bb3c7b58ee4":["f4abec28b874149a7223e32cc7a01704c27790de"],"57da959ec15bb701bd1d1bf3c613b69009ff4bfd":["fda45bae072048ea73bab14187426f7d45a4cb08"],"f4abec28b874149a7223e32cc7a01704c27790de":["057a1793765d068ea9302f1a29e21734ee58d41e"],"057a1793765d068ea9302f1a29e21734ee58d41e":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"de522d9303bd67c8473a269a1319125d1f3700e0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7bb889a868ab9d608bde8136f42ed7234a3a927b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["057a1793765d068ea9302f1a29e21734ee58d41e"],"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"fda45bae072048ea73bab14187426f7d45a4cb08":["57da959ec15bb701bd1d1bf3c613b69009ff4bfd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7bb889a868ab9d608bde8136f42ed7234a3a927b","de522d9303bd67c8473a269a1319125d1f3700e0"],"7bb889a868ab9d608bde8136f42ed7234a3a927b":["fda45bae072048ea73bab14187426f7d45a4cb08","de522d9303bd67c8473a269a1319125d1f3700e0"],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3dc707eb4c159b3029aac235f5f36bb3c7b58ee4":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"57da959ec15bb701bd1d1bf3c613b69009ff4bfd":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"f4abec28b874149a7223e32cc7a01704c27790de":["3dc707eb4c159b3029aac235f5f36bb3c7b58ee4"],"057a1793765d068ea9302f1a29e21734ee58d41e":["f4abec28b874149a7223e32cc7a01704c27790de"],"de522d9303bd67c8473a269a1319125d1f3700e0":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["de522d9303bd67c8473a269a1319125d1f3700e0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}