{"path":"lucene/src/java/org/apache/lucene/search/FieldCacheImpl.DocTermsCache#createValue(AtomicIndexReader,Entry,boolean).mjava","commits":[{"id":"2725b2d479964ea5aaea0ba4ae2634716f3ec26c","date":1327188170,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/FieldCacheImpl.DocTermsCache#createValue(AtomicIndexReader,Entry,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/FieldCacheImpl.DocTermsCache#createValue(IndexReader,Entry,boolean).mjava","sourceNew":"    @Override\n    protected Object createValue(AtomicIndexReader reader, Entry entryKey, boolean setDocsWithField /* ignored */)\n        throws IOException {\n\n      Terms terms = reader.terms(entryKey.field);\n\n      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();\n\n      final int termCountHardLimit = reader.maxDoc();\n\n      // Holds the actual term data, expanded.\n      final PagedBytes bytes = new PagedBytes(15);\n\n      int startBPV;\n\n      if (terms != null) {\n        // Try for coarse estimate for number of bits; this\n        // should be an underestimate most of the time, which\n        // is fine -- GrowableWriter will reallocate as needed\n        long numUniqueTerms = 0;\n        try {\n          numUniqueTerms = terms.getUniqueTermCount();\n        } catch (UnsupportedOperationException uoe) {\n          numUniqueTerms = -1;\n        }\n        if (numUniqueTerms != -1) {\n          if (numUniqueTerms > termCountHardLimit) {\n            numUniqueTerms = termCountHardLimit;\n          }\n          startBPV = PackedInts.bitsRequired(numUniqueTerms*4);\n        } else {\n          startBPV = 1;\n        }\n      } else {\n        startBPV = 1;\n      }\n\n      final GrowableWriter docToOffset = new GrowableWriter(startBPV, reader.maxDoc(), fasterButMoreRAM);\n      \n      // pointer==0 means not set\n      bytes.copyUsingLengthPrefix(new BytesRef());\n\n      if (terms != null) {\n        int termCount = 0;\n        final TermsEnum termsEnum = terms.iterator(null);\n        DocsEnum docs = null;\n        while(true) {\n          if (termCount++ == termCountHardLimit) {\n            // app is misusing the API (there is more than\n            // one term per doc); in this case we make best\n            // effort to load what we can (see LUCENE-2142)\n            break;\n          }\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n          final long pointer = bytes.copyUsingLengthPrefix(term);\n          docs = termsEnum.docs(null, docs, false);\n          while (true) {\n            final int docID = docs.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            docToOffset.set(docID, pointer);\n          }\n        }\n      }\n\n      // maybe an int-only impl?\n      return new DocTermsImpl(bytes.freeze(true), docToOffset.getMutable());\n    }\n\n","sourceOld":"    @Override\n    protected Object createValue(IndexReader reader, Entry entryKey, boolean setDocsWithField /* ignored */)\n        throws IOException {\n\n      Terms terms = reader.terms(entryKey.field);\n\n      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();\n\n      final int termCountHardLimit = reader.maxDoc();\n\n      // Holds the actual term data, expanded.\n      final PagedBytes bytes = new PagedBytes(15);\n\n      int startBPV;\n\n      if (terms != null) {\n        // Try for coarse estimate for number of bits; this\n        // should be an underestimate most of the time, which\n        // is fine -- GrowableWriter will reallocate as needed\n        long numUniqueTerms = 0;\n        try {\n          numUniqueTerms = terms.getUniqueTermCount();\n        } catch (UnsupportedOperationException uoe) {\n          numUniqueTerms = -1;\n        }\n        if (numUniqueTerms != -1) {\n          if (numUniqueTerms > termCountHardLimit) {\n            numUniqueTerms = termCountHardLimit;\n          }\n          startBPV = PackedInts.bitsRequired(numUniqueTerms*4);\n        } else {\n          startBPV = 1;\n        }\n      } else {\n        startBPV = 1;\n      }\n\n      final GrowableWriter docToOffset = new GrowableWriter(startBPV, reader.maxDoc(), fasterButMoreRAM);\n      \n      // pointer==0 means not set\n      bytes.copyUsingLengthPrefix(new BytesRef());\n\n      if (terms != null) {\n        int termCount = 0;\n        final TermsEnum termsEnum = terms.iterator(null);\n        DocsEnum docs = null;\n        while(true) {\n          if (termCount++ == termCountHardLimit) {\n            // app is misusing the API (there is more than\n            // one term per doc); in this case we make best\n            // effort to load what we can (see LUCENE-2142)\n            break;\n          }\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n          final long pointer = bytes.copyUsingLengthPrefix(term);\n          docs = termsEnum.docs(null, docs, false);\n          while (true) {\n            final int docID = docs.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            docToOffset.set(docID, pointer);\n          }\n        }\n      }\n\n      // maybe an int-only impl?\n      return new DocTermsImpl(bytes.freeze(true), docToOffset.getMutable());\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da6d5ac19a80d65b1e864251f155d30960353b7e","date":1327881054,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/FieldCacheImpl.DocTermsCache#createValue(AtomicReader,Entry,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/FieldCacheImpl.DocTermsCache#createValue(AtomicIndexReader,Entry,boolean).mjava","sourceNew":"    @Override\n    protected Object createValue(AtomicReader reader, Entry entryKey, boolean setDocsWithField /* ignored */)\n        throws IOException {\n\n      Terms terms = reader.terms(entryKey.field);\n\n      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();\n\n      final int termCountHardLimit = reader.maxDoc();\n\n      // Holds the actual term data, expanded.\n      final PagedBytes bytes = new PagedBytes(15);\n\n      int startBPV;\n\n      if (terms != null) {\n        // Try for coarse estimate for number of bits; this\n        // should be an underestimate most of the time, which\n        // is fine -- GrowableWriter will reallocate as needed\n        long numUniqueTerms = 0;\n        try {\n          numUniqueTerms = terms.getUniqueTermCount();\n        } catch (UnsupportedOperationException uoe) {\n          numUniqueTerms = -1;\n        }\n        if (numUniqueTerms != -1) {\n          if (numUniqueTerms > termCountHardLimit) {\n            numUniqueTerms = termCountHardLimit;\n          }\n          startBPV = PackedInts.bitsRequired(numUniqueTerms*4);\n        } else {\n          startBPV = 1;\n        }\n      } else {\n        startBPV = 1;\n      }\n\n      final GrowableWriter docToOffset = new GrowableWriter(startBPV, reader.maxDoc(), fasterButMoreRAM);\n      \n      // pointer==0 means not set\n      bytes.copyUsingLengthPrefix(new BytesRef());\n\n      if (terms != null) {\n        int termCount = 0;\n        final TermsEnum termsEnum = terms.iterator(null);\n        DocsEnum docs = null;\n        while(true) {\n          if (termCount++ == termCountHardLimit) {\n            // app is misusing the API (there is more than\n            // one term per doc); in this case we make best\n            // effort to load what we can (see LUCENE-2142)\n            break;\n          }\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n          final long pointer = bytes.copyUsingLengthPrefix(term);\n          docs = termsEnum.docs(null, docs, false);\n          while (true) {\n            final int docID = docs.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            docToOffset.set(docID, pointer);\n          }\n        }\n      }\n\n      // maybe an int-only impl?\n      return new DocTermsImpl(bytes.freeze(true), docToOffset.getMutable());\n    }\n\n","sourceOld":"    @Override\n    protected Object createValue(AtomicIndexReader reader, Entry entryKey, boolean setDocsWithField /* ignored */)\n        throws IOException {\n\n      Terms terms = reader.terms(entryKey.field);\n\n      final boolean fasterButMoreRAM = ((Boolean) entryKey.custom).booleanValue();\n\n      final int termCountHardLimit = reader.maxDoc();\n\n      // Holds the actual term data, expanded.\n      final PagedBytes bytes = new PagedBytes(15);\n\n      int startBPV;\n\n      if (terms != null) {\n        // Try for coarse estimate for number of bits; this\n        // should be an underestimate most of the time, which\n        // is fine -- GrowableWriter will reallocate as needed\n        long numUniqueTerms = 0;\n        try {\n          numUniqueTerms = terms.getUniqueTermCount();\n        } catch (UnsupportedOperationException uoe) {\n          numUniqueTerms = -1;\n        }\n        if (numUniqueTerms != -1) {\n          if (numUniqueTerms > termCountHardLimit) {\n            numUniqueTerms = termCountHardLimit;\n          }\n          startBPV = PackedInts.bitsRequired(numUniqueTerms*4);\n        } else {\n          startBPV = 1;\n        }\n      } else {\n        startBPV = 1;\n      }\n\n      final GrowableWriter docToOffset = new GrowableWriter(startBPV, reader.maxDoc(), fasterButMoreRAM);\n      \n      // pointer==0 means not set\n      bytes.copyUsingLengthPrefix(new BytesRef());\n\n      if (terms != null) {\n        int termCount = 0;\n        final TermsEnum termsEnum = terms.iterator(null);\n        DocsEnum docs = null;\n        while(true) {\n          if (termCount++ == termCountHardLimit) {\n            // app is misusing the API (there is more than\n            // one term per doc); in this case we make best\n            // effort to load what we can (see LUCENE-2142)\n            break;\n          }\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n          final long pointer = bytes.copyUsingLengthPrefix(term);\n          docs = termsEnum.docs(null, docs, false);\n          while (true) {\n            final int docID = docs.nextDoc();\n            if (docID == DocsEnum.NO_MORE_DOCS) {\n              break;\n            }\n            docToOffset.set(docID, pointer);\n          }\n        }\n      }\n\n      // maybe an int-only impl?\n      return new DocTermsImpl(bytes.freeze(true), docToOffset.getMutable());\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"da6d5ac19a80d65b1e864251f155d30960353b7e":["2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"da6d5ac19a80d65b1e864251f155d30960353b7e":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817","2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["da6d5ac19a80d65b1e864251f155d30960353b7e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["da6d5ac19a80d65b1e864251f155d30960353b7e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}