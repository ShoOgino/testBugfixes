{"path":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","commits":[{"id":"3e8715d826e588419327562287d5d6a8040d63d6","date":1427987148,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","pathOld":"/dev/null","sourceNew":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms:\n          allowedMaxTerms = maxPrefixCount;\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["da2239d9d14a7d57574534378c9057d8c45bbb4c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d2638f781be724518ff6c2263d14a48cf6e68017","date":1427989059,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","pathOld":"/dev/null","sourceNew":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms:\n          allowedMaxTerms = maxPrefixCount;\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6b4eefaade8d3fbd38d87b84907a9d2e50cffbc","date":1429175938,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","sourceNew":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms, except for the empty string:\n          if (bounds[0].length == 0) {\n            allowedMaxTerms = Integer.MAX_VALUE;\n          } else {\n            allowedMaxTerms = maxPrefixCount;\n          }\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","sourceOld":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms:\n          allowedMaxTerms = maxPrefixCount;\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da2239d9d14a7d57574534378c9057d8c45bbb4c","date":1442937100,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","sourceNew":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-prefix terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms, except for the empty string:\n          if (bounds[0].length == 0) {\n            allowedMaxTerms = Integer.MAX_VALUE;\n          } else {\n            allowedMaxTerms = maxPrefixCount;\n          }\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n          if (commonPrefix == 0) {\n            int min;\n            if (minTerm.length == 0) {\n              min = 0;\n            } else {\n              min = minTerm.bytes[minTerm.offset] & 0xff;\n            }\n            int max;\n            if (maxTerm.length == 0) {\n              max = 0;\n            } else {\n              max = maxTerm.bytes[maxTerm.offset] & 0xff;\n            }\n            if (max > min) {\n              // When maxPrefixCount is small (< 16), each byte of the term can require more than one \"level\" of auto-prefixing:\n              // NOTE: this is still only approximate ... it's tricky to get a closed form max bound that's \"tight\"\n              allowedMaxTerms += MathUtil.log(max-min, maxPrefixCount);\n            }\n          }\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-prefix terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","sourceOld":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms, except for the empty string:\n          if (bounds[0].length == 0) {\n            allowedMaxTerms = Integer.MAX_VALUE;\n          } else {\n            allowedMaxTerms = maxPrefixCount;\n          }\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","bugFix":["3e8715d826e588419327562287d5d6a8040d63d6"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","date":1466407389,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","sourceNew":null,"sourceOld":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-prefix terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms, except for the empty string:\n          if (bounds[0].length == 0) {\n            allowedMaxTerms = Integer.MAX_VALUE;\n          } else {\n            allowedMaxTerms = maxPrefixCount;\n          }\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n          if (commonPrefix == 0) {\n            int min;\n            if (minTerm.length == 0) {\n              min = 0;\n            } else {\n              min = minTerm.bytes[minTerm.offset] & 0xff;\n            }\n            int max;\n            if (maxTerm.length == 0) {\n              max = 0;\n            } else {\n              max = maxTerm.bytes[maxTerm.offset] & 0xff;\n            }\n            if (max > min) {\n              // When maxPrefixCount is small (< 16), each byte of the term can require more than one \"level\" of auto-prefixing:\n              // NOTE: this is still only approximate ... it's tricky to get a closed form max bound that's \"tight\"\n              allowedMaxTerms += MathUtil.log(max-min, maxPrefixCount);\n            }\n          }\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-prefix terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6aaba221b22442bdf0ef28770c25fe259dfb3f55","date":1466496193,"type":4,"author":"Noble Paul","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","sourceNew":null,"sourceOld":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-prefix terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms, except for the empty string:\n          if (bounds[0].length == 0) {\n            allowedMaxTerms = Integer.MAX_VALUE;\n          } else {\n            allowedMaxTerms = maxPrefixCount;\n          }\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n          if (commonPrefix == 0) {\n            int min;\n            if (minTerm.length == 0) {\n              min = 0;\n            } else {\n              min = minTerm.bytes[minTerm.offset] & 0xff;\n            }\n            int max;\n            if (maxTerm.length == 0) {\n              max = 0;\n            } else {\n              max = maxTerm.bytes[maxTerm.offset] & 0xff;\n            }\n            if (max > min) {\n              // When maxPrefixCount is small (< 16), each byte of the term can require more than one \"level\" of auto-prefixing:\n              // NOTE: this is still only approximate ... it's tricky to get a closed form max bound that's \"tight\"\n              allowedMaxTerms += MathUtil.log(max-min, maxPrefixCount);\n            }\n          }\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-prefix terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms.VerifyAutoPrefixTerms#finish(int,int).mjava","sourceNew":null,"sourceOld":"    public void finish(int expectedNumHits, int maxPrefixCount) {\n\n      if (maxPrefixCount != -1) {\n        // Auto-prefix terms were used in this test\n        long allowedMaxTerms;\n\n        if (bounds.length == 1) {\n          // Simple prefix query: we should never see more than maxPrefixCount terms, except for the empty string:\n          if (bounds[0].length == 0) {\n            allowedMaxTerms = Integer.MAX_VALUE;\n          } else {\n            allowedMaxTerms = maxPrefixCount;\n          }\n        } else {\n          // Trickier: we need to allow for maxPrefixTerms for each different leading byte in the min and max:\n          assert bounds.length == 2;\n          BytesRef minTerm = bounds[0];\n          BytesRef maxTerm = bounds[1];\n\n          int commonPrefix = 0;\n          for(int i=0;i<minTerm.length && i<maxTerm.length;i++) {\n            if (minTerm.bytes[minTerm.offset+i] != maxTerm.bytes[maxTerm.offset+i]) {\n              commonPrefix = i;\n              break;\n            }\n          }\n\n          allowedMaxTerms = maxPrefixCount * (long) ((minTerm.length-commonPrefix) + (maxTerm.length-commonPrefix));\n          if (commonPrefix == 0) {\n            int min;\n            if (minTerm.length == 0) {\n              min = 0;\n            } else {\n              min = minTerm.bytes[minTerm.offset] & 0xff;\n            }\n            int max;\n            if (maxTerm.length == 0) {\n              max = 0;\n            } else {\n              max = maxTerm.bytes[maxTerm.offset] & 0xff;\n            }\n            if (max > min) {\n              // When maxPrefixCount is small (< 16), each byte of the term can require more than one \"level\" of auto-prefixing:\n              // NOTE: this is still only approximate ... it's tricky to get a closed form max bound that's \"tight\"\n              allowedMaxTerms += MathUtil.log(max-min, maxPrefixCount);\n            }\n          }\n        }\n\n        assertTrue(\"totTermCount=\" + totTermCount + \" is > allowedMaxTerms=\" + allowedMaxTerms, totTermCount <= allowedMaxTerms);\n      }\n\n      assertEquals(expectedNumHits, allHits.cardinality());\n      int sum = 0;\n      for(Map.Entry<BytesRef,Integer> ent : prefixCounts.entrySet()) {\n\n        BytesRef prefix = ent.getKey();\n        if (VERBOSE) {\n          System.out.println(\"  verify prefix=\" + TestUtil.bytesRefToString(prefix) + \" count=\" + ent.getValue());\n        }\n\n        if (maxPrefixCount != -1) {\n          // Auto-prefix terms were used in this test\n\n          int sumLeftoverSuffix = 0;\n          for(BytesRef bound : bounds) {\n\n            int minSharedLength = Math.min(bound.length, prefix.length);\n            int commonPrefix = minSharedLength;\n            for(int i=0;i<minSharedLength;i++) {\n              if (bound.bytes[bound.offset+i] != prefix.bytes[prefix.offset+i]) {\n                commonPrefix = i;\n                break;\n              }\n            }\n            sumLeftoverSuffix += bound.length - commonPrefix;\n          }\n\n          long limit = (1+sumLeftoverSuffix) * (long) maxPrefixCount;\n\n          assertTrue(\"maxPrefixCount=\" + maxPrefixCount + \" prefix=\" + prefix + \" sumLeftoverSuffix=\" + sumLeftoverSuffix + \" limit=\" + limit + \" vs actual=\" +ent.getValue(),\n                     ent.getValue() <= limit);\n        }\n\n        sum += ent.getValue();\n      }\n\n      // Make sure no test bug:\n      assertEquals(totPrefixCount, sum);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["da2239d9d14a7d57574534378c9057d8c45bbb4c","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["da2239d9d14a7d57574534378c9057d8c45bbb4c"],"b6b4eefaade8d3fbd38d87b84907a9d2e50cffbc":["3e8715d826e588419327562287d5d6a8040d63d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d2638f781be724518ff6c2263d14a48cf6e68017":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3e8715d826e588419327562287d5d6a8040d63d6"],"3e8715d826e588419327562287d5d6a8040d63d6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"da2239d9d14a7d57574534378c9057d8c45bbb4c":["b6b4eefaade8d3fbd38d87b84907a9d2e50cffbc"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["da2239d9d14a7d57574534378c9057d8c45bbb4c","6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"]},"commit2Childs":{"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"b6b4eefaade8d3fbd38d87b84907a9d2e50cffbc":["da2239d9d14a7d57574534378c9057d8c45bbb4c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d2638f781be724518ff6c2263d14a48cf6e68017","3e8715d826e588419327562287d5d6a8040d63d6"],"d2638f781be724518ff6c2263d14a48cf6e68017":[],"3e8715d826e588419327562287d5d6a8040d63d6":["b6b4eefaade8d3fbd38d87b84907a9d2e50cffbc","d2638f781be724518ff6c2263d14a48cf6e68017"],"da2239d9d14a7d57574534378c9057d8c45bbb4c":["6aaba221b22442bdf0ef28770c25fe259dfb3f55","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d2638f781be724518ff6c2263d14a48cf6e68017","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}