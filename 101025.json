{"path":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","commits":[{"id":"79759974460bc59933cd169acc94f5c6b16368d5","date":1471318443,"type":1,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","date":1471496851,"type":1,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8220da23feaeb400771f18161c4965dea5ab4cd","date":1530366342,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n    if (fcontext.isShard()) {\n      response.add(\"more\", shardHasMoreBuckets);  // lazily evaluated\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n    if (fcontext.isShard()) {\n      response.add(\"more\", shardHasMoreBuckets);  // lazily evaluated\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n    if (fcontext.isShard()) {\n      response.add(\"more\", shardHasMoreBuckets);  // lazily evaluated\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56a9893014b284af4d1af451e6c02e7ffdf5b6e","date":1590065972,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"rawtypes\"})\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n    if (fcontext.isShard()) {\n      response.add(\"more\", shardHasMoreBuckets);  // lazily evaluated\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n    if (fcontext.isShard()) {\n      response.add(\"more\", shardHasMoreBuckets);  // lazily evaluated\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a56a9893014b284af4d1af451e6c02e7ffdf5b6e":["e8220da23feaeb400771f18161c4965dea5ab4cd"],"e8220da23feaeb400771f18161c4965dea5ab4cd":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["403d05f7f8d69b65659157eff1bc1d2717f04c66","e8220da23feaeb400771f18161c4965dea5ab4cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","79759974460bc59933cd169acc94f5c6b16368d5"],"79759974460bc59933cd169acc94f5c6b16368d5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a56a9893014b284af4d1af451e6c02e7ffdf5b6e"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["403d05f7f8d69b65659157eff1bc1d2717f04c66","e8220da23feaeb400771f18161c4965dea5ab4cd"]},"commit2Childs":{"a56a9893014b284af4d1af451e6c02e7ffdf5b6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e8220da23feaeb400771f18161c4965dea5ab4cd":["a56a9893014b284af4d1af451e6c02e7ffdf5b6e","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["e8220da23feaeb400771f18161c4965dea5ab4cd","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["403d05f7f8d69b65659157eff1bc1d2717f04c66","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","79759974460bc59933cd169acc94f5c6b16368d5","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"79759974460bc59933cd169acc94f5c6b16368d5":["2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}