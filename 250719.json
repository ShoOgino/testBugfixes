{"path":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    files = new ArrayList<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for (String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS)\n        addIfExists(files, IndexFileNames.segmentFileName(name, ext));\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(files, IndexFileNames.segmentFileName(docStoreSegment, ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(files, IndexFileNames.segmentFileName(name, ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      files.add(delFileName);\n    }\n\n    // Careful logic for norms files    \n    if (normGen != null) {\n      for(int i=0;i<normGen.length;i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        } else if (NO == gen) {\n          // No separate norms but maybe plain norms\n          // in the non compound file case:\n          if (!hasSingleNormFile && !useCompoundFile) {\n            String fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n            if (dir.fileExists(fileName)) {\n              files.add(fileName);\n            }\n          }\n        } else if (CHECK_DIR == gen) {\n          // Pre-2.1: we have to check file existence\n          String fileName = null;\n          if (useCompoundFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i);\n          } else if (!hasSingleNormFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n          }\n          if (fileName != null && dir.fileExists(fileName)) {\n            files.add(fileName);\n          }\n        }\n      }\n    } else if (preLockless || (!hasSingleNormFile && !useCompoundFile)) {\n      // Pre-2.1: we have to scan the dir to find all\n      // matching _X.sN/_X.fN files for our segment:\n      String prefix;\n      if (useCompoundFile)\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION);\n      else\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION);\n      int prefixLength = prefix.length();\n      String[] allFiles = dir.listAll();\n      final IndexFileNameFilter filter = IndexFileNameFilter.getFilter();\n      for(int i=0;i<allFiles.length;i++) {\n        String fileName = allFiles[i];\n        if (filter.accept(null, fileName) && fileName.length() > prefixLength && Character.isDigit(fileName.charAt(prefixLength)) && fileName.startsWith(prefix)) {\n          files.add(fileName);\n        }\n      }\n    }\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    files = new ArrayList<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for (String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS)\n        addIfExists(files, IndexFileNames.segmentFileName(name, ext));\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(files, IndexFileNames.segmentFileName(docStoreSegment, ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(files, IndexFileNames.segmentFileName(name, ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      files.add(delFileName);\n    }\n\n    // Careful logic for norms files    \n    if (normGen != null) {\n      for(int i=0;i<normGen.length;i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        } else if (NO == gen) {\n          // No separate norms but maybe plain norms\n          // in the non compound file case:\n          if (!hasSingleNormFile && !useCompoundFile) {\n            String fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n            if (dir.fileExists(fileName)) {\n              files.add(fileName);\n            }\n          }\n        } else if (CHECK_DIR == gen) {\n          // Pre-2.1: we have to check file existence\n          String fileName = null;\n          if (useCompoundFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i);\n          } else if (!hasSingleNormFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n          }\n          if (fileName != null && dir.fileExists(fileName)) {\n            files.add(fileName);\n          }\n        }\n      }\n    } else if (preLockless || (!hasSingleNormFile && !useCompoundFile)) {\n      // Pre-2.1: we have to scan the dir to find all\n      // matching _X.sN/_X.fN files for our segment:\n      String prefix;\n      if (useCompoundFile)\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION);\n      else\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION);\n      int prefixLength = prefix.length();\n      String[] allFiles = dir.listAll();\n      final IndexFileNameFilter filter = IndexFileNameFilter.getFilter();\n      for(int i=0;i<allFiles.length;i++) {\n        String fileName = allFiles[i];\n        if (filter.accept(null, fileName) && fileName.length() > prefixLength && Character.isDigit(fileName.charAt(prefixLength)) && fileName.startsWith(prefix)) {\n          files.add(fileName);\n        }\n      }\n    }\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // Careful logic for norms files    \n    if (normGen != null) {\n      for(int i=0;i<normGen.length;i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        } else if (NO == gen) {\n          // No separate norms but maybe plain norms\n          // in the non compound file case:\n          if (!hasSingleNormFile && !useCompoundFile) {\n            String fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n            if (dir.fileExists(fileName)) {\n              fileSet.add(fileName);\n            }\n          }\n        } else if (CHECK_DIR == gen) {\n          // Pre-2.1: we have to check file existence\n          String fileName = null;\n          if (useCompoundFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i);\n          } else if (!hasSingleNormFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n          }\n          if (fileName != null && dir.fileExists(fileName)) {\n            fileSet.add(fileName);\n          }\n        }\n      }\n    } else if (preLockless || (!hasSingleNormFile && !useCompoundFile)) {\n      // Pre-2.1: we have to scan the dir to find all\n      // matching _X.sN/_X.fN files for our segment:\n      String prefix;\n      if (useCompoundFile) {\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION);\n      } else {\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION);\n      }\n      final String pattern = prefix + \"\\\\d+\";\n\n      String[] allFiles = dir.listAll();\n      for(int i=0;i<allFiles.length;i++) {\n        String fileName = allFiles[i];\n        if (fileName.matches(pattern)) {\n          fileSet.add(fileName);\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    files = new ArrayList<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for (String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS)\n        addIfExists(files, IndexFileNames.segmentFileName(name, ext));\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(files, IndexFileNames.segmentFileName(docStoreSegment, ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(files, IndexFileNames.segmentFileName(name, ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      files.add(delFileName);\n    }\n\n    // Careful logic for norms files    \n    if (normGen != null) {\n      for(int i=0;i<normGen.length;i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        } else if (NO == gen) {\n          // No separate norms but maybe plain norms\n          // in the non compound file case:\n          if (!hasSingleNormFile && !useCompoundFile) {\n            String fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n            if (dir.fileExists(fileName)) {\n              files.add(fileName);\n            }\n          }\n        } else if (CHECK_DIR == gen) {\n          // Pre-2.1: we have to check file existence\n          String fileName = null;\n          if (useCompoundFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i);\n          } else if (!hasSingleNormFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n          }\n          if (fileName != null && dir.fileExists(fileName)) {\n            files.add(fileName);\n          }\n        }\n      }\n    } else if (preLockless || (!hasSingleNormFile && !useCompoundFile)) {\n      // Pre-2.1: we have to scan the dir to find all\n      // matching _X.sN/_X.fN files for our segment:\n      String prefix;\n      if (useCompoundFile)\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION);\n      else\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION);\n      int prefixLength = prefix.length();\n      String[] allFiles = dir.listAll();\n      final IndexFileNameFilter filter = IndexFileNameFilter.getFilter();\n      for(int i=0;i<allFiles.length;i++) {\n        String fileName = allFiles[i];\n        if (filter.accept(null, fileName) && fileName.length() > prefixLength && Character.isDigit(fileName.charAt(prefixLength)) && fileName.startsWith(prefix)) {\n          files.add(fileName);\n        }\n      }\n    }\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb10b6bcde550b87d8f10e5f010bd8f3021023b6","date":1274974592,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // Careful logic for norms files    \n    if (normGen != null) {\n      for(int i=0;i<normGen.length;i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        } else if (NO == gen) {\n          // No separate norms but maybe plain norms\n          // in the non compound file case:\n          if (!hasSingleNormFile && !useCompoundFile) {\n            String fileName = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n            if (dir.fileExists(fileName)) {\n              fileSet.add(fileName);\n            }\n          }\n        } else if (CHECK_DIR == gen) {\n          // Pre-2.1: we have to check file existence\n          String fileName = null;\n          if (useCompoundFile) {\n            fileName = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.SEPARATE_NORMS_EXTENSION + i);\n          } else if (!hasSingleNormFile) {\n            fileName = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n          }\n          if (fileName != null && dir.fileExists(fileName)) {\n            fileSet.add(fileName);\n          }\n        }\n      }\n    } else if (preLockless || (!hasSingleNormFile && !useCompoundFile)) {\n      // Pre-2.1: we have to scan the dir to find all\n      // matching _X.sN/_X.fN files for our segment:\n      String prefix;\n      if (useCompoundFile) {\n        prefix = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.SEPARATE_NORMS_EXTENSION);\n      } else {\n        prefix = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.PLAIN_NORMS_EXTENSION);\n      }\n      final String pattern = prefix + \"\\\\d+\";\n\n      String[] allFiles = dir.listAll();\n      for(int i=0;i<allFiles.length;i++) {\n        String fileName = allFiles[i];\n        if (fileName.matches(pattern)) {\n          fileSet.add(fileName);\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // Careful logic for norms files    \n    if (normGen != null) {\n      for(int i=0;i<normGen.length;i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        } else if (NO == gen) {\n          // No separate norms but maybe plain norms\n          // in the non compound file case:\n          if (!hasSingleNormFile && !useCompoundFile) {\n            String fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n            if (dir.fileExists(fileName)) {\n              fileSet.add(fileName);\n            }\n          }\n        } else if (CHECK_DIR == gen) {\n          // Pre-2.1: we have to check file existence\n          String fileName = null;\n          if (useCompoundFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i);\n          } else if (!hasSingleNormFile) {\n            fileName = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n          }\n          if (fileName != null && dir.fileExists(fileName)) {\n            fileSet.add(fileName);\n          }\n        }\n      }\n    } else if (preLockless || (!hasSingleNormFile && !useCompoundFile)) {\n      // Pre-2.1: we have to scan the dir to find all\n      // matching _X.sN/_X.fN files for our segment:\n      String prefix;\n      if (useCompoundFile) {\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.SEPARATE_NORMS_EXTENSION);\n      } else {\n        prefix = IndexFileNames.segmentFileName(name, IndexFileNames.PLAIN_NORMS_EXTENSION);\n      }\n      final String pattern = prefix + \"\\\\d+\";\n\n      String[] allFiles = dir.listAll();\n      for(int i=0;i<allFiles.length;i++) {\n        String fileName = allFiles[i];\n        if (fileName.matches(pattern)) {\n          fileSet.add(fileName);\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6267e1ce56c2eec111425690cd04e251b6f14952","date":1275222352,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // Careful logic for norms files    \n    if (normGen != null) {\n      for(int i=0;i<normGen.length;i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        } else if (NO == gen) {\n          // No separate norms but maybe plain norms\n          // in the non compound file case:\n          if (!hasSingleNormFile && !useCompoundFile) {\n            String fileName = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n            if (dir.fileExists(fileName)) {\n              fileSet.add(fileName);\n            }\n          }\n        } else if (CHECK_DIR == gen) {\n          // Pre-2.1: we have to check file existence\n          String fileName = null;\n          if (useCompoundFile) {\n            fileName = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.SEPARATE_NORMS_EXTENSION + i);\n          } else if (!hasSingleNormFile) {\n            fileName = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.PLAIN_NORMS_EXTENSION + i);\n          }\n          if (fileName != null && dir.fileExists(fileName)) {\n            fileSet.add(fileName);\n          }\n        }\n      }\n    } else if (preLockless || (!hasSingleNormFile && !useCompoundFile)) {\n      // Pre-2.1: we have to scan the dir to find all\n      // matching _X.sN/_X.fN files for our segment:\n      String prefix;\n      if (useCompoundFile) {\n        prefix = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.SEPARATE_NORMS_EXTENSION);\n      } else {\n        prefix = IndexFileNames.segmentFileName(name, \"\", IndexFileNames.PLAIN_NORMS_EXTENSION);\n      }\n      final String pattern = prefix + \"\\\\d+\";\n\n      String[] allFiles = dir.listAll();\n      for(int i=0;i<allFiles.length;i++) {\n        String fileName = allFiles[i];\n        if (fileName.matches(pattern)) {\n          fileSet.add(fileName);\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01f60198ece724a6e96cd0b45f289cf42ff83d4f","date":1286864103,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n    //nocommit - is there a better way to get all the dat / idx files?\n    for(String file : dir.listAll()) {\n      if(file.startsWith(name) && (file.endsWith(\"dat\") || file.endsWith(\"idx\"))){\n        fileSet.add(file);\n      }\n    }\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e28c49f1fb6215a550fdadcf3805aa629b63ec0","date":1288081775,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n    //nocommit - is there a better way to get all the dat / idx files?\n    for(String file : dir.listAll()) {\n      if(file.startsWith(name) && (file.endsWith(\"dat\") || file.endsWith(\"idx\"))){\n        fileSet.add(file);\n      }\n    }\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a493e6d0c3ad86bd55c0a1360d110142e948f2bd","date":1289406991,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e1cbd7e289dc1243c7a59e1a83d078163a147fe","date":1292268032,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors == 1) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        } else if (hasVectors == 2) {\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }      \n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors == 1) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      } else if (hasVectors == 2) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5dd55ef4d8a74ff17963e786d91a8ddc54806cfa","date":1292347838,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors == 1) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        } else if (hasVectors == 2) {\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }      \n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors == 1) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      } else if (hasVectors == 2) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n          addIfExists(fileSet, IndexFileNames.segmentFileName(docStoreSegment, \"\", ext));\n      }\n    } else if (!useCompoundFile) {\n      for (String ext : IndexFileNames.STORE_INDEX_EXTENSIONS)\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0c7a8f7304b75b1528814c5820fa23a96816c27","date":1298314239,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ec33385f6fbb6ce172882d14605790418a5d31","date":1298910796,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1224a4027481acce15495b03bce9b48b93b42722","date":1300792329,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (int i = 0; i < normGen.length; i++) {\n        long gen = normGen[i];\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fe2fc74577855eadfb5eae3153c2fffdaaf791","date":1305237079,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n\n    Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n\n    if (files != null) {\n      // Already cached:\n      return files;\n    }\n    \n    Set<String> fileSet = new HashSet<String>();\n    \n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (hasVectors) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (hasVectors) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }      \n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e8d7ba2175f47e280231533f7d3016249cea88b","date":1307711934,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0aab6e810b4b0d3743d6a048be0602801f4b3920","date":1308671625,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"783841adc7a8e8fccf65036e753f660f059f39ae","date":1308748848,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"3.4\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"3.4\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"3.4\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"67aadace85f701c87a4e0721eedcda25d8415a70","date":1314201925,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"3.4\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      segmentCodecs.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.FIELDS_EXTENSION));\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_INDEX_EXTENSION));\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.FIELDS_EXTENSION));\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        if (getHasVectors()) {\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n          fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n        }\n      }\n    } else if (!useCompoundFile) {\n      if (getHasVectors()) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_INDEX_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_DOCUMENTS_EXTENSION));\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.VECTORS_FIELDS_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"091eda9854cc9e0ece4516ce6bc0bcac3a10226a","date":1323046561,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    // TODO: push this to codec?\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae7b1abd869bbf7d8ae72b0e7ae3852b363bb074","date":1323052749,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // because separate norm files are unconditionally stored outside cfs,\n    // we must explicitly ask for their filenames if we might have separate norms:\n    // remove this when 3.x indexes are no longer supported\n    if (normGen != null) {\n      codec.normsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    // TODO: push this to codec?\n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // because separate norm files are unconditionally stored outside cfs,\n    // we must explicitly ask for their filenames if we might have separate norms:\n    // remove this when 3.x indexes are no longer supported\n    if (normGen != null) {\n      codec.normsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // because separate norm files are unconditionally stored outside cfs,\n    // we must explicitly ask for their filenames if we might have separate norms:\n    // remove this when 3.x indexes are no longer supported\n    if (normGen != null) {\n      codec.normsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      for(String ext : IndexFileNames.NON_STORE_INDEX_EXTENSIONS) {\n        addIfExists(fileSet, IndexFileNames.segmentFileName(name, \"\", ext));\n      }\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n   \n    if (normGen != null) {\n      for (Entry<Integer,Long> entry : normGen.entrySet()) {\n        long gen = entry.getValue();\n        if (gen >= YES) {\n          // Definitely a separate norm file, with generation:\n          fileSet.add(IndexFileNames.fileNameFromGeneration(name, IndexFileNames.SEPARATE_NORMS_EXTENSION + entry.getKey(), gen));\n        }\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ee7817a665237cb0657ed2bd7ae2a2b91ce6aaf9","date":1327025939,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    // because deletions are stored outside CFS, we must check deletes here\n    // note: before the WTF logic was: delFileName != null && (hasDeletions() || fileExists(delFileName))... \n    if (hasDeletions()) {\n      codec.liveDocsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    // because separate norm files are unconditionally stored outside cfs,\n    // we must explicitly ask for their filenames if we might have separate norms:\n    // remove this when 3.x indexes are no longer supported\n    if (normGen != null) {\n      codec.normsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // because separate norm files are unconditionally stored outside cfs,\n    // we must explicitly ask for their filenames if we might have separate norms:\n    // remove this when 3.x indexes are no longer supported\n    if (normGen != null) {\n      codec.normsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c3b7e9f4d596b06859aafa44caeaa23b201e231","date":1327083022,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    // because deletions are stored outside CFS, we must check deletes here\n    // note: before the WTF logic was: delFileName != null && (hasDeletions() || fileExists(delFileName))... \n    if (hasDeletions()) {\n      codec.liveDocsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    // because separate norm files are unconditionally stored outside cfs,\n    // we must explicitly ask for their filenames if we might have separate norms:\n    // remove this when 3.x indexes are no longer supported\n    if (normGen != null) {\n      codec.normsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","date":1327836826,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // because separate norm files are unconditionally stored outside cfs,\n    // we must explicitly ask for their filenames if we might have separate norms:\n    // remove this when 3.x indexes are no longer supported\n    if (normGen != null) {\n      codec.normsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    String delFileName = IndexFileNames.fileNameFromGeneration(name, IndexFileNames.DELETES_EXTENSION, delGen);\n    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {\n      fileSet.add(delFileName);\n    }\n\n    // because separate norm files are unconditionally stored outside cfs,\n    // we must explicitly ask for their filenames if we might have separate norms:\n    // remove this when 3.x indexes are no longer supported\n    if (normGen != null) {\n      codec.normsFormat().separateFiles(dir, this, fileSet);\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e4eedfa4412feb41bebd1d683a30ae438ca27452","date":1327840352,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(dir, this, fileSet);\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"94178119d0991364aefca2b8e6dfe429a6843ad0","date":1327843096,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(dir, this, fileSet);\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(dir, this, fileSet);\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78977ccc47b451a8e645b77504e2ef0a05e4b1a3","date":1327846052,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(this, fileSet);\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(dir, this, fileSet);\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3","date":1327944832,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(this, fileSet);\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"296df632fd63421ea20756fa11ad36fbc6f4c8a9","date":1327957998,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"410e066f093e407222d9681429d209084e783149","date":1327958394,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    boolean useCompoundFile = getUseCompoundFile();\n\n    if (useCompoundFile) {\n      fileSet.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      if (version != null && StringHelper.getVersionComparator().compare(\"4.0\", version) <= 0) {\n        fileSet.add(IndexFileNames.segmentFileName(name, \"\",\n            IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n      }\n    } else {\n      codec.files(dir, this, fileSet);\n    }\n    \n    // regardless of compound file setting: these files are always in the directory\n    codec.separateFiles(dir, this, fileSet);\n\n    if (docStoreOffset != -1) {\n      // We are sharing doc stores (stored fields, term\n      // vectors) with other segments\n      assert docStoreSegment != null;\n      // TODO: push this out into preflex fieldsFormat?\n      if (docStoreIsCompoundFile) {\n        fileSet.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n    }\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentInfo#files().mjava","sourceNew":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","sourceOld":"  public List<String> files() throws IOException {\n    final long fisVersion = fieldInfosVersion;\n    if (fisVersion != (fieldInfosVersion = getFieldInfos().getVersion())) {\n      clearFilesCache(); // FIS has modifications - need to recompute\n    } else if (files != null) {\n      // Already cached:\n      return files;\n    }\n    final Set<String> fileSet = new HashSet<String>();\n\n    codec.files(this, fileSet);\n\n    files = new ArrayList<String>(fileSet);\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ee7817a665237cb0657ed2bd7ae2a2b91ce6aaf9":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"d3fe2fc74577855eadfb5eae3153c2fffdaaf791":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["3cc749c053615f5871f3b95715fe292f34e70a53","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["6267e1ce56c2eec111425690cd04e251b6f14952"],"783841adc7a8e8fccf65036e753f660f059f39ae":["0aab6e810b4b0d3743d6a048be0602801f4b3920"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["6267e1ce56c2eec111425690cd04e251b6f14952","5dd55ef4d8a74ff17963e786d91a8ddc54806cfa"],"94178119d0991364aefca2b8e6dfe429a6843ad0":["e4eedfa4412feb41bebd1d683a30ae438ca27452"],"14ec33385f6fbb6ce172882d14605790418a5d31":["b0c7a8f7304b75b1528814c5820fa23a96816c27"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["135621f3a0670a9394eb563224a3b76cc4dddc0f","d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["a3776dccca01c11e7046323cfad46a3b4a471233","2e8d7ba2175f47e280231533f7d3016249cea88b"],"06584e6e98d592b34e1329b384182f368d2025e8":["7b91922b55d15444d554721b352861d028eb8278"],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"2553b00f699380c64959ccb27991289aae87be2e":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","783841adc7a8e8fccf65036e753f660f059f39ae"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["2e8d7ba2175f47e280231533f7d3016249cea88b","783841adc7a8e8fccf65036e753f660f059f39ae"],"091eda9854cc9e0ece4516ce6bc0bcac3a10226a":["3cc749c053615f5871f3b95715fe292f34e70a53"],"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3":["78977ccc47b451a8e645b77504e2ef0a05e4b1a3"],"6267e1ce56c2eec111425690cd04e251b6f14952":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","1224a4027481acce15495b03bce9b48b93b42722"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1224a4027481acce15495b03bce9b48b93b42722","d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["3cc749c053615f5871f3b95715fe292f34e70a53","ae7b1abd869bbf7d8ae72b0e7ae3852b363bb074"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["3615ce4a1f785ae1b779244de52c6a7d99227e60","5c3b7e9f4d596b06859aafa44caeaa23b201e231"],"67aadace85f701c87a4e0721eedcda25d8415a70":["783841adc7a8e8fccf65036e753f660f059f39ae"],"e4eedfa4412feb41bebd1d683a30ae438ca27452":["5c3b7e9f4d596b06859aafa44caeaa23b201e231"],"5c3b7e9f4d596b06859aafa44caeaa23b201e231":["ee7817a665237cb0657ed2bd7ae2a2b91ce6aaf9"],"fd92b8bcc88e969302510acf77bd6970da3994c4":["3615ce4a1f785ae1b779244de52c6a7d99227e60","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"78977ccc47b451a8e645b77504e2ef0a05e4b1a3":["94178119d0991364aefca2b8e6dfe429a6843ad0"],"01f60198ece724a6e96cd0b45f289cf42ff83d4f":["6267e1ce56c2eec111425690cd04e251b6f14952"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["d3fe2fc74577855eadfb5eae3153c2fffdaaf791","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bde51b089eb7f86171eb3406e38a274743f9b7ac","1224a4027481acce15495b03bce9b48b93b42722"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ae7b1abd869bbf7d8ae72b0e7ae3852b363bb074":["091eda9854cc9e0ece4516ce6bc0bcac3a10226a"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"1224a4027481acce15495b03bce9b48b93b42722":["14ec33385f6fbb6ce172882d14605790418a5d31"],"410e066f093e407222d9681429d209084e783149":["fd92b8bcc88e969302510acf77bd6970da3994c4","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"85a883878c0af761245ab048babc63d099f835f3":["0e28c49f1fb6215a550fdadcf3805aa629b63ec0","a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"3cc749c053615f5871f3b95715fe292f34e70a53":["06584e6e98d592b34e1329b384182f368d2025e8"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["1224a4027481acce15495b03bce9b48b93b42722","c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["85a883878c0af761245ab048babc63d099f835f3","5dd55ef4d8a74ff17963e786d91a8ddc54806cfa"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"7b91922b55d15444d554721b352861d028eb8278":["67aadace85f701c87a4e0721eedcda25d8415a70"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["5dd55ef4d8a74ff17963e786d91a8ddc54806cfa"],"5dd55ef4d8a74ff17963e786d91a8ddc54806cfa":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"0e28c49f1fb6215a550fdadcf3805aa629b63ec0":["01f60198ece724a6e96cd0b45f289cf42ff83d4f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"ee7817a665237cb0657ed2bd7ae2a2b91ce6aaf9":["5c3b7e9f4d596b06859aafa44caeaa23b201e231"],"d3fe2fc74577855eadfb5eae3153c2fffdaaf791":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","a3776dccca01c11e7046323cfad46a3b4a471233","2e8d7ba2175f47e280231533f7d3016249cea88b"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe","85a883878c0af761245ab048babc63d099f835f3"],"783841adc7a8e8fccf65036e753f660f059f39ae":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","67aadace85f701c87a4e0721eedcda25d8415a70"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"94178119d0991364aefca2b8e6dfe429a6843ad0":["78977ccc47b451a8e645b77504e2ef0a05e4b1a3"],"14ec33385f6fbb6ce172882d14605790418a5d31":["1224a4027481acce15495b03bce9b48b93b42722"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["2553b00f699380c64959ccb27991289aae87be2e"],"06584e6e98d592b34e1329b384182f368d2025e8":["3cc749c053615f5871f3b95715fe292f34e70a53"],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["783841adc7a8e8fccf65036e753f660f059f39ae"],"2553b00f699380c64959ccb27991289aae87be2e":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"091eda9854cc9e0ece4516ce6bc0bcac3a10226a":["ae7b1abd869bbf7d8ae72b0e7ae3852b363bb074"],"be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"6267e1ce56c2eec111425690cd04e251b6f14952":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","01f60198ece724a6e96cd0b45f289cf42ff83d4f"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ee7817a665237cb0657ed2bd7ae2a2b91ce6aaf9","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","fd92b8bcc88e969302510acf77bd6970da3994c4"],"c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31":["fd92b8bcc88e969302510acf77bd6970da3994c4","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"e4eedfa4412feb41bebd1d683a30ae438ca27452":["94178119d0991364aefca2b8e6dfe429a6843ad0"],"67aadace85f701c87a4e0721eedcda25d8415a70":["7b91922b55d15444d554721b352861d028eb8278"],"5c3b7e9f4d596b06859aafa44caeaa23b201e231":["c9f2d6bb11ccaac366d9b7652b2feb0c715d9c31","e4eedfa4412feb41bebd1d683a30ae438ca27452"],"fd92b8bcc88e969302510acf77bd6970da3994c4":["410e066f093e407222d9681429d209084e783149"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"78977ccc47b451a8e645b77504e2ef0a05e4b1a3":["be9e3e7d2fc880996ffcfe9a8fc47057b647e9e3"],"01f60198ece724a6e96cd0b45f289cf42ff83d4f":["0e28c49f1fb6215a550fdadcf3805aa629b63ec0"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","0aab6e810b4b0d3743d6a048be0602801f4b3920","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ae7b1abd869bbf7d8ae72b0e7ae3852b363bb074":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["5dd55ef4d8a74ff17963e786d91a8ddc54806cfa"],"1224a4027481acce15495b03bce9b48b93b42722":["d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"410e066f093e407222d9681429d209084e783149":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"85a883878c0af761245ab048babc63d099f835f3":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["d3fe2fc74577855eadfb5eae3153c2fffdaaf791","135621f3a0670a9394eb563224a3b76cc4dddc0f"],"3cc749c053615f5871f3b95715fe292f34e70a53":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","091eda9854cc9e0ece4516ce6bc0bcac3a10226a","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","410e066f093e407222d9681429d209084e783149"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["6267e1ce56c2eec111425690cd04e251b6f14952"],"7b91922b55d15444d554721b352861d028eb8278":["06584e6e98d592b34e1329b384182f368d2025e8"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["14ec33385f6fbb6ce172882d14605790418a5d31","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"5dd55ef4d8a74ff17963e786d91a8ddc54806cfa":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ab5cb6a74aefb78aa0569857970b9151dfe2e787","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"0e28c49f1fb6215a550fdadcf3805aa629b63ec0":["85a883878c0af761245ab048babc63d099f835f3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","410e066f093e407222d9681429d209084e783149","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}