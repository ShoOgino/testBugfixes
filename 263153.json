{"path":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillShingleBuffer().mjava","commits":[{"id":"0dda87e5ad7246b25d0da56a16ead95360499d86","date":1249273990,"type":1,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillShingleBuffer().mjava","pathOld":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillOutputBuf(Token).mjava","sourceNew":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private boolean fillShingleBuffer() throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      if (getNextToken()) {\n        shingleBuf.add(captureState());\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.remove(0);\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n    \n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      shingleBuf.remove(0);\n    }\n    \n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n\n    clearShingles();\n\n    endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    for (Iterator it = shingleBuf.iterator(); it.hasNext(); ) {\n      restoreState((AttributeSource.State) it.next());\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(termAtt.termBuffer(), 0, termAtt.termLength());\n      }\n\n      endOffsets[i] = offsetAtt.endOffset();\n      i++;\n    }\n    \n    return true;\n  }\n\n","sourceOld":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private void fillOutputBuf(Token token) throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      token = getNextToken(token);\n      if (token != null) {\n        shingleBuf.add(token.clone());\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.remove(0);\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      if (shingleBuf.isEmpty()) {\n        return;\n      } else {\n        shingleBuf.remove(0);\n      }\n    }\n\n    clearShingles();\n\n    int[] endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    Token shingle = null;\n    for (Iterator it = shingleBuf.iterator(); it.hasNext(); ) {\n      shingle = (Token) it.next();\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(shingle.termBuffer(), 0, shingle.termLength());\n      }\n\n      endOffsets[i] = shingle.endOffset();\n      i++;\n    }\n\n    if ((! shingleBuf.isEmpty()) && outputUnigrams) {\n      Token unigram = (Token) shingleBuf.getFirst();\n      unigram.setPositionIncrement(1);\n      outputBuf.add(unigram);\n    }\n\n    /*\n     * Push new tokens to the output buffer.\n     */\n    if (!shingleBuf.isEmpty()) {\n      Token firstShingle = (Token) shingleBuf.get(0);\n      shingle = (Token) firstShingle.clone();\n      shingle.setType(tokenType);\n    }\n    for (int j = 1; j < shingleBuf.size(); j++) {\n      shingle.setEndOffset(endOffsets[j]);\n      StringBuffer buf = shingles[j];\n      int termLength = buf.length();\n      char[] termBuffer = shingle.termBuffer();\n      if (termBuffer.length < termLength)\n        termBuffer = shingle.resizeTermBuffer(termLength);\n      buf.getChars(0, termLength, termBuffer, 0);\n      shingle.setTermLength(termLength);\n      if ((! outputUnigrams) && j == 1) {\n        shingle.setPositionIncrement(1);\n      } else {\n        shingle.setPositionIncrement(0);\n      }\n      outputBuf.add(shingle.clone());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4","date":1252476174,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillShingleBuffer().mjava","pathOld":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillShingleBuffer().mjava","sourceNew":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private boolean fillShingleBuffer() throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      if (getNextToken()) {\n        shingleBuf.add(captureState());\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.removeFirst();\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n    \n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      shingleBuf.removeFirst();\n    }\n    \n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n\n    clearShingles();\n\n    endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    for (Iterator it = shingleBuf.iterator(); it.hasNext(); ) {\n      restoreState((AttributeSource.State) it.next());\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(termAtt.termBuffer(), 0, termAtt.termLength());\n      }\n\n      endOffsets[i] = offsetAtt.endOffset();\n      i++;\n    }\n    \n    return true;\n  }\n\n","sourceOld":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private boolean fillShingleBuffer() throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      if (getNextToken()) {\n        shingleBuf.add(captureState());\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.remove(0);\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n    \n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      shingleBuf.remove(0);\n    }\n    \n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n\n    clearShingles();\n\n    endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    for (Iterator it = shingleBuf.iterator(); it.hasNext(); ) {\n      restoreState((AttributeSource.State) it.next());\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(termAtt.termBuffer(), 0, termAtt.termLength());\n      }\n\n      endOffsets[i] = offsetAtt.endOffset();\n      i++;\n    }\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60cdc0e643184821eb066795a8791cd82559f46e","date":1257941914,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillShingleBuffer().mjava","pathOld":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillShingleBuffer().mjava","sourceNew":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private boolean fillShingleBuffer() throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      if (getNextToken()) {\n        shingleBuf.add(captureState());\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.removeFirst();\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n    \n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      shingleBuf.removeFirst();\n    }\n    \n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n\n    clearShingles();\n\n    endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    for (Iterator<State> it = shingleBuf.iterator(); it.hasNext(); ) {\n      restoreState(it.next());\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(termAtt.termBuffer(), 0, termAtt.termLength());\n      }\n\n      endOffsets[i] = offsetAtt.endOffset();\n      i++;\n    }\n    \n    return true;\n  }\n\n","sourceOld":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private boolean fillShingleBuffer() throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      if (getNextToken()) {\n        shingleBuf.add(captureState());\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.removeFirst();\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n    \n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      shingleBuf.removeFirst();\n    }\n    \n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n\n    clearShingles();\n\n    endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    for (Iterator it = shingleBuf.iterator(); it.hasNext(); ) {\n      restoreState((AttributeSource.State) it.next());\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(termAtt.termBuffer(), 0, termAtt.termLength());\n      }\n\n      endOffsets[i] = offsetAtt.endOffset();\n      i++;\n    }\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf5d35662f99ce0a5b777b6b1585aa3a3ffa8f39","date":1264946641,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter#fillShingleBuffer().mjava","sourceNew":null,"sourceOld":"  /**\n   * Fill the output buffer with new shingles.\n   *\n   * @throws IOException if there's a problem getting the next token\n   */\n  private boolean fillShingleBuffer() throws IOException {\n    boolean addedToken = false;\n    /*\n     * Try to fill the shingle buffer.\n     */\n    do {\n      if (getNextToken()) {\n        shingleBuf.add(captureState());\n        if (shingleBuf.size() > maxShingleSize)\n        {\n          shingleBuf.removeFirst();\n        }\n        addedToken = true;\n      } else {\n        break;\n      }\n    } while (shingleBuf.size() < maxShingleSize);\n\n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n    \n    /*\n     * If no new token could be added to the shingle buffer, we have reached\n     * the end of the input stream and have to discard the least recent token.\n     */\n    if (! addedToken) {\n      shingleBuf.removeFirst();\n    }\n    \n    if (shingleBuf.isEmpty()) {\n      return false;\n    }\n\n    clearShingles();\n\n    endOffsets = new int[shingleBuf.size()];\n    for (int i = 0; i < endOffsets.length; i++) {\n      endOffsets[i] = 0;\n    }\n\n    int i = 0;\n    for (Iterator<State> it = shingleBuf.iterator(); it.hasNext(); ) {\n      restoreState(it.next());\n      for (int j = i; j < shingles.length; j++) {\n        if (shingles[j].length() != 0) {\n          shingles[j].append(TOKEN_SEPARATOR);\n        }\n        shingles[j].append(termAtt.termBuffer(), 0, termAtt.termLength());\n      }\n\n      endOffsets[i] = offsetAtt.endOffset();\n      i++;\n    }\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"60cdc0e643184821eb066795a8791cd82559f46e":["f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4"],"cf5d35662f99ce0a5b777b6b1585aa3a3ffa8f39":["60cdc0e643184821eb066795a8791cd82559f46e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0dda87e5ad7246b25d0da56a16ead95360499d86":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4":["0dda87e5ad7246b25d0da56a16ead95360499d86"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cf5d35662f99ce0a5b777b6b1585aa3a3ffa8f39"]},"commit2Childs":{"60cdc0e643184821eb066795a8791cd82559f46e":["cf5d35662f99ce0a5b777b6b1585aa3a3ffa8f39"],"cf5d35662f99ce0a5b777b6b1585aa3a3ffa8f39":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0dda87e5ad7246b25d0da56a16ead95360499d86"],"0dda87e5ad7246b25d0da56a16ead95360499d86":["f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4"],"f6a10bd7a06139a7fe2285d8094a66bc2cdaeaf4":["60cdc0e643184821eb066795a8791cd82559f46e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}