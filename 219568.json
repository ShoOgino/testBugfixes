{"path":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenFilter#testMaximumGraphCacheSize().mjava","commits":[{"id":"7836a9b132efc1162fb9d817b3e766f0a82212be","date":1543916862,"type":0,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenFilter#testMaximumGraphCacheSize().mjava","pathOld":"/dev/null","sourceNew":"  public void testMaximumGraphCacheSize() throws IOException {\n\n    Token[] tokens = new Token[GraphTokenFilter.MAX_TOKEN_CACHE_SIZE + 5];\n    for (int i = 0; i < GraphTokenFilter.MAX_TOKEN_CACHE_SIZE + 5; i++) {\n      tokens[i] = new Token(\"a\", 1, i * 2, i * 2 + 1);\n    }\n\n    GraphTokenFilter gts = new TestFilter(new CannedTokenStream(tokens));\n    Exception e = expectThrows(IllegalStateException.class, () -> {\n      gts.reset();\n      gts.incrementBaseToken();\n      while (true) {\n        gts.incrementGraphToken();\n      }\n    });\n    assertEquals(\"Too many cached tokens (> 100)\", e.getMessage());\n\n    gts.reset();\n    // after reset, the cache should be cleared and so we can read ahead once more\n    gts.incrementBaseToken();\n    gts.incrementGraphToken();\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7836a9b132efc1162fb9d817b3e766f0a82212be":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7836a9b132efc1162fb9d817b3e766f0a82212be"]},"commit2Childs":{"7836a9b132efc1162fb9d817b3e766f0a82212be":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7836a9b132efc1162fb9d817b3e766f0a82212be"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}