{"path":"solr/core/src/java/org/apache/solr/handler/tagger/Tagger#process().mjava","commits":[{"id":"e091f281a6e026f8bb17aaf194efd0bbd3a7f549","date":1528221895,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/tagger/Tagger#process().mjava","pathOld":"/dev/null","sourceNew":"  public void process() throws IOException {\n    if (terms == null)\n      return;\n\n    //a shared pointer to the head used by this method and each Tag instance.\n    final TagLL[] head = new TagLL[1];\n\n    TermPrefixCursor cursor = null;//re-used\n\n    //boolean switch used to log warnings in case tokens where skipped during tagging.\n    boolean skippedTokens = false;\n\n    while (tokenStream.incrementToken()) {\n      if (log.isTraceEnabled()) {\n        log.trace(\"Token: {}, posInc: {},  offset: [{},{}]\",\n                byteRefAtt, posIncAtt.getPositionIncrement(),\n                offsetAtt.startOffset(), offsetAtt.endOffset());\n      }\n      //check for posInc < 1 (alternate Tokens, such as expanded Synonyms)\n      if (posIncAtt.getPositionIncrement() < 1) {\n        //(a) Deal with this as a configuration issue and throw an exception\n        if (!skipAltTokens) {\n          //TODO throw UnsupportedTokenException when PhraseBuilder is ported\n          throw new IllegalStateException(\"Query Analyzer generates alternate \"\n              + \"Tokens (posInc == 0). Please adapt your Analyzer configuration or \"\n              + \"enable '\" + TaggerRequestHandler.SKIP_ALT_TOKENS + \"' to skip such \"\n              + \"tokens. NOTE: enabling '\" + TaggerRequestHandler.SKIP_ALT_TOKENS\n              + \"' might result in wrong tagging results if the index time analyzer \"\n              + \"is not configured accordingly. For detailed information see \"\n              + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n        } else {\n          //(b) In case the index time analyser had indexed all variants (users\n          //    need to ensure that) processing of alternate tokens can be skipped\n          //    as anyways all alternatives will be contained in the FST.\n          skippedTokens = true;\n          log.trace(\"  ... ignored token\");\n          continue;\n        }\n      }\n      //-- If PositionIncrement > 1 (stopwords)\n      if (!ignoreStopWords && posIncAtt.getPositionIncrement() > 1) {\n        log.trace(\"   - posInc > 1 ... mark cluster as done\");\n        advanceTagsAndProcessClusterIfDone(head, null);\n      }\n\n      final BytesRef term;\n      //NOTE: we need to lookup tokens if\n      // * the LookupAtt is true OR\n      // * there are still advancing tags (to find the longest possible match)\n      if(taggingAtt.isTaggable() || head[0] != null){\n        //-- Lookup the term id from the next token\n        term = byteRefAtt.getBytesRef();\n        if (term.length == 0) {\n          throw new IllegalArgumentException(\"term: \" + term.utf8ToString() + \" analyzed to a zero-length token\");\n        }\n      } else { //no current cluster AND lookup == false ...\n        term = null; //skip this token\n      }\n\n      //-- Process tag\n      advanceTagsAndProcessClusterIfDone(head, term);\n\n      //-- only create new Tags for Tokens we need to lookup\n      if (taggingAtt.isTaggable() && term != null) {\n\n        //determine if the terms index has a term starting with the provided term\n        // TODO create a pool of these cursors to reuse them more?  could be trivial impl\n        if (cursor == null)// (else the existing cursor will be re-used)\n          cursor = new TermPrefixCursor(terms.iterator(), liveDocs, docIdsCache);\n        if (cursor.advance(term)) {\n          TagLL newTail = new TagLL(head, cursor, offsetAtt.startOffset(), offsetAtt.endOffset(), null);\n          cursor = null;//because the new tag now \"owns\" this instance\n          //and add it to the end\n          if (head[0] == null) {\n            head[0] = newTail;\n          } else {\n            for (TagLL t = head[0]; true; t = t.nextTag) {\n              if (t.nextTag == null) {\n                t.addAfterLL(newTail);\n                break;\n              }\n            }\n          }\n        }\n      }//if termId >= 0\n    }//end while(incrementToken())\n\n    //-- Finish all tags\n    advanceTagsAndProcessClusterIfDone(head, null);\n    assert head[0] == null;\n\n    if(!loggedSkippedAltTokenWarning && skippedTokens){\n      loggedSkippedAltTokenWarning = true; //only log once\n      log.warn(\"The Tagger skipped some alternate tokens (tokens with posInc == 0) \"\n          + \"while processing text. This may cause problems with some Analyzer \"\n          + \"configurations (e.g. query time synonym expansion). For details see \"\n          + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n    }\n\n    tokenStream.end();\n    //tokenStream.close(); caller closes because caller acquired it\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":0,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/tagger/Tagger#process().mjava","pathOld":"/dev/null","sourceNew":"  public void process() throws IOException {\n    if (terms == null)\n      return;\n\n    //a shared pointer to the head used by this method and each Tag instance.\n    final TagLL[] head = new TagLL[1];\n\n    TermPrefixCursor cursor = null;//re-used\n\n    //boolean switch used to log warnings in case tokens where skipped during tagging.\n    boolean skippedTokens = false;\n\n    while (tokenStream.incrementToken()) {\n      if (log.isTraceEnabled()) {\n        log.trace(\"Token: {}, posInc: {},  offset: [{},{}]\",\n                byteRefAtt, posIncAtt.getPositionIncrement(),\n                offsetAtt.startOffset(), offsetAtt.endOffset());\n      }\n      //check for posInc < 1 (alternate Tokens, such as expanded Synonyms)\n      if (posIncAtt.getPositionIncrement() < 1) {\n        //(a) Deal with this as a configuration issue and throw an exception\n        if (!skipAltTokens) {\n          //TODO throw UnsupportedTokenException when PhraseBuilder is ported\n          throw new IllegalStateException(\"Query Analyzer generates alternate \"\n              + \"Tokens (posInc == 0). Please adapt your Analyzer configuration or \"\n              + \"enable '\" + TaggerRequestHandler.SKIP_ALT_TOKENS + \"' to skip such \"\n              + \"tokens. NOTE: enabling '\" + TaggerRequestHandler.SKIP_ALT_TOKENS\n              + \"' might result in wrong tagging results if the index time analyzer \"\n              + \"is not configured accordingly. For detailed information see \"\n              + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n        } else {\n          //(b) In case the index time analyser had indexed all variants (users\n          //    need to ensure that) processing of alternate tokens can be skipped\n          //    as anyways all alternatives will be contained in the FST.\n          skippedTokens = true;\n          log.trace(\"  ... ignored token\");\n          continue;\n        }\n      }\n      //-- If PositionIncrement > 1 (stopwords)\n      if (!ignoreStopWords && posIncAtt.getPositionIncrement() > 1) {\n        log.trace(\"   - posInc > 1 ... mark cluster as done\");\n        advanceTagsAndProcessClusterIfDone(head, null);\n      }\n\n      final BytesRef term;\n      //NOTE: we need to lookup tokens if\n      // * the LookupAtt is true OR\n      // * there are still advancing tags (to find the longest possible match)\n      if(taggingAtt.isTaggable() || head[0] != null){\n        //-- Lookup the term id from the next token\n        term = byteRefAtt.getBytesRef();\n        if (term.length == 0) {\n          throw new IllegalArgumentException(\"term: \" + term.utf8ToString() + \" analyzed to a zero-length token\");\n        }\n      } else { //no current cluster AND lookup == false ...\n        term = null; //skip this token\n      }\n\n      //-- Process tag\n      advanceTagsAndProcessClusterIfDone(head, term);\n\n      //-- only create new Tags for Tokens we need to lookup\n      if (taggingAtt.isTaggable() && term != null) {\n\n        //determine if the terms index has a term starting with the provided term\n        // TODO create a pool of these cursors to reuse them more?  could be trivial impl\n        if (cursor == null)// (else the existing cursor will be re-used)\n          cursor = new TermPrefixCursor(terms.iterator(), liveDocs, docIdsCache);\n        if (cursor.advance(term)) {\n          TagLL newTail = new TagLL(head, cursor, offsetAtt.startOffset(), offsetAtt.endOffset(), null);\n          cursor = null;//because the new tag now \"owns\" this instance\n          //and add it to the end\n          if (head[0] == null) {\n            head[0] = newTail;\n          } else {\n            for (TagLL t = head[0]; true; t = t.nextTag) {\n              if (t.nextTag == null) {\n                t.addAfterLL(newTail);\n                break;\n              }\n            }\n          }\n        }\n      }//if termId >= 0\n    }//end while(incrementToken())\n\n    //-- Finish all tags\n    advanceTagsAndProcessClusterIfDone(head, null);\n    assert head[0] == null;\n\n    if(!loggedSkippedAltTokenWarning && skippedTokens){\n      loggedSkippedAltTokenWarning = true; //only log once\n      log.warn(\"The Tagger skipped some alternate tokens (tokens with posInc == 0) \"\n          + \"while processing text. This may cause problems with some Analyzer \"\n          + \"configurations (e.g. query time synonym expansion). For details see \"\n          + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n    }\n\n    tokenStream.end();\n    //tokenStream.close(); caller closes because caller acquired it\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":0,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/tagger/Tagger#process().mjava","pathOld":"/dev/null","sourceNew":"  public void process() throws IOException {\n    if (terms == null)\n      return;\n\n    //a shared pointer to the head used by this method and each Tag instance.\n    final TagLL[] head = new TagLL[1];\n\n    TermPrefixCursor cursor = null;//re-used\n\n    //boolean switch used to log warnings in case tokens where skipped during tagging.\n    boolean skippedTokens = false;\n\n    while (tokenStream.incrementToken()) {\n      if (log.isTraceEnabled()) {\n        log.trace(\"Token: {}, posInc: {},  offset: [{},{}]\",\n                byteRefAtt, posIncAtt.getPositionIncrement(),\n                offsetAtt.startOffset(), offsetAtt.endOffset());\n      }\n      //check for posInc < 1 (alternate Tokens, such as expanded Synonyms)\n      if (posIncAtt.getPositionIncrement() < 1) {\n        //(a) Deal with this as a configuration issue and throw an exception\n        if (!skipAltTokens) {\n          //TODO throw UnsupportedTokenException when PhraseBuilder is ported\n          throw new IllegalStateException(\"Query Analyzer generates alternate \"\n              + \"Tokens (posInc == 0). Please adapt your Analyzer configuration or \"\n              + \"enable '\" + TaggerRequestHandler.SKIP_ALT_TOKENS + \"' to skip such \"\n              + \"tokens. NOTE: enabling '\" + TaggerRequestHandler.SKIP_ALT_TOKENS\n              + \"' might result in wrong tagging results if the index time analyzer \"\n              + \"is not configured accordingly. For detailed information see \"\n              + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n        } else {\n          //(b) In case the index time analyser had indexed all variants (users\n          //    need to ensure that) processing of alternate tokens can be skipped\n          //    as anyways all alternatives will be contained in the FST.\n          skippedTokens = true;\n          log.trace(\"  ... ignored token\");\n          continue;\n        }\n      }\n      //-- If PositionIncrement > 1 (stopwords)\n      if (!ignoreStopWords && posIncAtt.getPositionIncrement() > 1) {\n        log.trace(\"   - posInc > 1 ... mark cluster as done\");\n        advanceTagsAndProcessClusterIfDone(head, null);\n      }\n\n      final BytesRef term;\n      //NOTE: we need to lookup tokens if\n      // * the LookupAtt is true OR\n      // * there are still advancing tags (to find the longest possible match)\n      if(taggingAtt.isTaggable() || head[0] != null){\n        //-- Lookup the term id from the next token\n        term = byteRefAtt.getBytesRef();\n        if (term.length == 0) {\n          throw new IllegalArgumentException(\"term: \" + term.utf8ToString() + \" analyzed to a zero-length token\");\n        }\n      } else { //no current cluster AND lookup == false ...\n        term = null; //skip this token\n      }\n\n      //-- Process tag\n      advanceTagsAndProcessClusterIfDone(head, term);\n\n      //-- only create new Tags for Tokens we need to lookup\n      if (taggingAtt.isTaggable() && term != null) {\n\n        //determine if the terms index has a term starting with the provided term\n        // TODO create a pool of these cursors to reuse them more?  could be trivial impl\n        if (cursor == null)// (else the existing cursor will be re-used)\n          cursor = new TermPrefixCursor(terms.iterator(), liveDocs, docIdsCache);\n        if (cursor.advance(term)) {\n          TagLL newTail = new TagLL(head, cursor, offsetAtt.startOffset(), offsetAtt.endOffset(), null);\n          cursor = null;//because the new tag now \"owns\" this instance\n          //and add it to the end\n          if (head[0] == null) {\n            head[0] = newTail;\n          } else {\n            for (TagLL t = head[0]; true; t = t.nextTag) {\n              if (t.nextTag == null) {\n                t.addAfterLL(newTail);\n                break;\n              }\n            }\n          }\n        }\n      }//if termId >= 0\n    }//end while(incrementToken())\n\n    //-- Finish all tags\n    advanceTagsAndProcessClusterIfDone(head, null);\n    assert head[0] == null;\n\n    if(!loggedSkippedAltTokenWarning && skippedTokens){\n      loggedSkippedAltTokenWarning = true; //only log once\n      log.warn(\"The Tagger skipped some alternate tokens (tokens with posInc == 0) \"\n          + \"while processing text. This may cause problems with some Analyzer \"\n          + \"configurations (e.g. query time synonym expansion). For details see \"\n          + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n    }\n\n    tokenStream.end();\n    //tokenStream.close(); caller closes because caller acquired it\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"575e66bd4b2349209027f6801184da7fc3cba13f","date":1587609169,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/tagger/Tagger#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/tagger/Tagger#process().mjava","sourceNew":"  public void process() throws IOException {\n    if (terms == null)\n      return;\n\n    //a shared pointer to the head used by this method and each Tag instance.\n    final TagLL[] head = new TagLL[1];\n\n    TermPrefixCursor cursor = null;//re-used\n\n    //boolean switch used to log warnings in case tokens where skipped during tagging.\n    boolean skippedTokens = false;\n\n    while (tokenStream.incrementToken()) {\n      if (log.isTraceEnabled()) {\n        log.trace(\"Token: {}, posInc: {},  offset: [{},{}]\",\n                byteRefAtt, posIncAtt.getPositionIncrement(),\n                offsetAtt.startOffset(), offsetAtt.endOffset());\n      }\n      //check for posInc < 1 (alternate Tokens, such as expanded Synonyms)\n      if (posIncAtt.getPositionIncrement() < 1) {\n        //(a) Deal with this as a configuration issue and throw an exception\n        if (!skipAltTokens) {\n          //TODO throw UnsupportedTokenException when PhraseBuilder is ported\n          throw new IllegalStateException(\"Query Analyzer generates alternate \"\n              + \"Tokens (posInc == 0). Please adapt your Analyzer configuration or \"\n              + \"enable '\" + TaggerRequestHandler.SKIP_ALT_TOKENS + \"' to skip such \"\n              + \"tokens. NOTE: enabling '\" + TaggerRequestHandler.SKIP_ALT_TOKENS\n              + \"' might result in wrong tagging results if the index time analyzer \"\n              + \"is not configured accordingly. For detailed information see \"\n              + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n        } else {\n          //(b) In case the index time analyser had indexed all variants (users\n          //    need to ensure that) processing of alternate tokens can be skipped\n          //    as anyways all alternatives will be contained in the FST.\n          skippedTokens = true;\n          log.trace(\"  ... ignored token\");\n          continue;\n        }\n      }\n      //-- If PositionIncrement > 1 (stopwords)\n      if (!ignoreStopWords && posIncAtt.getPositionIncrement() > 1) {\n        log.trace(\"   - posInc > 1 ... mark cluster as done\");\n        advanceTagsAndProcessClusterIfDone(head, null);\n      }\n\n      final BytesRef term;\n      //NOTE: we need to lookup tokens if\n      // * the LookupAtt is true OR\n      // * there are still advancing tags (to find the longest possible match)\n      if(taggingAtt.isTaggable() || head[0] != null){\n        //-- Lookup the term id from the next token\n        term = byteRefAtt.getBytesRef();\n        if (term.length == 0) {\n          throw new IllegalArgumentException(\"term: \" + term.utf8ToString() + \" analyzed to a zero-length token\");\n        }\n      } else { //no current cluster AND lookup == false ...\n        term = null; //skip this token\n      }\n\n      //-- Process tag\n      advanceTagsAndProcessClusterIfDone(head, term);\n\n      //-- only create new Tags for Tokens we need to lookup\n      if (taggingAtt.isTaggable() && term != null) {\n\n        //determine if the terms index has a term starting with the provided term\n        // TODO create a pool of these cursors to reuse them more?  could be trivial impl\n        if (cursor == null)// (else the existing cursor will be re-used)\n          cursor = new TermPrefixCursor(terms.iterator(), liveDocs, docIdsCache);\n        if (cursor.advance(term)) {\n          TagLL newTail = new TagLL(head, cursor, offsetAtt.startOffset(), offsetAtt.endOffset(), null);\n          cursor = null;//because the new tag now \"owns\" this instance\n          //and add it to the end\n          if (head[0] == null) {\n            head[0] = newTail;\n          } else {\n            for (TagLL t = head[0]; true; t = t.nextTag) {\n              if (t.nextTag == null) {\n                t.addAfterLL(newTail);\n                break;\n              }\n            }\n          }\n        }\n      }//if termId >= 0\n    }//end while(incrementToken())\n\n    //-- Finish all tags\n    advanceTagsAndProcessClusterIfDone(head, null);\n    assert head[0] == null;\n\n    if(!loggedSkippedAltTokenWarning && skippedTokens){\n      loggedSkippedAltTokenWarning = true; //only log once\n      log.warn(\"{}{}{}{}\"\n          , \"The Tagger skipped some alternate tokens (tokens with posInc == 0) \"\n          , \"while processing text. This may cause problems with some Analyzer \"\n          , \"configurations (e.g. query time synonym expansion). For details see \"\n          , \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n    }\n\n    tokenStream.end();\n    //tokenStream.close(); caller closes because caller acquired it\n  }\n\n","sourceOld":"  public void process() throws IOException {\n    if (terms == null)\n      return;\n\n    //a shared pointer to the head used by this method and each Tag instance.\n    final TagLL[] head = new TagLL[1];\n\n    TermPrefixCursor cursor = null;//re-used\n\n    //boolean switch used to log warnings in case tokens where skipped during tagging.\n    boolean skippedTokens = false;\n\n    while (tokenStream.incrementToken()) {\n      if (log.isTraceEnabled()) {\n        log.trace(\"Token: {}, posInc: {},  offset: [{},{}]\",\n                byteRefAtt, posIncAtt.getPositionIncrement(),\n                offsetAtt.startOffset(), offsetAtt.endOffset());\n      }\n      //check for posInc < 1 (alternate Tokens, such as expanded Synonyms)\n      if (posIncAtt.getPositionIncrement() < 1) {\n        //(a) Deal with this as a configuration issue and throw an exception\n        if (!skipAltTokens) {\n          //TODO throw UnsupportedTokenException when PhraseBuilder is ported\n          throw new IllegalStateException(\"Query Analyzer generates alternate \"\n              + \"Tokens (posInc == 0). Please adapt your Analyzer configuration or \"\n              + \"enable '\" + TaggerRequestHandler.SKIP_ALT_TOKENS + \"' to skip such \"\n              + \"tokens. NOTE: enabling '\" + TaggerRequestHandler.SKIP_ALT_TOKENS\n              + \"' might result in wrong tagging results if the index time analyzer \"\n              + \"is not configured accordingly. For detailed information see \"\n              + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n        } else {\n          //(b) In case the index time analyser had indexed all variants (users\n          //    need to ensure that) processing of alternate tokens can be skipped\n          //    as anyways all alternatives will be contained in the FST.\n          skippedTokens = true;\n          log.trace(\"  ... ignored token\");\n          continue;\n        }\n      }\n      //-- If PositionIncrement > 1 (stopwords)\n      if (!ignoreStopWords && posIncAtt.getPositionIncrement() > 1) {\n        log.trace(\"   - posInc > 1 ... mark cluster as done\");\n        advanceTagsAndProcessClusterIfDone(head, null);\n      }\n\n      final BytesRef term;\n      //NOTE: we need to lookup tokens if\n      // * the LookupAtt is true OR\n      // * there are still advancing tags (to find the longest possible match)\n      if(taggingAtt.isTaggable() || head[0] != null){\n        //-- Lookup the term id from the next token\n        term = byteRefAtt.getBytesRef();\n        if (term.length == 0) {\n          throw new IllegalArgumentException(\"term: \" + term.utf8ToString() + \" analyzed to a zero-length token\");\n        }\n      } else { //no current cluster AND lookup == false ...\n        term = null; //skip this token\n      }\n\n      //-- Process tag\n      advanceTagsAndProcessClusterIfDone(head, term);\n\n      //-- only create new Tags for Tokens we need to lookup\n      if (taggingAtt.isTaggable() && term != null) {\n\n        //determine if the terms index has a term starting with the provided term\n        // TODO create a pool of these cursors to reuse them more?  could be trivial impl\n        if (cursor == null)// (else the existing cursor will be re-used)\n          cursor = new TermPrefixCursor(terms.iterator(), liveDocs, docIdsCache);\n        if (cursor.advance(term)) {\n          TagLL newTail = new TagLL(head, cursor, offsetAtt.startOffset(), offsetAtt.endOffset(), null);\n          cursor = null;//because the new tag now \"owns\" this instance\n          //and add it to the end\n          if (head[0] == null) {\n            head[0] = newTail;\n          } else {\n            for (TagLL t = head[0]; true; t = t.nextTag) {\n              if (t.nextTag == null) {\n                t.addAfterLL(newTail);\n                break;\n              }\n            }\n          }\n        }\n      }//if termId >= 0\n    }//end while(incrementToken())\n\n    //-- Finish all tags\n    advanceTagsAndProcessClusterIfDone(head, null);\n    assert head[0] == null;\n\n    if(!loggedSkippedAltTokenWarning && skippedTokens){\n      loggedSkippedAltTokenWarning = true; //only log once\n      log.warn(\"The Tagger skipped some alternate tokens (tokens with posInc == 0) \"\n          + \"while processing text. This may cause problems with some Analyzer \"\n          + \"configurations (e.g. query time synonym expansion). For details see \"\n          + \"https://github.com/OpenSextant/SolrTextTagger/pull/11#issuecomment-24936225\");\n    }\n\n    tokenStream.end();\n    //tokenStream.close(); caller closes because caller acquired it\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e091f281a6e026f8bb17aaf194efd0bbd3a7f549"],"575e66bd4b2349209027f6801184da7fc3cba13f":["e091f281a6e026f8bb17aaf194efd0bbd3a7f549"],"f592209545c71895260367152601e9200399776d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e091f281a6e026f8bb17aaf194efd0bbd3a7f549"],"e091f281a6e026f8bb17aaf194efd0bbd3a7f549":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["575e66bd4b2349209027f6801184da7fc3cba13f"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","e091f281a6e026f8bb17aaf194efd0bbd3a7f549"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"575e66bd4b2349209027f6801184da7fc3cba13f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f592209545c71895260367152601e9200399776d":[],"e091f281a6e026f8bb17aaf194efd0bbd3a7f549":["b70042a8a492f7054d480ccdd2be9796510d4327","575e66bd4b2349209027f6801184da7fc3cba13f","f592209545c71895260367152601e9200399776d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}