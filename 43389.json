{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d","date":1335141740,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bd9ddb59e9d33950773d186a8b726b5610ae3aad","date":1341258232,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"181b1aa5a99534972fbfd5595cdbb38bba5f39ee","date":1350576187,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"62e52115b56781006682fd92c6938efaf174304d","date":1351014780,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d55763df1c6badbe23b44b735ca86273d27caed","date":1357229491,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":["3af8c90c5e965a1a8011e827ab59de734c7dfb79","e4f3b0a30c9d521b86f768348f832af93505b4eb","901d103ab7c2eeae92b111fc91bb1b00580a3fd7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3af8c90c5e965a1a8011e827ab59de734c7dfb79","date":1368108782,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":["0d55763df1c6badbe23b44b735ca86273d27caed"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7af110b00ea8df9429309d83e38e0533d82e144f","date":1376924768,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"31d4861802ca404d78ca1d15f4550eec415b9199","date":1376947894,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ad5831ce5311e0afb145f4ffafb431feb9ac224","date":1383743871,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          processEvents(false, true);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ee59f646cf24586a449cad77391a60a3ac8d8959","date":1408015131,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          processEvents(false, true);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          processEvents(false, true);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"949847c0040cd70a68222d526cb0da7bf6cbb3c2","date":1410997182,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          tragicEvent(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          if (tragedy == null) {\n            // Done: finish the full flush! (unless we hit OOM or something)\n            docWriter.finishFullFlush(success);\n            processEvents(false, true);\n            doAfterFlush();\n          }\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          handleOOM(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(success);\n          processEvents(false, true);\n          doAfterFlush();\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":["901d103ab7c2eeae92b111fc91bb1b00580a3fd7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9299079153fd7895bf3cf6835cf7019af2ba89b3","date":1417813477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (AbortingException | OutOfMemoryError tragedy) {\n          tragicEvent(tragedy, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          if (tragedy == null) {\n            // Done: finish the full flush! (unless we hit OOM or something)\n            docWriter.finishFullFlush(success);\n            processEvents(false, true);\n            doAfterFlush();\n          }\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads(this);\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (OutOfMemoryError oom) {\n          tragicEvent(oom, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          if (tragedy == null) {\n            // Done: finish the full flush! (unless we hit OOM or something)\n            docWriter.finishFullFlush(success);\n            processEvents(false, true);\n            doAfterFlush();\n          }\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":["e4f3b0a30c9d521b86f768348f832af93505b4eb","901d103ab7c2eeae92b111fc91bb1b00580a3fd7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e4f3b0a30c9d521b86f768348f832af93505b4eb","date":1420797674,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (AbortingException | OutOfMemoryError tragedy) {\n          tragicEvent(tragedy, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          if (tragedy == null) {\n            // Done: finish the full flush! (unless we hit OOM or something)\n            docWriter.finishFullFlush(success);\n            processEvents(false, true);\n            doAfterFlush();\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anySegmentFlushed = docWriter.flushAllThreads();\n          if (!anySegmentFlushed) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (AbortingException | OutOfMemoryError tragedy) {\n          tragicEvent(tragedy, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          if (tragedy == null) {\n            // Done: finish the full flush! (unless we hit OOM or something)\n            docWriter.finishFullFlush(success);\n            processEvents(false, true);\n            doAfterFlush();\n          }\n        }\n      }\n      if (anySegmentFlushed) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":["9299079153fd7895bf3cf6835cf7019af2ba89b3","c00afe74a80796ed1f30a9509b150ff104746a1f","0d55763df1c6badbe23b44b735ca86273d27caed"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"901d103ab7c2eeae92b111fc91bb1b00580a3fd7","date":1422827173,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      boolean success = false;\n      synchronized (fullFlushLock) {\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n          success = true;\n        } finally {\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(this, success);\n          if (success) {\n            processEvents(false, true);\n            doAfterFlush();\n          } else {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } catch (AbortingException | OutOfMemoryError tragedy) {\n      tragicEvent(tragedy, \"getReader\");\n      // never reached but javac disagrees:\n      return null;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      synchronized (fullFlushLock) {\n        boolean success = false;\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          success = true;\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n        } catch (AbortingException | OutOfMemoryError tragedy) {\n          tragicEvent(tragedy, \"getReader\");\n          // never reached but javac disagrees:\n          return null;\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n          if (tragedy == null) {\n            // Done: finish the full flush! (unless we hit OOM or something)\n            docWriter.finishFullFlush(success);\n            processEvents(false, true);\n            doAfterFlush();\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":["949847c0040cd70a68222d526cb0da7bf6cbb3c2","9299079153fd7895bf3cf6835cf7019af2ba89b3","0d55763df1c6badbe23b44b735ca86273d27caed"],"bugIntro":["c48871ed951104729f5e17a8ee1091b43fa18980"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c48871ed951104729f5e17a8ee1091b43fa18980","date":1446564542,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      boolean success = false;\n      synchronized (fullFlushLock) {\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n          success = true;\n        } finally {\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(this, success);\n          if (success) {\n            processEvents(false, true);\n            doAfterFlush();\n          } else {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } catch (AbortingException | VirtualMachineError tragedy) {\n      tragicEvent(tragedy, \"getReader\");\n      // never reached but javac disagrees:\n      return null;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      boolean success = false;\n      synchronized (fullFlushLock) {\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n          success = true;\n        } finally {\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(this, success);\n          if (success) {\n            processEvents(false, true);\n            doAfterFlush();\n          } else {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } catch (AbortingException | OutOfMemoryError tragedy) {\n      tragicEvent(tragedy, \"getReader\");\n      // never reached but javac disagrees:\n      return null;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":["901d103ab7c2eeae92b111fc91bb1b00580a3fd7"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d49a158012a8ff48f328a4558e4bfcffbaed16f","date":1453677440,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {\n    ensureOpen();\n\n    if (writeAllDeletes && applyAllDeletes == false) {\n      throw new IllegalArgumentException(\"applyAllDeletes must be true when writeAllDeletes=true\");\n    }\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      boolean success = false;\n      synchronized (fullFlushLock) {\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            if (writeAllDeletes) {\n              // Must move the deletes to disk:\n              System.out.println(\"IW: now readerPool.commit\");\n              readerPool.commit(segmentInfos);\n            }\n\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes, writeAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n          success = true;\n        } finally {\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(this, success);\n          if (success) {\n            processEvents(false, true);\n            doAfterFlush();\n          } else {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } catch (AbortingException | VirtualMachineError tragedy) {\n      tragicEvent(tragedy, \"getReader\");\n      // never reached but javac disagrees:\n      return null;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      boolean success = false;\n      synchronized (fullFlushLock) {\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n          success = true;\n        } finally {\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(this, success);\n          if (success) {\n            processEvents(false, true);\n            doAfterFlush();\n          } else {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } catch (AbortingException | VirtualMachineError tragedy) {\n      tragicEvent(tragedy, \"getReader\");\n      // never reached but javac disagrees:\n      return null;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":["f372764a5bd3ebacde5b99ee3303153eb5ec0d2f","f372764a5bd3ebacde5b99ee3303153eb5ec0d2f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"68496c2200e559fb7802f7575427b7a482659afb","date":1455207618,"type":5,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {\n    ensureOpen();\n\n    if (writeAllDeletes && applyAllDeletes == false) {\n      throw new IllegalArgumentException(\"applyAllDeletes must be true when writeAllDeletes=true\");\n    }\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      boolean success = false;\n      synchronized (fullFlushLock) {\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            if (writeAllDeletes) {\n              // Must move the deletes to disk:\n              readerPool.commit(segmentInfos);\n            }\n\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes, writeAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n          success = true;\n        } finally {\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(this, success);\n          if (success) {\n            processEvents(false, true);\n            doAfterFlush();\n          } else {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } catch (AbortingException | VirtualMachineError tragedy) {\n      tragicEvent(tragedy, \"getReader\");\n      // never reached but javac disagrees:\n      return null;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then opening a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * DirectoryReader#openIfChanged}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException If there is a low-level I/O error\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    DirectoryReader r = null;\n    doBeforeFlush();\n    boolean anyChanges = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    boolean success2 = false;\n    try {\n      boolean success = false;\n      synchronized (fullFlushLock) {\n        try {\n          anyChanges = docWriter.flushAllThreads();\n          if (!anyChanges) {\n            // prevent double increment since docWriter#doFlush increments the flushcount\n            // if we flushed anything.\n            flushCount.incrementAndGet();\n          }\n          // Prevent segmentInfos from changing while opening the\n          // reader; in theory we could instead do similar retry logic,\n          // just like we do when loading segments_N\n          synchronized(this) {\n            anyChanges |= maybeApplyDeletes(applyAllDeletes);\n            r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n            }\n          }\n          success = true;\n        } finally {\n          // Done: finish the full flush!\n          docWriter.finishFullFlush(this, success);\n          if (success) {\n            processEvents(false, true);\n            doAfterFlush();\n          } else {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception during NRT reader\");\n            }\n          }\n        }\n      }\n      if (anyChanges) {\n        maybeMerge(config.getMergePolicy(), MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n      }\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n      }\n      success2 = true;\n    } catch (AbortingException | VirtualMachineError tragedy) {\n      tragicEvent(tragedy, \"getReader\");\n      // never reached but javac disagrees:\n      return null;\n    } finally {\n      if (!success2) {\n        IOUtils.closeWhileHandlingException(r);\n      }\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["bd9ddb59e9d33950773d186a8b726b5610ae3aad"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["181b1aa5a99534972fbfd5595cdbb38bba5f39ee","0d55763df1c6badbe23b44b735ca86273d27caed"],"7af110b00ea8df9429309d83e38e0533d82e144f":["3af8c90c5e965a1a8011e827ab59de734c7dfb79"],"ee59f646cf24586a449cad77391a60a3ac8d8959":["4ad5831ce5311e0afb145f4ffafb431feb9ac224"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["3af8c90c5e965a1a8011e827ab59de734c7dfb79","7af110b00ea8df9429309d83e38e0533d82e144f"],"31d4861802ca404d78ca1d15f4550eec415b9199":["3af8c90c5e965a1a8011e827ab59de734c7dfb79","7af110b00ea8df9429309d83e38e0533d82e144f"],"f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"901d103ab7c2eeae92b111fc91bb1b00580a3fd7":["e4f3b0a30c9d521b86f768348f832af93505b4eb"],"4ad5831ce5311e0afb145f4ffafb431feb9ac224":["7af110b00ea8df9429309d83e38e0533d82e144f"],"c48871ed951104729f5e17a8ee1091b43fa18980":["901d103ab7c2eeae92b111fc91bb1b00580a3fd7"],"0d55763df1c6badbe23b44b735ca86273d27caed":["181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"bd9ddb59e9d33950773d186a8b726b5610ae3aad":["f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d"],"62e52115b56781006682fd92c6938efaf174304d":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d","bd9ddb59e9d33950773d186a8b726b5610ae3aad"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3af8c90c5e965a1a8011e827ab59de734c7dfb79":["0d55763df1c6badbe23b44b735ca86273d27caed"],"181b1aa5a99534972fbfd5595cdbb38bba5f39ee":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"e4f3b0a30c9d521b86f768348f832af93505b4eb":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"68496c2200e559fb7802f7575427b7a482659afb":["c48871ed951104729f5e17a8ee1091b43fa18980","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["ee59f646cf24586a449cad77391a60a3ac8d8959"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["68496c2200e559fb7802f7575427b7a482659afb"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["c48871ed951104729f5e17a8ee1091b43fa18980"]},"commit2Childs":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["62e52115b56781006682fd92c6938efaf174304d","181b1aa5a99534972fbfd5595cdbb38bba5f39ee"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"7af110b00ea8df9429309d83e38e0533d82e144f":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199","4ad5831ce5311e0afb145f4ffafb431feb9ac224"],"ee59f646cf24586a449cad77391a60a3ac8d8959":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"31d4861802ca404d78ca1d15f4550eec415b9199":[],"f3a2f7df6ce044e8e7f5fe84cb5b23682fa1b27d":["bd9ddb59e9d33950773d186a8b726b5610ae3aad","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"901d103ab7c2eeae92b111fc91bb1b00580a3fd7":["c48871ed951104729f5e17a8ee1091b43fa18980"],"4ad5831ce5311e0afb145f4ffafb431feb9ac224":["ee59f646cf24586a449cad77391a60a3ac8d8959"],"c48871ed951104729f5e17a8ee1091b43fa18980":["68496c2200e559fb7802f7575427b7a482659afb","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"bd9ddb59e9d33950773d186a8b726b5610ae3aad":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"0d55763df1c6badbe23b44b735ca86273d27caed":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","3af8c90c5e965a1a8011e827ab59de734c7dfb79"],"62e52115b56781006682fd92c6938efaf174304d":[],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"181b1aa5a99534972fbfd5595cdbb38bba5f39ee":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","0d55763df1c6badbe23b44b735ca86273d27caed","62e52115b56781006682fd92c6938efaf174304d"],"3af8c90c5e965a1a8011e827ab59de734c7dfb79":["7af110b00ea8df9429309d83e38e0533d82e144f","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199"],"e4f3b0a30c9d521b86f768348f832af93505b4eb":["901d103ab7c2eeae92b111fc91bb1b00580a3fd7"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["e4f3b0a30c9d521b86f768348f832af93505b4eb"],"68496c2200e559fb7802f7575427b7a482659afb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["68496c2200e559fb7802f7575427b7a482659afb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199","62e52115b56781006682fd92c6938efaf174304d","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}