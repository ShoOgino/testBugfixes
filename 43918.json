{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenOffsetFilterFactory#test().mjava","commits":[{"id":"64cf07d2eb6bab312c43411d6a3e0373ed15a245","date":1429731531,"type":0,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLimitTokenOffsetFilterFactory#test().mjava","pathOld":"/dev/null","sourceNew":"  public void test() throws Exception {\n    for (final boolean consumeAll : new boolean[]{true, false}) {\n      Reader reader = new StringReader(\"A1 B2 C3 D4 E5 F6\");\n      MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n      tokenizer.setReader(reader);\n      tokenizer.setEnableChecks(consumeAll);\n      TokenStream stream = tokenizer;\n      stream = tokenFilterFactory(\"LimitTokenOffset\",\n          LimitTokenOffsetFilterFactory.MAX_START_OFFSET, \"3\",\n          LimitTokenOffsetFilterFactory.CONSUME_ALL_TOKENS_KEY, Boolean.toString(consumeAll)\n      ).create(stream);\n      assertTokenStreamContents(stream, new String[]{\"A1\", \"B2\"});\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"64cf07d2eb6bab312c43411d6a3e0373ed15a245":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["64cf07d2eb6bab312c43411d6a3e0373ed15a245"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["64cf07d2eb6bab312c43411d6a3e0373ed15a245"],"64cf07d2eb6bab312c43411d6a3e0373ed15a245":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}