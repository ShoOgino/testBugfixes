{"path":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(_TestUtil.getTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(_TestUtil.getTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(_TestUtil.getTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(_TestUtil.getTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(TestUtil.getTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(_TestUtil.getTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0d579490a72f2e6297eaa648940611234c57cf1","date":1395917140,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(TestUtil.createTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(TestUtil.getTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c","date":1396633078,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(createTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(TestUtil.createTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(createTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(TestUtil.getTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171","date":1412231650,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n    \n    final Directory d = newFSDirectory(createTempDir(\"CFSManySubFiles\"));\n    byte id[] = StringHelper.randomId();\n    \n    final int FILE_COUNT = atLeast(500);\n    \n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(id, d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n    \n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(id, d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n    \n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n    \n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(createTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"989d940c4bf402188f4f0ae13736836885227383","date":1412263633,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":null,"sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n    \n    final Directory d = newFSDirectory(createTempDir(\"CFSManySubFiles\"));\n    byte id[] = StringHelper.randomId();\n    \n    final int FILE_COUNT = atLeast(500);\n    \n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(id, d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n    \n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(id, d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n    \n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n    \n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseCompoundFormatTestCase#testManySubFiles().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCompoundFile#testManySubFiles().mjava","sourceNew":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n    final MockDirectoryWrapper dir = newMockFSDirectory(createTempDir(\"CFSManySubFiles\"));\n    \n    final int FILE_COUNT = atLeast(500);\n    \n    for (int fileIdx = 0; fileIdx < FILE_COUNT; fileIdx++) {\n      IndexOutput out = dir.createOutput(\"_123.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    assertEquals(0, dir.getFileHandleCount());\n    \n    SegmentInfo si = newSegmentInfo(dir, \"_123\");\n    si.getCodec().compoundFormat().write(dir, si, Arrays.asList(dir.listAll()), MergeState.CheckAbort.NONE, IOContext.DEFAULT);\n    Directory cfs = si.getCodec().compoundFormat().getCompoundReader(dir, si, IOContext.DEFAULT);\n    \n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    for (int fileIdx = 0; fileIdx < FILE_COUNT; fileIdx++) {\n      ins[fileIdx] = cfs.openInput(\"_123.\" + fileIdx, newIOContext(random()));\n    }\n    \n    assertEquals(1, dir.getFileHandleCount());\n\n    for (int fileIdx = 0; fileIdx < FILE_COUNT; fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n    \n    assertEquals(1, dir.getFileHandleCount());\n    \n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfs.close();\n    \n    dir.close();\n  }\n\n","sourceOld":"  // Make sure we don't somehow use more than 1 descriptor\n  // when reading a CFS with many subs:\n  public void testManySubFiles() throws IOException {\n\n    final Directory d = newFSDirectory(createTempDir(\"CFSManySubFiles\"));\n    final int FILE_COUNT = atLeast(500);\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      IndexOutput out = d.createOutput(\"file.\" + fileIdx, newIOContext(random()));\n      out.writeByte((byte) fileIdx);\n      out.close();\n    }\n    \n    final CompoundFileDirectory cfd = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), true);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      final String fileName = \"file.\" + fileIdx;\n      d.copy(cfd, fileName, fileName, newIOContext(random()));\n    }\n    cfd.close();\n\n    final IndexInput[] ins = new IndexInput[FILE_COUNT];\n    final CompoundFileDirectory cfr = new CompoundFileDirectory(d, \"c.cfs\", newIOContext(random()), false);\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx] = cfr.openInput(\"file.\" + fileIdx, newIOContext(random()));\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      assertEquals((byte) fileIdx, ins[fileIdx].readByte());\n    }\n\n    for(int fileIdx=0;fileIdx<FILE_COUNT;fileIdx++) {\n      ins[fileIdx].close();\n    }\n    cfr.close();\n    d.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"989d940c4bf402188f4f0ae13736836885227383":["f382b2e9f4ca7dbe98e2f15da70983ecfc02b171"],"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["6613659748fe4411a7dcf85266e55db1f95f7315","a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"6613659748fe4411a7dcf85266e55db1f95f7315":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["d0d579490a72f2e6297eaa648940611234c57cf1"],"9bb9a29a5e71a90295f175df8919802993142c9a":["2a0f5bb79c600763ffe7b8141df59a3169d31e48","989d940c4bf402188f4f0ae13736836885227383"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0d579490a72f2e6297eaa648940611234c57cf1":["6613659748fe4411a7dcf85266e55db1f95f7315"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9bb9a29a5e71a90295f175df8919802993142c9a"]},"commit2Childs":{"989d940c4bf402188f4f0ae13736836885227383":["9bb9a29a5e71a90295f175df8919802993142c9a"],"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171":["989d940c4bf402188f4f0ae13736836885227383"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["f382b2e9f4ca7dbe98e2f15da70983ecfc02b171","9bb9a29a5e71a90295f175df8919802993142c9a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["2a0f5bb79c600763ffe7b8141df59a3169d31e48","d0d579490a72f2e6297eaa648940611234c57cf1"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"9bb9a29a5e71a90295f175df8919802993142c9a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["6613659748fe4411a7dcf85266e55db1f95f7315"],"d0d579490a72f2e6297eaa648940611234c57cf1":["a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}