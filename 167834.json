{"path":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","commits":[{"id":"03e17b020972a0d6e8d6823f545571a66646a167","date":1547847724,"type":1,"author":"Toke Eskildsen","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","sourceNew":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","sourceOld":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c89f1ef80a9432f4eabaeda9a1e135cd72e60836","date":1547972642,"type":1,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","sourceNew":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","sourceOld":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57cb6df494f10aeb3fab477b1ce4a9187455a227","date":1574155024,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene70/Lucene70DocValuesConsumer#addTermsDict(SortedSetDocValues).mjava","sourceNew":null,"sourceOld":"  private void addTermsDict(SortedSetDocValues values) throws IOException {\n    final long size = values.getValueCount();\n    meta.writeVLong(size);\n    meta.writeInt(Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT);\n\n    ByteBuffersDataOutput addressBuffer = new ByteBuffersDataOutput();\n    ByteBuffersIndexOutput addressOutput = new ByteBuffersIndexOutput(addressBuffer, \"temp\", \"temp\");\n    meta.writeInt(DIRECT_MONOTONIC_BLOCK_SHIFT);\n    long numBlocks = (size + Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) >>> Lucene70DocValuesFormat.TERMS_DICT_BLOCK_SHIFT;\n    DirectMonotonicWriter writer = DirectMonotonicWriter.getInstance(meta, addressOutput, numBlocks, DIRECT_MONOTONIC_BLOCK_SHIFT);\n\n    BytesRefBuilder previous = new BytesRefBuilder();\n    long ord = 0;\n    long start = data.getFilePointer();\n    int maxLength = 0;\n    TermsEnum iterator = values.termsEnum();\n    for (BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n      if ((ord & Lucene70DocValuesFormat.TERMS_DICT_BLOCK_MASK) == 0) {\n        writer.add(data.getFilePointer() - start);\n        data.writeVInt(term.length);\n        data.writeBytes(term.bytes, term.offset, term.length);\n      } else {\n        final int prefixLength = StringHelper.bytesDifference(previous.get(), term);\n        final int suffixLength = term.length - prefixLength;\n        assert suffixLength > 0; // terms are unique\n\n        data.writeByte((byte) (Math.min(prefixLength, 15) | (Math.min(15, suffixLength - 1) << 4)));\n        if (prefixLength >= 15) {\n          data.writeVInt(prefixLength - 15);\n        }\n        if (suffixLength >= 16) {\n          data.writeVInt(suffixLength - 16);\n        }\n        data.writeBytes(term.bytes, term.offset + prefixLength, term.length - prefixLength);\n      }\n      maxLength = Math.max(maxLength, term.length);\n      previous.copyBytes(term);\n      ++ord;\n    }\n    writer.finish();\n    meta.writeInt(maxLength);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n    start = data.getFilePointer();\n    addressBuffer.copyTo(data);\n    meta.writeLong(start);\n    meta.writeLong(data.getFilePointer() - start);\n\n    // Now write the reverse terms index\n    writeTermsIndex(values);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03e17b020972a0d6e8d6823f545571a66646a167":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","03e17b020972a0d6e8d6823f545571a66646a167"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"57cb6df494f10aeb3fab477b1ce4a9187455a227":["03e17b020972a0d6e8d6823f545571a66646a167"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57cb6df494f10aeb3fab477b1ce4a9187455a227"]},"commit2Childs":{"03e17b020972a0d6e8d6823f545571a66646a167":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","57cb6df494f10aeb3fab477b1ce4a9187455a227"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["03e17b020972a0d6e8d6823f545571a66646a167","c89f1ef80a9432f4eabaeda9a1e135cd72e60836"],"57cb6df494f10aeb3fab477b1ce4a9187455a227":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}