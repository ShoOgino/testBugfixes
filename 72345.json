{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","commits":[{"id":"a41df1900c455d603b9d2d4b71084b4514af5e6c","date":1355146922,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  public CompressingStoredFieldsReader( Directory d, SegmentInfo si, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"/dev/null","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"818c86419d333447415a4e14fec4365320992e26","date":1370973407,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["3a88f37cd0154833b5c58daac509eb8be347d0f2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"47081d784f5fff71bb715c806c824b50901392fb","date":1378303234,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6120217e09092280e618050d052131ebcf6802d5","date":1395430033,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      if (indexStream.getFilePointer() != indexStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + indexStreamFN + \"\\\": read \" + indexStream.getFilePointer() + \" vs size \" + indexStream.length() + \" (resource: \" + indexStream + \")\");\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      if (indexStream.getFilePointer() != indexStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + indexStreamFN + \"\\\": read \" + indexStream.getFilePointer() + \" vs size \" + indexStream.length() + \" (resource: \" + indexStream + \")\");\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["3a88f37cd0154833b5c58daac509eb8be347d0f2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      if (indexStream.getFilePointer() != indexStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + indexStreamFN + \"\\\": read \" + indexStream.getFilePointer() + \" vs size \" + indexStream.length() + \" (resource: \" + indexStream + \")\");\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a88f37cd0154833b5c58daac509eb8be347d0f2","date":1397029487,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        assert maxPointer + CodecUtil.footerLength() == d.fileLength(fieldsStreamFN);\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        maxPointer = d.fileLength(fieldsStreamFN);\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":["818c86419d333447415a4e14fec4365320992e26","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"bugIntro":["30183f633ab3761007ab3be1733cdb4291320693"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"30183f633ab3761007ab3be1733cdb4291320693","date":1397836581,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      long maxPointer = -1;\n      \n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (version >= VERSION_CHECKSUM) {\n        if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n          throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length());\n        }\n      } else {\n        maxPointer = fieldsStream.length();\n      }\n      this.maxPointer = maxPointer;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        assert maxPointer + CodecUtil.footerLength() == d.fileLength(fieldsStreamFN);\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        maxPointer = d.fileLength(fieldsStreamFN);\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":["3a88f37cd0154833b5c58daac509eb8be347d0f2"],"bugIntro":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b612f3f700a1ca999f12198b7a33c65b4a96fd0","date":1406127397,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      long maxPointer = -1;\n      \n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (version >= VERSION_CHECKSUM) {\n        if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n          throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length());\n        }\n      } else {\n        maxPointer = fieldsStream.length();\n      }\n      this.maxPointer = maxPointer;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(fieldsStream);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      long maxPointer = -1;\n      \n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (version >= VERSION_CHECKSUM) {\n        if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n          throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length());\n        }\n      } else {\n        maxPointer = fieldsStream.length();\n      }\n      this.maxPointer = maxPointer;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      long maxPointer = -1;\n      \n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (version >= VERSION_CHECKSUM) {\n        if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n          throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n        }\n      } else {\n        maxPointer = fieldsStream.length();\n      }\n      this.maxPointer = maxPointer;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(fieldsStream);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      long maxPointer = -1;\n      \n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (version >= VERSION_CHECKSUM) {\n        if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n          throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length());\n        }\n      } else {\n        maxPointer = fieldsStream.length();\n      }\n      this.maxPointer = maxPointer;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(fieldsStream);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":["30183f633ab3761007ab3be1733cdb4291320693","47081d784f5fff71bb715c806c824b50901392fb"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"389e8bca54f58e35576077f3ff46f123b3660018","date":1411859915,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId());\n      assert CodecUtil.segmentHeaderLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      maxPointer = indexStream.readVLong();\n      CodecUtil.checkFooter(indexStream);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkSegmentHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId());\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      long maxPointer = -1;\n      \n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (version >= VERSION_CHECKSUM) {\n        if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n          throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n        }\n      } else {\n        maxPointer = fieldsStream.length();\n      }\n      this.maxPointer = maxPointer;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(fieldsStream);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6ac4bff3307e88928bf48cd1a283ff7da1f82464","date":1411914960,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId());\n        assert CodecUtil.segmentHeaderLength(codecNameIdx) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkSegmentHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId());\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId());\n      assert CodecUtil.segmentHeaderLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      maxPointer = indexStream.readVLong();\n      CodecUtil.checkFooter(indexStream);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkSegmentHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId());\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a78b813d9350cc28625598f6dbbb49b586a40618","date":1412073147,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkSegmentHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId());\n        assert CodecUtil.segmentHeaderLength(codecNameIdx) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkSegmentHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId());\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkSegmentHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);\n      final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n      // Load the index into memory\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n\n      long maxPointer = -1;\n      \n      if (version >= VERSION_CHECKSUM) {\n        maxPointer = indexStream.readVLong();\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (version >= VERSION_CHECKSUM) {\n        if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n          throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n        }\n      } else {\n        maxPointer = fieldsStream.length();\n      }\n      this.maxPointer = maxPointer;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_BIG_CHUNKS) {\n        chunkSize = fieldsStream.readVInt();\n      } else {\n        chunkSize = -1;\n      }\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(fieldsStream);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkSegmentHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkSegmentHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f09f483a0844bb9dc34fb10380cb053aa96219b","date":1418894001,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.bytes = new BytesRef();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd7962f4da329a4e559727022b752c5cefaee5da","date":1421356185,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      if (maxPointer + CodecUtil.footerLength() != fieldsStream.length()) {\n        throw new CorruptIndexException(\"Invalid fieldsStream maxPointer (file truncated?): maxPointer=\" + maxPointer + \", length=\" + fieldsStream.length(), fieldsStream);\n      }\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0267c69e2456a3477a1ad785723f2135da3117e","date":1425317087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b06445ae1731e049327712db0454e5643ca9b7fe","date":1425329139,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5","date":1488285484,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n\n      fieldsStream.seek(maxPointer);\n      numChunks = fieldsStream.readVLong();\n      numDirtyChunks = fieldsStream.readVLong();\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70a4487b07c49a1861c05720e04624826ecbe9fa","date":1580924108,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(fieldsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      long maxPointer = -1;\n      FieldsIndex indexReader = null;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"fdx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version2 + \" != \" + version, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong();\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, INDEX_EXTENSION_PREFIX, INDEX_CODEC_NAME, si.getId());\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.maxPointer = maxPointer;\n      this.indexReader = indexReader;\n\n      fieldsStream.seek(maxPointer);\n      numChunks = fieldsStream.readVLong();\n      numDirtyChunks = fieldsStream.readVLong();\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    \n    int version = -1;\n    long maxPointer = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_INDEX_EXTENSION);    \n    try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n        maxPointer = indexStream.readVLong();\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(indexStream, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.maxPointer = maxPointer;\n    this.indexReader = indexReader;\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      final int fieldsVersion = CodecUtil.checkIndexHeader(fieldsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != fieldsVersion) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + fieldsVersion, fieldsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n\n      fieldsStream.seek(maxPointer);\n      numChunks = fieldsStream.readVLong();\n      numDirtyChunks = fieldsStream.readVLong();\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b78d8dfe50af510bace3600bfc4cfa0b031f776","date":1598430423,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    ChecksumIndexInput metaIn = null;\n    try {\n      // Open the data file\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(fieldsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_OFFHEAP_INDEX) {\n        final String metaStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, META_EXTENSION);\n        metaIn = d.openChecksumInput(metaStreamFN, IOContext.READONCE);\n        CodecUtil.checkIndexHeader(metaIn, INDEX_CODEC_NAME + \"Meta\", META_VERSION_START, version, si.getId(), segmentSuffix);\n      }\n      if (version >= VERSION_META) {\n        chunkSize = metaIn.readVInt();\n        packedIntsVersion = metaIn.readVInt();\n      } else {\n        chunkSize = fieldsStream.readVInt();\n        packedIntsVersion = fieldsStream.readVInt();\n      }\n\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      long maxPointer = -1;\n      FieldsIndex indexReader = null;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"fdx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version2 + \" != \" + version, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong();\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, INDEX_EXTENSION, INDEX_CODEC_NAME, si.getId(), metaIn);\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.maxPointer = maxPointer;\n      this.indexReader = indexReader;\n\n      if (version >= VERSION_META) {\n        numChunks = metaIn.readVLong();\n        numDirtyChunks = metaIn.readVLong();\n      } else {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n      }\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n      }\n\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, null);\n        metaIn.close();\n      }\n\n      success = true;\n    } catch (Throwable t) {\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, t);\n        throw new AssertionError(\"unreachable\");\n      } else {\n        throw t;\n      }\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, metaIn);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    try {\n      // Open the data file and read metadata\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(fieldsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == fieldsStream.getFilePointer();\n\n      chunkSize = fieldsStream.readVInt();\n      packedIntsVersion = fieldsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      long maxPointer = -1;\n      FieldsIndex indexReader = null;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"fdx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version2 + \" != \" + version, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong();\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, INDEX_EXTENSION_PREFIX, INDEX_CODEC_NAME, si.getId());\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.maxPointer = maxPointer;\n      this.indexReader = indexReader;\n\n      fieldsStream.seek(maxPointer);\n      numChunks = fieldsStream.readVLong();\n      numDirtyChunks = fieldsStream.readVLong();\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"45264aed0cfa8a8a55ae1292b0e336d29cd88401","date":1600361948,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#CompressingStoredFieldsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    ChecksumIndexInput metaIn = null;\n    try {\n      // Open the data file\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(fieldsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_OFFHEAP_INDEX) {\n        final String metaStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, META_EXTENSION);\n        metaIn = d.openChecksumInput(metaStreamFN, IOContext.READONCE);\n        CodecUtil.checkIndexHeader(metaIn, INDEX_CODEC_NAME + \"Meta\", META_VERSION_START, version, si.getId(), segmentSuffix);\n      }\n      if (version >= VERSION_META) {\n        chunkSize = metaIn.readVInt();\n        packedIntsVersion = metaIn.readVInt();\n      } else {\n        chunkSize = fieldsStream.readVInt();\n        packedIntsVersion = fieldsStream.readVInt();\n      }\n\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      long maxPointer = -1;\n      FieldsIndex indexReader = null;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"fdx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version2 + \" != \" + version, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong();\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, INDEX_EXTENSION, INDEX_CODEC_NAME, si.getId(), metaIn);\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.maxPointer = maxPointer;\n      this.indexReader = indexReader;\n\n      if (version >= VERSION_META) {\n        numDirtyChunks = metaIn.readVLong();\n        numDirtyDocs = metaIn.readVLong();\n      } else {\n        // Old versions of this format did not record numDirtyDocs. Since bulk\n        // merges are disabled on version increments anyway, we make no effort\n        // to get valid values of numDirtyChunks and numDirtyDocs.\n        numDirtyChunks = numDirtyDocs = -1;\n      }\n\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, null);\n        metaIn.close();\n      }\n\n      success = true;\n    } catch (Throwable t) {\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, t);\n        throw new AssertionError(\"unreachable\");\n      } else {\n        throw t;\n      }\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, metaIn);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingStoredFieldsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    final String fieldsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, FIELDS_EXTENSION);\n    ChecksumIndexInput metaIn = null;\n    try {\n      // Open the data file\n      fieldsStream = d.openInput(fieldsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(fieldsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == fieldsStream.getFilePointer();\n\n      if (version >= VERSION_OFFHEAP_INDEX) {\n        final String metaStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, META_EXTENSION);\n        metaIn = d.openChecksumInput(metaStreamFN, IOContext.READONCE);\n        CodecUtil.checkIndexHeader(metaIn, INDEX_CODEC_NAME + \"Meta\", META_VERSION_START, version, si.getId(), segmentSuffix);\n      }\n      if (version >= VERSION_META) {\n        chunkSize = metaIn.readVInt();\n        packedIntsVersion = metaIn.readVInt();\n      } else {\n        chunkSize = fieldsStream.readVInt();\n        packedIntsVersion = fieldsStream.readVInt();\n      }\n\n      decompressor = compressionMode.newDecompressor();\n      this.merging = false;\n      this.state = new BlockState();\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(fieldsStream);\n\n      long maxPointer = -1;\n      FieldsIndex indexReader = null;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"fdx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version2 + \" != \" + version, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong();\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, INDEX_EXTENSION, INDEX_CODEC_NAME, si.getId(), metaIn);\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.maxPointer = maxPointer;\n      this.indexReader = indexReader;\n\n      if (version >= VERSION_META) {\n        numChunks = metaIn.readVLong();\n        numDirtyChunks = metaIn.readVLong();\n      } else {\n        fieldsStream.seek(maxPointer);\n        numChunks = fieldsStream.readVLong();\n        numDirtyChunks = fieldsStream.readVLong();\n      }\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, fieldsStream);\n      }\n\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, null);\n        metaIn.close();\n      }\n\n      success = true;\n    } catch (Throwable t) {\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, t);\n        throw new AssertionError(\"unreachable\");\n      } else {\n        throw t;\n      }\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, metaIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1f3b037cd083286b2af89f96e768f85dcd8072d6":["6120217e09092280e618050d052131ebcf6802d5"],"6ac4bff3307e88928bf48cd1a283ff7da1f82464":["389e8bca54f58e35576077f3ff46f123b3660018"],"a78b813d9350cc28625598f6dbbb49b586a40618":["6ac4bff3307e88928bf48cd1a283ff7da1f82464"],"70a4487b07c49a1861c05720e04624826ecbe9fa":["b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["bd7962f4da329a4e559727022b752c5cefaee5da","b0267c69e2456a3477a1ad785723f2135da3117e"],"b06445ae1731e049327712db0454e5643ca9b7fe":["bd7962f4da329a4e559727022b752c5cefaee5da","b0267c69e2456a3477a1ad785723f2135da3117e"],"9bb9a29a5e71a90295f175df8919802993142c9a":["9a70ce9bddc6f985feb8e5e182aebe20872328d4","a78b813d9350cc28625598f6dbbb49b586a40618"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"818c86419d333447415a4e14fec4365320992e26":["a41df1900c455d603b9d2d4b71084b4514af5e6c"],"45264aed0cfa8a8a55ae1292b0e336d29cd88401":["2b78d8dfe50af510bace3600bfc4cfa0b031f776"],"a41df1900c455d603b9d2d4b71084b4514af5e6c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5":["b0267c69e2456a3477a1ad785723f2135da3117e"],"6120217e09092280e618050d052131ebcf6802d5":["47081d784f5fff71bb715c806c824b50901392fb"],"47081d784f5fff71bb715c806c824b50901392fb":["818c86419d333447415a4e14fec4365320992e26"],"2b78d8dfe50af510bace3600bfc4cfa0b031f776":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"5eb2511ababf862ea11e10761c70ee560cd84510":["6120217e09092280e618050d052131ebcf6802d5","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"30183f633ab3761007ab3be1733cdb4291320693":["3a88f37cd0154833b5c58daac509eb8be347d0f2"],"b0267c69e2456a3477a1ad785723f2135da3117e":["bd7962f4da329a4e559727022b752c5cefaee5da"],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a41df1900c455d603b9d2d4b71084b4514af5e6c"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["a78b813d9350cc28625598f6dbbb49b586a40618"],"4b612f3f700a1ca999f12198b7a33c65b4a96fd0":["30183f633ab3761007ab3be1733cdb4291320693"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["4b612f3f700a1ca999f12198b7a33c65b4a96fd0"],"1f09f483a0844bb9dc34fb10380cb053aa96219b":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"bd7962f4da329a4e559727022b752c5cefaee5da":["1f09f483a0844bb9dc34fb10380cb053aa96219b"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"389e8bca54f58e35576077f3ff46f123b3660018":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"3a88f37cd0154833b5c58daac509eb8be347d0f2":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["45264aed0cfa8a8a55ae1292b0e336d29cd88401"]},"commit2Childs":{"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","3a88f37cd0154833b5c58daac509eb8be347d0f2"],"6ac4bff3307e88928bf48cd1a283ff7da1f82464":["a78b813d9350cc28625598f6dbbb49b586a40618"],"a78b813d9350cc28625598f6dbbb49b586a40618":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"70a4487b07c49a1861c05720e04624826ecbe9fa":["2b78d8dfe50af510bace3600bfc4cfa0b031f776"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"b06445ae1731e049327712db0454e5643ca9b7fe":[],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a41df1900c455d603b9d2d4b71084b4514af5e6c","407687e67faf6e1f02a211ca078d8e3eed631027"],"818c86419d333447415a4e14fec4365320992e26":["47081d784f5fff71bb715c806c824b50901392fb"],"a41df1900c455d603b9d2d4b71084b4514af5e6c":["818c86419d333447415a4e14fec4365320992e26","407687e67faf6e1f02a211ca078d8e3eed631027"],"45264aed0cfa8a8a55ae1292b0e336d29cd88401":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6120217e09092280e618050d052131ebcf6802d5":["1f3b037cd083286b2af89f96e768f85dcd8072d6","5eb2511ababf862ea11e10761c70ee560cd84510"],"b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"47081d784f5fff71bb715c806c824b50901392fb":["6120217e09092280e618050d052131ebcf6802d5"],"2b78d8dfe50af510bace3600bfc4cfa0b031f776":["45264aed0cfa8a8a55ae1292b0e336d29cd88401"],"5eb2511ababf862ea11e10761c70ee560cd84510":[],"30183f633ab3761007ab3be1733cdb4291320693":["4b612f3f700a1ca999f12198b7a33c65b4a96fd0"],"b0267c69e2456a3477a1ad785723f2135da3117e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"4b612f3f700a1ca999f12198b7a33c65b4a96fd0":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["9bb9a29a5e71a90295f175df8919802993142c9a","389e8bca54f58e35576077f3ff46f123b3660018"],"1f09f483a0844bb9dc34fb10380cb053aa96219b":["bd7962f4da329a4e559727022b752c5cefaee5da"],"bd7962f4da329a4e559727022b752c5cefaee5da":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","b0267c69e2456a3477a1ad785723f2135da3117e"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["1f09f483a0844bb9dc34fb10380cb053aa96219b"],"389e8bca54f58e35576077f3ff46f123b3660018":["6ac4bff3307e88928bf48cd1a283ff7da1f82464"],"3a88f37cd0154833b5c58daac509eb8be347d0f2":["30183f633ab3761007ab3be1733cdb4291320693"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","5eb2511ababf862ea11e10761c70ee560cd84510","407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}