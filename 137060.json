{"path":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","commits":[{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","pathOld":"/dev/null","sourceNew":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      // if the field as an instanceof FieldsReader.FieldForMerge, we're in merge mode\n      // and field.binaryValue() already returns the compressed value for a field\n      // with isCompressed()==true, so we disable compression in that case\n      boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n      if (field.isCompressed())\n        bits |= FieldsWriter.FIELD_IS_COMPRESSED;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isCompressed()) {\n        // compression is enabled for the current field\n        byte[] data = null;\n                  \n        if (disableCompression) {\n          // optimized case for merging, the data\n          // is already compressed\n          data = field.binaryValue();\n        } else {\n          // check if it is a binary field\n          if (field.isBinary()) {\n            data = compress(field.binaryValue());\n          }\n          else {\n            data = compress(field.stringValue().getBytes(\"UTF-8\"));\n          }\n        }\n        final int len = data.length;\n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, len);\n      }\n      else {\n        // compression is disabled for the current field\n        if (field.isBinary()) {\n          byte[] data = field.binaryValue();\n          final int len = data.length;\n          fieldsStream.writeVInt(len);\n          fieldsStream.writeBytes(data, len);\n        }\n        else {\n          fieldsStream.writeString(field.stringValue());\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d7203a8194ca217ec527231120df075e9bec237","date":1219055463,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","pathOld":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","sourceNew":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      // if the field as an instanceof FieldsReader.FieldForMerge, we're in merge mode\n      // and field.binaryValue() already returns the compressed value for a field\n      // with isCompressed()==true, so we disable compression in that case\n      boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n      if (field.isCompressed())\n        bits |= FieldsWriter.FIELD_IS_COMPRESSED;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isCompressed()) {\n        // compression is enabled for the current field\n        final byte[] data;\n        final int len;\n        final int offset;\n        if (disableCompression) {\n          // optimized case for merging, the data\n          // is already compressed\n          data = field.getBinaryValue();\n          len = field.getBinaryLength();\n          offset = field.getBinaryOffset();  \n        } else {\n          // check if it is a binary field\n          if (field.isBinary()) {\n            data = compress(field.getBinaryValue(), field.getBinaryOffset(), field.getBinaryLength());\n          } else {\n            byte x[] = field.stringValue().getBytes(\"UTF-8\");\n            data = compress(x, 0, x.length);\n          }\n          len = data.length;\n          offset = 0;\n        }\n        \n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        // compression is disabled for the current field\n        if (field.isBinary()) {\n          final byte[] data;\n          final int len;\n          final int offset;\n          data = field.getBinaryValue();\n          len = field.getBinaryLength();\n          offset =  field.getBinaryOffset();\n\n          fieldsStream.writeVInt(len);\n          fieldsStream.writeBytes(data, offset, len);\n        }\n        else {\n          fieldsStream.writeString(field.stringValue());\n        }\n      }\n    }\n\n","sourceOld":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      // if the field as an instanceof FieldsReader.FieldForMerge, we're in merge mode\n      // and field.binaryValue() already returns the compressed value for a field\n      // with isCompressed()==true, so we disable compression in that case\n      boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n      if (field.isCompressed())\n        bits |= FieldsWriter.FIELD_IS_COMPRESSED;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isCompressed()) {\n        // compression is enabled for the current field\n        byte[] data = null;\n                  \n        if (disableCompression) {\n          // optimized case for merging, the data\n          // is already compressed\n          data = field.binaryValue();\n        } else {\n          // check if it is a binary field\n          if (field.isBinary()) {\n            data = compress(field.binaryValue());\n          }\n          else {\n            data = compress(field.stringValue().getBytes(\"UTF-8\"));\n          }\n        }\n        final int len = data.length;\n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, len);\n      }\n      else {\n        // compression is disabled for the current field\n        if (field.isBinary()) {\n          byte[] data = field.binaryValue();\n          final int len = data.length;\n          fieldsStream.writeVInt(len);\n          fieldsStream.writeBytes(data, len);\n        }\n        else {\n          fieldsStream.writeString(field.stringValue());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d03062c59d1dcb53f10a483e2259b28499f94b3e","date":1220450371,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","pathOld":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","sourceNew":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      // if the field as an instanceof FieldsReader.FieldForMerge, we're in merge mode\n      // and field.binaryValue() already returns the compressed value for a field\n      // with isCompressed()==true, so we disable compression in that case\n      boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n      if (field.isCompressed())\n        bits |= FieldsWriter.FIELD_IS_COMPRESSED;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isCompressed()) {\n        // compression is enabled for the current field\n        final byte[] data;\n        final int len;\n        final int offset;\n        if (disableCompression) {\n          // optimized case for merging, the data\n          // is already compressed\n          data = field.getBinaryValue();\n          assert data != null;\n          len = field.getBinaryLength();\n          offset = field.getBinaryOffset();  \n        } else {\n          // check if it is a binary field\n          if (field.isBinary()) {\n            data = compress(field.getBinaryValue(), field.getBinaryOffset(), field.getBinaryLength());\n          } else {\n            byte x[] = field.stringValue().getBytes(\"UTF-8\");\n            data = compress(x, 0, x.length);\n          }\n          len = data.length;\n          offset = 0;\n        }\n        \n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        // compression is disabled for the current field\n        if (field.isBinary()) {\n          final byte[] data;\n          final int len;\n          final int offset;\n          data = field.getBinaryValue();\n          len = field.getBinaryLength();\n          offset =  field.getBinaryOffset();\n\n          fieldsStream.writeVInt(len);\n          fieldsStream.writeBytes(data, offset, len);\n        }\n        else {\n          fieldsStream.writeString(field.stringValue());\n        }\n      }\n    }\n\n","sourceOld":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      // if the field as an instanceof FieldsReader.FieldForMerge, we're in merge mode\n      // and field.binaryValue() already returns the compressed value for a field\n      // with isCompressed()==true, so we disable compression in that case\n      boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n      if (field.isCompressed())\n        bits |= FieldsWriter.FIELD_IS_COMPRESSED;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isCompressed()) {\n        // compression is enabled for the current field\n        final byte[] data;\n        final int len;\n        final int offset;\n        if (disableCompression) {\n          // optimized case for merging, the data\n          // is already compressed\n          data = field.getBinaryValue();\n          len = field.getBinaryLength();\n          offset = field.getBinaryOffset();  \n        } else {\n          // check if it is a binary field\n          if (field.isBinary()) {\n            data = compress(field.getBinaryValue(), field.getBinaryOffset(), field.getBinaryLength());\n          } else {\n            byte x[] = field.stringValue().getBytes(\"UTF-8\");\n            data = compress(x, 0, x.length);\n          }\n          len = data.length;\n          offset = 0;\n        }\n        \n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        // compression is disabled for the current field\n        if (field.isBinary()) {\n          final byte[] data;\n          final int len;\n          final int offset;\n          data = field.getBinaryValue();\n          len = field.getBinaryLength();\n          offset =  field.getBinaryOffset();\n\n          fieldsStream.writeVInt(len);\n          fieldsStream.writeBytes(data, offset, len);\n        }\n        else {\n          fieldsStream.writeString(field.stringValue());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"de01496176b31b9496ca92b2faebc31e16d91cc0","date":1237569222,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","pathOld":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","sourceNew":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      // if the field as an instanceof FieldsReader.FieldForMerge, we're in merge mode\n      // and field.binaryValue() already returns the compressed value for a field\n      // with isCompressed()==true, so we disable compression in that case\n      boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n      if (field.isCompressed())\n        bits |= FieldsWriter.FIELD_IS_COMPRESSED;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isCompressed()) {\n        // compression is enabled for the current field\n        final byte[] data;\n        final int len;\n        final int offset;\n        if (disableCompression) {\n          // optimized case for merging, the data\n          // is already compressed\n          data = field.getBinaryValue();\n          assert data != null;\n          len = field.getBinaryLength();\n          offset = field.getBinaryOffset();  \n        } else {\n          // check if it is a binary field\n          if (field.isBinary()) {\n            data = CompressionTools.compress(field.getBinaryValue(), field.getBinaryOffset(), field.getBinaryLength());\n          } else {\n            byte x[] = field.stringValue().getBytes(\"UTF-8\");\n            data = CompressionTools.compress(x, 0, x.length);\n          }\n          len = data.length;\n          offset = 0;\n        }\n        \n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        // compression is disabled for the current field\n        if (field.isBinary()) {\n          final byte[] data;\n          final int len;\n          final int offset;\n          data = field.getBinaryValue();\n          len = field.getBinaryLength();\n          offset =  field.getBinaryOffset();\n\n          fieldsStream.writeVInt(len);\n          fieldsStream.writeBytes(data, offset, len);\n        }\n        else {\n          fieldsStream.writeString(field.stringValue());\n        }\n      }\n    }\n\n","sourceOld":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      // if the field as an instanceof FieldsReader.FieldForMerge, we're in merge mode\n      // and field.binaryValue() already returns the compressed value for a field\n      // with isCompressed()==true, so we disable compression in that case\n      boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n      if (field.isCompressed())\n        bits |= FieldsWriter.FIELD_IS_COMPRESSED;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isCompressed()) {\n        // compression is enabled for the current field\n        final byte[] data;\n        final int len;\n        final int offset;\n        if (disableCompression) {\n          // optimized case for merging, the data\n          // is already compressed\n          data = field.getBinaryValue();\n          assert data != null;\n          len = field.getBinaryLength();\n          offset = field.getBinaryOffset();  \n        } else {\n          // check if it is a binary field\n          if (field.isBinary()) {\n            data = compress(field.getBinaryValue(), field.getBinaryOffset(), field.getBinaryLength());\n          } else {\n            byte x[] = field.stringValue().getBytes(\"UTF-8\");\n            data = compress(x, 0, x.length);\n          }\n          len = data.length;\n          offset = 0;\n        }\n        \n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        // compression is disabled for the current field\n        if (field.isBinary()) {\n          final byte[] data;\n          final int len;\n          final int offset;\n          data = field.getBinaryValue();\n          len = field.getBinaryLength();\n          offset =  field.getBinaryOffset();\n\n          fieldsStream.writeVInt(len);\n          fieldsStream.writeBytes(data, offset, len);\n        }\n        else {\n          fieldsStream.writeString(field.stringValue());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e0c804f7aa477229414a7e12882af490c241f64d","date":1254963299,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","pathOld":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","sourceNew":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isBinary()) {\n        final byte[] data;\n        final int len;\n        final int offset;\n        data = field.getBinaryValue();\n        len = field.getBinaryLength();\n        offset =  field.getBinaryOffset();\n\n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        fieldsStream.writeString(field.stringValue());\n      }\n    }\n\n","sourceOld":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      // if the field as an instanceof FieldsReader.FieldForMerge, we're in merge mode\n      // and field.binaryValue() already returns the compressed value for a field\n      // with isCompressed()==true, so we disable compression in that case\n      boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n      if (field.isCompressed())\n        bits |= FieldsWriter.FIELD_IS_COMPRESSED;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isCompressed()) {\n        // compression is enabled for the current field\n        final byte[] data;\n        final int len;\n        final int offset;\n        if (disableCompression) {\n          // optimized case for merging, the data\n          // is already compressed\n          data = field.getBinaryValue();\n          assert data != null;\n          len = field.getBinaryLength();\n          offset = field.getBinaryOffset();  \n        } else {\n          // check if it is a binary field\n          if (field.isBinary()) {\n            data = CompressionTools.compress(field.getBinaryValue(), field.getBinaryOffset(), field.getBinaryLength());\n          } else {\n            byte x[] = field.stringValue().getBytes(\"UTF-8\");\n            data = CompressionTools.compress(x, 0, x.length);\n          }\n          len = data.length;\n          offset = 0;\n        }\n        \n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        // compression is disabled for the current field\n        if (field.isBinary()) {\n          final byte[] data;\n          final int len;\n          final int offset;\n          data = field.getBinaryValue();\n          len = field.getBinaryLength();\n          offset =  field.getBinaryOffset();\n\n          fieldsStream.writeVInt(len);\n          fieldsStream.writeBytes(data, offset, len);\n        }\n        else {\n          fieldsStream.writeString(field.stringValue());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","pathOld":"src/java/org/apache/lucene/index/FieldsWriter#writeField(FieldInfo,Fieldable).mjava","sourceNew":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isBinary()) {\n        final byte[] data;\n        final int len;\n        final int offset;\n        data = field.getBinaryValue();\n        len = field.getBinaryLength();\n        offset =  field.getBinaryOffset();\n\n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        fieldsStream.writeString(field.stringValue());\n      }\n    }\n\n","sourceOld":"    final void writeField(FieldInfo fi, Fieldable field) throws IOException {\n      fieldsStream.writeVInt(fi.number);\n      byte bits = 0;\n      if (field.isTokenized())\n        bits |= FieldsWriter.FIELD_IS_TOKENIZED;\n      if (field.isBinary())\n        bits |= FieldsWriter.FIELD_IS_BINARY;\n                \n      fieldsStream.writeByte(bits);\n                \n      if (field.isBinary()) {\n        final byte[] data;\n        final int len;\n        final int offset;\n        data = field.getBinaryValue();\n        len = field.getBinaryLength();\n        offset =  field.getBinaryOffset();\n\n        fieldsStream.writeVInt(len);\n        fieldsStream.writeBytes(data, offset, len);\n      }\n      else {\n        fieldsStream.writeString(field.stringValue());\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7d7203a8194ca217ec527231120df075e9bec237":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e0c804f7aa477229414a7e12882af490c241f64d":["de01496176b31b9496ca92b2faebc31e16d91cc0"],"de01496176b31b9496ca92b2faebc31e16d91cc0":["d03062c59d1dcb53f10a483e2259b28499f94b3e"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["e0c804f7aa477229414a7e12882af490c241f64d"],"d03062c59d1dcb53f10a483e2259b28499f94b3e":["7d7203a8194ca217ec527231120df075e9bec237"]},"commit2Childs":{"7d7203a8194ca217ec527231120df075e9bec237":["d03062c59d1dcb53f10a483e2259b28499f94b3e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["7d7203a8194ca217ec527231120df075e9bec237"],"e0c804f7aa477229414a7e12882af490c241f64d":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"de01496176b31b9496ca92b2faebc31e16d91cc0":["e0c804f7aa477229414a7e12882af490c241f64d"],"d03062c59d1dcb53f10a483e2259b28499f94b3e":["de01496176b31b9496ca92b2faebc31e16d91cc0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}