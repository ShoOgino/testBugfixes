{"path":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","commits":[{"id":"42579622cc27f9908e64f29fa1130bfc28306009","date":1177874771,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"/dev/null","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    Similarity similarity = Similarity.getDefault();\n    DocumentWriter writer = new DocumentWriter(dir, new SimpleAnalyzer(), similarity, 50);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    String segName = \"test\";\n    writer.addDocument(segName, doc);\n    SegmentReader reader = SegmentReader.get(new SegmentInfo(segName, 1, dir));\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b20bed3506d9b128ea30a7a62e2a8b1d7df697b0","date":1185569419,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    Similarity similarity = Similarity.getDefault();\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.segmentInfos.info(writer.segmentInfos.size()-1);\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    Similarity similarity = Similarity.getDefault();\n    DocumentWriter writer = new DocumentWriter(dir, new SimpleAnalyzer(), similarity, 50);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    String segName = \"test\";\n    writer.addDocument(segName, doc);\n    SegmentReader reader = SegmentReader.get(new SegmentInfo(segName, 1, dir));\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b1405362241b561f5590ff4a87d5d6e173bcd9cf","date":1190107634,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    Similarity similarity = Similarity.getDefault();\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    Similarity similarity = Similarity.getDefault();\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.segmentInfos.info(writer.segmentInfos.size()-1);\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3d6229c48c0cbc7849950f7a240f07739812b2f","date":1199345558,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    Similarity similarity = Similarity.getDefault();\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0018e7a0579df5d3de71d0bd878322a7abef04d9","date":1202242049,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next(final Token reusableToken) throws IOException {\n        assert reusableToken != null;\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return reusableToken.reinit(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next() throws IOException {\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return new Token(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223","date":1227051709,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);\n      \n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      public Token next(final Token reusableToken) throws IOException {\n        assert reusableToken != null;\n        if (index == tokens.length) {\n          return null;\n        } else {\n          return reusableToken.reinit(tokens[index++], 0, 0);\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);\n      \n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1","date":1255502337,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.flush();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(info);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1326054a8d3aa66382d49decc7f330955c9c6f71","date":1257386139,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"360d15dc189fb48153cb62234f7d20819e4e292e","date":1263562938,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT).setAnalyzer(new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT).setAnalyzer(new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new SimpleAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","pathOld":"src/test/org/apache/lucene/index/TestDocumentWriter#testPreAnalyzedField().mjava","sourceNew":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","sourceOld":"  public void testPreAnalyzedField() throws IOException {\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    \n    doc.add(new Field(\"preanalyzed\", new TokenStream() {\n      private String[] tokens = new String[] {\"term1\", \"term2\", \"term3\", \"term2\"};\n      private int index = 0;\n      \n      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n      \n      @Override\n      public boolean incrementToken() throws IOException {\n        if (index == tokens.length) {\n          return false;\n        } else {\n          clearAttributes();\n          termAtt.setTermBuffer(tokens[index++]);\n          return true;\n        }        \n      }\n      \n    }, TermVector.NO));\n    \n    writer.addDocument(doc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    SegmentReader reader = SegmentReader.get(true, info, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n\n    TermPositions termPositions = reader.termPositions(new Term(\"preanalyzed\", \"term1\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(0, termPositions.nextPosition());\n\n    termPositions.seek(new Term(\"preanalyzed\", \"term2\"));\n    assertTrue(termPositions.next());\n    assertEquals(2, termPositions.freq());\n    assertEquals(1, termPositions.nextPosition());\n    assertEquals(3, termPositions.nextPosition());\n    \n    termPositions.seek(new Term(\"preanalyzed\", \"term3\"));\n    assertTrue(termPositions.next());\n    assertEquals(1, termPositions.freq());\n    assertEquals(2, termPositions.nextPosition());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["0018e7a0579df5d3de71d0bd878322a7abef04d9"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["b20bed3506d9b128ea30a7a62e2a8b1d7df697b0"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"b20bed3506d9b128ea30a7a62e2a8b1d7df697b0":["42579622cc27f9908e64f29fa1130bfc28306009"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"0018e7a0579df5d3de71d0bd878322a7abef04d9":["d3d6229c48c0cbc7849950f7a240f07739812b2f"],"360d15dc189fb48153cb62234f7d20819e4e292e":["1326054a8d3aa66382d49decc7f330955c9c6f71"],"1326054a8d3aa66382d49decc7f330955c9c6f71":["be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["360d15dc189fb48153cb62234f7d20819e4e292e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8d78f014fded44fbde905f4f84cdc21907b371e8":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"42579622cc27f9908e64f29fa1130bfc28306009":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d3d6229c48c0cbc7849950f7a240f07739812b2f":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["d3d6229c48c0cbc7849950f7a240f07739812b2f"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"b20bed3506d9b128ea30a7a62e2a8b1d7df697b0":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1":["1326054a8d3aa66382d49decc7f330955c9c6f71"],"0018e7a0579df5d3de71d0bd878322a7abef04d9":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"360d15dc189fb48153cb62234f7d20819e4e292e":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"1326054a8d3aa66382d49decc7f330955c9c6f71":["360d15dc189fb48153cb62234f7d20819e4e292e"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["42579622cc27f9908e64f29fa1130bfc28306009"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1"],"42579622cc27f9908e64f29fa1130bfc28306009":["b20bed3506d9b128ea30a7a62e2a8b1d7df697b0"],"d3d6229c48c0cbc7849950f7a240f07739812b2f":["0018e7a0579df5d3de71d0bd878322a7abef04d9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}