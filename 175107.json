{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","commits":[{"id":"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69","date":1352818449,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n    assert bytes.length == length;\n\n    final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case STOP:\n          return;\n      }\n    }\n    assert documentInput.getPosition() == bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + \" \" + bytes.length;\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n    assert bytes.length == length;\n\n    final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case STOP:\n          return;\n      }\n    }\n    assert documentInput.getPosition() == bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + \" \" + bytes.length;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n    assert bytes.length == length;\n\n    final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case STOP:\n          return;\n      }\n    }\n    assert documentInput.getPosition() == bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + \" \" + bytes.length;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90f762b9c981401224de7f0a7c1ffc8fbc67574f","date":1366475889,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs + \" (resource=\" + fieldsStream + \")\");\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields + \" (resource=\" + fieldsStream + \")\");\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n    assert bytes.length == length;\n\n    final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case STOP:\n          return;\n      }\n    }\n    assert documentInput.getPosition() == bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + \" \" + bytes.length;\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n    assert bytes.length == length;\n\n    final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case STOP:\n          return;\n      }\n    }\n    assert documentInput.getPosition() == bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + \" \" + bytes.length;\n  }\n\n","bugFix":null,"bugIntro":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb635b7759c901613d0bc72e51e039ba422b823b","date":1370853590,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs + \" (resource=\" + fieldsStream + \")\");\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields + \" (resource=\" + fieldsStream + \")\");\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n    decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n    assert bytes.length == length;\n\n    final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case STOP:\n          return;\n      }\n    }\n    assert documentInput.getPosition() == bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + \" \" + bytes.length;\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs + \" (resource=\" + fieldsStream + \")\");\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields + \" (resource=\" + fieldsStream + \")\");\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n    assert bytes.length == length;\n\n    final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case STOP:\n          return;\n      }\n    }\n    assert documentInput.getPosition() == bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + \" \" + bytes.length;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"47081d784f5fff71bb715c806c824b50901392fb","date":1378303234,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs + \" (resource=\" + fieldsStream + \")\");\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields + \" (resource=\" + fieldsStream + \")\");\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final DataInput documentInput;\n    if (version >= VERSION_BIG_CHUNKS && totalLength >= 2 * chunkSize) {\n      assert chunkSize > 0;\n      assert offset < chunkSize;\n\n      decompressor.decompress(fieldsStream, chunkSize, offset, Math.min(length, chunkSize - offset), bytes);\n      documentInput = new DataInput() {\n\n        int decompressed = bytes.length;\n\n        void fillBuffer() throws IOException {\n          assert decompressed <= length;\n          if (decompressed == length) {\n            throw new EOFException();\n          }\n          final int toDecompress = Math.min(length - decompressed, chunkSize);\n          decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, bytes);\n          decompressed += toDecompress;\n        }\n\n        @Override\n        public byte readByte() throws IOException {\n          if (bytes.length == 0) {\n            fillBuffer();\n          }\n          --bytes.length;\n          return bytes.bytes[bytes.offset++];\n        }\n\n        @Override\n        public void readBytes(byte[] b, int offset, int len) throws IOException {\n          while (len > bytes.length) {\n            System.arraycopy(bytes.bytes, bytes.offset, b, offset, bytes.length);\n            len -= bytes.length;\n            offset += bytes.length;\n            fillBuffer();\n          }\n          System.arraycopy(bytes.bytes, bytes.offset, b, offset, len);\n          bytes.offset += len;\n          bytes.length -= len;\n        }\n\n      };\n    } else {\n      final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n      decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n      assert bytes.length == length;\n      documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    }\n\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs + \" (resource=\" + fieldsStream + \")\");\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields + \" (resource=\" + fieldsStream + \")\");\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n    decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n    assert bytes.length == length;\n\n    final ByteArrayDataInput documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          assert documentInput.getPosition() <= bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + bytes.length;\n          break;\n        case STOP:\n          return;\n      }\n    }\n    assert documentInput.getPosition() == bytes.offset + bytes.length : documentInput.getPosition() + \" \" + bytes.offset + \" \" + bytes.length;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs, fieldsStream);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields, fieldsStream);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final DataInput documentInput;\n    if (version >= VERSION_BIG_CHUNKS && totalLength >= 2 * chunkSize) {\n      assert chunkSize > 0;\n      assert offset < chunkSize;\n\n      decompressor.decompress(fieldsStream, chunkSize, offset, Math.min(length, chunkSize - offset), bytes);\n      documentInput = new DataInput() {\n\n        int decompressed = bytes.length;\n\n        void fillBuffer() throws IOException {\n          assert decompressed <= length;\n          if (decompressed == length) {\n            throw new EOFException();\n          }\n          final int toDecompress = Math.min(length - decompressed, chunkSize);\n          decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, bytes);\n          decompressed += toDecompress;\n        }\n\n        @Override\n        public byte readByte() throws IOException {\n          if (bytes.length == 0) {\n            fillBuffer();\n          }\n          --bytes.length;\n          return bytes.bytes[bytes.offset++];\n        }\n\n        @Override\n        public void readBytes(byte[] b, int offset, int len) throws IOException {\n          while (len > bytes.length) {\n            System.arraycopy(bytes.bytes, bytes.offset, b, offset, bytes.length);\n            len -= bytes.length;\n            offset += bytes.length;\n            fillBuffer();\n          }\n          System.arraycopy(bytes.bytes, bytes.offset, b, offset, len);\n          bytes.offset += len;\n          bytes.length -= len;\n        }\n\n      };\n    } else {\n      final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n      decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n      assert bytes.length == length;\n      documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    }\n\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs + \" (resource=\" + fieldsStream + \")\");\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength + \" (resource=\" + fieldsStream + \")\");\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields + \" (resource=\" + fieldsStream + \")\");\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final DataInput documentInput;\n    if (version >= VERSION_BIG_CHUNKS && totalLength >= 2 * chunkSize) {\n      assert chunkSize > 0;\n      assert offset < chunkSize;\n\n      decompressor.decompress(fieldsStream, chunkSize, offset, Math.min(length, chunkSize - offset), bytes);\n      documentInput = new DataInput() {\n\n        int decompressed = bytes.length;\n\n        void fillBuffer() throws IOException {\n          assert decompressed <= length;\n          if (decompressed == length) {\n            throw new EOFException();\n          }\n          final int toDecompress = Math.min(length - decompressed, chunkSize);\n          decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, bytes);\n          decompressed += toDecompress;\n        }\n\n        @Override\n        public byte readByte() throws IOException {\n          if (bytes.length == 0) {\n            fillBuffer();\n          }\n          --bytes.length;\n          return bytes.bytes[bytes.offset++];\n        }\n\n        @Override\n        public void readBytes(byte[] b, int offset, int len) throws IOException {\n          while (len > bytes.length) {\n            System.arraycopy(bytes.bytes, bytes.offset, b, offset, bytes.length);\n            len -= bytes.length;\n            offset += bytes.length;\n            fillBuffer();\n          }\n          System.arraycopy(bytes.bytes, bytes.offset, b, offset, len);\n          bytes.offset += len;\n          bytes.length -= len;\n        }\n\n      };\n    } else {\n      final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n      decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n      assert bytes.length == length;\n      documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    }\n\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","bugFix":["90f762b9c981401224de7f0a7c1ffc8fbc67574f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"389e8bca54f58e35576077f3ff46f123b3660018","date":1411859915,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs, fieldsStream);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields, fieldsStream);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final DataInput documentInput;\n    if (totalLength >= 2 * chunkSize) {\n      assert chunkSize > 0;\n      assert offset < chunkSize;\n\n      decompressor.decompress(fieldsStream, chunkSize, offset, Math.min(length, chunkSize - offset), bytes);\n      documentInput = new DataInput() {\n\n        int decompressed = bytes.length;\n\n        void fillBuffer() throws IOException {\n          assert decompressed <= length;\n          if (decompressed == length) {\n            throw new EOFException();\n          }\n          final int toDecompress = Math.min(length - decompressed, chunkSize);\n          decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, bytes);\n          decompressed += toDecompress;\n        }\n\n        @Override\n        public byte readByte() throws IOException {\n          if (bytes.length == 0) {\n            fillBuffer();\n          }\n          --bytes.length;\n          return bytes.bytes[bytes.offset++];\n        }\n\n        @Override\n        public void readBytes(byte[] b, int offset, int len) throws IOException {\n          while (len > bytes.length) {\n            System.arraycopy(bytes.bytes, bytes.offset, b, offset, bytes.length);\n            len -= bytes.length;\n            offset += bytes.length;\n            fillBuffer();\n          }\n          System.arraycopy(bytes.bytes, bytes.offset, b, offset, len);\n          bytes.offset += len;\n          bytes.length -= len;\n        }\n\n      };\n    } else {\n      final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n      decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n      assert bytes.length == length;\n      documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    }\n\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs, fieldsStream);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields, fieldsStream);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final DataInput documentInput;\n    if (version >= VERSION_BIG_CHUNKS && totalLength >= 2 * chunkSize) {\n      assert chunkSize > 0;\n      assert offset < chunkSize;\n\n      decompressor.decompress(fieldsStream, chunkSize, offset, Math.min(length, chunkSize - offset), bytes);\n      documentInput = new DataInput() {\n\n        int decompressed = bytes.length;\n\n        void fillBuffer() throws IOException {\n          assert decompressed <= length;\n          if (decompressed == length) {\n            throw new EOFException();\n          }\n          final int toDecompress = Math.min(length - decompressed, chunkSize);\n          decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, bytes);\n          decompressed += toDecompress;\n        }\n\n        @Override\n        public byte readByte() throws IOException {\n          if (bytes.length == 0) {\n            fillBuffer();\n          }\n          --bytes.length;\n          return bytes.bytes[bytes.offset++];\n        }\n\n        @Override\n        public void readBytes(byte[] b, int offset, int len) throws IOException {\n          while (len > bytes.length) {\n            System.arraycopy(bytes.bytes, bytes.offset, b, offset, bytes.length);\n            len -= bytes.length;\n            offset += bytes.length;\n            fillBuffer();\n          }\n          System.arraycopy(bytes.bytes, bytes.offset, b, offset, len);\n          bytes.offset += len;\n          bytes.length -= len;\n        }\n\n      };\n    } else {\n      final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n      decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n      assert bytes.length == length;\n      documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    }\n\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs, fieldsStream);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields, fieldsStream);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final DataInput documentInput;\n    if (totalLength >= 2 * chunkSize) {\n      assert chunkSize > 0;\n      assert offset < chunkSize;\n\n      decompressor.decompress(fieldsStream, chunkSize, offset, Math.min(length, chunkSize - offset), bytes);\n      documentInput = new DataInput() {\n\n        int decompressed = bytes.length;\n\n        void fillBuffer() throws IOException {\n          assert decompressed <= length;\n          if (decompressed == length) {\n            throw new EOFException();\n          }\n          final int toDecompress = Math.min(length - decompressed, chunkSize);\n          decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, bytes);\n          decompressed += toDecompress;\n        }\n\n        @Override\n        public byte readByte() throws IOException {\n          if (bytes.length == 0) {\n            fillBuffer();\n          }\n          --bytes.length;\n          return bytes.bytes[bytes.offset++];\n        }\n\n        @Override\n        public void readBytes(byte[] b, int offset, int len) throws IOException {\n          while (len > bytes.length) {\n            System.arraycopy(bytes.bytes, bytes.offset, b, offset, bytes.length);\n            len -= bytes.length;\n            offset += bytes.length;\n            fillBuffer();\n          }\n          System.arraycopy(bytes.bytes, bytes.offset, b, offset, len);\n          bytes.offset += len;\n          bytes.length -= len;\n        }\n\n      };\n    } else {\n      final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n      decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n      assert bytes.length == length;\n      documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    }\n\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs, fieldsStream);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields, fieldsStream);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final DataInput documentInput;\n    if (version >= VERSION_BIG_CHUNKS && totalLength >= 2 * chunkSize) {\n      assert chunkSize > 0;\n      assert offset < chunkSize;\n\n      decompressor.decompress(fieldsStream, chunkSize, offset, Math.min(length, chunkSize - offset), bytes);\n      documentInput = new DataInput() {\n\n        int decompressed = bytes.length;\n\n        void fillBuffer() throws IOException {\n          assert decompressed <= length;\n          if (decompressed == length) {\n            throw new EOFException();\n          }\n          final int toDecompress = Math.min(length - decompressed, chunkSize);\n          decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, bytes);\n          decompressed += toDecompress;\n        }\n\n        @Override\n        public byte readByte() throws IOException {\n          if (bytes.length == 0) {\n            fillBuffer();\n          }\n          --bytes.length;\n          return bytes.bytes[bytes.offset++];\n        }\n\n        @Override\n        public void readBytes(byte[] b, int offset, int len) throws IOException {\n          while (len > bytes.length) {\n            System.arraycopy(bytes.bytes, bytes.offset, b, offset, bytes.length);\n            len -= bytes.length;\n            offset += bytes.length;\n            fillBuffer();\n          }\n          System.arraycopy(bytes.bytes, bytes.offset, b, offset, len);\n          bytes.offset += len;\n          bytes.length -= len;\n        }\n\n      };\n    } else {\n      final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n      decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n      assert bytes.length == length;\n      documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    }\n\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f09f483a0844bb9dc34fb10380cb053aa96219b","date":1418894001,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n\n    final SerializedDocument doc = document(docID);\n\n    for (int fieldIDX = 0; fieldIDX < doc.numStoredFields; fieldIDX++) {\n      final long infoAndBits = doc.in.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(doc.in, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(doc.in, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n    fieldsStream.seek(indexReader.getStartPointer(docID));\n\n    final int docBase = fieldsStream.readVInt();\n    final int chunkDocs = fieldsStream.readVInt();\n    if (docID < docBase\n        || docID >= docBase + chunkDocs\n        || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"Corrupted: docID=\" + docID\n          + \", docBase=\" + docBase + \", chunkDocs=\" + chunkDocs\n          + \", numDocs=\" + numDocs, fieldsStream);\n    }\n\n    final int numStoredFields, offset, length, totalLength;\n    if (chunkDocs == 1) {\n      numStoredFields = fieldsStream.readVInt();\n      offset = 0;\n      length = fieldsStream.readVInt();\n      totalLength = length;\n    } else {\n      final int bitsPerStoredFields = fieldsStream.readVInt();\n      if (bitsPerStoredFields == 0) {\n        numStoredFields = fieldsStream.readVInt();\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerStoredFields=\" + bitsPerStoredFields, fieldsStream);\n      } else {\n        final long filePointer = fieldsStream.getFilePointer();\n        final PackedInts.Reader reader = PackedInts.getDirectReaderNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerStoredFields);\n        numStoredFields = (int) (reader.get(docID - docBase));\n        fieldsStream.seek(filePointer + PackedInts.Format.PACKED.byteCount(packedIntsVersion, chunkDocs, bitsPerStoredFields));\n      }\n\n      final int bitsPerLength = fieldsStream.readVInt();\n      if (bitsPerLength == 0) {\n        length = fieldsStream.readVInt();\n        offset = (docID - docBase) * length;\n        totalLength = chunkDocs * length;\n      } else if (bitsPerStoredFields > 31) {\n        throw new CorruptIndexException(\"bitsPerLength=\" + bitsPerLength, fieldsStream);\n      } else {\n        final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(fieldsStream, PackedInts.Format.PACKED, packedIntsVersion, chunkDocs, bitsPerLength, 1);\n        int off = 0;\n        for (int i = 0; i < docID - docBase; ++i) {\n          off += it.next();\n        }\n        offset = off;\n        length = (int) it.next();\n        off += length;\n        for (int i = docID - docBase + 1; i < chunkDocs; ++i) {\n          off += it.next();\n        }\n        totalLength = off;\n      }\n    }\n\n    if ((length == 0) != (numStoredFields == 0)) {\n      throw new CorruptIndexException(\"length=\" + length + \", numStoredFields=\" + numStoredFields, fieldsStream);\n    }\n    if (numStoredFields == 0) {\n      // nothing to do\n      return;\n    }\n\n    final DataInput documentInput;\n    if (totalLength >= 2 * chunkSize) {\n      assert chunkSize > 0;\n      assert offset < chunkSize;\n\n      decompressor.decompress(fieldsStream, chunkSize, offset, Math.min(length, chunkSize - offset), bytes);\n      documentInput = new DataInput() {\n\n        int decompressed = bytes.length;\n\n        void fillBuffer() throws IOException {\n          assert decompressed <= length;\n          if (decompressed == length) {\n            throw new EOFException();\n          }\n          final int toDecompress = Math.min(length - decompressed, chunkSize);\n          decompressor.decompress(fieldsStream, toDecompress, 0, toDecompress, bytes);\n          decompressed += toDecompress;\n        }\n\n        @Override\n        public byte readByte() throws IOException {\n          if (bytes.length == 0) {\n            fillBuffer();\n          }\n          --bytes.length;\n          return bytes.bytes[bytes.offset++];\n        }\n\n        @Override\n        public void readBytes(byte[] b, int offset, int len) throws IOException {\n          while (len > bytes.length) {\n            System.arraycopy(bytes.bytes, bytes.offset, b, offset, bytes.length);\n            len -= bytes.length;\n            offset += bytes.length;\n            fillBuffer();\n          }\n          System.arraycopy(bytes.bytes, bytes.offset, b, offset, len);\n          bytes.offset += len;\n          bytes.length -= len;\n        }\n\n      };\n    } else {\n      final BytesRef bytes = totalLength <= BUFFER_REUSE_THRESHOLD ? this.bytes : new BytesRef();\n      decompressor.decompress(fieldsStream, totalLength, offset, length, bytes);\n      assert bytes.length == length;\n      documentInput = new ByteArrayDataInput(bytes.bytes, bytes.offset, bytes.length);\n    }\n\n    for (int fieldIDX = 0; fieldIDX < numStoredFields; fieldIDX++) {\n      final long infoAndBits = documentInput.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(documentInput, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(documentInput, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e4ea8c2c59f77765de616c84abb04a3a84632e6d","date":1447972427,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader#visitDocument(int,StoredFieldVisitor).mjava","sourceNew":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n\n    final SerializedDocument doc = document(docID);\n\n    for (int fieldIDX = 0; fieldIDX < doc.numStoredFields; fieldIDX++) {\n      final long infoAndBits = doc.in.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(doc.in, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          if (fieldIDX == doc.numStoredFields - 1) {// don't skipField on last field value; treat like STOP\n            return;\n          }\n          skipField(doc.in, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void visitDocument(int docID, StoredFieldVisitor visitor)\n      throws IOException {\n\n    final SerializedDocument doc = document(docID);\n\n    for (int fieldIDX = 0; fieldIDX < doc.numStoredFields; fieldIDX++) {\n      final long infoAndBits = doc.in.readVLong();\n      final int fieldNumber = (int) (infoAndBits >>> TYPE_BITS);\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n\n      final int bits = (int) (infoAndBits & TYPE_MASK);\n      assert bits <= NUMERIC_DOUBLE: \"bits=\" + Integer.toHexString(bits);\n\n      switch(visitor.needsField(fieldInfo)) {\n        case YES:\n          readField(doc.in, visitor, fieldInfo, bits);\n          break;\n        case NO:\n          skipField(doc.in, bits);\n          break;\n        case STOP:\n          return;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"90f762b9c981401224de7f0a7c1ffc8fbc67574f":["5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["47081d784f5fff71bb715c806c824b50901392fb"],"fb635b7759c901613d0bc72e51e039ba422b823b":["90f762b9c981401224de7f0a7c1ffc8fbc67574f"],"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9bb9a29a5e71a90295f175df8919802993142c9a":["9a70ce9bddc6f985feb8e5e182aebe20872328d4","389e8bca54f58e35576077f3ff46f123b3660018"],"e4ea8c2c59f77765de616c84abb04a3a84632e6d":["1f09f483a0844bb9dc34fb10380cb053aa96219b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69"],"1f09f483a0844bb9dc34fb10380cb053aa96219b":["9bb9a29a5e71a90295f175df8919802993142c9a"],"389e8bca54f58e35576077f3ff46f123b3660018":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"47081d784f5fff71bb715c806c824b50901392fb":["fb635b7759c901613d0bc72e51e039ba422b823b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e4ea8c2c59f77765de616c84abb04a3a84632e6d"]},"commit2Childs":{"90f762b9c981401224de7f0a7c1ffc8fbc67574f":["fb635b7759c901613d0bc72e51e039ba422b823b"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["9bb9a29a5e71a90295f175df8919802993142c9a","389e8bca54f58e35576077f3ff46f123b3660018"],"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69":["90f762b9c981401224de7f0a7c1ffc8fbc67574f","407687e67faf6e1f02a211ca078d8e3eed631027"],"fb635b7759c901613d0bc72e51e039ba422b823b":["47081d784f5fff71bb715c806c824b50901392fb"],"9bb9a29a5e71a90295f175df8919802993142c9a":["1f09f483a0844bb9dc34fb10380cb053aa96219b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69","407687e67faf6e1f02a211ca078d8e3eed631027"],"e4ea8c2c59f77765de616c84abb04a3a84632e6d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"1f09f483a0844bb9dc34fb10380cb053aa96219b":["e4ea8c2c59f77765de616c84abb04a3a84632e6d"],"389e8bca54f58e35576077f3ff46f123b3660018":["9bb9a29a5e71a90295f175df8919802993142c9a"],"47081d784f5fff71bb715c806c824b50901392fb":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}