{"path":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","commits":[{"id":"98a8a68e6714cb8742c790308b9f5180d63417d4","date":1272554039,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"/dev/null","sourceNew":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.terms[a.pos].compareTo(b.terms[b.pos]) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      String val = seg.terms[seg.pos];\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.terms[seg.pos]) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","d4d69c535930b5cce125cff868d40f6373dc27d4","d4d69c535930b5cce125cff868d40f6373dc27d4","7679cc7d5b465ec8936979698cedf5fdbd71c95c","7679cc7d5b465ec8936979698cedf5fdbd71c95c","7679cc7d5b465ec8936979698cedf5fdbd71c95c","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","1da2c39cf47fc10dc839d8c37890a2b009081e76"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"be20f9fed1d3edcb1c84abcc39df87a90fab22df","date":1275590285,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.si.lookup(a.pos, a.tempBR).compareTo(b.si.lookup(b.pos, b.tempBR)) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    final BytesRef tempBR = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      BytesRef val = seg.si.lookup(seg.pos, tempBR);\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.si.lookup(seg.pos, seg.tempBR)) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.terms[a.pos].compareTo(b.terms[b.pos]) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      String val = seg.terms[seg.pos];\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.terms[seg.pos]) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c42658ca6fd632045bce4a5238d766c64cb51018","date":1275608581,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.si.lookup(seg.pos, seg.tempBR);\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      // Is this always safe? Or could the byte[] be changed?\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.si.lookup(seg.pos, seg.tempBR);          \n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.si.lookup(a.pos, a.tempBR).compareTo(b.si.lookup(b.pos, b.tempBR)) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    final BytesRef tempBR = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      BytesRef val = seg.si.lookup(seg.pos, tempBR);\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.si.lookup(seg.pos, seg.tempBR)) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":["9328857b6413a6142e4cf01276887353c23898ed","9328857b6413a6142e4cf01276887353c23898ed","9328857b6413a6142e4cf01276887353c23898ed","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9069c2e665572658f846820b6cb8ad53de19df0","date":1276611358,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.si.lookup(seg.pos, seg.tempBR);\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      // Is this always safe? Or could the byte[] be changed?\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.si.lookup(seg.pos, seg.tempBR);          \n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","d4d69c535930b5cce125cff868d40f6373dc27d4","d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.si.lookup(seg.pos, seg.tempBR);\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      // Is this always safe? Or could the byte[] be changed?\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.si.lookup(seg.pos, seg.tempBR);          \n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2dadf0f3286a34a0fee6e788ffce88624bf2984e","date":1294260428,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":["1da2c39cf47fc10dc839d8c37890a2b009081e76"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"755f2f419306d7297c8feee10d1897addf4b2dd0","date":1294442354,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a10b98ef1ef4bf9e38d2e07a9e425a916afa8705","date":1294747166,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    SolrIndexReader topReader = searcher.getReader();\n    final SolrIndexReader[] leafReaders = topReader.getLeafReaders();\n    int[] offsets = topReader.getLeafOffsets();\n\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leafReaders.length; i++) {\n      final SegFacet segFacet = new SegFacet(leafReaders[i], offsets[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leafReaders.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leafReaders.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1da2c39cf47fc10dc839d8c37890a2b009081e76","date":1299662336,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":["98a8a68e6714cb8742c790308b9f5180d63417d4","2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>() {\n      {\n        initialize(leaves.length);\n      }\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seek(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"be20f9fed1d3edcb1c84abcc39df87a90fab22df":["98a8a68e6714cb8742c790308b9f5180d63417d4"],"c26f00b574427b55127e869b935845554afde1fa":["fd9cc9d77712aba3662f24632df7539ab75e3667","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"5f4e87790277826a2aea119328600dfb07761f32":["c42658ca6fd632045bce4a5238d766c64cb51018","e9069c2e665572658f846820b6cb8ad53de19df0"],"2553b00f699380c64959ccb27991289aae87be2e":["1da2c39cf47fc10dc839d8c37890a2b009081e76","fd9cc9d77712aba3662f24632df7539ab75e3667"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["1da2c39cf47fc10dc839d8c37890a2b009081e76","fd9cc9d77712aba3662f24632df7539ab75e3667"],"e9069c2e665572658f846820b6cb8ad53de19df0":["c42658ca6fd632045bce4a5238d766c64cb51018"],"1da2c39cf47fc10dc839d8c37890a2b009081e76":["a10b98ef1ef4bf9e38d2e07a9e425a916afa8705"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["868da859b43505d9d2a023bfeae6dd0c795f5295","1da2c39cf47fc10dc839d8c37890a2b009081e76"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["2553b00f699380c64959ccb27991289aae87be2e"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["29ef99d61cda9641b6250bf9567329a6e65f901d","1da2c39cf47fc10dc839d8c37890a2b009081e76"],"755f2f419306d7297c8feee10d1897addf4b2dd0":["2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["e9069c2e665572658f846820b6cb8ad53de19df0","a10b98ef1ef4bf9e38d2e07a9e425a916afa8705"],"2dadf0f3286a34a0fee6e788ffce88624bf2984e":["e9069c2e665572658f846820b6cb8ad53de19df0"],"c42658ca6fd632045bce4a5238d766c64cb51018":["be20f9fed1d3edcb1c84abcc39df87a90fab22df"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"98a8a68e6714cb8742c790308b9f5180d63417d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"a10b98ef1ef4bf9e38d2e07a9e425a916afa8705":["755f2f419306d7297c8feee10d1897addf4b2dd0"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["1da2c39cf47fc10dc839d8c37890a2b009081e76"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["5f4e87790277826a2aea119328600dfb07761f32","a10b98ef1ef4bf9e38d2e07a9e425a916afa8705"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"be20f9fed1d3edcb1c84abcc39df87a90fab22df":["c42658ca6fd632045bce4a5238d766c64cb51018"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5f4e87790277826a2aea119328600dfb07761f32":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"2553b00f699380c64959ccb27991289aae87be2e":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"e9069c2e665572658f846820b6cb8ad53de19df0":["5f4e87790277826a2aea119328600dfb07761f32","29ef99d61cda9641b6250bf9567329a6e65f901d","2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"1da2c39cf47fc10dc839d8c37890a2b009081e76":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d619839baa8ce5503e496b94a9e42ad6f079293f","fd9cc9d77712aba3662f24632df7539ab75e3667"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"d619839baa8ce5503e496b94a9e42ad6f079293f":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"755f2f419306d7297c8feee10d1897addf4b2dd0":["a10b98ef1ef4bf9e38d2e07a9e425a916afa8705"],"c42658ca6fd632045bce4a5238d766c64cb51018":["5f4e87790277826a2aea119328600dfb07761f32","e9069c2e665572658f846820b6cb8ad53de19df0"],"2dadf0f3286a34a0fee6e788ffce88624bf2984e":["755f2f419306d7297c8feee10d1897addf4b2dd0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["98a8a68e6714cb8742c790308b9f5180d63417d4"],"98a8a68e6714cb8742c790308b9f5180d63417d4":["be20f9fed1d3edcb1c84abcc39df87a90fab22df"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"a10b98ef1ef4bf9e38d2e07a9e425a916afa8705":["1da2c39cf47fc10dc839d8c37890a2b009081e76","29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["c26f00b574427b55127e869b935845554afde1fa","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","a258fbb26824fd104ed795e5d9033d2d040049ee"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d619839baa8ce5503e496b94a9e42ad6f079293f","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}