{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterGraphFilter#testRandomHugeStrings().mjava","commits":[{"id":"098528909bb70948871fd7ed865fafb87ed73964","date":1484667487,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterGraphFilter#testRandomHugeStrings().mjava","pathOld":"/dev/null","sourceNew":"  /** blast some enormous random strings through the analyzer */\n  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          TokenStream wdgf = new WordDelimiterGraphFilter(tokenizer, flags, protectedWords);\n          return new TokenStreamComponents(tokenizer, wdgf);\n        }\n      };\n      // TODO: properly support positionLengthAttribute\n      checkRandomData(random(), a, 20*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"302d34f2c66e8d489ee13078305c330cbf67b226","date":1484754357,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterGraphFilter#testRandomHugeStrings().mjava","pathOld":"/dev/null","sourceNew":"  /** blast some enormous random strings through the analyzer */\n  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          TokenStream wdgf = new WordDelimiterGraphFilter(tokenizer, flags, protectedWords);\n          return new TokenStreamComponents(tokenizer, wdgf);\n        }\n      };\n      // TODO: properly support positionLengthAttribute\n      checkRandomData(random(), a, 20*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterGraphFilter#testRandomHugeStrings().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterGraphFilter#testRandomHugeStrings().mjava","sourceNew":"  /** blast some enormous random strings through the analyzer */\n  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(3);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          TokenStream wdgf = new WordDelimiterGraphFilter(tokenizer, flags, protectedWords);\n          return new TokenStreamComponents(tokenizer, wdgf);\n        }\n      };\n      // TODO: properly support positionLengthAttribute\n      checkRandomData(random(), a, 10*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n\n","sourceOld":"  /** blast some enormous random strings through the analyzer */\n  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(5);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          TokenStream wdgf = new WordDelimiterGraphFilter(tokenizer, flags, protectedWords);\n          return new TokenStreamComponents(tokenizer, wdgf);\n        }\n      };\n      // TODO: properly support positionLengthAttribute\n      checkRandomData(random(), a, 20*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["71da933d30aea361ccc224d6544c451cbf49916d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"71da933d30aea361ccc224d6544c451cbf49916d","date":1579874339,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterGraphFilter#testRandomHugeStrings().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterGraphFilter#testRandomHugeStrings().mjava","sourceNew":"  /** blast some enormous random strings through the analyzer */\n  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(1);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          TokenStream wdgf = new WordDelimiterGraphFilter(tokenizer, flags, protectedWords);\n          return new TokenStreamComponents(tokenizer, wdgf);\n        }\n      };\n      // TODO: properly support positionLengthAttribute\n      checkRandomData(random(), a, 10*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n\n","sourceOld":"  /** blast some enormous random strings through the analyzer */\n  public void testRandomHugeStrings() throws Exception {\n    int numIterations = atLeast(3);\n    for (int i = 0; i < numIterations; i++) {\n      final int flags = random().nextInt(512);\n      final CharArraySet protectedWords;\n      if (random().nextBoolean()) {\n        protectedWords = new CharArraySet(new HashSet<>(Arrays.asList(\"a\", \"b\", \"cd\")), false);\n      } else {\n        protectedWords = null;\n      }\n      \n      Analyzer a = new Analyzer() {\n        \n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n          TokenStream wdgf = new WordDelimiterGraphFilter(tokenizer, flags, protectedWords);\n          return new TokenStreamComponents(tokenizer, wdgf);\n        }\n      };\n      // TODO: properly support positionLengthAttribute\n      checkRandomData(random(), a, 10*RANDOM_MULTIPLIER, 8192, false, false);\n      a.close();\n    }\n  }\n\n","bugFix":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["098528909bb70948871fd7ed865fafb87ed73964"],"098528909bb70948871fd7ed865fafb87ed73964":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71da933d30aea361ccc224d6544c451cbf49916d"],"71da933d30aea361ccc224d6544c451cbf49916d":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"302d34f2c66e8d489ee13078305c330cbf67b226":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","098528909bb70948871fd7ed865fafb87ed73964"]},"commit2Childs":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["71da933d30aea361ccc224d6544c451cbf49916d"],"098528909bb70948871fd7ed865fafb87ed73964":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","302d34f2c66e8d489ee13078305c330cbf67b226"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["098528909bb70948871fd7ed865fafb87ed73964","302d34f2c66e8d489ee13078305c330cbf67b226"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"71da933d30aea361ccc224d6544c451cbf49916d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"302d34f2c66e8d489ee13078305c330cbf67b226":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","302d34f2c66e8d489ee13078305c330cbf67b226"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}