{"path":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","commits":[{"id":"e7533828cbcc5f498a44cca5d9bce92692663778","date":1408525002,"type":0,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"/dev/null","sourceNew":"  private List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    if (atomicReader == null) {\n      throw new IOException(\"You must first call Classifier#train\");\n    }\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(atomicReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["8f0780ce1bf8d563b5988dc0d6f9ade232de0b61"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  private List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    if (leafReader == null) {\n      throw new IOException(\"You must first call Classifier#train\");\n    }\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","sourceOld":"  private List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    if (atomicReader == null) {\n      throw new IOException(\"You must first call Classifier#train\");\n    }\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(atomicReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  private List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    if (leafReader == null) {\n      throw new IOException(\"You must first call Classifier#train\");\n    }\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","sourceOld":"  private List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    if (leafReader == null) {\n      throw new IOException(\"You must first call Classifier#train\");\n    }\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1b1d9c529eb221063d2cb164d05be5f922980ac7","date":1430403225,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  private List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","sourceOld":"  private List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    if (leafReader == null) {\n      throw new IOException(\"You must first call Classifier#train\");\n    }\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9ba9b7b122d927a15ff4837e3d72876c609fef1b","date":1441232513,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      if (next.length > 0) {\n        double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n        dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","sourceOld":"  private List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n      dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","bugFix":null,"bugIntro":["9c63b5b9eba0164523ce84e04469a458710d9f26","8f0780ce1bf8d563b5988dc0d6f9ade232de0b61"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9c63b5b9eba0164523ce84e04469a458710d9f26","date":1443530980,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      if (next.length > 0) {\n        // We are passing the term to IndexSearcher so we need to make sure it will not change over time\n        next = BytesRef.deepCopyOf(next);\n        double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n        dataList.add(new ClassificationResult<>(next, clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      if (next.length > 0) {\n        double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n        dataList.add(new ClassificationResult<>(BytesRef.deepCopyOf(next), clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","bugFix":["9ba9b7b122d927a15ff4837e3d72876c609fef1b"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"134a24d0cb66520908d88384f1a559875704ed25","date":1445326601,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum classesEnum = classes.iterator();\n    BytesRef next;\n    String[] tokenizedText = tokenize(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = classesEnum.next()) != null) {\n      if (next.length > 0) {\n        // We are passing the term to IndexSearcher so we need to make sure it will not change over time\n        next = BytesRef.deepCopyOf(next);\n        double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedText, next, docsWithClassSize);\n        assignedClasses.add(new ClassificationResult<>(next, clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> assignedClassesNorm = normClassificationResults(assignedClasses);\n\n    return assignedClassesNorm;\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> dataList = new ArrayList<>();\n\n    Terms terms = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef next;\n    String[] tokenizedDoc = tokenizeDoc(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = termsEnum.next()) != null) {\n      if (next.length > 0) {\n        // We are passing the term to IndexSearcher so we need to make sure it will not change over time\n        next = BytesRef.deepCopyOf(next);\n        double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedDoc, next, docsWithClassSize);\n        dataList.add(new ClassificationResult<>(next, clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> returnList = new ArrayList<>();\n    if (!dataList.isEmpty()) {\n      Collections.sort(dataList);\n      // this is a negative number closest to 0 = a\n      double smax = dataList.get(0).getScore();\n\n      double sumLog = 0;\n      // log(sum(exp(x_n-a)))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        // getScore-smax <=0 (both negative, smax is the smallest abs()\n        sumLog += Math.exp(cr.getScore() - smax);\n      }\n      // loga=a+log(sum(exp(x_n-a))) = log(sum(exp(x_n)))\n      double loga = smax;\n      loga += Math.log(sumLog);\n\n      // 1/sum*x = exp(log(x))*1/sum = exp(log(x)-log(sum))\n      for (ClassificationResult<BytesRef> cr : dataList) {\n        returnList.add(new ClassificationResult<>(cr.getAssignedClass(), Math.exp(cr.getScore() - loga)));\n      }\n    }\n\n    return returnList;\n  }\n\n","bugFix":null,"bugIntro":["8f0780ce1bf8d563b5988dc0d6f9ade232de0b61"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38b5bd3ae837751f57f363e9a41b833794222814","date":1445342257,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum classesEnum = classes.iterator();\n    BytesRef next;\n    String[] tokenizedText = tokenize(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = classesEnum.next()) != null) {\n      if (next.length > 0) {\n        // We are passing the term to IndexSearcher so we need to make sure it will not change over time\n        Term term = new Term(this.classFieldName, next);\n        double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n        assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum classesEnum = classes.iterator();\n    BytesRef next;\n    String[] tokenizedText = tokenize(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = classesEnum.next()) != null) {\n      if (next.length > 0) {\n        // We are passing the term to IndexSearcher so we need to make sure it will not change over time\n        next = BytesRef.deepCopyOf(next);\n        double clVal = calculateLogPrior(next, docsWithClassSize) + calculateLogLikelihood(tokenizedText, next, docsWithClassSize);\n        assignedClasses.add(new ClassificationResult<>(next, clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    ArrayList<ClassificationResult<BytesRef>> assignedClassesNorm = normClassificationResults(assignedClasses);\n\n    return assignedClassesNorm;\n  }\n\n","bugFix":null,"bugIntro":["8f0780ce1bf8d563b5988dc0d6f9ade232de0b61"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9dce777c41006be1f71018e7565152f6dbc67140","date":1445869278,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum classesEnum = classes.iterator();\n    BytesRef next;\n    String[] tokenizedText = tokenize(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = classesEnum.next()) != null) {\n      if (next.length > 0) {\n        Term term = new Term(this.classFieldName, next);\n        double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n        assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum classesEnum = classes.iterator();\n    BytesRef next;\n    String[] tokenizedText = tokenize(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = classesEnum.next()) != null) {\n      if (next.length > 0) {\n        // We are passing the term to IndexSearcher so we need to make sure it will not change over time\n        Term term = new Term(this.classFieldName, next);\n        double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n        assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f0780ce1bf8d563b5988dc0d6f9ade232de0b61","date":1464272038,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    if (classes != null) {\n      TermsEnum classesEnum = classes.iterator();\n      BytesRef next;\n      String[] tokenizedText = tokenize(inputDocument);\n      int docsWithClassSize = countDocsWithClass();\n      while ((next = classesEnum.next()) != null) {\n        if (next.length > 0) {\n          Term term = new Term(this.classFieldName, next);\n          double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n          assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n        }\n      }\n    }\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum classesEnum = classes.iterator();\n    BytesRef next;\n    String[] tokenizedText = tokenize(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = classesEnum.next()) != null) {\n      if (next.length > 0) {\n        Term term = new Term(this.classFieldName, next);\n        double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n        assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","bugFix":["e7533828cbcc5f498a44cca5d9bce92692663778","9ba9b7b122d927a15ff4837e3d72876c609fef1b","38b5bd3ae837751f57f363e9a41b833794222814","134a24d0cb66520908d88384f1a559875704ed25"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83870855d82aba6819217abeff5a40779dbb28b4","date":1464291012,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    if (classes != null) {\n      TermsEnum classesEnum = classes.iterator();\n      BytesRef next;\n      String[] tokenizedText = tokenize(inputDocument);\n      int docsWithClassSize = countDocsWithClass();\n      while ((next = classesEnum.next()) != null) {\n        if (next.length > 0) {\n          Term term = new Term(this.classFieldName, next);\n          double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n          assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n        }\n      }\n    }\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum classesEnum = classes.iterator();\n    BytesRef next;\n    String[] tokenizedText = tokenize(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = classesEnum.next()) != null) {\n      if (next.length > 0) {\n        Term term = new Term(this.classFieldName, next);\n        double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n        assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"444d4b906d0e3398f87d6a5c4967c508f11a7f0b","date":1466507434,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(indexReader, classFieldName);\n    if (classes != null) {\n      TermsEnum classesEnum = classes.iterator();\n      BytesRef next;\n      String[] tokenizedText = tokenize(inputDocument);\n      int docsWithClassSize = countDocsWithClass();\n      while ((next = classesEnum.next()) != null) {\n        if (next.length > 0) {\n          Term term = new Term(this.classFieldName, next);\n          double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n          assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n        }\n      }\n    }\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    if (classes != null) {\n      TermsEnum classesEnum = classes.iterator();\n      BytesRef next;\n      String[] tokenizedText = tokenize(inputDocument);\n      int docsWithClassSize = countDocsWithClass();\n      while ((next = classesEnum.next()) != null) {\n        if (next.length > 0) {\n          Term term = new Term(this.classFieldName, next);\n          double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n          assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n        }\n      }\n    }\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(indexReader, classFieldName);\n    if (classes != null) {\n      TermsEnum classesEnum = classes.iterator();\n      BytesRef next;\n      String[] tokenizedText = tokenize(inputDocument);\n      int docsWithClassSize = countDocsWithClass();\n      while ((next = classesEnum.next()) != null) {\n        if (next.length > 0) {\n          Term term = new Term(this.classFieldName, next);\n          double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n          assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n        }\n      }\n    }\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(leafReader, classFieldName);\n    TermsEnum classesEnum = classes.iterator();\n    BytesRef next;\n    String[] tokenizedText = tokenize(inputDocument);\n    int docsWithClassSize = countDocsWithClass();\n    while ((next = classesEnum.next()) != null) {\n      if (next.length > 0) {\n        Term term = new Term(this.classFieldName, next);\n        double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n        assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n      }\n    }\n\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/SimpleNaiveBayesClassifier#assignClassNormalizedList(String).mjava","sourceNew":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiTerms.getTerms(indexReader, classFieldName);\n    if (classes != null) {\n      TermsEnum classesEnum = classes.iterator();\n      BytesRef next;\n      String[] tokenizedText = tokenize(inputDocument);\n      int docsWithClassSize = countDocsWithClass();\n      while ((next = classesEnum.next()) != null) {\n        if (next.length > 0) {\n          Term term = new Term(this.classFieldName, next);\n          double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n          assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n        }\n      }\n    }\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","sourceOld":"  /**\n   * Calculate probabilities for all classes for a given input text\n   * @param inputDocument the input text as a {@code String}\n   * @return a {@code List} of {@code ClassificationResult}, one for each existing class\n   * @throws IOException if assigning probabilities fails\n   */\n  protected List<ClassificationResult<BytesRef>> assignClassNormalizedList(String inputDocument) throws IOException {\n    List<ClassificationResult<BytesRef>> assignedClasses = new ArrayList<>();\n\n    Terms classes = MultiFields.getTerms(indexReader, classFieldName);\n    if (classes != null) {\n      TermsEnum classesEnum = classes.iterator();\n      BytesRef next;\n      String[] tokenizedText = tokenize(inputDocument);\n      int docsWithClassSize = countDocsWithClass();\n      while ((next = classesEnum.next()) != null) {\n        if (next.length > 0) {\n          Term term = new Term(this.classFieldName, next);\n          double clVal = calculateLogPrior(term, docsWithClassSize) + calculateLogLikelihood(tokenizedText, term, docsWithClassSize);\n          assignedClasses.add(new ClassificationResult<>(term.bytes(), clVal));\n        }\n      }\n    }\n    // normalization; the values transforms to a 0-1 range\n    return normClassificationResults(assignedClasses);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"444d4b906d0e3398f87d6a5c4967c508f11a7f0b":["8f0780ce1bf8d563b5988dc0d6f9ade232de0b61"],"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"9dce777c41006be1f71018e7565152f6dbc67140":["38b5bd3ae837751f57f363e9a41b833794222814"],"83870855d82aba6819217abeff5a40779dbb28b4":["9dce777c41006be1f71018e7565152f6dbc67140","8f0780ce1bf8d563b5988dc0d6f9ade232de0b61"],"134a24d0cb66520908d88384f1a559875704ed25":["9c63b5b9eba0164523ce84e04469a458710d9f26"],"1b1d9c529eb221063d2cb164d05be5f922980ac7":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["e7533828cbcc5f498a44cca5d9bce92692663778"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["9dce777c41006be1f71018e7565152f6dbc67140","444d4b906d0e3398f87d6a5c4967c508f11a7f0b"],"9ba9b7b122d927a15ff4837e3d72876c609fef1b":["1b1d9c529eb221063d2cb164d05be5f922980ac7"],"e7533828cbcc5f498a44cca5d9bce92692663778":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9c63b5b9eba0164523ce84e04469a458710d9f26":["9ba9b7b122d927a15ff4837e3d72876c609fef1b"],"8f0780ce1bf8d563b5988dc0d6f9ade232de0b61":["9dce777c41006be1f71018e7565152f6dbc67140"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"38b5bd3ae837751f57f363e9a41b833794222814":["134a24d0cb66520908d88384f1a559875704ed25"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["444d4b906d0e3398f87d6a5c4967c508f11a7f0b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["04e775de416dd2d8067b10db1c8af975a1d5017e"]},"commit2Childs":{"444d4b906d0e3398f87d6a5c4967c508f11a7f0b":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","04e775de416dd2d8067b10db1c8af975a1d5017e"],"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["1b1d9c529eb221063d2cb164d05be5f922980ac7"],"9dce777c41006be1f71018e7565152f6dbc67140":["83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","8f0780ce1bf8d563b5988dc0d6f9ade232de0b61"],"83870855d82aba6819217abeff5a40779dbb28b4":[],"134a24d0cb66520908d88384f1a559875704ed25":["38b5bd3ae837751f57f363e9a41b833794222814"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"1b1d9c529eb221063d2cb164d05be5f922980ac7":["9ba9b7b122d927a15ff4837e3d72876c609fef1b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"9ba9b7b122d927a15ff4837e3d72876c609fef1b":["9c63b5b9eba0164523ce84e04469a458710d9f26"],"e7533828cbcc5f498a44cca5d9bce92692663778":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"9c63b5b9eba0164523ce84e04469a458710d9f26":["134a24d0cb66520908d88384f1a559875704ed25"],"8f0780ce1bf8d563b5988dc0d6f9ade232de0b61":["444d4b906d0e3398f87d6a5c4967c508f11a7f0b","83870855d82aba6819217abeff5a40779dbb28b4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e7533828cbcc5f498a44cca5d9bce92692663778"],"38b5bd3ae837751f57f363e9a41b833794222814":["9dce777c41006be1f71018e7565152f6dbc67140"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["83870855d82aba6819217abeff5a40779dbb28b4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}