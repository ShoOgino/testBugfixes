{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","commits":[{"id":"367f57e2ee85b7f7e28cfe73370a22cf67624f65","date":1476778467,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointsReader).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointsReader reader) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = reader.size(fieldName);\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      reader.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(reader.getDocID(i));\n    }\n\n    build(1, numLeaves, reader, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"/dev/null","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4ad863d796f4e72a3a1ef4bacd2e19c3e9258c9","date":1481155163,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":["b35cfd3fa0a5c9e066b0256c4818af1d2a9f22d7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b35cfd3fa0a5c9e066b0256c4818af1d2a9f22d7","date":1482745036,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":["c4ad863d796f4e72a3a1ef4bacd2e19c3e9258c9"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15fe6782474c00ec2ccc636052a025f8fe0bdb8b","date":1484743707,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"302d34f2c66e8d489ee13078305c330cbf67b226","date":1484754357,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41f60ea1802fda42d3c91d023406066d00ddb5f8","date":1535615991,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76a51551f05a6c96a115b5a656837ecc8fd0b1ff","date":1551422476,"type":3,"author":"iverase","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b88a121b875f9ae2ac50f85cf46dcb680f126357","date":1555416009,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0f206e78bea6261260b24c406e920d05c7ca2f3","date":1570809619,"type":3,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    computePackedValueBounds(values, 0, Math.toIntExact(pointCount), minPackedValue, maxPackedValue, scratchBytesRef1);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue.clone(), maxPackedValue.clone(), parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    computePackedValueBounds(values, 0, Math.toIntExact(pointCount), minPackedValue, maxPackedValue, scratchBytesRef1);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue.clone(), maxPackedValue.clone(), parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7","date":1588412059,"type":3,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    pointCount = values.size();\n\n    final int numLeaves = Math.toIntExact((pointCount + maxPointsInLeafNode - 1) / maxPointsInLeafNode);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    computePackedValueBounds(values, 0, Math.toIntExact(pointCount), minPackedValue, maxPackedValue, scratchBytesRef1);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, 0, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue.clone(), maxPackedValue.clone(), parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, maxPointsInLeafNode, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    computePackedValueBounds(values, 0, Math.toIntExact(pointCount), minPackedValue, maxPackedValue, scratchBytesRef1);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue.clone(), maxPackedValue.clone(), parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, Math.toIntExact(countPerLeaf), leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"125e5eeb7e933deec0cc0510c2368fe1ec7c36ce","date":1589215155,"type":3,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    pointCount = values.size();\n\n    final int numLeaves = Math.toIntExact((pointCount + maxPointsInLeafNode - 1) / maxPointsInLeafNode);\n    final int numSplits = numLeaves - 1;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numSplits * bytesPerDim];\n    final byte[] splitDimensionValues = new byte[numSplits];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    computePackedValueBounds(values, 0, Math.toIntExact(pointCount), minPackedValue, maxPackedValue, scratchBytesRef1);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(0, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue.clone(), maxPackedValue.clone(), parentSplits,\n          splitPackedValues, splitDimensionValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    scratchBytesRef1.length = bytesPerDim;\n    scratchBytesRef1.bytes = splitPackedValues;\n\n    BKDTreeLeafNodes leafNodes  = new BKDTreeLeafNodes() {\n      @Override\n      public long getLeafLP(int index) {\n        return leafBlockFPs[index];\n      }\n\n      @Override\n      public BytesRef getSplitValue(int index) {\n        scratchBytesRef1.offset = index * bytesPerDim;\n        return scratchBytesRef1;\n      }\n\n      @Override\n      public int getSplitDimension(int index) {\n        return splitDimensionValues[index] & 0xff;\n      }\n\n      @Override\n      public int numLeaves() {\n        return leafBlockFPs.length;\n      }\n    };\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, maxPointsInLeafNode, leafNodes);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    pointCount = values.size();\n\n    final int numLeaves = Math.toIntExact((pointCount + maxPointsInLeafNode - 1) / maxPointsInLeafNode);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    computePackedValueBounds(values, 0, Math.toIntExact(pointCount), minPackedValue, maxPackedValue, scratchBytesRef1);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(1, 0, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue.clone(), maxPackedValue.clone(), parentSplits,\n          splitPackedValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, maxPointsInLeafNode, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78e689a3b60e84c75dc6dd7b181a71fc19ef8482","date":1591689554,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,IndexOutput,IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private Runnable writeFieldNDims(IndexOutput metaOut, IndexOutput indexOut, IndexOutput dataOut, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    pointCount = values.size();\n\n    final int numLeaves = Math.toIntExact((pointCount + maxPointsInLeafNode - 1) / maxPointsInLeafNode);\n    final int numSplits = numLeaves - 1;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numSplits * bytesPerDim];\n    final byte[] splitDimensionValues = new byte[numSplits];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    computePackedValueBounds(values, 0, Math.toIntExact(pointCount), minPackedValue, maxPackedValue, scratchBytesRef1);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final long dataStartFP = dataOut.getFilePointer();\n    final int[] parentSplits = new int[numIndexDims];\n    build(0, numLeaves, values, 0, Math.toIntExact(pointCount), dataOut,\n          minPackedValue.clone(), maxPackedValue.clone(), parentSplits,\n          splitPackedValues, splitDimensionValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    scratchBytesRef1.length = bytesPerDim;\n    scratchBytesRef1.bytes = splitPackedValues;\n\n    BKDTreeLeafNodes leafNodes  = new BKDTreeLeafNodes() {\n      @Override\n      public long getLeafLP(int index) {\n        return leafBlockFPs[index];\n      }\n\n      @Override\n      public BytesRef getSplitValue(int index) {\n        scratchBytesRef1.offset = index * bytesPerDim;\n        return scratchBytesRef1;\n      }\n\n      @Override\n      public int getSplitDimension(int index) {\n        return splitDimensionValues[index] & 0xff;\n      }\n\n      @Override\n      public int numLeaves() {\n        return leafBlockFPs.length;\n      }\n    };\n\n    return () -> {\n      try {\n        writeIndex(metaOut, indexOut, maxPointsInLeafNode, leafNodes, dataStartFP);\n      } catch (IOException e) {\n        throw new UncheckedIOException(e);\n      }\n    };\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    pointCount = values.size();\n\n    final int numLeaves = Math.toIntExact((pointCount + maxPointsInLeafNode - 1) / maxPointsInLeafNode);\n    final int numSplits = numLeaves - 1;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numSplits * bytesPerDim];\n    final byte[] splitDimensionValues = new byte[numSplits];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    computePackedValueBounds(values, 0, Math.toIntExact(pointCount), minPackedValue, maxPackedValue, scratchBytesRef1);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      docsSeen.set(values.getDocID(i));\n    }\n\n    final int[] parentSplits = new int[numIndexDims];\n    build(0, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n          minPackedValue.clone(), maxPackedValue.clone(), parentSplits,\n          splitPackedValues, splitDimensionValues, leafBlockFPs,\n          new int[maxPointsInLeafNode]);\n    assert Arrays.equals(parentSplits, new int[numIndexDims]);\n\n    scratchBytesRef1.length = bytesPerDim;\n    scratchBytesRef1.bytes = splitPackedValues;\n\n    BKDTreeLeafNodes leafNodes  = new BKDTreeLeafNodes() {\n      @Override\n      public long getLeafLP(int index) {\n        return leafBlockFPs[index];\n      }\n\n      @Override\n      public BytesRef getSplitValue(int index) {\n        scratchBytesRef1.offset = index * bytesPerDim;\n        return scratchBytesRef1;\n      }\n\n      @Override\n      public int getSplitDimension(int index) {\n        return splitDimensionValues[index] & 0xff;\n      }\n\n      @Override\n      public int numLeaves() {\n        return leafBlockFPs.length;\n      }\n    };\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, maxPointsInLeafNode, leafNodes);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f6652c943595e92c187ee904c382863013eae28f":["41f60ea1802fda42d3c91d023406066d00ddb5f8"],"367f57e2ee85b7f7e28cfe73370a22cf67624f65":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"76a51551f05a6c96a115b5a656837ecc8fd0b1ff":["f6652c943595e92c187ee904c382863013eae28f"],"b35cfd3fa0a5c9e066b0256c4818af1d2a9f22d7":["c4ad863d796f4e72a3a1ef4bacd2e19c3e9258c9"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","367f57e2ee85b7f7e28cfe73370a22cf67624f65"],"c4ad863d796f4e72a3a1ef4bacd2e19c3e9258c9":["367f57e2ee85b7f7e28cfe73370a22cf67624f65"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["9856095f7afb5a607bf5e65077615ed91273508c","b35cfd3fa0a5c9e066b0256c4818af1d2a9f22d7"],"302d34f2c66e8d489ee13078305c330cbf67b226":["f03e4bed5023ec3ef93a771b8888cae991cf448d","15fe6782474c00ec2ccc636052a025f8fe0bdb8b"],"b88a121b875f9ae2ac50f85cf46dcb680f126357":["76a51551f05a6c96a115b5a656837ecc8fd0b1ff"],"41f60ea1802fda42d3c91d023406066d00ddb5f8":["15fe6782474c00ec2ccc636052a025f8fe0bdb8b"],"125e5eeb7e933deec0cc0510c2368fe1ec7c36ce":["d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"78e689a3b60e84c75dc6dd7b181a71fc19ef8482":["125e5eeb7e933deec0cc0510c2368fe1ec7c36ce"],"d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7":["d0f206e78bea6261260b24c406e920d05c7ca2f3"],"d0f206e78bea6261260b24c406e920d05c7ca2f3":["b88a121b875f9ae2ac50f85cf46dcb680f126357"],"9856095f7afb5a607bf5e65077615ed91273508c":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","c4ad863d796f4e72a3a1ef4bacd2e19c3e9258c9"],"15fe6782474c00ec2ccc636052a025f8fe0bdb8b":["b35cfd3fa0a5c9e066b0256c4818af1d2a9f22d7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["78e689a3b60e84c75dc6dd7b181a71fc19ef8482"],"b0b597c65628ca9e73913a07e81691f8229bae35":["b88a121b875f9ae2ac50f85cf46dcb680f126357","d0f206e78bea6261260b24c406e920d05c7ca2f3"]},"commit2Childs":{"f6652c943595e92c187ee904c382863013eae28f":["76a51551f05a6c96a115b5a656837ecc8fd0b1ff"],"367f57e2ee85b7f7e28cfe73370a22cf67624f65":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","c4ad863d796f4e72a3a1ef4bacd2e19c3e9258c9"],"76a51551f05a6c96a115b5a656837ecc8fd0b1ff":["b88a121b875f9ae2ac50f85cf46dcb680f126357"],"b35cfd3fa0a5c9e066b0256c4818af1d2a9f22d7":["f03e4bed5023ec3ef93a771b8888cae991cf448d","15fe6782474c00ec2ccc636052a025f8fe0bdb8b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["9856095f7afb5a607bf5e65077615ed91273508c"],"c4ad863d796f4e72a3a1ef4bacd2e19c3e9258c9":["b35cfd3fa0a5c9e066b0256c4818af1d2a9f22d7","9856095f7afb5a607bf5e65077615ed91273508c"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["302d34f2c66e8d489ee13078305c330cbf67b226"],"302d34f2c66e8d489ee13078305c330cbf67b226":[],"b88a121b875f9ae2ac50f85cf46dcb680f126357":["d0f206e78bea6261260b24c406e920d05c7ca2f3","b0b597c65628ca9e73913a07e81691f8229bae35"],"41f60ea1802fda42d3c91d023406066d00ddb5f8":["f6652c943595e92c187ee904c382863013eae28f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["367f57e2ee85b7f7e28cfe73370a22cf67624f65","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"125e5eeb7e933deec0cc0510c2368fe1ec7c36ce":["78e689a3b60e84c75dc6dd7b181a71fc19ef8482"],"d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7":["125e5eeb7e933deec0cc0510c2368fe1ec7c36ce"],"78e689a3b60e84c75dc6dd7b181a71fc19ef8482":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d0f206e78bea6261260b24c406e920d05c7ca2f3":["d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7","b0b597c65628ca9e73913a07e81691f8229bae35"],"9856095f7afb5a607bf5e65077615ed91273508c":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"15fe6782474c00ec2ccc636052a025f8fe0bdb8b":["302d34f2c66e8d489ee13078305c330cbf67b226","41f60ea1802fda42d3c91d023406066d00ddb5f8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["302d34f2c66e8d489ee13078305c330cbf67b226","cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}