{"path":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total bast path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost parital path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n          \n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;    \t\t\t\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total bast path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost parital path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n          \n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;    \t\t\t\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c02a930d0368fcdb10bd2196d59dc0a8593f738","date":1335839264,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n          \n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;    \t\t\t\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total bast path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost parital path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n          \n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;    \t\t\t\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4093b270ba337f9c25a4c0e6cb2ae2c07f697376","date":1347897716,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n          \n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n          \n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;    \t\t\t\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2b45d6769cfaeb4456b4b66cdd5e25c8940f2a4","date":1449124064,"type":3,"author":"Christian Moen","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n          \n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60380b37ed701033fb7211062affa5d9105428e1","date":1463046862,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54204c8a3ca26aeafd273139fc29baf70d0f6786","date":1564170395,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output().intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput().intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output().intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput().intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8061ddd97f3352007d927dae445884a6f3d857b","date":1564988276,"type":3,"author":"Atri Sharma","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","pathOld":"lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output().intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput().intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output().intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput().intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        if (outputNBest) {\n          backtraceNBest(posData, false);\n        }\n        backtrace(posData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        if (outputNBest) {\n          backtraceNBest(leastPosData, false);\n        }\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n        if (outputNBest) {\n          fixupPendingList();\n        }\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n\n        if (pending.size() != 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=posData.pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      // In the case of normal mode, it doesn't process unknown word greedily.\n\n      if (!searchMode && unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);\n        }\n\n        unknownWordEndIndex = posData.pos + unknownWordLength;\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      if (outputNBest) {\n        backtraceNBest(endPosData, true);\n      }\n      backtrace(endPosData, leastIDX);\n      if (outputNBest) {\n        fixupPendingList();\n      }\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54204c8a3ca26aeafd273139fc29baf70d0f6786":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"60380b37ed701033fb7211062affa5d9105428e1":["f2b45d6769cfaeb4456b4b66cdd5e25c8940f2a4"],"1c02a930d0368fcdb10bd2196d59dc0a8593f738":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f2b45d6769cfaeb4456b4b66cdd5e25c8940f2a4":["4093b270ba337f9c25a4c0e6cb2ae2c07f697376"],"f8061ddd97f3352007d927dae445884a6f3d857b":["d470c8182e92b264680e34081b75e70a9f2b3c89","54204c8a3ca26aeafd273139fc29baf70d0f6786"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["f2b45d6769cfaeb4456b4b66cdd5e25c8940f2a4","d470c8182e92b264680e34081b75e70a9f2b3c89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["54204c8a3ca26aeafd273139fc29baf70d0f6786"],"4093b270ba337f9c25a4c0e6cb2ae2c07f697376":["1c02a930d0368fcdb10bd2196d59dc0a8593f738"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["f2b45d6769cfaeb4456b4b66cdd5e25c8940f2a4","60380b37ed701033fb7211062affa5d9105428e1"]},"commit2Childs":{"54204c8a3ca26aeafd273139fc29baf70d0f6786":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["1c02a930d0368fcdb10bd2196d59dc0a8593f738"],"60380b37ed701033fb7211062affa5d9105428e1":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"1c02a930d0368fcdb10bd2196d59dc0a8593f738":["4093b270ba337f9c25a4c0e6cb2ae2c07f697376"],"f2b45d6769cfaeb4456b4b66cdd5e25c8940f2a4":["60380b37ed701033fb7211062affa5d9105428e1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89"],"f8061ddd97f3352007d927dae445884a6f3d857b":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["54204c8a3ca26aeafd273139fc29baf70d0f6786","f8061ddd97f3352007d927dae445884a6f3d857b","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4093b270ba337f9c25a4c0e6cb2ae2c07f697376":["f2b45d6769cfaeb4456b4b66cdd5e25c8940f2a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f8061ddd97f3352007d927dae445884a6f3d857b","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}