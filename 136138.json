{"path":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","commits":[{"id":"58c36d634c9789cb739fbd175c1a8d50b3303f6b","date":1478022614,"type":0,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9720b151fde2073f4e401450f4574e5f31c2d0ff","date":1478184029,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4bb8aa50eb067e6c60b53a4b0c32db5c692c572f","date":1496913354,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","pathOld":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","sourceNew":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","pathOld":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","sourceNew":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","pathOld":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","sourceNew":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","pathOld":"solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTRScoringQuery#testLTRScoringQuery().mjava","sourceNew":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits.value);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  public void testLTRScoringQuery() throws IOException, ModelException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"0\", Field.Store.YES));\n    doc.add(newTextField(\"field\", \"wizard the the the the the oz\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 1.0f));\n\n    w.addDocument(doc);\n    doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    // 1 extra token, but wizard and oz are close;\n    doc.add(newTextField(\"field\", \"wizard oz the the the the the the\",\n        Field.Store.NO));\n    doc.add(new FloatDocValuesField(\"final-score\", 2.0f));\n    w.addDocument(doc);\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // Do ordinary BooleanQuery:\n    final BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"wizard\")), BooleanClause.Occur.SHOULD);\n    bqBuilder.add(new TermQuery(new Term(\"field\", \"oz\")), BooleanClause.Occur.SHOULD);\n    final IndexSearcher searcher = getSearcher(r);\n    // first run the standard query\n    final TopDocs hits = searcher.search(bqBuilder.build(), 10);\n    assertEquals(2, hits.totalHits);\n    assertEquals(\"0\", searcher.doc(hits.scoreDocs[0].doc).get(\"id\"));\n    assertEquals(\"1\", searcher.doc(hits.scoreDocs[1].doc).get(\"id\"));\n\n    List<Feature> features = makeFeatures(new int[] {0, 1, 2});\n    final List<Feature> allFeatures = makeFeatures(new int[] {0, 1, 2, 3, 4, 5,\n        6, 7, 8, 9});\n    List<Normalizer> norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    LTRScoringModel ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    LTRScoringQuery.ModelWeight modelWeight = performQuery(hits, searcher,\n        hits.scoreDocs[0].doc, new LTRScoringQuery(ltrScoringModel));\n    assertEquals(3, modelWeight.getModelFeatureValuesNormalized().length);\n\n    for (int i = 0; i < 3; i++) {\n      assertEquals(i, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    int[] posVals = new int[] {0, 1, 2};\n    int pos = 0;\n    for (LTRScoringQuery.FeatureInfo fInfo:modelWeight.getFeaturesInfo()) {\n        if (fInfo == null){\n          continue;\n        }\n        assertEquals(posVals[pos], fInfo.getValue(), 0.0001);\n        assertEquals(\"f\"+posVals[pos], fInfo.getName());\n        pos++;\n    }\n\n    final int[] mixPositions = new int[] {8, 2, 4, 9, 0};\n    features = makeFeatures(mixPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(ltrScoringModel));\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(mixPositions[i],\n          modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n\n    final ModelException expectedModelException = new ModelException(\"no features declared for model test\");\n    final int[] noPositions = new int[] {};\n    features = makeFeatures(noPositions);\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),IdentityNormalizer.INSTANCE));\n    try {\n      ltrScoringModel = TestLinearModel.createLinearModel(\"test\",\n          features, norms, \"test\", allFeatures, TestLinearModel.makeFeatureWeights(features));\n      fail(\"unexpectedly got here instead of catching \"+expectedModelException);\n      modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n          new LTRScoringQuery(ltrScoringModel));\n      assertEquals(0, modelWeight.getModelFeatureWeights().length);\n    } catch (ModelException actualModelException) {\n      assertEquals(expectedModelException.toString(), actualModelException.toString());\n    }\n\n    // test normalizers\n    features = makeFilterFeatures(mixPositions);\n    final Normalizer norm = new Normalizer() {\n\n      @Override\n      public float normalize(float value) {\n        return 42.42f;\n      }\n\n      @Override\n      public LinkedHashMap<String,Object> paramsToMap() {\n        return null;\n      }\n\n      @Override\n      protected void validate() throws NormalizerException {\n      }\n\n    };\n    norms =\n        new ArrayList<Normalizer>(\n            Collections.nCopies(features.size(),norm));\n    final LTRScoringModel normMeta = TestLinearModel.createLinearModel(\"test\",\n        features, norms, \"test\", allFeatures,\n        TestLinearModel.makeFeatureWeights(features));\n\n    modelWeight = performQuery(hits, searcher, hits.scoreDocs[0].doc,\n        new LTRScoringQuery(normMeta));\n    normMeta.normalizeFeaturesInPlace(modelWeight.getModelFeatureValuesNormalized());\n    assertEquals(mixPositions.length,\n        modelWeight.getModelFeatureWeights().length);\n    for (int i = 0; i < mixPositions.length; i++) {\n      assertEquals(42.42f, modelWeight.getModelFeatureValuesNormalized()[i], 0.0001);\n    }\n    r.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"58c36d634c9789cb739fbd175c1a8d50b3303f6b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9720b151fde2073f4e401450f4574e5f31c2d0ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","58c36d634c9789cb739fbd175c1a8d50b3303f6b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4bb8aa50eb067e6c60b53a4b0c32db5c692c572f":["58c36d634c9789cb739fbd175c1a8d50b3303f6b"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["28288370235ed02234a64753cdbf0c6ec096304a"],"28288370235ed02234a64753cdbf0c6ec096304a":["58c36d634c9789cb739fbd175c1a8d50b3303f6b","4bb8aa50eb067e6c60b53a4b0c32db5c692c572f"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["58c36d634c9789cb739fbd175c1a8d50b3303f6b","4bb8aa50eb067e6c60b53a4b0c32db5c692c572f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"]},"commit2Childs":{"58c36d634c9789cb739fbd175c1a8d50b3303f6b":["9720b151fde2073f4e401450f4574e5f31c2d0ff","4bb8aa50eb067e6c60b53a4b0c32db5c692c572f","28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"9720b151fde2073f4e401450f4574e5f31c2d0ff":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["58c36d634c9789cb739fbd175c1a8d50b3303f6b","9720b151fde2073f4e401450f4574e5f31c2d0ff"],"4bb8aa50eb067e6c60b53a4b0c32db5c692c572f":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"28288370235ed02234a64753cdbf0c6ec096304a":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9720b151fde2073f4e401450f4574e5f31c2d0ff","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}