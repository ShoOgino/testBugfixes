{"path":"solr/core/src/java/org/apache/solr/schema/FieldType.DefaultAnalyzer#createComponents(String).mjava","commits":[{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldType.DefaultAnalyzer#createComponents(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldType.DefaultAnalyzer#createComponents(String,Reader).mjava","sourceNew":"    @Override\n    public TokenStreamComponents createComponents(String fieldName) {\n      Tokenizer ts = new Tokenizer() {\n        final char[] cbuf = new char[maxChars];\n        final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n        final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n        @Override\n        public boolean incrementToken() throws IOException {\n          clearAttributes();\n          int n = input.read(cbuf,0,maxChars);\n          if (n<=0) return false;\n          String s = toInternal(new String(cbuf,0,n));\n          termAtt.setEmpty().append(s);\n          offsetAtt.setOffset(correctOffset(0),correctOffset(n));\n          return true;\n        }\n      };\n\n      return new TokenStreamComponents(ts);\n    }\n\n","sourceOld":"    @Override\n    public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n      Tokenizer ts = new Tokenizer(reader) {\n        final char[] cbuf = new char[maxChars];\n        final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n        final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n        @Override\n        public boolean incrementToken() throws IOException {\n          clearAttributes();\n          int n = input.read(cbuf,0,maxChars);\n          if (n<=0) return false;\n          String s = toInternal(new String(cbuf,0,n));\n          termAtt.setEmpty().append(s);\n          offsetAtt.setOffset(correctOffset(0),correctOffset(n));\n          return true;\n        }\n      };\n\n      return new TokenStreamComponents(ts);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb1921ba901ad34c1b448d0b8c98a563dfea7dd9","date":1501254464,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldType.DefaultAnalyzer#createComponents(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldType.DefaultAnalyzer#createComponents(String).mjava","sourceNew":"    @Override\n    public TokenStreamComponents createComponents(String fieldName) {\n      Tokenizer ts = new Tokenizer() {\n        final char[] cbuf = new char[maxChars];\n        final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n        final BytesTermAttribute bytesAtt = isPointField() ? addAttribute(BytesTermAttribute.class) : null;\n        final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n        @Override\n        public boolean incrementToken() throws IOException {\n          clearAttributes();\n          int n = input.read(cbuf,0,maxChars);\n          if (n<=0) return false;\n          if (isPointField()) {\n            BytesRef b = ((PointField)FieldType.this).toInternalByteRef(new String(cbuf, 0, n));\n            bytesAtt.setBytesRef(b);\n          } else {\n            String s = toInternal(new String(cbuf, 0, n));\n            termAtt.setEmpty().append(s);\n          }\n          offsetAtt.setOffset(correctOffset(0),correctOffset(n));\n          return true;\n        }\n      };\n\n      return new TokenStreamComponents(ts);\n    }\n\n","sourceOld":"    @Override\n    public TokenStreamComponents createComponents(String fieldName) {\n      Tokenizer ts = new Tokenizer() {\n        final char[] cbuf = new char[maxChars];\n        final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n        final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n        @Override\n        public boolean incrementToken() throws IOException {\n          clearAttributes();\n          int n = input.read(cbuf,0,maxChars);\n          if (n<=0) return false;\n          String s = toInternal(new String(cbuf,0,n));\n          termAtt.setEmpty().append(s);\n          offsetAtt.setOffset(correctOffset(0),correctOffset(n));\n          return true;\n        }\n      };\n\n      return new TokenStreamComponents(ts);\n    }\n\n","bugFix":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/schema/FieldType.DefaultAnalyzer#createComponents(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/schema/FieldType.DefaultAnalyzer#createComponents(String).mjava","sourceNew":"    @Override\n    public TokenStreamComponents createComponents(String fieldName) {\n      Tokenizer ts = new Tokenizer() {\n        final char[] cbuf = new char[maxChars];\n        final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n        final BytesTermAttribute bytesAtt = isPointField() ? addAttribute(BytesTermAttribute.class) : null;\n        final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n        @Override\n        public boolean incrementToken() throws IOException {\n          clearAttributes();\n          int n = input.read(cbuf,0,maxChars);\n          if (n<=0) return false;\n          if (isPointField()) {\n            BytesRef b = ((PointField)FieldType.this).toInternalByteRef(new String(cbuf, 0, n));\n            bytesAtt.setBytesRef(b);\n          } else {\n            String s = toInternal(new String(cbuf, 0, n));\n            termAtt.setEmpty().append(s);\n          }\n          offsetAtt.setOffset(correctOffset(0),correctOffset(n));\n          return true;\n        }\n      };\n\n      return new TokenStreamComponents(ts);\n    }\n\n","sourceOld":"    @Override\n    public TokenStreamComponents createComponents(String fieldName) {\n      Tokenizer ts = new Tokenizer() {\n        final char[] cbuf = new char[maxChars];\n        final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n        final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n        @Override\n        public boolean incrementToken() throws IOException {\n          clearAttributes();\n          int n = input.read(cbuf,0,maxChars);\n          if (n<=0) return false;\n          String s = toInternal(new String(cbuf,0,n));\n          termAtt.setEmpty().append(s);\n          offsetAtt.setOffset(correctOffset(0),correctOffset(n));\n          return true;\n        }\n      };\n\n      return new TokenStreamComponents(ts);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","fb1921ba901ad34c1b448d0b8c98a563dfea7dd9"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fb1921ba901ad34c1b448d0b8c98a563dfea7dd9":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fb1921ba901ad34c1b448d0b8c98a563dfea7dd9"]},"commit2Childs":{"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","fb1921ba901ad34c1b448d0b8c98a563dfea7dd9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"fb1921ba901ad34c1b448d0b8c98a563dfea7dd9":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}