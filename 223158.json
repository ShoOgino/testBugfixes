{"path":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","commits":[{"id":"0f080986da691a3bba7b757f43ab72cdc82b57ce","date":1273069619,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n        new StringReader(input)), 1, 1, 0, 0, 0);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n        new StringReader(input)), 1, 1, 0, 0, 0);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n                new StringReader(input)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n        new StringReader(input)), 1, 1, 0, 0, 0);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":null,"bugIntro":["fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n                new StringReader(input)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n        new StringReader(input)), 1, 1, 0, 0, 0);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n                new StringReader(input)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n        new StringReader(input)), 1, 1, 0, 0, 0);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fcbc12aa8147f5203ca283e7252ba4280d6ffd16","date":1305663400,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new MockTokenizer(\n                new StringReader(input), MockTokenizer.KEYWORD, false), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n                new StringReader(input)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":["2fd023a662cc25ae7e0ad0f33d71c476a16d0579","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new MockTokenizer(\n                new StringReader(input), MockTokenizer.KEYWORD, false), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n                new StringReader(input)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new MockTokenizer(\n                new StringReader(input), MockTokenizer.KEYWORD, false), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(\n                new StringReader(input)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec1acb945fb5751735f5c9482576c8760d97b6ab","date":1315370590,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    int flags = GENERATE_WORD_PARTS | GENERATE_NUMBER_PARTS | SPLIT_ON_CASE_CHANGE | SPLIT_ON_NUMERICS | STEM_ENGLISH_POSSESSIVE;\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new MockTokenizer(\n                new StringReader(input), MockTokenizer.KEYWORD, false), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, flags, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new MockTokenizer(\n                new StringReader(input), MockTokenizer.KEYWORD, false), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter#doSplit(String,String...).mjava","sourceNew":"  public void doSplit(final String input, String... output) throws Exception {\n    int flags = GENERATE_WORD_PARTS | GENERATE_NUMBER_PARTS | SPLIT_ON_CASE_CHANGE | SPLIT_ON_NUMERICS | STEM_ENGLISH_POSSESSIVE;\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new MockTokenizer(\n                new StringReader(input), MockTokenizer.KEYWORD, false), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, flags, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","sourceOld":"  public void doSplit(final String input, String... output) throws Exception {\n    int flags = GENERATE_WORD_PARTS | GENERATE_NUMBER_PARTS | SPLIT_ON_CASE_CHANGE | SPLIT_ON_NUMERICS | STEM_ENGLISH_POSSESSIVE;\n    WordDelimiterFilter wdf = new WordDelimiterFilter(new MockTokenizer(\n                new StringReader(input), MockTokenizer.KEYWORD, false), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, flags, null);\n    \n    assertTokenStreamContents(wdf, output);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fcbc12aa8147f5203ca283e7252ba4280d6ffd16":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["ec1acb945fb5751735f5c9482576c8760d97b6ab"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["3bb13258feba31ab676502787ab2e1779f129b7a","fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"a3776dccca01c11e7046323cfad46a3b4a471233":["4e8cc373c801e54cec75daf9f52792cb4b17f536","fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"ec1acb945fb5751735f5c9482576c8760d97b6ab":["fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["0f080986da691a3bba7b757f43ab72cdc82b57ce","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"3bb13258feba31ab676502787ab2e1779f129b7a":["0f080986da691a3bba7b757f43ab72cdc82b57ce","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["0f080986da691a3bba7b757f43ab72cdc82b57ce"]},"commit2Childs":{"fcbc12aa8147f5203ca283e7252ba4280d6ffd16":["c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233","ec1acb945fb5751735f5c9482576c8760d97b6ab"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":[],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"ec1acb945fb5751735f5c9482576c8760d97b6ab":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"3bb13258feba31ab676502787ab2e1779f129b7a":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["fcbc12aa8147f5203ca283e7252ba4280d6ffd16","a3776dccca01c11e7046323cfad46a3b4a471233","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}