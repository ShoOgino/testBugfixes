{"path":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/MapReduceIndexerTool#run(Options).mjava","commits":[{"id":"d6e604e9030fb0cabf0c5a85ae6039921a81419c","date":1386009743,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/MapReduceIndexerTool#run(Options).mjava","pathOld":"/dev/null","sourceNew":"  /** API for Java clients; visible for testing; may become a public API eventually */\n  int run(Options options) throws Exception {\n\n    if (\"local\".equals(getConf().get(\"mapred.job.tracker\"))) {\n      throw new IllegalStateException(\n        \"Running with LocalJobRunner (i.e. all of Hadoop inside a single JVM) is not supported \" +\n        \"because LocalJobRunner does not (yet) implement the Hadoop Distributed Cache feature, \" +\n        \"which is required for passing files via --files and --libjars\");\n    }\n\n    long programStartTime = System.currentTimeMillis();\n    if (options.fairSchedulerPool != null) {\n      getConf().set(\"mapred.fairscheduler.pool\", options.fairSchedulerPool);\n    }\n    getConf().setInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, options.maxSegments);\n    \n    // switch off a false warning about allegedly not implementing Tool\n    // also see http://hadoop.6.n7.nabble.com/GenericOptionsParser-warning-td8103.html\n    // also see https://issues.apache.org/jira/browse/HADOOP-8183\n    getConf().setBoolean(\"mapred.used.genericoptionsparser\", true);\n    \n    if (options.log4jConfigFile != null) {\n      Utils.setLogConfigFile(options.log4jConfigFile, getConf());\n      addDistributedCacheFile(options.log4jConfigFile, getConf());\n    }\n\n    job = Job.getInstance(getConf());\n    job.setJarByClass(getClass());\n\n    if (options.morphlineFile == null) {\n      throw new ArgumentParserException(\"Argument --morphline-file is required\", null);\n    }\n    verifyGoLiveArgs(options, null);\n    verifyZKStructure(options, null);\n    \n    int mappers = new JobClient(job.getConfiguration()).getClusterStatus().getMaxMapTasks(); // MR1\n    //int mappers = job.getCluster().getClusterStatus().getMapSlotCapacity(); // Yarn only\n    LOG.info(\"Cluster reports {} mapper slots\", mappers);\n    \n    if (options.mappers == -1) { \n      mappers = 8 * mappers; // better accomodate stragglers\n    } else {\n      mappers = options.mappers;\n    }\n    if (mappers <= 0) {\n      throw new IllegalStateException(\"Illegal number of mappers: \" + mappers);\n    }\n    options.mappers = mappers;\n    \n    FileSystem fs = options.outputDir.getFileSystem(job.getConfiguration());\n    if (fs.exists(options.outputDir) && !delete(options.outputDir, true, fs)) {\n      return -1;\n    }\n    Path outputResultsDir = new Path(options.outputDir, RESULTS_DIR);\n    Path outputReduceDir = new Path(options.outputDir, \"reducers\");\n    Path outputStep1Dir = new Path(options.outputDir, \"tmp1\");    \n    Path outputStep2Dir = new Path(options.outputDir, \"tmp2\");    \n    Path outputTreeMergeStep = new Path(options.outputDir, \"mtree-merge-output\");\n    Path fullInputList = new Path(outputStep1Dir, FULL_INPUT_LIST);\n    \n    LOG.debug(\"Creating list of input files for mappers: {}\", fullInputList);\n    long numFiles = addInputFiles(options.inputFiles, options.inputLists, fullInputList, job.getConfiguration());\n    if (numFiles == 0) {\n      LOG.info(\"No input files found - nothing to process\");\n      return 0;\n    }\n    int numLinesPerSplit = (int) ceilDivide(numFiles, mappers);\n    if (numLinesPerSplit < 0) { // numeric overflow from downcasting long to int?\n      numLinesPerSplit = Integer.MAX_VALUE;\n    }\n    numLinesPerSplit = Math.max(1, numLinesPerSplit);\n\n    int realMappers = Math.min(mappers, (int) ceilDivide(numFiles, numLinesPerSplit));\n    calculateNumReducers(options, realMappers);\n    int reducers = options.reducers;\n    LOG.info(\"Using these parameters: \" +\n        \"numFiles: {}, mappers: {}, realMappers: {}, reducers: {}, shards: {}, fanout: {}, maxSegments: {}\",\n        new Object[] {numFiles, mappers, realMappers, reducers, options.shards, options.fanout, options.maxSegments});\n        \n    \n    LOG.info(\"Randomizing list of {} input files to spread indexing load more evenly among mappers\", numFiles);\n    long startTime = System.currentTimeMillis();      \n    if (numFiles < job.getConfiguration().getInt(MAIN_MEMORY_RANDOMIZATION_THRESHOLD, 100001)) {\n      // If there are few input files reduce latency by directly running main memory randomization \n      // instead of launching a high latency MapReduce job\n      randomizeFewInputFiles(fs, outputStep2Dir, fullInputList);\n    } else {\n      // Randomize using a MapReduce job. Use sequential algorithm below a certain threshold because there's no\n      // benefit in using many parallel mapper tasks just to randomize the order of a few lines each\n      int numLinesPerRandomizerSplit = Math.max(10 * 1000 * 1000, numLinesPerSplit);\n      Job randomizerJob = randomizeManyInputFiles(getConf(), fullInputList, outputStep2Dir, numLinesPerRandomizerSplit);\n      if (!waitForCompletion(randomizerJob, options.isVerbose)) {\n        return -1; // job failed\n      }\n    }\n    float secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n    LOG.info(\"Done. Randomizing list of {} input files took {} secs\", numFiles, secs);\n    \n    \n    job.setInputFormatClass(NLineInputFormat.class);\n    NLineInputFormat.addInputPath(job, outputStep2Dir);\n    NLineInputFormat.setNumLinesPerSplit(job, numLinesPerSplit);    \n    FileOutputFormat.setOutputPath(job, outputReduceDir);\n    \n    String mapperClass = job.getConfiguration().get(JobContext.MAP_CLASS_ATTR);\n    if (mapperClass == null) { // enable customization\n      Class clazz = MorphlineMapper.class;\n      mapperClass = clazz.getName();\n      job.setMapperClass(clazz);\n    }\n    job.setJobName(getClass().getName() + \"/\" + Utils.getShortClassName(mapperClass));\n    \n    if (job.getConfiguration().get(JobContext.REDUCE_CLASS_ATTR) == null) { // enable customization\n      job.setReducerClass(SolrReducer.class);\n    }\n    if (options.updateConflictResolver == null) {\n      throw new IllegalArgumentException(\"updateConflictResolver must not be null\");\n    }\n    job.getConfiguration().set(SolrReducer.UPDATE_CONFLICT_RESOLVER, options.updateConflictResolver);\n    \n    if (options.zkHost != null) {\n      assert options.collection != null;\n      /*\n       * MapReduce partitioner that partitions the Mapper output such that each\n       * SolrInputDocument gets sent to the SolrCloud shard that it would have\n       * been sent to if the document were ingested via the standard SolrCloud\n       * Near Real Time (NRT) API.\n       * \n       * In other words, this class implements the same partitioning semantics\n       * as the standard SolrCloud NRT API. This enables to mix batch updates\n       * from MapReduce ingestion with updates from standard NRT ingestion on\n       * the same SolrCloud cluster, using identical unique document keys.\n       */\n      if (job.getConfiguration().get(JobContext.PARTITIONER_CLASS_ATTR) == null) { // enable customization\n        job.setPartitionerClass(SolrCloudPartitioner.class);\n      }\n      job.getConfiguration().set(SolrCloudPartitioner.ZKHOST, options.zkHost);\n      job.getConfiguration().set(SolrCloudPartitioner.COLLECTION, options.collection);\n    }\n    job.getConfiguration().setInt(SolrCloudPartitioner.SHARDS, options.shards);\n\n    job.setOutputFormatClass(SolrOutputFormat.class);\n    if (options.solrHomeDir != null) {\n      SolrOutputFormat.setupSolrHomeCache(options.solrHomeDir, job);\n    } else {\n      assert options.zkHost != null;\n      // use the config that this collection uses for the SolrHomeCache.\n      ZooKeeperInspector zki = new ZooKeeperInspector();\n      SolrZkClient zkClient = zki.getZkClient(options.zkHost);\n      try {\n        String configName = zki.readConfigName(zkClient, options.collection);\n        File tmpSolrHomeDir = zki.downloadConfigDir(zkClient, configName);\n        SolrOutputFormat.setupSolrHomeCache(tmpSolrHomeDir, job);\n        options.solrHomeDir = tmpSolrHomeDir;\n      } finally {\n        zkClient.close();\n      }\n    }\n    \n    MorphlineMapRunner runner = setupMorphline(options);\n    if (options.isDryRun && runner != null) {\n      LOG.info(\"Indexing {} files in dryrun mode\", numFiles);\n      startTime = System.currentTimeMillis();\n      dryRun(runner, fs, fullInputList);\n      secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n      LOG.info(\"Done. Indexing {} files in dryrun mode took {} secs\", numFiles, secs);\n      goodbye(null, programStartTime);\n      return 0;\n    }          \n    job.getConfiguration().set(MorphlineMapRunner.MORPHLINE_FILE_PARAM, options.morphlineFile.getName());\n\n    job.setNumReduceTasks(reducers);  \n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(SolrInputDocumentWritable.class);\n    LOG.info(\"Indexing {} files using {} real mappers into {} reducers\", new Object[] {numFiles, realMappers, reducers});\n    startTime = System.currentTimeMillis();\n    if (!waitForCompletion(job, true)) {\n      return -1; // job failed\n    }\n\n    secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n    LOG.info(\"Done. Indexing {} files using {} real mappers into {} reducers took {} secs\", new Object[] {numFiles, realMappers, reducers, secs});\n\n    int mtreeMergeIterations = 0;\n    if (reducers > options.shards) {\n      mtreeMergeIterations = (int) Math.round(log(options.fanout, reducers / options.shards));\n    }\n    LOG.debug(\"MTree merge iterations to do: {}\", mtreeMergeIterations);\n    int mtreeMergeIteration = 1;\n    while (reducers > options.shards) { // run a mtree merge iteration\n      job = Job.getInstance(getConf());\n      job.setJarByClass(getClass());\n      job.setJobName(getClass().getName() + \"/\" + Utils.getShortClassName(TreeMergeMapper.class));\n      job.setMapperClass(TreeMergeMapper.class);\n      job.setOutputFormatClass(TreeMergeOutputFormat.class);\n      job.setNumReduceTasks(0);  \n      job.setOutputKeyClass(Text.class);\n      job.setOutputValueClass(NullWritable.class);    \n      job.setInputFormatClass(NLineInputFormat.class);\n      \n      Path inputStepDir = new Path(options.outputDir, \"mtree-merge-input-iteration\" + mtreeMergeIteration);\n      fullInputList = new Path(inputStepDir, FULL_INPUT_LIST);    \n      LOG.debug(\"MTree merge iteration {}/{}: Creating input list file for mappers {}\", new Object[] {mtreeMergeIteration, mtreeMergeIterations, fullInputList});\n      numFiles = createTreeMergeInputDirList(outputReduceDir, fs, fullInputList);    \n      if (numFiles != reducers) {\n        throw new IllegalStateException(\"Not same reducers: \" + reducers + \", numFiles: \" + numFiles);\n      }\n      NLineInputFormat.addInputPath(job, fullInputList);\n      NLineInputFormat.setNumLinesPerSplit(job, options.fanout);    \n      FileOutputFormat.setOutputPath(job, outputTreeMergeStep);\n      \n      LOG.info(\"MTree merge iteration {}/{}: Merging {} shards into {} shards using fanout {}\", new Object[] { \n          mtreeMergeIteration, mtreeMergeIterations, reducers, (reducers / options.fanout), options.fanout});\n      startTime = System.currentTimeMillis();\n      if (!waitForCompletion(job, options.isVerbose)) {\n        return -1; // job failed\n      }\n      secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n      LOG.info(\"MTree merge iteration {}/{}: Done. Merging {} shards into {} shards using fanout {} took {} secs\",\n          new Object[] {mtreeMergeIteration, mtreeMergeIterations, reducers, (reducers / options.fanout), options.fanout, secs});\n      \n      if (!delete(outputReduceDir, true, fs)) {\n        return -1;\n      }\n      if (!rename(outputTreeMergeStep, outputReduceDir, fs)) {\n        return -1;\n      }\n      assert reducers % options.fanout == 0;\n      reducers = reducers / options.fanout;\n      mtreeMergeIteration++;\n    }\n    assert reducers == options.shards;\n    \n    // normalize output shard dir prefix, i.e.\n    // rename part-r-00000 to part-00000 (stems from zero tree merge iterations)\n    // rename part-m-00000 to part-00000 (stems from > 0 tree merge iterations)\n    for (FileStatus stats : fs.listStatus(outputReduceDir)) {\n      String dirPrefix = SolrOutputFormat.getOutputName(job);\n      Path srcPath = stats.getPath();\n      if (stats.isDirectory() && srcPath.getName().startsWith(dirPrefix)) {\n        String dstName = dirPrefix + srcPath.getName().substring(dirPrefix.length() + \"-m\".length());\n        Path dstPath = new Path(srcPath.getParent(), dstName);\n        if (!rename(srcPath, dstPath, fs)) {\n          return -1;\n        }        \n      }\n    };    \n    \n    // publish results dir    \n    if (!rename(outputReduceDir, outputResultsDir, fs)) {\n      return -1;\n    }\n\n    if (options.goLive && !new GoLive().goLive(options, listSortedOutputShardDirs(outputResultsDir, fs))) {\n      return -1;\n    }\n    \n    goodbye(job, programStartTime);    \n    return 0;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70f91c8322fbffe3a3a897ef20ea19119cac10cd","date":1386170124,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/MapReduceIndexerTool#run(Options).mjava","pathOld":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/MapReduceIndexerTool#run(Options).mjava","sourceNew":"  /** API for Java clients; visible for testing; may become a public API eventually */\n  int run(Options options) throws Exception {\n\n    if (\"local\".equals(getConf().get(\"mapred.job.tracker\"))) {\n      throw new IllegalStateException(\n        \"Running with LocalJobRunner (i.e. all of Hadoop inside a single JVM) is not supported \" +\n        \"because LocalJobRunner does not (yet) implement the Hadoop Distributed Cache feature, \" +\n        \"which is required for passing files via --files and --libjars\");\n    }\n\n    long programStartTime = System.currentTimeMillis();\n    if (options.fairSchedulerPool != null) {\n      getConf().set(\"mapred.fairscheduler.pool\", options.fairSchedulerPool);\n    }\n    getConf().setInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, options.maxSegments);\n    \n    // switch off a false warning about allegedly not implementing Tool\n    // also see http://hadoop.6.n7.nabble.com/GenericOptionsParser-warning-td8103.html\n    // also see https://issues.apache.org/jira/browse/HADOOP-8183\n    getConf().setBoolean(\"mapred.used.genericoptionsparser\", true);\n    \n    if (options.log4jConfigFile != null) {\n      Utils.setLogConfigFile(options.log4jConfigFile, getConf());\n      addDistributedCacheFile(options.log4jConfigFile, getConf());\n    }\n\n    job = Job.getInstance(getConf());\n    job.setJarByClass(getClass());\n\n    if (options.morphlineFile == null) {\n      throw new ArgumentParserException(\"Argument --morphline-file is required\", null);\n    }\n    verifyGoLiveArgs(options, null);\n    verifyZKStructure(options, null);\n    \n    int mappers = new JobClient(job.getConfiguration()).getClusterStatus().getMaxMapTasks(); // MR1\n    //int mappers = job.getCluster().getClusterStatus().getMapSlotCapacity(); // Yarn only\n    LOG.info(\"Cluster reports {} mapper slots\", mappers);\n    \n    if (options.mappers == -1) { \n      mappers = 8 * mappers; // better accomodate stragglers\n    } else {\n      mappers = options.mappers;\n    }\n    if (mappers <= 0) {\n      throw new IllegalStateException(\"Illegal number of mappers: \" + mappers);\n    }\n    options.mappers = mappers;\n    \n    FileSystem fs = options.outputDir.getFileSystem(job.getConfiguration());\n    if (fs.exists(options.outputDir) && !delete(options.outputDir, true, fs)) {\n      return -1;\n    }\n    Path outputResultsDir = new Path(options.outputDir, RESULTS_DIR);\n    Path outputReduceDir = new Path(options.outputDir, \"reducers\");\n    Path outputStep1Dir = new Path(options.outputDir, \"tmp1\");    \n    Path outputStep2Dir = new Path(options.outputDir, \"tmp2\");    \n    Path outputTreeMergeStep = new Path(options.outputDir, \"mtree-merge-output\");\n    Path fullInputList = new Path(outputStep1Dir, FULL_INPUT_LIST);\n    \n    LOG.debug(\"Creating list of input files for mappers: {}\", fullInputList);\n    long numFiles = addInputFiles(options.inputFiles, options.inputLists, fullInputList, job.getConfiguration());\n    if (numFiles == 0) {\n      LOG.info(\"No input files found - nothing to process\");\n      return 0;\n    }\n    int numLinesPerSplit = (int) ceilDivide(numFiles, mappers);\n    if (numLinesPerSplit < 0) { // numeric overflow from downcasting long to int?\n      numLinesPerSplit = Integer.MAX_VALUE;\n    }\n    numLinesPerSplit = Math.max(1, numLinesPerSplit);\n\n    int realMappers = Math.min(mappers, (int) ceilDivide(numFiles, numLinesPerSplit));\n    calculateNumReducers(options, realMappers);\n    int reducers = options.reducers;\n    LOG.info(\"Using these parameters: \" +\n        \"numFiles: {}, mappers: {}, realMappers: {}, reducers: {}, shards: {}, fanout: {}, maxSegments: {}\",\n        new Object[] {numFiles, mappers, realMappers, reducers, options.shards, options.fanout, options.maxSegments});\n        \n    \n    LOG.info(\"Randomizing list of {} input files to spread indexing load more evenly among mappers\", numFiles);\n    long startTime = System.currentTimeMillis();      \n    if (numFiles < job.getConfiguration().getInt(MAIN_MEMORY_RANDOMIZATION_THRESHOLD, 100001)) {\n      // If there are few input files reduce latency by directly running main memory randomization \n      // instead of launching a high latency MapReduce job\n      randomizeFewInputFiles(fs, outputStep2Dir, fullInputList);\n    } else {\n      // Randomize using a MapReduce job. Use sequential algorithm below a certain threshold because there's no\n      // benefit in using many parallel mapper tasks just to randomize the order of a few lines each\n      int numLinesPerRandomizerSplit = Math.max(10 * 1000 * 1000, numLinesPerSplit);\n      Job randomizerJob = randomizeManyInputFiles(getConf(), fullInputList, outputStep2Dir, numLinesPerRandomizerSplit);\n      if (!waitForCompletion(randomizerJob, options.isVerbose)) {\n        return -1; // job failed\n      }\n    }\n    float secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n    LOG.info(\"Done. Randomizing list of {} input files took {} secs\", numFiles, secs);\n    \n    \n    job.setInputFormatClass(NLineInputFormat.class);\n    NLineInputFormat.addInputPath(job, outputStep2Dir);\n    NLineInputFormat.setNumLinesPerSplit(job, numLinesPerSplit);    \n    FileOutputFormat.setOutputPath(job, outputReduceDir);\n    \n    String mapperClass = job.getConfiguration().get(JobContext.MAP_CLASS_ATTR);\n    if (mapperClass == null) { // enable customization\n      Class clazz = MorphlineMapper.class;\n      mapperClass = clazz.getName();\n      job.setMapperClass(clazz);\n    }\n    job.setJobName(getClass().getName() + \"/\" + Utils.getShortClassName(mapperClass));\n    \n    if (job.getConfiguration().get(JobContext.REDUCE_CLASS_ATTR) == null) { // enable customization\n      job.setReducerClass(SolrReducer.class);\n    }\n    if (options.updateConflictResolver == null) {\n      throw new IllegalArgumentException(\"updateConflictResolver must not be null\");\n    }\n    job.getConfiguration().set(SolrReducer.UPDATE_CONFLICT_RESOLVER, options.updateConflictResolver);\n    \n    if (options.zkHost != null) {\n      assert options.collection != null;\n      /*\n       * MapReduce partitioner that partitions the Mapper output such that each\n       * SolrInputDocument gets sent to the SolrCloud shard that it would have\n       * been sent to if the document were ingested via the standard SolrCloud\n       * Near Real Time (NRT) API.\n       * \n       * In other words, this class implements the same partitioning semantics\n       * as the standard SolrCloud NRT API. This enables to mix batch updates\n       * from MapReduce ingestion with updates from standard NRT ingestion on\n       * the same SolrCloud cluster, using identical unique document keys.\n       */\n      if (job.getConfiguration().get(JobContext.PARTITIONER_CLASS_ATTR) == null) { // enable customization\n        job.setPartitionerClass(SolrCloudPartitioner.class);\n      }\n      job.getConfiguration().set(SolrCloudPartitioner.ZKHOST, options.zkHost);\n      job.getConfiguration().set(SolrCloudPartitioner.COLLECTION, options.collection);\n    }\n    job.getConfiguration().setInt(SolrCloudPartitioner.SHARDS, options.shards);\n\n    job.setOutputFormatClass(SolrOutputFormat.class);\n    if (options.solrHomeDir != null) {\n      SolrOutputFormat.setupSolrHomeCache(options.solrHomeDir, job);\n    } else {\n      assert options.zkHost != null;\n      // use the config that this collection uses for the SolrHomeCache.\n      ZooKeeperInspector zki = new ZooKeeperInspector();\n      SolrZkClient zkClient = zki.getZkClient(options.zkHost);\n      try {\n        String configName = zki.readConfigName(zkClient, options.collection);\n        File tmpSolrHomeDir = zki.downloadConfigDir(zkClient, configName);\n        SolrOutputFormat.setupSolrHomeCache(tmpSolrHomeDir, job);\n        options.solrHomeDir = tmpSolrHomeDir;\n      } finally {\n        zkClient.close();\n      }\n    }\n    \n    MorphlineMapRunner runner = setupMorphline(options);\n    if (options.isDryRun && runner != null) {\n      LOG.info(\"Indexing {} files in dryrun mode\", numFiles);\n      startTime = System.currentTimeMillis();\n      dryRun(runner, fs, fullInputList);\n      secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n      LOG.info(\"Done. Indexing {} files in dryrun mode took {} secs\", numFiles, secs);\n      goodbye(null, programStartTime);\n      return 0;\n    }          \n    job.getConfiguration().set(MorphlineMapRunner.MORPHLINE_FILE_PARAM, options.morphlineFile.getName());\n\n    job.setNumReduceTasks(reducers);  \n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(SolrInputDocumentWritable.class);\n    LOG.info(\"Indexing {} files using {} real mappers into {} reducers\", new Object[] {numFiles, realMappers, reducers});\n    startTime = System.currentTimeMillis();\n    if (!waitForCompletion(job, true)) {\n      return -1; // job failed\n    }\n\n    secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n    LOG.info(\"Done. Indexing {} files using {} real mappers into {} reducers took {} secs\", new Object[] {numFiles, realMappers, reducers, secs});\n\n    int mtreeMergeIterations = 0;\n    if (reducers > options.shards) {\n      mtreeMergeIterations = (int) Math.round(log(options.fanout, reducers / options.shards));\n    }\n    LOG.debug(\"MTree merge iterations to do: {}\", mtreeMergeIterations);\n    int mtreeMergeIteration = 1;\n    while (reducers > options.shards) { // run a mtree merge iteration\n      job = Job.getInstance(getConf());\n      job.setJarByClass(getClass());\n      job.setJobName(getClass().getName() + \"/\" + Utils.getShortClassName(TreeMergeMapper.class));\n      job.setMapperClass(TreeMergeMapper.class);\n      job.setOutputFormatClass(TreeMergeOutputFormat.class);\n      job.setNumReduceTasks(0);  \n      job.setOutputKeyClass(Text.class);\n      job.setOutputValueClass(NullWritable.class);    \n      job.setInputFormatClass(NLineInputFormat.class);\n      \n      Path inputStepDir = new Path(options.outputDir, \"mtree-merge-input-iteration\" + mtreeMergeIteration);\n      fullInputList = new Path(inputStepDir, FULL_INPUT_LIST);    \n      LOG.debug(\"MTree merge iteration {}/{}: Creating input list file for mappers {}\", new Object[] {mtreeMergeIteration, mtreeMergeIterations, fullInputList});\n      numFiles = createTreeMergeInputDirList(outputReduceDir, fs, fullInputList);    \n      if (numFiles != reducers) {\n        throw new IllegalStateException(\"Not same reducers: \" + reducers + \", numFiles: \" + numFiles);\n      }\n      NLineInputFormat.addInputPath(job, fullInputList);\n      NLineInputFormat.setNumLinesPerSplit(job, options.fanout);    \n      FileOutputFormat.setOutputPath(job, outputTreeMergeStep);\n      \n      LOG.info(\"MTree merge iteration {}/{}: Merging {} shards into {} shards using fanout {}\", new Object[] { \n          mtreeMergeIteration, mtreeMergeIterations, reducers, (reducers / options.fanout), options.fanout});\n      startTime = System.currentTimeMillis();\n      if (!waitForCompletion(job, options.isVerbose)) {\n        return -1; // job failed\n      }\n      secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n      LOG.info(\"MTree merge iteration {}/{}: Done. Merging {} shards into {} shards using fanout {} took {} secs\",\n          new Object[] {mtreeMergeIteration, mtreeMergeIterations, reducers, (reducers / options.fanout), options.fanout, secs});\n      \n      if (!delete(outputReduceDir, true, fs)) {\n        return -1;\n      }\n      if (!rename(outputTreeMergeStep, outputReduceDir, fs)) {\n        return -1;\n      }\n      assert reducers % options.fanout == 0;\n      reducers = reducers / options.fanout;\n      mtreeMergeIteration++;\n    }\n    assert reducers == options.shards;\n    \n    // normalize output shard dir prefix, i.e.\n    // rename part-r-00000 to part-00000 (stems from zero tree merge iterations)\n    // rename part-m-00000 to part-00000 (stems from > 0 tree merge iterations)\n    for (FileStatus stats : fs.listStatus(outputReduceDir)) {\n      String dirPrefix = SolrOutputFormat.getOutputName(job);\n      Path srcPath = stats.getPath();\n      if (stats.isDirectory() && srcPath.getName().startsWith(dirPrefix)) {\n        String dstName = dirPrefix + srcPath.getName().substring(dirPrefix.length() + \"-m\".length());\n        Path dstPath = new Path(srcPath.getParent(), dstName);\n        if (!rename(srcPath, dstPath, fs)) {\n          return -1;\n        }        \n      }\n    };    \n    \n    // publish results dir    \n    if (!rename(outputReduceDir, outputResultsDir, fs)) {\n      return -1;\n    }\n\n    if (options.goLive && !new GoLive().goLive(options, listSortedOutputShardDirs(outputResultsDir, fs))) {\n      return -1;\n    }\n    \n    goodbye(job, programStartTime);    \n    return 0;\n  }\n\n","sourceOld":"  /** API for Java clients; visible for testing; may become a public API eventually */\n  int run(Options options) throws Exception {\n\n    if (\"local\".equals(getConf().get(\"mapred.job.tracker\"))) {\n      throw new IllegalStateException(\n        \"Running with LocalJobRunner (i.e. all of Hadoop inside a single JVM) is not supported \" +\n        \"because LocalJobRunner does not (yet) implement the Hadoop Distributed Cache feature, \" +\n        \"which is required for passing files via --files and --libjars\");\n    }\n\n    long programStartTime = System.currentTimeMillis();\n    if (options.fairSchedulerPool != null) {\n      getConf().set(\"mapred.fairscheduler.pool\", options.fairSchedulerPool);\n    }\n    getConf().setInt(SolrOutputFormat.SOLR_RECORD_WRITER_MAX_SEGMENTS, options.maxSegments);\n    \n    // switch off a false warning about allegedly not implementing Tool\n    // also see http://hadoop.6.n7.nabble.com/GenericOptionsParser-warning-td8103.html\n    // also see https://issues.apache.org/jira/browse/HADOOP-8183\n    getConf().setBoolean(\"mapred.used.genericoptionsparser\", true);\n    \n    if (options.log4jConfigFile != null) {\n      Utils.setLogConfigFile(options.log4jConfigFile, getConf());\n      addDistributedCacheFile(options.log4jConfigFile, getConf());\n    }\n\n    job = Job.getInstance(getConf());\n    job.setJarByClass(getClass());\n\n    if (options.morphlineFile == null) {\n      throw new ArgumentParserException(\"Argument --morphline-file is required\", null);\n    }\n    verifyGoLiveArgs(options, null);\n    verifyZKStructure(options, null);\n    \n    int mappers = new JobClient(job.getConfiguration()).getClusterStatus().getMaxMapTasks(); // MR1\n    //int mappers = job.getCluster().getClusterStatus().getMapSlotCapacity(); // Yarn only\n    LOG.info(\"Cluster reports {} mapper slots\", mappers);\n    \n    if (options.mappers == -1) { \n      mappers = 8 * mappers; // better accomodate stragglers\n    } else {\n      mappers = options.mappers;\n    }\n    if (mappers <= 0) {\n      throw new IllegalStateException(\"Illegal number of mappers: \" + mappers);\n    }\n    options.mappers = mappers;\n    \n    FileSystem fs = options.outputDir.getFileSystem(job.getConfiguration());\n    if (fs.exists(options.outputDir) && !delete(options.outputDir, true, fs)) {\n      return -1;\n    }\n    Path outputResultsDir = new Path(options.outputDir, RESULTS_DIR);\n    Path outputReduceDir = new Path(options.outputDir, \"reducers\");\n    Path outputStep1Dir = new Path(options.outputDir, \"tmp1\");    \n    Path outputStep2Dir = new Path(options.outputDir, \"tmp2\");    \n    Path outputTreeMergeStep = new Path(options.outputDir, \"mtree-merge-output\");\n    Path fullInputList = new Path(outputStep1Dir, FULL_INPUT_LIST);\n    \n    LOG.debug(\"Creating list of input files for mappers: {}\", fullInputList);\n    long numFiles = addInputFiles(options.inputFiles, options.inputLists, fullInputList, job.getConfiguration());\n    if (numFiles == 0) {\n      LOG.info(\"No input files found - nothing to process\");\n      return 0;\n    }\n    int numLinesPerSplit = (int) ceilDivide(numFiles, mappers);\n    if (numLinesPerSplit < 0) { // numeric overflow from downcasting long to int?\n      numLinesPerSplit = Integer.MAX_VALUE;\n    }\n    numLinesPerSplit = Math.max(1, numLinesPerSplit);\n\n    int realMappers = Math.min(mappers, (int) ceilDivide(numFiles, numLinesPerSplit));\n    calculateNumReducers(options, realMappers);\n    int reducers = options.reducers;\n    LOG.info(\"Using these parameters: \" +\n        \"numFiles: {}, mappers: {}, realMappers: {}, reducers: {}, shards: {}, fanout: {}, maxSegments: {}\",\n        new Object[] {numFiles, mappers, realMappers, reducers, options.shards, options.fanout, options.maxSegments});\n        \n    \n    LOG.info(\"Randomizing list of {} input files to spread indexing load more evenly among mappers\", numFiles);\n    long startTime = System.currentTimeMillis();      \n    if (numFiles < job.getConfiguration().getInt(MAIN_MEMORY_RANDOMIZATION_THRESHOLD, 100001)) {\n      // If there are few input files reduce latency by directly running main memory randomization \n      // instead of launching a high latency MapReduce job\n      randomizeFewInputFiles(fs, outputStep2Dir, fullInputList);\n    } else {\n      // Randomize using a MapReduce job. Use sequential algorithm below a certain threshold because there's no\n      // benefit in using many parallel mapper tasks just to randomize the order of a few lines each\n      int numLinesPerRandomizerSplit = Math.max(10 * 1000 * 1000, numLinesPerSplit);\n      Job randomizerJob = randomizeManyInputFiles(getConf(), fullInputList, outputStep2Dir, numLinesPerRandomizerSplit);\n      if (!waitForCompletion(randomizerJob, options.isVerbose)) {\n        return -1; // job failed\n      }\n    }\n    float secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n    LOG.info(\"Done. Randomizing list of {} input files took {} secs\", numFiles, secs);\n    \n    \n    job.setInputFormatClass(NLineInputFormat.class);\n    NLineInputFormat.addInputPath(job, outputStep2Dir);\n    NLineInputFormat.setNumLinesPerSplit(job, numLinesPerSplit);    \n    FileOutputFormat.setOutputPath(job, outputReduceDir);\n    \n    String mapperClass = job.getConfiguration().get(JobContext.MAP_CLASS_ATTR);\n    if (mapperClass == null) { // enable customization\n      Class clazz = MorphlineMapper.class;\n      mapperClass = clazz.getName();\n      job.setMapperClass(clazz);\n    }\n    job.setJobName(getClass().getName() + \"/\" + Utils.getShortClassName(mapperClass));\n    \n    if (job.getConfiguration().get(JobContext.REDUCE_CLASS_ATTR) == null) { // enable customization\n      job.setReducerClass(SolrReducer.class);\n    }\n    if (options.updateConflictResolver == null) {\n      throw new IllegalArgumentException(\"updateConflictResolver must not be null\");\n    }\n    job.getConfiguration().set(SolrReducer.UPDATE_CONFLICT_RESOLVER, options.updateConflictResolver);\n    \n    if (options.zkHost != null) {\n      assert options.collection != null;\n      /*\n       * MapReduce partitioner that partitions the Mapper output such that each\n       * SolrInputDocument gets sent to the SolrCloud shard that it would have\n       * been sent to if the document were ingested via the standard SolrCloud\n       * Near Real Time (NRT) API.\n       * \n       * In other words, this class implements the same partitioning semantics\n       * as the standard SolrCloud NRT API. This enables to mix batch updates\n       * from MapReduce ingestion with updates from standard NRT ingestion on\n       * the same SolrCloud cluster, using identical unique document keys.\n       */\n      if (job.getConfiguration().get(JobContext.PARTITIONER_CLASS_ATTR) == null) { // enable customization\n        job.setPartitionerClass(SolrCloudPartitioner.class);\n      }\n      job.getConfiguration().set(SolrCloudPartitioner.ZKHOST, options.zkHost);\n      job.getConfiguration().set(SolrCloudPartitioner.COLLECTION, options.collection);\n    }\n    job.getConfiguration().setInt(SolrCloudPartitioner.SHARDS, options.shards);\n\n    job.setOutputFormatClass(SolrOutputFormat.class);\n    if (options.solrHomeDir != null) {\n      SolrOutputFormat.setupSolrHomeCache(options.solrHomeDir, job);\n    } else {\n      assert options.zkHost != null;\n      // use the config that this collection uses for the SolrHomeCache.\n      ZooKeeperInspector zki = new ZooKeeperInspector();\n      SolrZkClient zkClient = zki.getZkClient(options.zkHost);\n      try {\n        String configName = zki.readConfigName(zkClient, options.collection);\n        File tmpSolrHomeDir = zki.downloadConfigDir(zkClient, configName);\n        SolrOutputFormat.setupSolrHomeCache(tmpSolrHomeDir, job);\n        options.solrHomeDir = tmpSolrHomeDir;\n      } finally {\n        zkClient.close();\n      }\n    }\n    \n    MorphlineMapRunner runner = setupMorphline(options);\n    if (options.isDryRun && runner != null) {\n      LOG.info(\"Indexing {} files in dryrun mode\", numFiles);\n      startTime = System.currentTimeMillis();\n      dryRun(runner, fs, fullInputList);\n      secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n      LOG.info(\"Done. Indexing {} files in dryrun mode took {} secs\", numFiles, secs);\n      goodbye(null, programStartTime);\n      return 0;\n    }          \n    job.getConfiguration().set(MorphlineMapRunner.MORPHLINE_FILE_PARAM, options.morphlineFile.getName());\n\n    job.setNumReduceTasks(reducers);  \n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(SolrInputDocumentWritable.class);\n    LOG.info(\"Indexing {} files using {} real mappers into {} reducers\", new Object[] {numFiles, realMappers, reducers});\n    startTime = System.currentTimeMillis();\n    if (!waitForCompletion(job, true)) {\n      return -1; // job failed\n    }\n\n    secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n    LOG.info(\"Done. Indexing {} files using {} real mappers into {} reducers took {} secs\", new Object[] {numFiles, realMappers, reducers, secs});\n\n    int mtreeMergeIterations = 0;\n    if (reducers > options.shards) {\n      mtreeMergeIterations = (int) Math.round(log(options.fanout, reducers / options.shards));\n    }\n    LOG.debug(\"MTree merge iterations to do: {}\", mtreeMergeIterations);\n    int mtreeMergeIteration = 1;\n    while (reducers > options.shards) { // run a mtree merge iteration\n      job = Job.getInstance(getConf());\n      job.setJarByClass(getClass());\n      job.setJobName(getClass().getName() + \"/\" + Utils.getShortClassName(TreeMergeMapper.class));\n      job.setMapperClass(TreeMergeMapper.class);\n      job.setOutputFormatClass(TreeMergeOutputFormat.class);\n      job.setNumReduceTasks(0);  \n      job.setOutputKeyClass(Text.class);\n      job.setOutputValueClass(NullWritable.class);    \n      job.setInputFormatClass(NLineInputFormat.class);\n      \n      Path inputStepDir = new Path(options.outputDir, \"mtree-merge-input-iteration\" + mtreeMergeIteration);\n      fullInputList = new Path(inputStepDir, FULL_INPUT_LIST);    \n      LOG.debug(\"MTree merge iteration {}/{}: Creating input list file for mappers {}\", new Object[] {mtreeMergeIteration, mtreeMergeIterations, fullInputList});\n      numFiles = createTreeMergeInputDirList(outputReduceDir, fs, fullInputList);    \n      if (numFiles != reducers) {\n        throw new IllegalStateException(\"Not same reducers: \" + reducers + \", numFiles: \" + numFiles);\n      }\n      NLineInputFormat.addInputPath(job, fullInputList);\n      NLineInputFormat.setNumLinesPerSplit(job, options.fanout);    \n      FileOutputFormat.setOutputPath(job, outputTreeMergeStep);\n      \n      LOG.info(\"MTree merge iteration {}/{}: Merging {} shards into {} shards using fanout {}\", new Object[] { \n          mtreeMergeIteration, mtreeMergeIterations, reducers, (reducers / options.fanout), options.fanout});\n      startTime = System.currentTimeMillis();\n      if (!waitForCompletion(job, options.isVerbose)) {\n        return -1; // job failed\n      }\n      secs = (System.currentTimeMillis() - startTime) / 1000.0f;\n      LOG.info(\"MTree merge iteration {}/{}: Done. Merging {} shards into {} shards using fanout {} took {} secs\",\n          new Object[] {mtreeMergeIteration, mtreeMergeIterations, reducers, (reducers / options.fanout), options.fanout, secs});\n      \n      if (!delete(outputReduceDir, true, fs)) {\n        return -1;\n      }\n      if (!rename(outputTreeMergeStep, outputReduceDir, fs)) {\n        return -1;\n      }\n      assert reducers % options.fanout == 0;\n      reducers = reducers / options.fanout;\n      mtreeMergeIteration++;\n    }\n    assert reducers == options.shards;\n    \n    // normalize output shard dir prefix, i.e.\n    // rename part-r-00000 to part-00000 (stems from zero tree merge iterations)\n    // rename part-m-00000 to part-00000 (stems from > 0 tree merge iterations)\n    for (FileStatus stats : fs.listStatus(outputReduceDir)) {\n      String dirPrefix = SolrOutputFormat.getOutputName(job);\n      Path srcPath = stats.getPath();\n      if (stats.isDirectory() && srcPath.getName().startsWith(dirPrefix)) {\n        String dstName = dirPrefix + srcPath.getName().substring(dirPrefix.length() + \"-m\".length());\n        Path dstPath = new Path(srcPath.getParent(), dstName);\n        if (!rename(srcPath, dstPath, fs)) {\n          return -1;\n        }        \n      }\n    };    \n    \n    // publish results dir    \n    if (!rename(outputReduceDir, outputResultsDir, fs)) {\n      return -1;\n    }\n\n    if (options.goLive && !new GoLive().goLive(options, listSortedOutputShardDirs(outputResultsDir, fs))) {\n      return -1;\n    }\n    \n    goodbye(job, programStartTime);    \n    return 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["d6e604e9030fb0cabf0c5a85ae6039921a81419c"],"d6e604e9030fb0cabf0c5a85ae6039921a81419c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"]},"commit2Childs":{"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d6e604e9030fb0cabf0c5a85ae6039921a81419c":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d6e604e9030fb0cabf0c5a85ae6039921a81419c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}