{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/classic/ClassicTokenizer#incrementToken().mjava","commits":[{"id":"313c36388b6cae6118f75a1860ad0ba0af7e1344","date":1601279368,"type":1,"author":"Tomoko Uchida","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/classic/ClassicTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == ClassicTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n\n        if (tokenType == ClassicTokenizer.ACRONYM_DEP) {\n          typeAtt.setType(ClassicTokenizer.TOKEN_TYPES[ClassicTokenizer.HOST]);\n          termAtt.setLength(termAtt.length() - 1); // remove extra '.'\n        } else {\n          typeAtt.setType(ClassicTokenizer.TOKEN_TYPES[tokenType]);\n        }\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == ClassicTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n\n        if (tokenType == ClassicTokenizer.ACRONYM_DEP) {\n          typeAtt.setType(ClassicTokenizer.TOKEN_TYPES[ClassicTokenizer.HOST]);\n          termAtt.setLength(termAtt.length() - 1); // remove extra '.'\n        } else {\n          typeAtt.setType(ClassicTokenizer.TOKEN_TYPES[tokenType]);\n        }\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"313c36388b6cae6118f75a1860ad0ba0af7e1344":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["313c36388b6cae6118f75a1860ad0ba0af7e1344"]},"commit2Childs":{"313c36388b6cae6118f75a1860ad0ba0af7e1344":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["313c36388b6cae6118f75a1860ad0ba0af7e1344"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}