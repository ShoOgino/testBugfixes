{"path":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","commits":[{"id":"95bf9c30ed04bd202c0161831dc06decc6670b73","date":1200828698,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"doc.maker=\"+Reuters20DocMaker.class.getName(),\n        \"doc.add.log.step=3\",\n        \"doc.term.vector=false\",\n        \"doc.maker.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // Reuters20DocMaker exhausts after 20 docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b","date":1245355139,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","sourceNew":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=\"+Reuters20ContentSource.class.getName(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // Reuters20ContentSource exhausts after 20 docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"doc.maker=\"+Reuters20DocMaker.class.getName(),\n        \"doc.add.log.step=3\",\n        \"doc.term.vector=false\",\n        \"doc.maker.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // Reuters20DocMaker exhausts after 20 docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4256bc1b3c94786287ccdfc751230374521843cf","date":1254612273,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","sourceNew":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=\"+Reuters20ContentSource.class.getName(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // Reuters20ContentSource exhausts after 20 docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=\"+Reuters20ContentSource.class.getName(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // Reuters20ContentSource exhausts after 20 docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90cb6b3f4e5652555b614adc90204287fbebd27c","date":1259494272,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","sourceNew":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=\"+Reuters20ContentSource.class.getName(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // Reuters20ContentSource exhausts after 20 docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","sourceNew":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\",\n        ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getConfig()\n            .getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","sourceNew":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\",\n        ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getConfig()\n            .getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","sourceNew":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\",\n        ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getConfig()\n            .getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\", ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergeScheduler().mjava","sourceNew":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\",\n        ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getConfig()\n            .getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge scheduler\".\n   */\n  public void testMergeScheduler() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.scheduler=\" + MyMergeScheduler.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n\n    assertTrue(\"did not use the specified MergeScheduler\",\n        ((MyMergeScheduler) benchmark.getRunData().getIndexWriter().getConfig()\n            .getMergeScheduler()).called);\n    benchmark.getRunData().getIndexWriter().close();\n\n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"95bf9c30ed04bd202c0161831dc06decc6670b73":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"90cb6b3f4e5652555b614adc90204287fbebd27c":["4256bc1b3c94786287ccdfc751230374521843cf"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b":["95bf9c30ed04bd202c0161831dc06decc6670b73"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1cedb00d2dd44640194401179358a2e3ba6051bf":["90cb6b3f4e5652555b614adc90204287fbebd27c"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"4256bc1b3c94786287ccdfc751230374521843cf":["6944b9fa6d8ef96b83ae2d3a4332d03b3857355b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"95bf9c30ed04bd202c0161831dc06decc6670b73":["6944b9fa6d8ef96b83ae2d3a4332d03b3857355b"],"90cb6b3f4e5652555b614adc90204287fbebd27c":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"6944b9fa6d8ef96b83ae2d3a4332d03b3857355b":["4256bc1b3c94786287ccdfc751230374521843cf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["95bf9c30ed04bd202c0161831dc06decc6670b73"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"4256bc1b3c94786287ccdfc751230374521843cf":["90cb6b3f4e5652555b614adc90204287fbebd27c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}