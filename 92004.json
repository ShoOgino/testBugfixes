{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","commits":[{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,TopSuggestDocsCollector).mjava","sourceNew":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    final int queueSize = getMaxTopNSearcherQueueSize(collector.getCountToCollect() * prefixPaths.size(),\n        scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst,\n        collector.getCountToCollect(), queueSize, comparator, new ScoringPathComparator(scorer)) {\n\n      private final CharsRefBuilder spare = new CharsRefBuilder();\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        int payloadSepIndex = parseSurfaceForm(path.cost.output2, payloadSep, spare);\n        int docID = parseDocID(path.cost.output2, payloadSepIndex);\n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        try {\n          float score = scorer.score(decode(path.cost.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n          scorer.weight.context());\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","sourceOld":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    final int queueSize = getMaxTopNSearcherQueueSize(collector.getCountToCollect() * prefixPaths.size(),\n        scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst,\n        collector.getCountToCollect(), queueSize, comparator, new ScoringPathComparator(scorer)) {\n\n      private final CharsRefBuilder spare = new CharsRefBuilder();\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        int payloadSepIndex = parseSurfaceForm(path.cost.output2, payloadSep, spare);\n        int docID = parseDocID(path.cost.output2, payloadSepIndex);\n        if (!scorer.accept(docID)) {\n          return false;\n        }\n        try {\n          float score = scorer.score(decode(path.cost.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n          scorer.weight.context());\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","date":1446074047,"type":3,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","sourceNew":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    // The topN is increased by a factor of # of intersected path\n    // to ensure search admissibility. For example, one suggestion can\n    // have multiple contexts, resulting in num_context paths for the\n    // suggestion instead of 1 in the FST. When queried for the suggestion,\n    // the topN value ensures that all paths to the suggestion are evaluated\n    // (in case of a match all context query).\n    // Note that collectors will early terminate as soon as enough suggestions\n    // have been collected, regardless of the set topN value. This value is the\n    // maximum number of suggestions that can be collected.\n    final int topN = collector.getCountToCollect() * prefixPaths.size();\n    final int queueSize = getMaxTopNSearcherQueueSize(topN, scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, topN, queueSize, comparator,\n        new ScoringPathComparator(scorer)) {\n\n      private final CharsRefBuilder spare = new CharsRefBuilder();\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        int payloadSepIndex = parseSurfaceForm(path.cost.output2, payloadSep, spare);\n        int docID = parseDocID(path.cost.output2, payloadSepIndex);\n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        try {\n          float score = scorer.score(decode(path.cost.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n          scorer.weight.context());\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","sourceOld":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    final int queueSize = getMaxTopNSearcherQueueSize(collector.getCountToCollect() * prefixPaths.size(),\n        scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst,\n        collector.getCountToCollect(), queueSize, comparator, new ScoringPathComparator(scorer)) {\n\n      private final CharsRefBuilder spare = new CharsRefBuilder();\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        int payloadSepIndex = parseSurfaceForm(path.cost.output2, payloadSep, spare);\n        int docID = parseDocID(path.cost.output2, payloadSepIndex);\n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        try {\n          float score = scorer.score(decode(path.cost.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n          scorer.weight.context());\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","bugFix":["8c33f6677a2078739058f81eca1df69d12cd62b0"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"902a92b60648a8925bfd9bb53a78669cd2ea98fd","date":1487797466,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","sourceNew":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    // The topN is increased by a factor of # of intersected path\n    // to ensure search admissibility. For example, one suggestion can\n    // have multiple contexts, resulting in num_context paths for the\n    // suggestion instead of 1 in the FST. When queried for the suggestion,\n    // the topN value ensures that all paths to the suggestion are evaluated\n    // (in case of a match all context query).\n    // Note that collectors will early terminate as soon as enough suggestions\n    // have been collected, regardless of the set topN value. This value is the\n    // maximum number of suggestions that can be collected.\n    final int topN = collector.getCountToCollect() * prefixPaths.size();\n    final int queueSize = getMaxTopNSearcherQueueSize(topN, scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, topN, queueSize, comparator,\n        new ScoringPathComparator(scorer)) {\n\n      private final ByteArrayDataInput scratchInput = new ByteArrayDataInput();\n\n      @Override\n      protected boolean acceptPartialPath(Util.FSTPath<Pair<Long,BytesRef>> path) {\n        if (collector.doSkipDuplicates()) {\n          // We are removing dups\n          if (path.payload == -1) {\n            // This path didn't yet see the complete surface form; let's see if it just did with the arc output we just added:\n            BytesRef arcOutput = path.arc.output.output2;\n            BytesRef output = path.output.output2;\n            for(int i=0;i<arcOutput.length;i++) {\n              if (arcOutput.bytes[arcOutput.offset + i] == payloadSep) {\n                // OK this arc that the path was just extended by contains the payloadSep, so we now have a full surface form in this path\n                path.payload = output.length - arcOutput.length + i;\n                assert output.bytes[output.offset + path.payload] == payloadSep;\n                break;\n              }\n            }\n          }\n\n          if (path.payload != -1) {\n            BytesRef output = path.output.output2;\n            spare.copyUTF8Bytes(output.bytes, output.offset, path.payload);\n            if (collector.seenSurfaceForms.contains(spare.chars(), 0, spare.length())) {\n              return false;\n            }\n          }\n        }\n        return true;\n      }\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        BytesRef output = path.output.output2;\n        int payloadSepIndex;\n        if (path.payload != -1) {\n          payloadSepIndex = path.payload;\n          spare.copyUTF8Bytes(output.bytes, output.offset, payloadSepIndex);\n        } else {\n          assert collector.doSkipDuplicates() == false;\n          payloadSepIndex = parseSurfaceForm(output, payloadSep, spare);\n        }\n\n        scratchInput.reset(output.bytes, output.offset + payloadSepIndex + 1, output.length - payloadSepIndex - 1);\n        int docID = scratchInput.readVInt();\n        \n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        if (collector.doSkipDuplicates()) {\n          // now record that we've seen this surface form:\n          char[] key = new char[spare.length()];\n          System.arraycopy(spare.chars(), 0, key, 0, spare.length());\n          if (collector.seenSurfaceForms.contains(key)) {\n            // we already collected a higher scoring document with this key, in this segment:\n            return false;\n          }\n          collector.seenSurfaceForms.add(key);\n        }\n        try {\n          float score = scorer.score(decode(path.output.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      BytesRef output = path.output.output2;\n      int payload = -1;\n      if (collector.doSkipDuplicates()) {\n        for(int j=0;j<output.length;j++) {\n          if (output.bytes[output.offset+j] == payloadSep) {\n            // Important to cache this, else we have a possibly O(N^2) cost where N is the length of suggestions\n            payload = j;\n            break;\n          }\n        }\n      }\n      \n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n                             scorer.weight.context(), payload);\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","sourceOld":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    // The topN is increased by a factor of # of intersected path\n    // to ensure search admissibility. For example, one suggestion can\n    // have multiple contexts, resulting in num_context paths for the\n    // suggestion instead of 1 in the FST. When queried for the suggestion,\n    // the topN value ensures that all paths to the suggestion are evaluated\n    // (in case of a match all context query).\n    // Note that collectors will early terminate as soon as enough suggestions\n    // have been collected, regardless of the set topN value. This value is the\n    // maximum number of suggestions that can be collected.\n    final int topN = collector.getCountToCollect() * prefixPaths.size();\n    final int queueSize = getMaxTopNSearcherQueueSize(topN, scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, topN, queueSize, comparator,\n        new ScoringPathComparator(scorer)) {\n\n      private final CharsRefBuilder spare = new CharsRefBuilder();\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        int payloadSepIndex = parseSurfaceForm(path.cost.output2, payloadSep, spare);\n        int docID = parseDocID(path.cost.output2, payloadSepIndex);\n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        try {\n          float score = scorer.score(decode(path.cost.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n          scorer.weight.context());\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54204c8a3ca26aeafd273139fc29baf70d0f6786","date":1564170395,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","sourceNew":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    // The topN is increased by a factor of # of intersected path\n    // to ensure search admissibility. For example, one suggestion can\n    // have multiple contexts, resulting in num_context paths for the\n    // suggestion instead of 1 in the FST. When queried for the suggestion,\n    // the topN value ensures that all paths to the suggestion are evaluated\n    // (in case of a match all context query).\n    // Note that collectors will early terminate as soon as enough suggestions\n    // have been collected, regardless of the set topN value. This value is the\n    // maximum number of suggestions that can be collected.\n    final int topN = collector.getCountToCollect() * prefixPaths.size();\n    final int queueSize = getMaxTopNSearcherQueueSize(topN, scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, topN, queueSize, comparator,\n        new ScoringPathComparator(scorer)) {\n\n      private final ByteArrayDataInput scratchInput = new ByteArrayDataInput();\n\n      @Override\n      protected boolean acceptPartialPath(Util.FSTPath<Pair<Long,BytesRef>> path) {\n        if (collector.doSkipDuplicates()) {\n          // We are removing dups\n          if (path.payload == -1) {\n            // This path didn't yet see the complete surface form; let's see if it just did with the arc output we just added:\n            BytesRef arcOutput = path.arc.output().output2;\n            BytesRef output = path.output.output2;\n            for(int i=0;i<arcOutput.length;i++) {\n              if (arcOutput.bytes[arcOutput.offset + i] == payloadSep) {\n                // OK this arc that the path was just extended by contains the payloadSep, so we now have a full surface form in this path\n                path.payload = output.length - arcOutput.length + i;\n                assert output.bytes[output.offset + path.payload] == payloadSep;\n                break;\n              }\n            }\n          }\n\n          if (path.payload != -1) {\n            BytesRef output = path.output.output2;\n            spare.copyUTF8Bytes(output.bytes, output.offset, path.payload);\n            if (collector.seenSurfaceForms.contains(spare.chars(), 0, spare.length())) {\n              return false;\n            }\n          }\n        }\n        return true;\n      }\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        BytesRef output = path.output.output2;\n        int payloadSepIndex;\n        if (path.payload != -1) {\n          payloadSepIndex = path.payload;\n          spare.copyUTF8Bytes(output.bytes, output.offset, payloadSepIndex);\n        } else {\n          assert collector.doSkipDuplicates() == false;\n          payloadSepIndex = parseSurfaceForm(output, payloadSep, spare);\n        }\n\n        scratchInput.reset(output.bytes, output.offset + payloadSepIndex + 1, output.length - payloadSepIndex - 1);\n        int docID = scratchInput.readVInt();\n        \n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        if (collector.doSkipDuplicates()) {\n          // now record that we've seen this surface form:\n          char[] key = new char[spare.length()];\n          System.arraycopy(spare.chars(), 0, key, 0, spare.length());\n          if (collector.seenSurfaceForms.contains(key)) {\n            // we already collected a higher scoring document with this key, in this segment:\n            return false;\n          }\n          collector.seenSurfaceForms.add(key);\n        }\n        try {\n          float score = scorer.score(decode(path.output.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      BytesRef output = path.output.output2;\n      int payload = -1;\n      if (collector.doSkipDuplicates()) {\n        for(int j=0;j<output.length;j++) {\n          if (output.bytes[output.offset+j] == payloadSep) {\n            // Important to cache this, else we have a possibly O(N^2) cost where N is the length of suggestions\n            payload = j;\n            break;\n          }\n        }\n      }\n      \n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n                             scorer.weight.context(), payload);\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","sourceOld":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    // The topN is increased by a factor of # of intersected path\n    // to ensure search admissibility. For example, one suggestion can\n    // have multiple contexts, resulting in num_context paths for the\n    // suggestion instead of 1 in the FST. When queried for the suggestion,\n    // the topN value ensures that all paths to the suggestion are evaluated\n    // (in case of a match all context query).\n    // Note that collectors will early terminate as soon as enough suggestions\n    // have been collected, regardless of the set topN value. This value is the\n    // maximum number of suggestions that can be collected.\n    final int topN = collector.getCountToCollect() * prefixPaths.size();\n    final int queueSize = getMaxTopNSearcherQueueSize(topN, scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, topN, queueSize, comparator,\n        new ScoringPathComparator(scorer)) {\n\n      private final ByteArrayDataInput scratchInput = new ByteArrayDataInput();\n\n      @Override\n      protected boolean acceptPartialPath(Util.FSTPath<Pair<Long,BytesRef>> path) {\n        if (collector.doSkipDuplicates()) {\n          // We are removing dups\n          if (path.payload == -1) {\n            // This path didn't yet see the complete surface form; let's see if it just did with the arc output we just added:\n            BytesRef arcOutput = path.arc.output.output2;\n            BytesRef output = path.output.output2;\n            for(int i=0;i<arcOutput.length;i++) {\n              if (arcOutput.bytes[arcOutput.offset + i] == payloadSep) {\n                // OK this arc that the path was just extended by contains the payloadSep, so we now have a full surface form in this path\n                path.payload = output.length - arcOutput.length + i;\n                assert output.bytes[output.offset + path.payload] == payloadSep;\n                break;\n              }\n            }\n          }\n\n          if (path.payload != -1) {\n            BytesRef output = path.output.output2;\n            spare.copyUTF8Bytes(output.bytes, output.offset, path.payload);\n            if (collector.seenSurfaceForms.contains(spare.chars(), 0, spare.length())) {\n              return false;\n            }\n          }\n        }\n        return true;\n      }\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        BytesRef output = path.output.output2;\n        int payloadSepIndex;\n        if (path.payload != -1) {\n          payloadSepIndex = path.payload;\n          spare.copyUTF8Bytes(output.bytes, output.offset, payloadSepIndex);\n        } else {\n          assert collector.doSkipDuplicates() == false;\n          payloadSepIndex = parseSurfaceForm(output, payloadSep, spare);\n        }\n\n        scratchInput.reset(output.bytes, output.offset + payloadSepIndex + 1, output.length - payloadSepIndex - 1);\n        int docID = scratchInput.readVInt();\n        \n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        if (collector.doSkipDuplicates()) {\n          // now record that we've seen this surface form:\n          char[] key = new char[spare.length()];\n          System.arraycopy(spare.chars(), 0, key, 0, spare.length());\n          if (collector.seenSurfaceForms.contains(key)) {\n            // we already collected a higher scoring document with this key, in this segment:\n            return false;\n          }\n          collector.seenSurfaceForms.add(key);\n        }\n        try {\n          float score = scorer.score(decode(path.output.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      BytesRef output = path.output.output2;\n      int payload = -1;\n      if (collector.doSkipDuplicates()) {\n        for(int j=0;j<output.length;j++) {\n          if (output.bytes[output.offset+j] == payloadSep) {\n            // Important to cache this, else we have a possibly O(N^2) cost where N is the length of suggestions\n            payload = j;\n            break;\n          }\n        }\n      }\n      \n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n                             scorer.weight.context(), payload);\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8061ddd97f3352007d927dae445884a6f3d857b","date":1564988276,"type":3,"author":"Atri Sharma","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(CompletionScorer,Bits,TopSuggestDocsCollector).mjava","sourceNew":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    // The topN is increased by a factor of # of intersected path\n    // to ensure search admissibility. For example, one suggestion can\n    // have multiple contexts, resulting in num_context paths for the\n    // suggestion instead of 1 in the FST. When queried for the suggestion,\n    // the topN value ensures that all paths to the suggestion are evaluated\n    // (in case of a match all context query).\n    // Note that collectors will early terminate as soon as enough suggestions\n    // have been collected, regardless of the set topN value. This value is the\n    // maximum number of suggestions that can be collected.\n    final int topN = collector.getCountToCollect() * prefixPaths.size();\n    final int queueSize = getMaxTopNSearcherQueueSize(topN, scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, topN, queueSize, comparator,\n        new ScoringPathComparator(scorer)) {\n\n      private final ByteArrayDataInput scratchInput = new ByteArrayDataInput();\n\n      @Override\n      protected boolean acceptPartialPath(Util.FSTPath<Pair<Long,BytesRef>> path) {\n        if (collector.doSkipDuplicates()) {\n          // We are removing dups\n          if (path.payload == -1) {\n            // This path didn't yet see the complete surface form; let's see if it just did with the arc output we just added:\n            BytesRef arcOutput = path.arc.output().output2;\n            BytesRef output = path.output.output2;\n            for(int i=0;i<arcOutput.length;i++) {\n              if (arcOutput.bytes[arcOutput.offset + i] == payloadSep) {\n                // OK this arc that the path was just extended by contains the payloadSep, so we now have a full surface form in this path\n                path.payload = output.length - arcOutput.length + i;\n                assert output.bytes[output.offset + path.payload] == payloadSep;\n                break;\n              }\n            }\n          }\n\n          if (path.payload != -1) {\n            BytesRef output = path.output.output2;\n            spare.copyUTF8Bytes(output.bytes, output.offset, path.payload);\n            if (collector.seenSurfaceForms.contains(spare.chars(), 0, spare.length())) {\n              return false;\n            }\n          }\n        }\n        return true;\n      }\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        BytesRef output = path.output.output2;\n        int payloadSepIndex;\n        if (path.payload != -1) {\n          payloadSepIndex = path.payload;\n          spare.copyUTF8Bytes(output.bytes, output.offset, payloadSepIndex);\n        } else {\n          assert collector.doSkipDuplicates() == false;\n          payloadSepIndex = parseSurfaceForm(output, payloadSep, spare);\n        }\n\n        scratchInput.reset(output.bytes, output.offset + payloadSepIndex + 1, output.length - payloadSepIndex - 1);\n        int docID = scratchInput.readVInt();\n        \n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        if (collector.doSkipDuplicates()) {\n          // now record that we've seen this surface form:\n          char[] key = new char[spare.length()];\n          System.arraycopy(spare.chars(), 0, key, 0, spare.length());\n          if (collector.seenSurfaceForms.contains(key)) {\n            // we already collected a higher scoring document with this key, in this segment:\n            return false;\n          }\n          collector.seenSurfaceForms.add(key);\n        }\n        try {\n          float score = scorer.score(decode(path.output.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      BytesRef output = path.output.output2;\n      int payload = -1;\n      if (collector.doSkipDuplicates()) {\n        for(int j=0;j<output.length;j++) {\n          if (output.bytes[output.offset+j] == payloadSep) {\n            // Important to cache this, else we have a possibly O(N^2) cost where N is the length of suggestions\n            payload = j;\n            break;\n          }\n        }\n      }\n      \n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n                             scorer.weight.context(), payload);\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","sourceOld":"  /**\n   * Collects at most {@link TopSuggestDocsCollector#getCountToCollect()} completions that\n   * match the provided {@link CompletionScorer}.\n   * <p>\n   * The {@link CompletionScorer#automaton} is intersected with the {@link #fst}.\n   * {@link CompletionScorer#weight} is used to compute boosts and/or extract context\n   * for each matched partial paths. A top N search is executed on {@link #fst} seeded with\n   * the matched partial paths. Upon reaching a completed path, {@link CompletionScorer#accept(int, Bits)}\n   * and {@link CompletionScorer#score(float, float)} is used on the document id, index weight\n   * and query boost to filter and score the entry, before being collected via\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, CharSequence, float)}\n   */\n  public void lookup(final CompletionScorer scorer, Bits acceptDocs, final TopSuggestDocsCollector collector) throws IOException {\n    final double liveDocsRatio = calculateLiveDocRatio(scorer.reader.numDocs(), scorer.reader.maxDoc());\n    if (liveDocsRatio == -1) {\n      return;\n    }\n    final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(scorer.automaton, fst);\n    // The topN is increased by a factor of # of intersected path\n    // to ensure search admissibility. For example, one suggestion can\n    // have multiple contexts, resulting in num_context paths for the\n    // suggestion instead of 1 in the FST. When queried for the suggestion,\n    // the topN value ensures that all paths to the suggestion are evaluated\n    // (in case of a match all context query).\n    // Note that collectors will early terminate as soon as enough suggestions\n    // have been collected, regardless of the set topN value. This value is the\n    // maximum number of suggestions that can be collected.\n    final int topN = collector.getCountToCollect() * prefixPaths.size();\n    final int queueSize = getMaxTopNSearcherQueueSize(topN, scorer.reader.numDocs(), liveDocsRatio, scorer.filtered);\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Comparator<Pair<Long, BytesRef>> comparator = getComparator();\n    Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, topN, queueSize, comparator,\n        new ScoringPathComparator(scorer)) {\n\n      private final ByteArrayDataInput scratchInput = new ByteArrayDataInput();\n\n      @Override\n      protected boolean acceptPartialPath(Util.FSTPath<Pair<Long,BytesRef>> path) {\n        if (collector.doSkipDuplicates()) {\n          // We are removing dups\n          if (path.payload == -1) {\n            // This path didn't yet see the complete surface form; let's see if it just did with the arc output we just added:\n            BytesRef arcOutput = path.arc.output.output2;\n            BytesRef output = path.output.output2;\n            for(int i=0;i<arcOutput.length;i++) {\n              if (arcOutput.bytes[arcOutput.offset + i] == payloadSep) {\n                // OK this arc that the path was just extended by contains the payloadSep, so we now have a full surface form in this path\n                path.payload = output.length - arcOutput.length + i;\n                assert output.bytes[output.offset + path.payload] == payloadSep;\n                break;\n              }\n            }\n          }\n\n          if (path.payload != -1) {\n            BytesRef output = path.output.output2;\n            spare.copyUTF8Bytes(output.bytes, output.offset, path.payload);\n            if (collector.seenSurfaceForms.contains(spare.chars(), 0, spare.length())) {\n              return false;\n            }\n          }\n        }\n        return true;\n      }\n\n      @Override\n      protected boolean acceptResult(Util.FSTPath<Pair<Long, BytesRef>> path) {\n        BytesRef output = path.output.output2;\n        int payloadSepIndex;\n        if (path.payload != -1) {\n          payloadSepIndex = path.payload;\n          spare.copyUTF8Bytes(output.bytes, output.offset, payloadSepIndex);\n        } else {\n          assert collector.doSkipDuplicates() == false;\n          payloadSepIndex = parseSurfaceForm(output, payloadSep, spare);\n        }\n\n        scratchInput.reset(output.bytes, output.offset + payloadSepIndex + 1, output.length - payloadSepIndex - 1);\n        int docID = scratchInput.readVInt();\n        \n        if (!scorer.accept(docID, acceptDocs)) {\n          return false;\n        }\n        if (collector.doSkipDuplicates()) {\n          // now record that we've seen this surface form:\n          char[] key = new char[spare.length()];\n          System.arraycopy(spare.chars(), 0, key, 0, spare.length());\n          if (collector.seenSurfaceForms.contains(key)) {\n            // we already collected a higher scoring document with this key, in this segment:\n            return false;\n          }\n          collector.seenSurfaceForms.add(key);\n        }\n        try {\n          float score = scorer.score(decode(path.output.output1), path.boost);\n          collector.collect(docID, spare.toCharsRef(), path.context, score);\n          return true;\n        } catch (IOException e) {\n          throw new RuntimeException(e);\n        }\n      }\n    };\n\n    for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n      scorer.weight.setNextMatch(path.input.get());\n      BytesRef output = path.output.output2;\n      int payload = -1;\n      if (collector.doSkipDuplicates()) {\n        for(int j=0;j<output.length;j++) {\n          if (output.bytes[output.offset+j] == payloadSep) {\n            // Important to cache this, else we have a possibly O(N^2) cost where N is the length of suggestions\n            payload = j;\n            break;\n          }\n        }\n      }\n      \n      searcher.addStartPaths(path.fstNode, path.output, false, path.input, scorer.weight.boost(),\n                             scorer.weight.context(), payload);\n    }\n    // hits are also returned by search()\n    // we do not use it, instead collect at acceptResult\n    searcher.search();\n    // search admissibility is not guaranteed\n    // see comment on getMaxTopNSearcherQueueSize\n    // assert  search.isComplete;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54204c8a3ca26aeafd273139fc29baf70d0f6786":["902a92b60648a8925bfd9bb53a78669cd2ea98fd"],"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"902a92b60648a8925bfd9bb53a78669cd2ea98fd":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"f8061ddd97f3352007d927dae445884a6f3d857b":["902a92b60648a8925bfd9bb53a78669cd2ea98fd","54204c8a3ca26aeafd273139fc29baf70d0f6786"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["54204c8a3ca26aeafd273139fc29baf70d0f6786"]},"commit2Childs":{"54204c8a3ca26aeafd273139fc29baf70d0f6786":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2":["902a92b60648a8925bfd9bb53a78669cd2ea98fd"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"902a92b60648a8925bfd9bb53a78669cd2ea98fd":["54204c8a3ca26aeafd273139fc29baf70d0f6786","f8061ddd97f3352007d927dae445884a6f3d857b"],"f8061ddd97f3352007d927dae445884a6f3d857b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}