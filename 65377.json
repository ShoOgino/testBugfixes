{"path":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testIllegalCustomEncoder().mjava","commits":[{"id":"cc8f931c07d7930ebee666cf6d69b1b6d9f9cd18","date":1339188570,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testIllegalCustomEncoder().mjava","pathOld":"/dev/null","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    for (int j = 0; j < leaves.length; j++) {\n      AtomicReader atomicReader = leaves[j].reader();\n    Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n    Bits liveDocs = atomicReader.getLiveDocs();\n    Type t = source.getType();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        assertEquals(0, source.getFloat(i), 0.000f);\n    }\n    \n\n    source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n      if (liveDocs == null || liveDocs.get(i)) {\n        assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n      } else {\n        assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n      }\n    }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"83cf9687053878376848c49a4e7c29d033569fea","date":1339197725,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCustomNorms#testIllegalCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testIllegalCustomEncoder().mjava","sourceNew":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    for (int j = 0; j < leaves.length; j++) {\n      AtomicReader atomicReader = leaves[j].reader();\n    Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n    Bits liveDocs = atomicReader.getLiveDocs();\n    Type t = source.getType();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        assertEquals(0, source.getFloat(i), 0.000f);\n    }\n    \n\n    source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n      if (liveDocs == null || liveDocs.get(i)) {\n        assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n      } else {\n        assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n      }\n    }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIllegalCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IllegalCustomEncodingSimilarity similarity = new IllegalCustomEncodingSimilarity();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(similarity);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    int numAdded = 0;\n    for (int i = 0; i < 100; i++) {\n      try {\n        bar.setStringValue(\"singleton\");\n        similarity.useByte = random().nextBoolean();\n        writer.addDocument(doc);\n        numAdded++;\n      } catch (IllegalArgumentException e) {}\n    }\n    \n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    assertEquals(numAdded, reader.numDocs());\n    IndexReaderContext topReaderContext = reader.getTopReaderContext();\n    AtomicReaderContext[] leaves = topReaderContext.leaves();\n    for (int j = 0; j < leaves.length; j++) {\n      AtomicReader atomicReader = leaves[j].reader();\n    Source source = random().nextBoolean() ? atomicReader.normValues(\"foo\").getSource() : atomicReader.normValues(\"foo\").getDirectSource();\n    Bits liveDocs = atomicReader.getLiveDocs();\n    Type t = source.getType();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n        assertEquals(0, source.getFloat(i), 0.000f);\n    }\n    \n\n    source = random().nextBoolean() ? atomicReader.normValues(\"bar\").getSource() : atomicReader.normValues(\"bar\").getDirectSource();\n    for (int i = 0; i < atomicReader.maxDoc(); i++) {\n      if (liveDocs == null || liveDocs.get(i)) {\n        assertEquals(\"type: \" + t, 1, source.getFloat(i), 0.000f);\n      } else {\n        assertEquals(\"type: \" + t, 0, source.getFloat(i), 0.000f);\n      }\n    }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"83cf9687053878376848c49a4e7c29d033569fea":["cc8f931c07d7930ebee666cf6d69b1b6d9f9cd18"],"cc8f931c07d7930ebee666cf6d69b1b6d9f9cd18":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83cf9687053878376848c49a4e7c29d033569fea"]},"commit2Childs":{"83cf9687053878376848c49a4e7c29d033569fea":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cc8f931c07d7930ebee666cf6d69b1b6d9f9cd18":["83cf9687053878376848c49a4e7c29d033569fea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cc8f931c07d7930ebee666cf6d69b1b6d9f9cd18"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}