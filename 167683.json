{"path":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","commits":[{"id":"16efeb5e41e35037f154efba9fdbbc13f8bc5cc2","date":1202772354,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"/dev/null","sourceNew":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    IndexWriter w = new IndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);\n    w.setUseCompoundFile(false);\n    /***\n    w.setMaxMergeDocs(Integer.MAX_VALUE);\n    w.setMaxFieldLength(10000);\n    w.setRAMBufferSizeMB(1);\n    w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    w.close();    \n\n    Map docs = new HashMap();\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    return docs;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["49adbad5232116eb2448ea8166464e6a68bca007"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"49adbad5232116eb2448ea8166464e6a68bca007","date":1202851885,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    IndexWriter w = new IndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n    /***\n    w.setMaxMergeDocs(Integer.MAX_VALUE);\n    w.setMaxFieldLength(10000);\n    w.setRAMBufferSizeMB(1);\n    w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    w.close();    \n\n    Map docs = new HashMap();\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    IndexWriter w = new IndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);\n    w.setUseCompoundFile(false);\n    /***\n    w.setMaxMergeDocs(Integer.MAX_VALUE);\n    w.setMaxFieldLength(10000);\n    w.setRAMBufferSizeMB(1);\n    w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    w.close();    \n\n    Map docs = new HashMap();\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    return docs;\n  }\n\n","bugFix":["16efeb5e41e35037f154efba9fdbbc13f8bc5cc2"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be","date":1204801324,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n    /***\n    w.setMaxMergeDocs(Integer.MAX_VALUE);\n    w.setMaxFieldLength(10000);\n    w.setRAMBufferSizeMB(1);\n    w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    w.close();    \n\n    Map docs = new HashMap();\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    IndexWriter w = new IndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n    /***\n    w.setMaxMergeDocs(Integer.MAX_VALUE);\n    w.setMaxFieldLength(10000);\n    w.setRAMBufferSizeMB(1);\n    w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    w.close();    \n\n    Map docs = new HashMap();\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8f450af7a7b034413833ed2a9508f99264ea49a","date":1211042958,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      /***\n          w.setMaxMergeDocs(Integer.MAX_VALUE);\n          w.setMaxFieldLength(10000);\n          w.setRAMBufferSizeMB(1);\n          w.setMergeFactor(10);\n      ***/\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n    /***\n    w.setMaxMergeDocs(Integer.MAX_VALUE);\n    w.setMaxFieldLength(10000);\n    w.setRAMBufferSizeMB(1);\n    w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    w.close();    \n\n    Map docs = new HashMap();\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5350389bf83287111f7760b9e3db3af8e3648474","date":1216372812,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      /***\n          w.setMaxMergeDocs(Integer.MAX_VALUE);\n          w.setMaxFieldLength(10000);\n          w.setRAMBufferSizeMB(1);\n          w.setMergeFactor(10);\n      ***/\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      /***\n          w.setMaxMergeDocs(Integer.MAX_VALUE);\n          w.setMaxFieldLength(10000);\n          w.setRAMBufferSizeMB(1);\n          w.setMergeFactor(10);\n      ***/\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4ae99f08f69aa3acba7cd75134e8447eb747559","date":1222344278,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);\n      w.setUseCompoundFile(false);\n\n      /***\n          w.setMaxMergeDocs(Integer.MAX_VALUE);\n          w.setMaxFieldLength(10000);\n          w.setRAMBufferSizeMB(1);\n          w.setMergeFactor(10);\n      ***/\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      /***\n          w.setMaxMergeDocs(Integer.MAX_VALUE);\n          w.setMaxFieldLength(10000);\n          w.setRAMBufferSizeMB(1);\n          w.setMergeFactor(10);\n      ***/\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4ff8864209d2e972cb4393600c26082f9a6533d","date":1239297466,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);\n      w.setUseCompoundFile(false);\n\n      /***\n          w.setMaxMergeDocs(Integer.MAX_VALUE);\n          w.setMaxFieldLength(10000);\n          w.setRAMBufferSizeMB(1);\n          w.setMergeFactor(10);\n      ***/\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87c966e9308847938a7c905c2e46a56d8df788b8","date":1255035452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e450c7d50c2fc84c963d0d7ade9d3217d868064d","date":1259932067,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT).setOpenMode(OpenMode.CREATE)\n          .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs));\n      LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n      lmp.setUseCompoundFile(false);\n      lmp.setUseCompoundDocStore(false);\n      lmp.setMergeFactor(mergeFactor);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT).setOpenMode(OpenMode.CREATE)\n          .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs));\n      LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n      lmp.setUseCompoundFile(false);\n      lmp.setUseCompoundDocStore(false);\n      lmp.setMergeFactor(mergeFactor);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setOpenMode(OpenMode.CREATE)\n          .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs));\n      LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n      lmp.setUseCompoundFile(false);\n      lmp.setUseCompoundDocStore(false);\n      lmp.setMergeFactor(mergeFactor);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n      w.setUseCompoundFile(false);\n\n      // force many merges\n      w.setMergeFactor(mergeFactor);\n      w.setRAMBufferSizeMB(.1);\n      w.setMaxBufferedDocs(maxBufferedDocs);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9802bb5985cb6cc3e0a3a0ecb2158acf4d5cfcf","date":1268662366,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory,int).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandom(int,int,int,Directory).mjava","sourceNew":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir, int maxThreadStates) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setOpenMode(OpenMode.CREATE)\n               .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs).setMaxThreadStates(maxThreadStates));\n      LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n      lmp.setUseCompoundFile(false);\n      lmp.setUseCompoundDocStore(false);\n      lmp.setMergeFactor(mergeFactor);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","sourceOld":"  public Map<String,Document> indexRandom(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    for(int iter=0;iter<3;iter++) {\n      IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setOpenMode(OpenMode.CREATE)\n          .setRAMBufferSizeMB(0.1).setMaxBufferedDocs(maxBufferedDocs));\n      LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n      lmp.setUseCompoundFile(false);\n      lmp.setUseCompoundDocStore(false);\n      lmp.setMergeFactor(mergeFactor);\n\n      threads = new IndexingThread[nThreads];\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = new IndexingThread();\n        th.w = w;\n        th.base = 1000000*i;\n        th.range = range;\n        th.iterations = iterations;\n        threads[i] = th;\n      }\n\n      for (int i=0; i<threads.length; i++) {\n        threads[i].start();\n      }\n      for (int i=0; i<threads.length; i++) {\n        threads[i].join();\n      }\n\n      // w.optimize();\n      w.close();    \n\n      for (int i=0; i<threads.length; i++) {\n        IndexingThread th = threads[i];\n        synchronized(th) {\n          docs.putAll(th.docs);\n        }\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n\n    return docs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e8f450af7a7b034413833ed2a9508f99264ea49a":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"c4ae99f08f69aa3acba7cd75134e8447eb747559":["5350389bf83287111f7760b9e3db3af8e3648474"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"c4ff8864209d2e972cb4393600c26082f9a6533d":["c4ae99f08f69aa3acba7cd75134e8447eb747559"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["49adbad5232116eb2448ea8166464e6a68bca007"],"16efeb5e41e35037f154efba9fdbbc13f8bc5cc2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["87c966e9308847938a7c905c2e46a56d8df788b8"],"49adbad5232116eb2448ea8166464e6a68bca007":["16efeb5e41e35037f154efba9fdbbc13f8bc5cc2"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a9802bb5985cb6cc3e0a3a0ecb2158acf4d5cfcf":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"87c966e9308847938a7c905c2e46a56d8df788b8":["c4ff8864209d2e972cb4393600c26082f9a6533d"],"5350389bf83287111f7760b9e3db3af8e3648474":["e8f450af7a7b034413833ed2a9508f99264ea49a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a9802bb5985cb6cc3e0a3a0ecb2158acf4d5cfcf"]},"commit2Childs":{"e8f450af7a7b034413833ed2a9508f99264ea49a":["5350389bf83287111f7760b9e3db3af8e3648474"],"c4ae99f08f69aa3acba7cd75134e8447eb747559":["c4ff8864209d2e972cb4393600c26082f9a6533d"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"c4ff8864209d2e972cb4393600c26082f9a6533d":["87c966e9308847938a7c905c2e46a56d8df788b8"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["e8f450af7a7b034413833ed2a9508f99264ea49a"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"16efeb5e41e35037f154efba9fdbbc13f8bc5cc2":["49adbad5232116eb2448ea8166464e6a68bca007"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"49adbad5232116eb2448ea8166464e6a68bca007":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["a9802bb5985cb6cc3e0a3a0ecb2158acf4d5cfcf"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["16efeb5e41e35037f154efba9fdbbc13f8bc5cc2"],"a9802bb5985cb6cc3e0a3a0ecb2158acf4d5cfcf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"87c966e9308847938a7c905c2e46a56d8df788b8":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"5350389bf83287111f7760b9e3db3af8e3648474":["c4ae99f08f69aa3acba7cd75134e8447eb747559"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}