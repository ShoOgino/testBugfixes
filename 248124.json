{"path":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","commits":[{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @Override\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @Override\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @Override\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<Exception>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<Map<String, Object>>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @Override\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"68b2523bf6d81a99aa007384dc8a69a71fec1cce","date":1477560907,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, (record, xpath) -> {\n            if (isEnd.get()) {\n              throwExp.set(false);\n              //To end the streaming . otherwise the parsing will go on forever\n              //though consumer has gone away\n              throw new RuntimeException(\"BREAK\");\n            }\n            Map<String, Object> row;\n            try {\n              row = readRow(record, xpath);\n            } catch (Exception e) {\n              isEnd.set(true);\n              return;\n            }\n            offer(row);\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @Override\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, (record, xpath) -> {\n            if (isEnd.get()) {\n              throwExp.set(false);\n              //To end the streaming . otherwise the parsing will go on forever\n              //though consumer has gone away\n              throw new RuntimeException(\"BREAK\");\n            }\n            Map<String, Object> row;\n            try {\n              row = readRow(record, xpath);\n            } catch (Exception e) {\n              isEnd.set(true);\n              return;\n            }\n            offer(row);\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @Override\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              if (isEnd.get()) {\n                throwExp.set(false);\n                //To end the streaming . otherwise the parsing will go on forever\n                //though consumer has gone away\n                throw new RuntimeException(\"BREAK\");\n              }\n              Map<String, Object> row;\n              try {\n                row = readRow(record, xpath);\n              } catch (Exception e) {\n                isEnd.set(true);\n                return;\n              }\n              offer(row);\n            }\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd","date":1534976797,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, (record, xpath) -> {\n            if (isEnd.get()) {\n              throwExp.set(false);\n              //To end the streaming . otherwise the parsing will go on forever\n              //though consumer has gone away\n              throw new RuntimeException(\"BREAK\");\n            }\n            Map<String, Object> row;\n            try {\n              row = readRow(record, xpath);\n            } catch (Exception e) {\n              isEnd.set(true);\n              return;\n            }\n            offer(row);\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            log.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              log.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            log.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              log.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, (record, xpath) -> {\n            if (isEnd.get()) {\n              throwExp.set(false);\n              //To end the streaming . otherwise the parsing will go on forever\n              //though consumer has gone away\n              throw new RuntimeException(\"BREAK\");\n            }\n            Map<String, Object> row;\n            try {\n              row = readRow(record, xpath);\n            } catch (Exception e) {\n              isEnd.set(true);\n              return;\n            }\n            offer(row);\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            LOG.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              LOG.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            LOG.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              LOG.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b","date":1598712724,"type":4,"author":"Alexandre Rafalovitch","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#getRowIterator(Reader,String).mjava","sourceNew":null,"sourceOld":"  private Iterator<Map<String, Object>> getRowIterator(final Reader data, final String s) {\n    //nothing atomic about it. I just needed a StongReference\n    final AtomicReference<Exception> exp = new AtomicReference<>();\n    final BlockingQueue<Map<String, Object>> blockingQueue = new ArrayBlockingQueue<>(blockingQueueSize);\n    final AtomicBoolean isEnd = new AtomicBoolean(false);\n    final AtomicBoolean throwExp = new AtomicBoolean(true);\n    publisherThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          xpathReader.streamRecords(data, (record, xpath) -> {\n            if (isEnd.get()) {\n              throwExp.set(false);\n              //To end the streaming . otherwise the parsing will go on forever\n              //though consumer has gone away\n              throw new RuntimeException(\"BREAK\");\n            }\n            Map<String, Object> row;\n            try {\n              row = readRow(record, xpath);\n            } catch (Exception e) {\n              isEnd.set(true);\n              return;\n            }\n            offer(row);\n          });\n        } catch (Exception e) {\n          if(throwExp.get()) exp.set(e);\n        } finally {\n          closeIt(data);\n          if (!isEnd.get()) {\n            offer(END_MARKER);\n          }\n        }\n      }\n      \n      private void offer(Map<String, Object> row) {\n        try {\n          while (!blockingQueue.offer(row, blockingQueueTimeOut, blockingQueueTimeOutUnits)) {\n            if (isEnd.get()) return;\n            log.debug(\"Timeout elapsed writing records.  Perhaps buffer size should be increased.\");\n          }\n        } catch (InterruptedException e) {\n          return;\n        } finally {\n          synchronized (this) {\n            notifyAll();\n          }\n        }\n      }\n    };\n    \n    publisherThread.start();\n\n    return new Iterator<Map<String, Object>>() {\n      private Map<String, Object> lastRow;\n      int count = 0;\n\n      @Override\n      public boolean hasNext() {\n        return !isEnd.get();\n      }\n\n      @Override\n      public Map<String, Object> next() {\n        Map<String, Object> row;\n        \n        do {\n          try {\n            row = blockingQueue.poll(blockingQueueTimeOut, blockingQueueTimeOutUnits);\n            if (row == null) {\n              log.debug(\"Timeout elapsed reading records.\");\n            }\n          } catch (InterruptedException e) {\n            log.debug(\"Caught InterruptedException while waiting for row.  Aborting.\");\n            isEnd.set(true);\n            return null;\n          }\n        } while (row == null);\n        \n        if (row == END_MARKER) {\n          isEnd.set(true);\n          if (exp.get() != null) {\n            String msg = \"Parsing failed for xml, url:\" + s + \" rows processed in this xml:\" + count;\n            if (lastRow != null) msg += \" last row in this xml:\" + lastRow;\n            if (ABORT.equals(onError)) {\n              wrapAndThrow(SEVERE, exp.get(), msg);\n            } else if (SKIP.equals(onError)) {\n              wrapAndThrow(DataImportHandlerException.SKIP, exp.get());\n            } else {\n              log.warn(msg, exp.get());\n            }\n          }\n          return null;\n        } \n        count++;\n        return lastRow = row;\n      }\n\n      @Override\n      public void remove() {\n        /*no op*/\n      }\n    };\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["c26f00b574427b55127e869b935845554afde1fa","7530de27b87b961b51f01bd1299b7004d46e8823"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7530de27b87b961b51f01bd1299b7004d46e8823"],"d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","68b2523bf6d81a99aa007384dc8a69a71fec1cce"],"7530de27b87b961b51f01bd1299b7004d46e8823":["c26f00b574427b55127e869b935845554afde1fa"],"68b2523bf6d81a99aa007384dc8a69a71fec1cce":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["68b2523bf6d81a99aa007384dc8a69a71fec1cce"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","68b2523bf6d81a99aa007384dc8a69a71fec1cce"],"d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","7530de27b87b961b51f01bd1299b7004d46e8823"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","c26f00b574427b55127e869b935845554afde1fa"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":[],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"68b2523bf6d81a99aa007384dc8a69a71fec1cce":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["d2c8f5c46c2501b61e2f55eb7ee59e6c5372290b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","80d0e6d59ae23f4a6f30eaf40bfb40742300287f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}