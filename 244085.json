{"path":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","commits":[{"id":"8493925b2e70246f0961df584c01a8c2e61ee52f","date":1523611602,"type":0,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"/dev/null","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, pos, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["fecf619c7c48a648bd7715ed28cb52c0600135fb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c6453827f947004a68ad9db7418781e9df2f660","date":1523626811,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"/dev/null","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, pos, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1b78922d87d77d3cbe7d8e77c0472ad2c92193ae","date":1543831042,"type":3,"author":"Christophe Bismuth","isMerge":false,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, pos, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, pos, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        final int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        final boolean isPunct = isPunctuation(firstCharacter);\n\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same character class are considered to be part of unknown word\n          unknownWordLength = 1;\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            final int ch = buffer.get(posAhead);\n            if (ch == -1) {\n              break;\n            }\n            if (characterId == characterDefinition.getCharacterClass((char) ch) &&\n                isPunctuation((char) ch) == isPunct) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fecf619c7c48a648bd7715ed28cb52c0600135fb","date":1549017451,"type":3,"author":"jimczi","isMerge":false,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, pos, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, pos, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":["8493925b2e70246f0961df584c01a8c2e61ee52f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d944ba4fb355a3b421c92761644795a12e28d1f","date":1552380556,"type":3,"author":"Yeongsu Kim","isMerge":false,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput.intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead+1, outputMaxPosAhead+arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        } \n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            if (VERBOSE) {\n              System.out.println(\"    USER word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1));\n            }\n            add(userDictionary, posData, pos, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER);\n            anyMatches = true;\n          }\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54204c8a3ca26aeafd273139fc29baf70d0f6786","date":1564170395,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output().intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput().intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead+1, outputMaxPosAhead+arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        } \n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output().intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput().intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput.intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead+1, outputMaxPosAhead+arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        } \n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8061ddd97f3352007d927dae445884a6f3d857b","date":1564988276,"type":3,"author":"Atri Sharma","isMerge":true,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output().intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput().intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead+1, outputMaxPosAhead+arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        } \n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output().intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput().intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output.intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput.intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead+1, outputMaxPosAhead+arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        } \n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output.intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac9f7831922bb899baba6064894c8ebb795cdee2","date":1566842943,"type":3,"author":"Namgyu Kim","isMerge":false,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (buffer.get(pos) != -1) {\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos + 1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for (int pos2 = pos; pos2 < positions.getNextPos(); pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for (int idx = 0; idx < posData2.count; idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for (int pos2 = pos; pos2 < positions.getNextPos(); pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for (int posAhead = pos; ; posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output().intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput().intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead + 1, outputMaxPosAhead + arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for (int posAhead = pos; ; posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output().intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput().intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead + 1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of(firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                && isPunctuation(ch, chType) == isPunct\n                && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (true) {\n\n      if (buffer.get(pos) == -1) {\n        // End\n        break;\n      }\n\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos+1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for(int idx=0;idx<posData2.count;idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos ++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output().intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput().intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead+1, outputMaxPosAhead+arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        } \n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for(int posAhead=pos;;posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output().intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput().intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of((int) firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  && isPunctuation(ch, chType) == isPunct\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"94be5c9ac2dabdbfde5ace6e311d1b2945200e79","date":1568361441,"type":3,"author":"jimczi","isMerge":false,"pathNew":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","pathOld":"lucene/analysis/nori/src/java/org/apache/lucene/analysis/ko/KoreanTokenizer#parse().mjava","sourceNew":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (buffer.get(pos) != -1) {\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos + 1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for (int pos2 = pos; pos2 < positions.getNextPos(); pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for (int idx = 0; idx < posData2.count; idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for (int pos2 = pos; pos2 < positions.getNextPos(); pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for (int posAhead = pos; ; posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output().intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput().intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead + 1, outputMaxPosAhead + arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for (int posAhead = pos; ; posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output().intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput().intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead + 1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of(firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          final boolean isDigit = Character.isDigit(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                  // split on punctuation\n                  && isPunctuation(ch, chType) == isPunct\n                  // split on digit\n                  && Character.isDigit(ch) == isDigit\n                  && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","sourceOld":"  /* Incrementally parse some more characters.  This runs\n   * the viterbi search forwards \"enough\" so that we\n   * generate some more tokens.  How much forward depends on\n   * the chars coming in, since some chars could cause\n   * longer-lasting ambiguity in the parsing.  Once the\n   * ambiguity is resolved, then we back trace, produce\n   * the pending tokens, and return. */\n  private void parse() throws IOException {\n    if (VERBOSE) {\n      System.out.println(\"\\nPARSE\");\n    }\n\n    // Index of the last character of unknown word:\n    int unknownWordEndIndex = -1;\n\n    // Maximum posAhead of user word in the entire input\n    int userWordMaxPosAhead = -1;\n\n    // Advances over each position (character):\n    while (buffer.get(pos) != -1) {\n      final Position posData = positions.get(pos);\n      final boolean isFrontier = positions.getNextPos() == pos + 1;\n\n      if (posData.count == 0) {\n        // No arcs arrive here; move to next position:\n        if (VERBOSE) {\n          System.out.println(\"    no arcs in; skip pos=\" + pos);\n        }\n        pos++;\n        continue;\n      }\n\n      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {\n        // We are at a \"frontier\", and only one node is\n        // alive, so whatever the eventual best path is must\n        // come through this node.  So we can safely commit\n        // to the prefix of the best path at this point:\n        backtrace(posData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        posData.costs[0] = 0;\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n        }\n      }\n\n      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {\n        // Safety: if we've buffered too much, force a\n        // backtrace now.  We find the least-cost partial\n        // path, across all paths, backtrace from it, and\n        // then prune all others.  Note that this, in\n        // general, can produce the wrong result, if the\n        // total best path did not in fact back trace\n        // through this partial best path.  But it's the\n        // best we can do... (short of not having a\n        // safety!).\n\n        // First pass: find least cost partial path so far,\n        // including ending at future positions:\n        int leastIDX = -1;\n        int leastCost = Integer.MAX_VALUE;\n        Position leastPosData = null;\n        for (int pos2 = pos; pos2 < positions.getNextPos(); pos2++) {\n          final Position posData2 = positions.get(pos2);\n          for (int idx = 0; idx < posData2.count; idx++) {\n            //System.out.println(\"    idx=\" + idx + \" cost=\" + cost);\n            final int cost = posData2.costs[idx];\n            if (cost < leastCost) {\n              leastCost = cost;\n              leastIDX = idx;\n              leastPosData = posData2;\n            }\n          }\n        }\n\n        // We will always have at least one live path:\n        assert leastIDX != -1;\n\n        // Second pass: prune all but the best path:\n        for (int pos2 = pos; pos2 < positions.getNextPos(); pos2++) {\n          final Position posData2 = positions.get(pos2);\n          if (posData2 != leastPosData) {\n            posData2.reset();\n          } else {\n            if (leastIDX != 0) {\n              posData2.costs[0] = posData2.costs[leastIDX];\n              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];\n              posData2.backPos[0] = posData2.backPos[leastIDX];\n              posData2.backWordPos[0] = posData2.backWordPos[leastIDX];\n              posData2.backIndex[0] = posData2.backIndex[leastIDX];\n              posData2.backID[0] = posData2.backID[leastIDX];\n              posData2.backType[0] = posData2.backType[leastIDX];\n            }\n            posData2.count = 1;\n          }\n        }\n\n        backtrace(leastPosData, 0);\n\n        // Re-base cost so we don't risk int overflow:\n        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);\n\n        if (pos != leastPosData.pos) {\n          // We jumped into a future position:\n          assert pos < leastPosData.pos;\n          pos = leastPosData.pos;\n        }\n        if (pending.size() > 0) {\n          return;\n        } else {\n          // This means the backtrace only produced\n          // punctuation tokens, so we must keep parsing.\n          continue;\n        }\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"\\n  extend @ pos=\" + pos + \" char=\" + (char) buffer.get(pos) + \" hex=\" + Integer.toHexString(buffer.get(pos)));\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"    \" + posData.count + \" arcs in\");\n      }\n\n      // Move to the first character that is not a whitespace.\n      // The whitespaces are added as a prefix for the term that we extract,\n      // this information is then used when computing the cost for the term using\n      // the space penalty factor.\n      // They are removed when the final tokens are generated.\n      if (Character.getType(buffer.get(pos)) == Character.SPACE_SEPARATOR) {\n        int nextChar = buffer.get(++pos);\n        while (nextChar != -1 && Character.getType(nextChar) == Character.SPACE_SEPARATOR) {\n          pos++;\n          nextChar = buffer.get(pos);\n        }\n      }\n      if (buffer.get(pos) == -1) {\n        pos = posData.pos;\n      }\n\n      boolean anyMatches = false;\n\n      // First try user dict:\n      if (userFST != null) {\n        userFST.getFirstArc(arc);\n        int output = 0;\n        int maxPosAhead = 0;\n        int outputMaxPosAhead = 0;\n        int arcFinalOutMaxPosAhead = 0;\n\n        for (int posAhead = pos; ; posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          if (userFST.findTargetArc(ch, arc, arc, posAhead == pos, userFSTReader) == null) {\n            break;\n          }\n          output += arc.output().intValue();\n          if (arc.isFinal()) {\n            maxPosAhead = posAhead;\n            outputMaxPosAhead = output;\n            arcFinalOutMaxPosAhead = arc.nextFinalOutput().intValue();\n            anyMatches = true;\n          }\n        }\n\n        // Longest matching for user word\n        if (anyMatches && maxPosAhead > userWordMaxPosAhead) {\n          if (VERBOSE) {\n            System.out.println(\"    USER word \" + new String(buffer.get(pos, maxPosAhead + 1)) + \" toPos=\" + (maxPosAhead + 1));\n          }\n          add(userDictionary, posData, pos, maxPosAhead + 1, outputMaxPosAhead + arcFinalOutMaxPosAhead, Type.USER);\n          userWordMaxPosAhead = Math.max(userWordMaxPosAhead, maxPosAhead);\n        }\n      }\n\n      // TODO: we can be more aggressive about user\n      // matches?  if we are \"under\" a user match then don't\n      // extend KNOWN/UNKNOWN paths?\n\n      if (!anyMatches) {\n        // Next, try known dictionary matches\n        fst.getFirstArc(arc);\n        int output = 0;\n\n        for (int posAhead = pos; ; posAhead++) {\n          final int ch = buffer.get(posAhead);\n          if (ch == -1) {\n            break;\n          }\n          //System.out.println(\"    match \" + (char) ch + \" posAhead=\" + posAhead);\n\n          if (fst.findTargetArc(ch, arc, arc, posAhead == pos, fstReader) == null) {\n            break;\n          }\n\n          output += arc.output().intValue();\n\n          // Optimization: for known words that are too-long\n          // (compound), we should pre-compute the 2nd\n          // best segmentation and store it in the\n          // dictionary instead of recomputing it each time a\n          // match is found.\n\n          if (arc.isFinal()) {\n            dictionary.lookupWordIds(output + arc.nextFinalOutput().intValue(), wordIdRef);\n            if (VERBOSE) {\n              System.out.println(\"    KNOWN word \" + new String(buffer.get(pos, posAhead - pos + 1)) + \" toPos=\" + (posAhead + 1) + \" \" + wordIdRef.length + \" wordIDs\");\n            }\n            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n              add(dictionary, posData, pos, posAhead + 1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN);\n              anyMatches = true;\n            }\n          }\n        }\n      }\n\n      if (unknownWordEndIndex > posData.pos) {\n        pos++;\n        continue;\n      }\n\n      final char firstCharacter = (char) buffer.get(pos);\n      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {\n\n        // Find unknown match:\n        int characterId = characterDefinition.getCharacterClass(firstCharacter);\n        // NOTE: copied from UnknownDictionary.lookup:\n        int unknownWordLength;\n        if (!characterDefinition.isGroup(firstCharacter)) {\n          unknownWordLength = 1;\n        } else {\n          // Extract unknown word. Characters with the same script are considered to be part of unknown word\n          unknownWordLength = 1;\n          UnicodeScript scriptCode = UnicodeScript.of(firstCharacter);\n          final boolean isPunct = isPunctuation(firstCharacter);\n          for (int posAhead = pos + 1; unknownWordLength < MAX_UNKNOWN_WORD_LENGTH; posAhead++) {\n            int next = buffer.get(posAhead);\n            if (next == -1) {\n              break;\n            }\n            char ch = (char) next;\n            int chType = Character.getType(ch);\n            UnicodeScript sc = UnicodeScript.of(next);\n            boolean sameScript = isSameScript(scriptCode, sc)\n                // Non-spacing marks inherit the script of their base character,\n                // following recommendations from UTR #24.\n                || chType == Character.NON_SPACING_MARK;\n\n            if (sameScript\n                && isPunctuation(ch, chType) == isPunct\n                && characterDefinition.isGroup(ch)) {\n              unknownWordLength++;\n            } else {\n              break;\n            }\n            // Update the script code and character class if the original script\n            // is Inherited or Common.\n            if (isCommonOrInherited(scriptCode) && isCommonOrInherited(sc) == false) {\n              scriptCode = sc;\n              characterId = characterDefinition.getCharacterClass(ch);\n            }\n          }\n        }\n\n        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same\n        if (VERBOSE) {\n          System.out.println(\"    UNKNOWN word len=\" + unknownWordLength + \" \" + wordIdRef.length + \" wordIDs\");\n        }\n        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {\n          add(unkDictionary, posData, pos, pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN);\n        }\n      }\n\n      pos++;\n    }\n\n    end = true;\n\n    if (pos > 0) {\n\n      final Position endPosData = positions.get(pos);\n      int leastCost = Integer.MAX_VALUE;\n      int leastIDX = -1;\n      if (VERBOSE) {\n        System.out.println(\"  end: \" + endPosData.count + \" nodes\");\n      }\n      for(int idx=0;idx<endPosData.count;idx++) {\n        // Add EOS cost:\n        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);\n        //System.out.println(\"    idx=\" + idx + \" cost=\" + cost + \" (pathCost=\" + endPosData.costs[idx] + \" bgCost=\" + costs.get(endPosData.lastRightID[idx], 0) + \") backPos=\" + endPosData.backPos[idx]);\n        if (cost < leastCost) {\n          leastCost = cost;\n          leastIDX = idx;\n        }\n      }\n\n      backtrace(endPosData, leastIDX);\n    } else {\n      // No characters in the input string; return no tokens!\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54204c8a3ca26aeafd273139fc29baf70d0f6786":["9d944ba4fb355a3b421c92761644795a12e28d1f"],"9d944ba4fb355a3b421c92761644795a12e28d1f":["fecf619c7c48a648bd7715ed28cb52c0600135fb"],"94be5c9ac2dabdbfde5ace6e311d1b2945200e79":["ac9f7831922bb899baba6064894c8ebb795cdee2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fecf619c7c48a648bd7715ed28cb52c0600135fb":["1b78922d87d77d3cbe7d8e77c0472ad2c92193ae"],"8493925b2e70246f0961df584c01a8c2e61ee52f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ac9f7831922bb899baba6064894c8ebb795cdee2":["54204c8a3ca26aeafd273139fc29baf70d0f6786"],"f8061ddd97f3352007d927dae445884a6f3d857b":["9d944ba4fb355a3b421c92761644795a12e28d1f","54204c8a3ca26aeafd273139fc29baf70d0f6786"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["94be5c9ac2dabdbfde5ace6e311d1b2945200e79"],"1b78922d87d77d3cbe7d8e77c0472ad2c92193ae":["5c6453827f947004a68ad9db7418781e9df2f660"],"5c6453827f947004a68ad9db7418781e9df2f660":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8493925b2e70246f0961df584c01a8c2e61ee52f"]},"commit2Childs":{"54204c8a3ca26aeafd273139fc29baf70d0f6786":["ac9f7831922bb899baba6064894c8ebb795cdee2","f8061ddd97f3352007d927dae445884a6f3d857b"],"9d944ba4fb355a3b421c92761644795a12e28d1f":["54204c8a3ca26aeafd273139fc29baf70d0f6786","f8061ddd97f3352007d927dae445884a6f3d857b"],"94be5c9ac2dabdbfde5ace6e311d1b2945200e79":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8493925b2e70246f0961df584c01a8c2e61ee52f","5c6453827f947004a68ad9db7418781e9df2f660"],"fecf619c7c48a648bd7715ed28cb52c0600135fb":["9d944ba4fb355a3b421c92761644795a12e28d1f"],"8493925b2e70246f0961df584c01a8c2e61ee52f":["5c6453827f947004a68ad9db7418781e9df2f660"],"ac9f7831922bb899baba6064894c8ebb795cdee2":["94be5c9ac2dabdbfde5ace6e311d1b2945200e79"],"f8061ddd97f3352007d927dae445884a6f3d857b":[],"1b78922d87d77d3cbe7d8e77c0472ad2c92193ae":["fecf619c7c48a648bd7715ed28cb52c0600135fb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"5c6453827f947004a68ad9db7418781e9df2f660":["1b78922d87d77d3cbe7d8e77c0472ad2c92193ae"]},"heads":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}