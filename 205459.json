{"path":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0b9507caf22f292ac0e5e59f62db4275adf4511","date":1310107283,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f49143da0a5d278a72f741432047fcfa6da996e","date":1316927425,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":["56584ae6fa4912e4dd6e818a7da3799cf807234f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"56584ae6fa4912e4dd6e818a7da3799cf807234f","date":1339586560,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":["2f49143da0a5d278a72f741432047fcfa6da996e"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fc706b1e03a539d44d99998108feb684bb44cbb2","date":1342522408,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), value);\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), value);\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.tokenStream(context.getFieldName(), value);\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":["be29e0e2cef1fd569147732e48caf8538790339b","68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a","c83d6c4335f31cae14f625a222bc842f20073dcd","c75ad090b206e619a5fbf1b70a0ffd1f5c840a16"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    try {\n      ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    try {\n      ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<Object>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    try {\n      ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1486037b0fcc4d552ab91d319279d41d68fe6a94","date":1437497377,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    try {\n      ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    try {\n      ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":["f4dcc36aaf3ab07f15e069adf183b7e6de5dcccb"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e859719dc778fb66d3d21e7be08cd408fc2bde98","date":1446717611,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    try {\n      ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"77e6111c8c695bcab271a048bf5aae6b05cf415b","date":1450974359,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokenStream, tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      // overwrite the vars \"tokenStream\", \"tokens\", and \"listBasedTokenStream\"\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(listBasedTokenStream, tokens);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":["68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a","0487f900016b7da69f089f740e28192189ef3972"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f15af35d55d70c34451f9df5edeaeff6b31f8cbe","date":1519625627,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        try (Reader sreader = new StringReader(source);\n             Reader reader = cfiltfac.create(sreader)) {\n          source = writeCharStream(namedList, reader);\n        } catch (IOException e) {\n          // do nothing.\n        }\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokenStream, tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      // overwrite the vars \"tokenStream\", \"tokens\", and \"listBasedTokenStream\"\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      try {\n        listBasedTokenStream.close();\n      } catch (IOException e) {\n        // do nothing;\n      }\n      listBasedTokenStream = new ListBasedTokenStream(listBasedTokenStream, tokens);\n    }\n\n    try {\n      listBasedTokenStream.close();\n    } catch (IOException e) {\n      // do nothing.\n    }\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        Reader reader = new StringReader(source);\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokenStream, tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      // overwrite the vars \"tokenStream\", \"tokens\", and \"listBasedTokenStream\"\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      listBasedTokenStream = new ListBasedTokenStream(listBasedTokenStream, tokens);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5","date":1591384964,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        @SuppressWarnings({\"rawtypes\"})\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        try (Reader sreader = new StringReader(source);\n             Reader reader = cfiltfac.create(sreader)) {\n          source = writeCharStream(namedList, reader);\n        } catch (IOException e) {\n          // do nothing.\n        }\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokenStream, tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      // overwrite the vars \"tokenStream\", \"tokens\", and \"listBasedTokenStream\"\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      try {\n        listBasedTokenStream.close();\n      } catch (IOException e) {\n        // do nothing;\n      }\n      listBasedTokenStream = new ListBasedTokenStream(listBasedTokenStream, tokens);\n    }\n\n    try {\n      listBasedTokenStream.close();\n    } catch (IOException e) {\n      // do nothing.\n    }\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<? extends Object> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      try (TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), value)) {\n        NamedList<List<NamedList>> namedList = new NamedList<>();\n        namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n        return namedList;\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<Object> namedList = new NamedList<>();\n\n    if (0 < cfiltfacs.length) {\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        try (Reader sreader = new StringReader(source);\n             Reader reader = cfiltfac.create(sreader)) {\n          source = writeCharStream(namedList, reader);\n        } catch (IOException e) {\n          // do nothing.\n        }\n      }\n    }\n\n    TokenStream tokenStream = tfac.create();\n    ((Tokenizer)tokenStream).setReader(tokenizerChain.initReader(null, new StringReader(value)));\n    List<AttributeSource> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokenStream, tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      for (final AttributeSource tok : tokens) {\n        tok.getAttribute(TokenTrackingAttribute.class).freezeStage();\n      }\n      // overwrite the vars \"tokenStream\", \"tokens\", and \"listBasedTokenStream\"\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      tokens = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n      try {\n        listBasedTokenStream.close();\n      } catch (IOException e) {\n        // do nothing;\n      }\n      listBasedTokenStream = new ListBasedTokenStream(listBasedTokenStream, tokens);\n    }\n\n    try {\n      listBasedTokenStream.close();\n    } catch (IOException e) {\n      // do nothing.\n    }\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"fc706b1e03a539d44d99998108feb684bb44cbb2":["56584ae6fa4912e4dd6e818a7da3799cf807234f"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["fc706b1e03a539d44d99998108feb684bb44cbb2","c83d6c4335f31cae14f625a222bc842f20073dcd"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f0b9507caf22f292ac0e5e59f62db4275adf4511"],"56584ae6fa4912e4dd6e818a7da3799cf807234f":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["1486037b0fcc4d552ab91d319279d41d68fe6a94"],"77e6111c8c695bcab271a048bf5aae6b05cf415b":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"1486037b0fcc4d552ab91d319279d41d68fe6a94":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"aba371508186796cc6151d8223a5b4e16d02e26e":["56584ae6fa4912e4dd6e818a7da3799cf807234f","fc706b1e03a539d44d99998108feb684bb44cbb2"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["fc706b1e03a539d44d99998108feb684bb44cbb2"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["56584ae6fa4912e4dd6e818a7da3799cf807234f","fc706b1e03a539d44d99998108feb684bb44cbb2"],"2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5":["f15af35d55d70c34451f9df5edeaeff6b31f8cbe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2f49143da0a5d278a72f741432047fcfa6da996e":["c26f00b574427b55127e869b935845554afde1fa"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f15af35d55d70c34451f9df5edeaeff6b31f8cbe":["77e6111c8c695bcab271a048bf5aae6b05cf415b"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["2f49143da0a5d278a72f741432047fcfa6da996e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["1486037b0fcc4d552ab91d319279d41d68fe6a94"],"fc706b1e03a539d44d99998108feb684bb44cbb2":["37a0f60745e53927c4c876cfe5b5a58170f0646c","aba371508186796cc6151d8223a5b4e16d02e26e","c83d6c4335f31cae14f625a222bc842f20073dcd","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"c26f00b574427b55127e869b935845554afde1fa":["2f49143da0a5d278a72f741432047fcfa6da996e"],"56584ae6fa4912e4dd6e818a7da3799cf807234f":["fc706b1e03a539d44d99998108feb684bb44cbb2","aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["77e6111c8c695bcab271a048bf5aae6b05cf415b"],"1486037b0fcc4d552ab91d319279d41d68fe6a94":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"77e6111c8c695bcab271a048bf5aae6b05cf415b":["f15af35d55d70c34451f9df5edeaeff6b31f8cbe"],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["c26f00b574427b55127e869b935845554afde1fa"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["f0b9507caf22f292ac0e5e59f62db4275adf4511"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2f49143da0a5d278a72f741432047fcfa6da996e":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["f0b9507caf22f292ac0e5e59f62db4275adf4511"],"f15af35d55d70c34451f9df5edeaeff6b31f8cbe":["2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["56584ae6fa4912e4dd6e818a7da3799cf807234f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}