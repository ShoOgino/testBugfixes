{"path":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testCrazyOffsetGap().mjava","commits":[{"id":"bdc1a53703bb3d96d108c76a4321c3fac506b341","date":1400331928,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testCrazyOffsetGap().mjava","pathOld":"/dev/null","sourceNew":"  public void testCrazyOffsetGap() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return -10;\n      }\n    };\n    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    // add good document\n    Document doc = new Document();\n    iw.addDocument(doc);\n    try {\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      iw.addDocument(doc);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {}\n    iw.shutdown();\n\n    // make sure we see our good doc\n    DirectoryReader r = DirectoryReader.open(dir);   \n    assertEquals(1, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["05fe562aa248790944d43cdd478f512572835ba0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testCrazyOffsetGap().mjava","pathOld":"/dev/null","sourceNew":"  public void testCrazyOffsetGap() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return -10;\n      }\n    };\n    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    // add good document\n    Document doc = new Document();\n    iw.addDocument(doc);\n    try {\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      iw.addDocument(doc);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {}\n    iw.shutdown();\n\n    // make sure we see our good doc\n    DirectoryReader r = DirectoryReader.open(dir);   \n    assertEquals(1, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testCrazyOffsetGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testCrazyOffsetGap().mjava","sourceNew":"  public void testCrazyOffsetGap() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return -10;\n      }\n    };\n    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(analyzer));\n    // add good document\n    Document doc = new Document();\n    iw.addDocument(doc);\n    try {\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      iw.addDocument(doc);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {}\n    iw.close();\n\n    // make sure we see our good doc\n    DirectoryReader r = DirectoryReader.open(dir);   \n    assertEquals(1, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCrazyOffsetGap() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return -10;\n      }\n    };\n    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    // add good document\n    Document doc = new Document();\n    iw.addDocument(doc);\n    try {\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      iw.addDocument(doc);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {}\n    iw.shutdown();\n\n    // make sure we see our good doc\n    DirectoryReader r = DirectoryReader.open(dir);   \n    assertEquals(1, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05fe562aa248790944d43cdd478f512572835ba0","date":1455901667,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testCrazyOffsetGap().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testCrazyOffsetGap().mjava","sourceNew":"  public void testCrazyOffsetGap() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return -10;\n      }\n    };\n    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(analyzer));\n    // add good document\n    Document doc = new Document();\n    iw.addDocument(doc);\n    expectThrows(IllegalArgumentException.class, () -> {\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      iw.addDocument(doc);\n    });\n    iw.commit();\n    iw.close();\n\n    // make sure we see our good doc\n    DirectoryReader r = DirectoryReader.open(dir);   \n    assertEquals(1, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testCrazyOffsetGap() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      public int getOffsetGap(String fieldName) {\n        return -10;\n      }\n    };\n    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(analyzer));\n    // add good document\n    Document doc = new Document();\n    iw.addDocument(doc);\n    try {\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      doc.add(new Field(\"foo\", \"bar\", ft));\n      iw.addDocument(doc);\n      fail(\"didn't get expected exception\");\n    } catch (IllegalArgumentException expected) {}\n    iw.close();\n\n    // make sure we see our good doc\n    DirectoryReader r = DirectoryReader.open(dir);   \n    assertEquals(1, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["bdc1a53703bb3d96d108c76a4321c3fac506b341"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bdc1a53703bb3d96d108c76a4321c3fac506b341":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"05fe562aa248790944d43cdd478f512572835ba0":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["bdc1a53703bb3d96d108c76a4321c3fac506b341"],"56572ec06f1407c066d6b7399413178b33176cd8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","bdc1a53703bb3d96d108c76a4321c3fac506b341"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["05fe562aa248790944d43cdd478f512572835ba0"]},"commit2Childs":{"bdc1a53703bb3d96d108c76a4321c3fac506b341":["d0ef034a4f10871667ae75181537775ddcf8ade4","56572ec06f1407c066d6b7399413178b33176cd8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["bdc1a53703bb3d96d108c76a4321c3fac506b341","56572ec06f1407c066d6b7399413178b33176cd8"],"05fe562aa248790944d43cdd478f512572835ba0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["05fe562aa248790944d43cdd478f512572835ba0"],"56572ec06f1407c066d6b7399413178b33176cd8":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["56572ec06f1407c066d6b7399413178b33176cd8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}