{"path":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","commits":[{"id":"dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4","date":1206538765,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (oldName.startsWith(\"23.\")) {\n          assertEquals(3, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n        }        \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    Hits hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")));\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = hits.doc(0);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (oldName.startsWith(\"23.\")) {\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")));\n      assertEquals(34, hits.length());\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")));\n      assertEquals(34, hits.length());\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")));\n      assertEquals(34, hits.length());\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    \n    Hits hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")));\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = hits.doc(0);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4ba1ab90d9a427e7f2c7d1e65a3ce5869ed8e5d","date":1210334686,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (oldName.startsWith(\"23.\")) {\n          assertEquals(4, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f = (Field) d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n        }        \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    Hits hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")));\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = hits.doc(0);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")));\n      assertEquals(34, hits.length());\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")));\n      assertEquals(34, hits.length());\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")));\n      assertEquals(34, hits.length());\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (oldName.startsWith(\"23.\")) {\n          assertEquals(3, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n        }        \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    Hits hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")));\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = hits.doc(0);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (oldName.startsWith(\"23.\")) {\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")));\n      assertEquals(34, hits.length());\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")));\n      assertEquals(34, hits.length());\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")));\n      assertEquals(34, hits.length());\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["c5e023aa3e1228b8ccacdc30d852eb88e996d1b2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5af07783dbc171e26a694c4f7d735e30c2769faa","date":1211569075,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (oldName.startsWith(\"23.\")) {\n          assertEquals(4, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f = (Field) d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n        }        \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (oldName.startsWith(\"23.\")) {\n          assertEquals(4, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f = (Field) d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n        }        \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    Hits hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")));\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = hits.doc(0);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")));\n      assertEquals(34, hits.length());\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")));\n      assertEquals(34, hits.length());\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")));\n      assertEquals(34, hits.length());\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5bf26a11728ffdf1d7a0eac68fd2cd501d45f367","date":1241174228,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n          // Test on indices >= 2.3\n          assertEquals(5, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f = (Field) d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = (Field) d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (oldName.startsWith(\"23.\")) {\n          assertEquals(4, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f = (Field) d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n        }        \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["c5e023aa3e1228b8ccacdc30d852eb88e996d1b2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5309ea37b2a7ec9c5f21c9eeacc9d9fb808cdb02","date":1243677645,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n          // Test on indices >= 2.3\n          assertEquals(5, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f = (Field) d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = (Field) d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.getDirectory(dirName);\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n          // Test on indices >= 2.3\n          assertEquals(5, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f = (Field) d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = (Field) d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5e023aa3e1228b8ccacdc30d852eb88e996d1b2","date":1247229077,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n          // Test on indices >= 2.3\n          assertEquals(5, fields.size());\n          Field f = (Field) d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = (Field) d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f = (Field) d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n          f = (Field) d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = (Field) d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":["dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4","f4ba1ab90d9a427e7f2c7d1e65a3ce5869ed8e5d","5bf26a11728ffdf1d7a0eac68fd2cd501d45f367"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8d1458a2543cbd30cbfe7929be4dcb5c5251659","date":1254582241,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":null,"sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a046c0c310bc77931fc8441bd920053b607dd14","date":1254584734,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":null,"sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1b736248cf13d8c143d4af78b588926f4151240","date":1254825163,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"/dev/null","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9a4b98263fc6c77bb5eb34f7c3e9fd7542b9650","date":1254831793,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":null,"sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c5c0bd3bf61809aea862d848dcf2119d3b9c38bf","date":1254831905,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"/dev/null","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","d4d69c535930b5cce125cff868d40f6373dc27d4","406e7055a3e99d3fa6ce49a555a51dd18b321806"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"712be41a80a289d25186217345860f2ddec4cab8","date":1254838366,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab50480bb5a7c7abad9762badcf87f8b69efeabe","date":1256591817,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            assertEquals(5, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e450c7d50c2fc84c963d0d7ade9d3217d868064d","date":1259932067,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List<Fieldable> fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f =  d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f =  d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f = (Field) d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = (Field) d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f = (Field) d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = (Field) d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = (Field) d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer(Version.LUCENE_CURRENT));\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List<Fieldable> fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f =  d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f =  d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer());\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List<Fieldable> fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f =  d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f =  d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List<Fieldable> fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f =  d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f =  d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer(Version.LUCENE_CURRENT));\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List<Fieldable> fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f =  d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f =  d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","pathOld":"src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(String,String).mjava","sourceNew":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List<Fieldable> fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f =  d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f =  d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void searchIndex(String dirName, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    //Query query = parser.parse(\"handle:1\");\n\n    dirName = fullDir(dirName);\n\n    Directory dir = FSDirectory.open(new File(dirName));\n    IndexSearcher searcher = new IndexSearcher(dir, true);\n    IndexReader reader = searcher.getIndexReader();\n\n    _TestUtil.checkIndex(dir);\n\n    for(int i=0;i<35;i++) {\n      if (!reader.isDeleted(i)) {\n        Document d = reader.document(i);\n        List<Fieldable> fields = d.getFields();\n        if (!oldName.startsWith(\"19.\") &&\n            !oldName.startsWith(\"20.\") &&\n            !oldName.startsWith(\"21.\") &&\n            !oldName.startsWith(\"22.\")) {\n\n          if (d.getField(\"content3\") == null) {\n            final int numFields = oldName.startsWith(\"29.\") ? 7 : 5;\n            assertEquals(numFields, fields.size());\n            Field f =  d.getField(\"id\");\n            assertEquals(\"\"+i, f.stringValue());\n\n            f = d.getField(\"utf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n            f =  d.getField(\"autf8\");\n            assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n        \n            f = d.getField(\"content2\");\n            assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n            f = d.getField(\"fie\\u2C77ld\");\n            assertEquals(\"field with non-ascii name\", f.stringValue());\n          }\n        }       \n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.doc(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    testHits(hits, 34, searcher.getIndexReader());\n\n    if (!oldName.startsWith(\"19.\") &&\n        !oldName.startsWith(\"20.\") &&\n        !oldName.startsWith(\"21.\") &&\n        !oldName.startsWith(\"22.\")) {\n      // Test on indices >= 2.3\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n      hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n      assertEquals(34, hits.length);\n    }\n\n    searcher.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ab50480bb5a7c7abad9762badcf87f8b69efeabe":["712be41a80a289d25186217345860f2ddec4cab8"],"f1b736248cf13d8c143d4af78b588926f4151240":["0a046c0c310bc77931fc8441bd920053b607dd14"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"0a046c0c310bc77931fc8441bd920053b607dd14":["c5e023aa3e1228b8ccacdc30d852eb88e996d1b2","e8d1458a2543cbd30cbfe7929be4dcb5c5251659"],"dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c5c0bd3bf61809aea862d848dcf2119d3b9c38bf":["a9a4b98263fc6c77bb5eb34f7c3e9fd7542b9650"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["ab50480bb5a7c7abad9762badcf87f8b69efeabe"],"a9a4b98263fc6c77bb5eb34f7c3e9fd7542b9650":["f1b736248cf13d8c143d4af78b588926f4151240"],"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["c5e023aa3e1228b8ccacdc30d852eb88e996d1b2"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"5bf26a11728ffdf1d7a0eac68fd2cd501d45f367":["5af07783dbc171e26a694c4f7d735e30c2769faa"],"5309ea37b2a7ec9c5f21c9eeacc9d9fb808cdb02":["5bf26a11728ffdf1d7a0eac68fd2cd501d45f367"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c5e023aa3e1228b8ccacdc30d852eb88e996d1b2":["5309ea37b2a7ec9c5f21c9eeacc9d9fb808cdb02"],"f4ba1ab90d9a427e7f2c7d1e65a3ce5869ed8e5d":["dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4"],"5af07783dbc171e26a694c4f7d735e30c2769faa":["f4ba1ab90d9a427e7f2c7d1e65a3ce5869ed8e5d"],"712be41a80a289d25186217345860f2ddec4cab8":["c5c0bd3bf61809aea862d848dcf2119d3b9c38bf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"]},"commit2Childs":{"ab50480bb5a7c7abad9762badcf87f8b69efeabe":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"f1b736248cf13d8c143d4af78b588926f4151240":["a9a4b98263fc6c77bb5eb34f7c3e9fd7542b9650"],"0a046c0c310bc77931fc8441bd920053b607dd14":["f1b736248cf13d8c143d4af78b588926f4151240"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4":["f4ba1ab90d9a427e7f2c7d1e65a3ce5869ed8e5d"],"c5c0bd3bf61809aea862d848dcf2119d3b9c38bf":["712be41a80a289d25186217345860f2ddec4cab8"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"a9a4b98263fc6c77bb5eb34f7c3e9fd7542b9650":["c5c0bd3bf61809aea862d848dcf2119d3b9c38bf"],"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["0a046c0c310bc77931fc8441bd920053b607dd14"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"5bf26a11728ffdf1d7a0eac68fd2cd501d45f367":["5309ea37b2a7ec9c5f21c9eeacc9d9fb808cdb02"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4"],"5309ea37b2a7ec9c5f21c9eeacc9d9fb808cdb02":["c5e023aa3e1228b8ccacdc30d852eb88e996d1b2"],"c5e023aa3e1228b8ccacdc30d852eb88e996d1b2":["0a046c0c310bc77931fc8441bd920053b607dd14","e8d1458a2543cbd30cbfe7929be4dcb5c5251659"],"f4ba1ab90d9a427e7f2c7d1e65a3ce5869ed8e5d":["5af07783dbc171e26a694c4f7d735e30c2769faa"],"5af07783dbc171e26a694c4f7d735e30c2769faa":["5bf26a11728ffdf1d7a0eac68fd2cd501d45f367"],"712be41a80a289d25186217345860f2ddec4cab8":["ab50480bb5a7c7abad9762badcf87f8b69efeabe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}