{"path":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#doTestMode(Normalizer2,int,int,int).mjava","commits":[{"id":"4434126f19baaf18fbed92b111931667ffb8ebbd","date":1418044101,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#doTestMode(Normalizer2,int,int,int).mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#doTestMode(Normalizer2,int,int).mjava","sourceNew":"  public void doTestMode(final Normalizer2 normalizer, int maxLength, int iterations, int bufferSize) throws IOException {\n    Analyzer a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      protected Reader initReader(String fieldName, Reader reader) {\n        return new ICUNormalizer2CharFilter(reader, normalizer, bufferSize);\n      }\n    };\n\n    for (int i = 0; i < iterations; i++) {\n      String input = TestUtil.randomUnicodeString(random(), maxLength);\n      if (input.length() == 0) {\n        continue;\n      }\n      String normalized = normalizer.normalize(input);\n      if (normalized.length() == 0) {\n        continue; // MockTokenizer doesnt tokenize empty string...\n      }\n      checkOneTerm(a, input, normalized);\n    }\n  }\n\n","sourceOld":"  public void doTestMode(final Normalizer2 normalizer, int maxLength, int iterations) throws IOException {\n    Analyzer a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      protected Reader initReader(String fieldName, Reader reader) {\n        return new ICUNormalizer2CharFilter(reader, normalizer);\n      }\n    };\n\n    for (int i = 0; i < iterations; i++) {\n      String input = TestUtil.randomUnicodeString(random(), maxLength);\n      if (input.length() == 0) {\n        continue;\n      }\n      String normalized = normalizer.normalize(input);\n      if (normalized.length() == 0) {\n        continue; // MockTokenizer doesnt tokenize empty string...\n      }\n      checkOneTerm(a, input, normalized);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#doTestMode(Normalizer2,int,int,int).mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#doTestMode(Normalizer2,int,int,int).mjava","sourceNew":"  public void doTestMode(final Normalizer2 normalizer, int maxLength, int iterations, int bufferSize) throws IOException {\n    Analyzer a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      protected Reader initReader(String fieldName, Reader reader) {\n        return new ICUNormalizer2CharFilter(reader, normalizer, bufferSize);\n      }\n    };\n\n    for (int i = 0; i < iterations; i++) {\n      String input = TestUtil.randomUnicodeString(random(), maxLength);\n      if (input.length() == 0) {\n        continue;\n      }\n      String normalized = normalizer.normalize(input);\n      if (normalized.length() == 0) {\n        continue; // MockTokenizer doesnt tokenize empty string...\n      }\n      checkOneTerm(a, input, normalized);\n    }\n    a.close();\n  }\n\n","sourceOld":"  public void doTestMode(final Normalizer2 normalizer, int maxLength, int iterations, int bufferSize) throws IOException {\n    Analyzer a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      protected Reader initReader(String fieldName, Reader reader) {\n        return new ICUNormalizer2CharFilter(reader, normalizer, bufferSize);\n      }\n    };\n\n    for (int i = 0; i < iterations; i++) {\n      String input = TestUtil.randomUnicodeString(random(), maxLength);\n      if (input.length() == 0) {\n        continue;\n      }\n      String normalized = normalizer.normalize(input);\n      if (normalized.length() == 0) {\n        continue; // MockTokenizer doesnt tokenize empty string...\n      }\n      checkOneTerm(a, input, normalized);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#doTestMode(Normalizer2,int,int,int).mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/TestICUNormalizer2CharFilter#doTestMode(Normalizer2,int,int,int).mjava","sourceNew":"  public void doTestMode(final Normalizer2 normalizer, int maxLength, int iterations, int bufferSize) throws IOException {\n    Analyzer a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      protected Reader initReader(String fieldName, Reader reader) {\n        return new ICUNormalizer2CharFilter(reader, normalizer, bufferSize);\n      }\n    };\n\n    for (int i = 0; i < iterations; i++) {\n      String input = TestUtil.randomUnicodeString(random(), maxLength);\n      if (input.length() == 0) {\n        continue;\n      }\n      String normalized = normalizer.normalize(input);\n      if (normalized.length() == 0) {\n        continue; // MockTokenizer doesnt tokenize empty string...\n      }\n      checkOneTerm(a, input, normalized);\n    }\n    a.close();\n  }\n\n","sourceOld":"  public void doTestMode(final Normalizer2 normalizer, int maxLength, int iterations, int bufferSize) throws IOException {\n    Analyzer a = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer(MockTokenizer.KEYWORD, false));\n      }\n\n      @Override\n      protected Reader initReader(String fieldName, Reader reader) {\n        return new ICUNormalizer2CharFilter(reader, normalizer, bufferSize);\n      }\n    };\n\n    for (int i = 0; i < iterations; i++) {\n      String input = TestUtil.randomUnicodeString(random(), maxLength);\n      if (input.length() == 0) {\n        continue;\n      }\n      String normalized = normalizer.normalize(input);\n      if (normalized.length() == 0) {\n        continue; // MockTokenizer doesnt tokenize empty string...\n      }\n      checkOneTerm(a, input, normalized);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["4434126f19baaf18fbed92b111931667ffb8ebbd","a56958d7f71a28824f20031ffbb2e13502a0274e"],"4434126f19baaf18fbed92b111931667ffb8ebbd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a56958d7f71a28824f20031ffbb2e13502a0274e":["4434126f19baaf18fbed92b111931667ffb8ebbd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a56958d7f71a28824f20031ffbb2e13502a0274e"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"4434126f19baaf18fbed92b111931667ffb8ebbd":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4434126f19baaf18fbed92b111931667ffb8ebbd"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}