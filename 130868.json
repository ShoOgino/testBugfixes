{"path":"solr/core/src/test/org/apache/solr/util/TestMaxTokenLenTokenizer#testSingleFieldDiffAnalyzers().mjava","commits":[{"id":"367e74558f41dfa2d24b323440dcb2d653ad1a29","date":1496009928,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/util/TestMaxTokenLenTokenizer#testSingleFieldDiffAnalyzers().mjava","pathOld":"/dev/null","sourceNew":"  public void testSingleFieldDiffAnalyzers() throws Exception {\n\n    clearIndex();\n\n    // using fields with definitions, different tokenizer factories respectively at index time and standard tokenizer at query time.\n\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":1,\\\"letter\\\":\\\"letter\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":2,\\\"lowerCase\\\":\\\"lowerCase\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":3,\\\"whiteSpace\\\":\\\"whiteSpace in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":4,\\\"unicodeWhiteSpace\\\":\\\"unicode in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":5,\\\"keyword\\\":\\\"keyword\\\"}},\\\"commit\\\":{}}\",null);\n\n    assertU(commit());\n\n    assertQ(\"Check the total number of docs\", req(\"q\",\"*:*\"), \"//result[@numFound=5]\");\n\n    //Tokens generated for \"letter\": \"let\" \"ter\" \"letter\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:let\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:lett\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"lowerCase\": \"low\" \"erC\" \"ase\" \"lowerCase\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:low\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:l\"), \"//result[@numFound=0]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:lo\"), \"//result[@numFound=0]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:lower\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"whiteSpace in\": \"whi\" \"teS\" \"pac\" \"e\" \"in\" \"whiteSpace\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:whi\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:teS\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:in\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:white\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"unicode in\": \"uni\" \"cod\" \"e\" \"in\" \"unicode\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:uni\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:cod\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:e\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:unico\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"keyword\": \"keyword\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:keyword\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:key\"), \"//result[@numFound=0]\");\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d1f5728f32a4a256b36cfabd7a2636452f599bb9","date":1496231774,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/util/TestMaxTokenLenTokenizer#testSingleFieldDiffAnalyzers().mjava","pathOld":"/dev/null","sourceNew":"  public void testSingleFieldDiffAnalyzers() throws Exception {\n\n    clearIndex();\n\n    // using fields with definitions, different tokenizer factories respectively at index time and standard tokenizer at query time.\n\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":1,\\\"letter\\\":\\\"letter\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":2,\\\"lowerCase\\\":\\\"lowerCase\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":3,\\\"whiteSpace\\\":\\\"whiteSpace in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":4,\\\"unicodeWhiteSpace\\\":\\\"unicode in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":5,\\\"keyword\\\":\\\"keyword\\\"}},\\\"commit\\\":{}}\",null);\n\n    assertU(commit());\n\n    assertQ(\"Check the total number of docs\", req(\"q\",\"*:*\"), \"//result[@numFound=5]\");\n\n    //Tokens generated for \"letter\": \"let\" \"ter\" \"letter\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:let\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:lett\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"lowerCase\": \"low\" \"erC\" \"ase\" \"lowerCase\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:low\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:l\"), \"//result[@numFound=0]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:lo\"), \"//result[@numFound=0]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:lower\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"whiteSpace in\": \"whi\" \"teS\" \"pac\" \"e\" \"in\" \"whiteSpace\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:whi\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:teS\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:in\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:white\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"unicode in\": \"uni\" \"cod\" \"e\" \"in\" \"unicode\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:uni\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:cod\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:e\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:unico\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"keyword\": \"keyword\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:keyword\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:key\"), \"//result[@numFound=0]\");\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/util/TestMaxTokenLenTokenizer#testSingleFieldDiffAnalyzers().mjava","pathOld":"/dev/null","sourceNew":"  public void testSingleFieldDiffAnalyzers() throws Exception {\n\n    clearIndex();\n\n    // using fields with definitions, different tokenizer factories respectively at index time and standard tokenizer at query time.\n\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":1,\\\"letter\\\":\\\"letter\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":2,\\\"lowerCase\\\":\\\"lowerCase\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":3,\\\"whiteSpace\\\":\\\"whiteSpace in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":4,\\\"unicodeWhiteSpace\\\":\\\"unicode in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":5,\\\"keyword\\\":\\\"keyword\\\"}},\\\"commit\\\":{}}\",null);\n\n    assertU(commit());\n\n    assertQ(\"Check the total number of docs\", req(\"q\",\"*:*\"), \"//result[@numFound=5]\");\n\n    //Tokens generated for \"letter\": \"let\" \"ter\" \"letter\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:let\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:lett\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"lowerCase\": \"low\" \"erC\" \"ase\" \"lowerCase\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:low\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:l\"), \"//result[@numFound=0]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:lo\"), \"//result[@numFound=0]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:lower\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"whiteSpace in\": \"whi\" \"teS\" \"pac\" \"e\" \"in\" \"whiteSpace\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:whi\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:teS\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:in\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:white\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"unicode in\": \"uni\" \"cod\" \"e\" \"in\" \"unicode\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:uni\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:cod\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:e\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:unico\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"keyword\": \"keyword\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:keyword\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:key\"), \"//result[@numFound=0]\");\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0","date":1537441025,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/util/TestMaxTokenLenTokenizer#testSingleFieldDiffAnalyzers().mjava","pathOld":"solr/core/src/test/org/apache/solr/util/TestMaxTokenLenTokenizer#testSingleFieldDiffAnalyzers().mjava","sourceNew":"  public void testSingleFieldDiffAnalyzers() throws Exception {\n\n    clearIndex();\n\n    // using fields with definitions, different tokenizer factories respectively at index time and standard tokenizer at query time.\n\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":1,\\\"letter\\\":\\\"letter\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":3,\\\"whiteSpace\\\":\\\"whiteSpace in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":4,\\\"unicodeWhiteSpace\\\":\\\"unicode in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":5,\\\"keyword\\\":\\\"keyword\\\"}},\\\"commit\\\":{}}\",null);\n\n    assertU(commit());\n\n    assertQ(\"Check the total number of docs\", req(\"q\",\"*:*\"), \"//result[@numFound=4]\");\n\n    //Tokens generated for \"letter\": \"let\" \"ter\" \"letter\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:let\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:lett\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"whiteSpace in\": \"whi\" \"teS\" \"pac\" \"e\" \"in\" \"whiteSpace\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:whi\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:teS\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:in\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:white\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"unicode in\": \"uni\" \"cod\" \"e\" \"in\" \"unicode\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:uni\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:cod\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:e\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:unico\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"keyword\": \"keyword\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:keyword\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:key\"), \"//result[@numFound=0]\");\n\n  }\n\n","sourceOld":"  public void testSingleFieldDiffAnalyzers() throws Exception {\n\n    clearIndex();\n\n    // using fields with definitions, different tokenizer factories respectively at index time and standard tokenizer at query time.\n\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":1,\\\"letter\\\":\\\"letter\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":2,\\\"lowerCase\\\":\\\"lowerCase\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":3,\\\"whiteSpace\\\":\\\"whiteSpace in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":4,\\\"unicodeWhiteSpace\\\":\\\"unicode in\\\"}},\\\"commit\\\":{}}\",null);\n    updateJ(\"{\\\"add\\\":{\\\"doc\\\": {\\\"id\\\":5,\\\"keyword\\\":\\\"keyword\\\"}},\\\"commit\\\":{}}\",null);\n\n    assertU(commit());\n\n    assertQ(\"Check the total number of docs\", req(\"q\",\"*:*\"), \"//result[@numFound=5]\");\n\n    //Tokens generated for \"letter\": \"let\" \"ter\" \"letter\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:let\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"letter:lett\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"lowerCase\": \"low\" \"erC\" \"ase\" \"lowerCase\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:low\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:l\"), \"//result[@numFound=0]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:lo\"), \"//result[@numFound=0]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"lowerCase:lower\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"whiteSpace in\": \"whi\" \"teS\" \"pac\" \"e\" \"in\" \"whiteSpace\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:whi\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:teS\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:in\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"whiteSpace:white\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"unicode in\": \"uni\" \"cod\" \"e\" \"in\" \"unicode\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:uni\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:cod\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:e\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"unicodeWhiteSpace:unico\"), \"//result[@numFound=0]\");\n\n    //Tokens generated for \"keyword\": \"keyword\" , maxTokenLen=3\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:keyword\"), \"//result[@numFound=1]\");\n    assertQ(\"Check the total number of docs\", req(\"q\",\"keyword:key\"), \"//result[@numFound=0]\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0":["d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","367e74558f41dfa2d24b323440dcb2d653ad1a29"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"367e74558f41dfa2d24b323440dcb2d653ad1a29":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d1f5728f32a4a256b36cfabd7a2636452f599bb9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","367e74558f41dfa2d24b323440dcb2d653ad1a29"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0"]},"commit2Childs":{"3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e9017cf144952056066919f1ebc7897ff9bd71b1","367e74558f41dfa2d24b323440dcb2d653ad1a29","d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"367e74558f41dfa2d24b323440dcb2d653ad1a29":["e9017cf144952056066919f1ebc7897ff9bd71b1","d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"d1f5728f32a4a256b36cfabd7a2636452f599bb9":["3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}