{"path":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","commits":[{"id":"047007f30fa7e5c9273d6dc8d292deca18da4c2c","date":1251016462,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d67c4ea31a7da55cffc14bca15efd0a8eb5cd449","date":1251235595,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","sourceNew":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeSource.AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","sourceOld":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ef91b3a79d28d958fb47a576d0ddf081dc8fecc5","date":1251239251,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","sourceNew":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","sourceOld":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link AttributeSource.AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add7d922e63099fbce8f0a1b31216df7ef5067f1","date":1252002701,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","sourceNew":"  /**\n   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <code>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","sourceOld":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c69d87d34a81230de56333f52f590caeb6d80667","date":1257848306,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set[String]).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(AttributeFactory,Reader,int,Set).mjava","sourceNew":"  /**\n   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <code>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set<String> untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","sourceOld":"  /**\n   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <code>input</code> to a the newly created JFlex scanner. Uses the given {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(AttributeFactory factory, Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(factory, input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c69d87d34a81230de56333f52f590caeb6d80667":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"ef91b3a79d28d958fb47a576d0ddf081dc8fecc5":["d67c4ea31a7da55cffc14bca15efd0a8eb5cd449"],"047007f30fa7e5c9273d6dc8d292deca18da4c2c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["ef91b3a79d28d958fb47a576d0ddf081dc8fecc5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d67c4ea31a7da55cffc14bca15efd0a8eb5cd449":["047007f30fa7e5c9273d6dc8d292deca18da4c2c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c69d87d34a81230de56333f52f590caeb6d80667"]},"commit2Childs":{"c69d87d34a81230de56333f52f590caeb6d80667":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ef91b3a79d28d958fb47a576d0ddf081dc8fecc5":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"047007f30fa7e5c9273d6dc8d292deca18da4c2c":["d67c4ea31a7da55cffc14bca15efd0a8eb5cd449"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["c69d87d34a81230de56333f52f590caeb6d80667"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["047007f30fa7e5c9273d6dc8d292deca18da4c2c"],"d67c4ea31a7da55cffc14bca15efd0a8eb5cd449":["ef91b3a79d28d958fb47a576d0ddf081dc8fecc5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}