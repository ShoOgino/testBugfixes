{"path":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","commits":[{"id":"790c3f61c9b891d66d919c5d10db9fa5216eb0f1","date":1274818604,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":["0bf41419d452997826ec5f17684993377be77f49"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf7efd82433f3f64684711c16edfd149db6af111","date":1317013128,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.reusableTokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.reusableTokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c39363fefe2d7f6a6d50ce8e8b758c17a257c58e","date":1328817590,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    CharArraySet stopWordsSet = new CharArraySet(TEST_VERSION_CURRENT, asSet(\"good\", \"test\", \"analyzer\"), false);\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    Set<Object> stopWordsSet = new HashSet<Object>();\n    stopWordsSet.add(\"good\");\n    stopWordsSet.add(\"test\");\n    stopWordsSet.add(\"analyzer\");\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","bugFix":["e450c7d50c2fc84c963d0d7ade9d3217d868064d","13ba39c40de7bda3b305a362bceb7a788e31df23"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer#testStopList().mjava","sourceNew":"  public void testStopList() throws IOException {\n    CharArraySet stopWordsSet = new CharArraySet(TEST_VERSION_CURRENT, asSet(\"good\", \"test\", \"analyzer\"), false);\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","sourceOld":"  public void testStopList() throws IOException {\n    CharArraySet stopWordsSet = new CharArraySet(TEST_VERSION_CURRENT, asSet(\"good\", \"test\", \"analyzer\"), false);\n    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);\n    StringReader reader = new StringReader(\"This is a good test of the english stop analyzer\");\n    TokenStream stream = newStop.tokenStream(\"test\", reader);\n    assertNotNull(stream);\n    CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n    \n    while (stream.incrementToken()) {\n      String text = termAtt.toString();\n      assertFalse(stopWordsSet.contains(text));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["c39363fefe2d7f6a6d50ce8e8b758c17a257c58e"],"c39363fefe2d7f6a6d50ce8e8b758c17a257c58e":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cf7efd82433f3f64684711c16edfd149db6af111":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["cf7efd82433f3f64684711c16edfd149db6af111"],"3bb13258feba31ab676502787ab2e1779f129b7a":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c39363fefe2d7f6a6d50ce8e8b758c17a257c58e":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"cf7efd82433f3f64684711c16edfd149db6af111":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["c39363fefe2d7f6a6d50ce8e8b758c17a257c58e"],"3bb13258feba31ab676502787ab2e1779f129b7a":[],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cf7efd82433f3f64684711c16edfd149db6af111","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}