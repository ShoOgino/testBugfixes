{"path":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","commits":[{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.optimize();\n    writer.close();\n    IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3a0403b45dfe384fae4a1b6e96c3265d000c498","date":1321445981,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(indexStore);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n    searcher.close();\n    reader.close();\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexSearcher searcher = new IndexSearcher(indexStore, true);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(indexStore);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n    reader.close();\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(indexStore);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n    searcher.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(indexStore);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n    reader.close();\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(indexStore);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n    searcher.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/CollationTestBase#testCollationKeySort(Analyzer,Analyzer,Analyzer,Analyzer,String,String,String,String).mjava","sourceNew":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(indexStore);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n    reader.close();\n  }\n\n","sourceOld":"  // Test using various international locales with accented characters (which\n  // sort differently depending on locale)\n  //\n  // Copied (and slightly modified) from \n  // org.apache.lucene.search.TestSort.testInternationalSort()\n  //  \n  // TODO: this test is really fragile. there are already 3 different cases,\n  // depending upon unicode version.\n  public void testCollationKeySort(Analyzer usAnalyzer,\n                                   Analyzer franceAnalyzer,\n                                   Analyzer swedenAnalyzer,\n                                   Analyzer denmarkAnalyzer,\n                                   String usResult,\n                                   String frResult,\n                                   String svResult,\n                                   String dkResult) throws Exception {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random, MockTokenizer.WHITESPACE, false)));\n\n    // document data:\n    // the tracer field is used to determine which document was hit\n    String[][] sortData = new String[][] {\n      // tracer contents US                 France             Sweden (sv_SE)     Denmark (da_DK)\n      {  \"A\",   \"x\",     \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\",      \"p\\u00EAche\"      },\n      {  \"B\",   \"y\",     \"HAT\",             \"HAT\",             \"HAT\",             \"HAT\"             },\n      {  \"C\",   \"x\",     \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\", \"p\\u00E9ch\\u00E9\" },\n      {  \"D\",   \"y\",     \"HUT\",             \"HUT\",             \"HUT\",             \"HUT\"             },\n      {  \"E\",   \"x\",     \"peach\",           \"peach\",           \"peach\",           \"peach\"           },\n      {  \"F\",   \"y\",     \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\",        \"H\\u00C5T\"        },\n      {  \"G\",   \"x\",     \"sin\",             \"sin\",             \"sin\",             \"sin\"             },\n      {  \"H\",   \"y\",     \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\",        \"H\\u00D8T\"        },\n      {  \"I\",   \"x\",     \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\",        \"s\\u00EDn\"        },\n      {  \"J\",   \"y\",     \"HOT\",             \"HOT\",             \"HOT\",             \"HOT\"             },\n    };\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    for (int i = 0 ; i < sortData.length ; ++i) {\n      Document doc = new Document();\n      doc.add(new Field(\"tracer\", sortData[i][0], customType));\n      doc.add(new TextField(\"contents\", sortData[i][1]));\n      if (sortData[i][2] != null) \n        doc.add(new TextField(\"US\", usAnalyzer.tokenStream(\"US\", new StringReader(sortData[i][2]))));\n      if (sortData[i][3] != null) \n        doc.add(new TextField(\"France\", franceAnalyzer.tokenStream(\"France\", new StringReader(sortData[i][3]))));\n      if (sortData[i][4] != null)\n        doc.add(new TextField(\"Sweden\", swedenAnalyzer.tokenStream(\"Sweden\", new StringReader(sortData[i][4]))));\n      if (sortData[i][5] != null) \n        doc.add(new TextField(\"Denmark\", denmarkAnalyzer.tokenStream(\"Denmark\", new StringReader(sortData[i][5]))));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(indexStore);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    Sort sort = new Sort();\n    Query queryX = new TermQuery(new Term (\"contents\", \"x\"));\n    Query queryY = new TermQuery(new Term (\"contents\", \"y\"));\n    \n    sort.setSort(new SortField(\"US\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, usResult);\n\n    sort.setSort(new SortField(\"France\", SortField.Type.STRING));\n    assertMatches(searcher, queryX, sort, frResult);\n\n    sort.setSort(new SortField(\"Sweden\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, svResult);\n\n    sort.setSort(new SortField(\"Denmark\", SortField.Type.STRING));\n    assertMatches(searcher, queryY, sort, dkResult);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["7b91922b55d15444d554721b352861d028eb8278"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7b91922b55d15444d554721b352861d028eb8278"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["0e7c2454a6a8237bfd0e953f5b940838408c9055","93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}