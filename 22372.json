{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","commits":[{"id":"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704","date":1371043069,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int).mjava","sourceNew":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_44)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_44)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(Version version, int minGram, int maxGram) {\n    if (!version.onOrAfter(Version.LUCENE_44)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    buffer = new char[maxGram + 1024];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd330c9d05eacbd6e952fe0dea852e7ae037eb50","date":1398873035,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","sourceNew":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_4_4)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_44)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_44)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff4227bb146f97aabae888091c19e48c88dbb0db","date":1406758576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","sourceNew":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_4_4)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance()\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_4_4)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cdab62f058ea765dd33deb05b4f19b7d626c801","date":1406803479,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","sourceNew":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_4_4)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_4_4)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance()\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":5,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int,boolean).mjava","sourceNew":"  private void init(int minGram, int maxGram, boolean edgesOnly) {\n    charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","sourceOld":"  private void init(Version version, int minGram, int maxGram, boolean edgesOnly) {\n    if (!edgesOnly && !version.onOrAfter(Version.LUCENE_4_4)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.edgesOnly = edgesOnly;\n    charBuffer = CharacterUtils.newCharacterBuffer(2 * maxGram + 1024); // 2 * maxGram in case all code points require 2 chars and + 1024 for buffering to not keep polling the Reader\n    buffer = new int[charBuffer.getBuffer().length];\n    // Make the term att large enough\n    termAtt.resizeBuffer(2 * maxGram);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["dd330c9d05eacbd6e952fe0dea852e7ae037eb50"],"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"dd330c9d05eacbd6e952fe0dea852e7ae037eb50":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["379db3ad24c4f0214f30a122265a6d6be003a99d"]},"commit2Childs":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704":["dd330c9d05eacbd6e952fe0dea852e7ae037eb50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"dd330c9d05eacbd6e952fe0dea852e7ae037eb50":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}