{"path":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#StandardTokenizer(Version,AttributeSource,Reader).mjava","commits":[{"id":"ba1116b3450a9c1642c89445d131b37344055245","date":1256329517,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#StandardTokenizer(Version,AttributeSource,Reader).mjava","pathOld":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#StandardTokenizer(AttributeSource,Reader,boolean).mjava","sourceNew":"  /**\n   * Creates a new StandardTokenizer with a given {@link AttributeSource}. \n   */\n  public StandardTokenizer(Version matchVersion, AttributeSource source, Reader input) {\n    super(source);\n    this.scanner = new StandardTokenizerImpl(input);\n    init(input, matchVersion);\n  }\n\n","sourceOld":"  /**\n   * Creates a new StandardTokenizer with a given {@link AttributeSource}. \n   */\n  public StandardTokenizer(AttributeSource source, Reader input, boolean replaceInvalidAcronym) {\n    super(source);\n    this.scanner = new StandardTokenizerImpl(input);\n    init(input, replaceInvalidAcronym);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#StandardTokenizer(Version,AttributeSource,Reader).mjava","pathOld":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#StandardTokenizer(Version,AttributeSource,Reader).mjava","sourceNew":"  /**\n   * Creates a new StandardTokenizer with a given {@link AttributeSource}. \n   */\n  public StandardTokenizer(Version matchVersion, AttributeSource source, Reader input) {\n    super(source);\n    this.scanner = new StandardTokenizerImpl(input);\n    init(input, matchVersion);\n  }\n\n","sourceOld":"  /**\n   * Creates a new StandardTokenizer with a given {@link AttributeSource}. \n   */\n  public StandardTokenizer(Version matchVersion, AttributeSource source, Reader input) {\n    super(source);\n    this.scanner = new StandardTokenizerImpl(input);\n    init(input, matchVersion);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["ba1116b3450a9c1642c89445d131b37344055245"],"ba1116b3450a9c1642c89445d131b37344055245":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ba1116b3450a9c1642c89445d131b37344055245"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ba1116b3450a9c1642c89445d131b37344055245":["9454a6510e2db155fb01faa5c049b06ece95fab9"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}