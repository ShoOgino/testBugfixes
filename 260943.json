{"path":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !writeFreq || postings.docFreqs[termID] > 0;\n\n    if (!writeFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (writeProx) {\n        writeProx(termID, fieldState.position);\n        if (writeOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !writeOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (writeProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (writeOffsets) {\n        writeOffsets(termID, postings.lastOffsets[termID]);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !writeFreq || postings.docFreqs[termID] > 0;\n\n    if (!writeFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (writeProx) {\n        writeProx(termID, fieldState.position);\n        if (writeOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !writeOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (writeProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (writeOffsets) {\n        writeOffsets(termID, postings.lastOffsets[termID]);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83ede60c0b5bb96ad193414bbd663193b56689b3","date":1338331478,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.docFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, postings.lastOffsets[termID]);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !writeFreq || postings.docFreqs[termID] > 0;\n\n    if (!writeFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (writeProx) {\n        writeProx(termID, fieldState.position);\n        if (writeOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !writeOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (writeProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (writeOffsets) {\n        writeOffsets(termID, postings.lastOffsets[termID]);\n      }\n    }\n  }\n\n","bugFix":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626","date":1339522233,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.docFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.docFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, postings.lastOffsets[termID]);\n      }\n    }\n  }\n\n","bugFix":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e2aa5e951cc02d4c8152098ebec9c4bac57b3a65","date":1344352872,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.termFreqs[termID]);\n      }\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.docFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.termFreqs[termID]);\n      }\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.docFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.termFreqs[termID]);\n      }\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.docFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.docFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.docFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.docFreqs[termID]);\n      }\n      postings.docFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.docFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52c7e49be259508735752fba88085255014a6ecf","date":1398706273,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.termFreqs[termID]);\n      }\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3394716f52b34ab259ad5247e7595d9f9db6e935","date":1398791921,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.termFreqs[termID]);\n      }\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    FreqProxPostingsArray postings = (FreqProxPostingsArray) termsHashPerField.postingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        assert docState.docID > postings.lastDocIDs[termID];\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        termsHashPerField.writeVInt(0, postings.lastDocCodes[termID]);\n        termsHashPerField.writeVInt(0, postings.termFreqs[termID]);\n      }\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n      }\n      if (hasOffsets) {\n        writeOffsets(termID, fieldState.offset);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4","date":1414017220,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n\n    assert docState.testPoint(\"FreqProxTermsWriterPerField.addTerm start\");\n\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e72e3ade782716457071fee4033f18689acc4c4f","date":1496770651,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (termFreqAtt.getTermFrequency() != 1) {\n        throw new IllegalStateException(\"field \\\"\" + fieldInfo.name + \"\\\": must index term freq while using custom TermFrequencyAttribute\");\n      }\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = getTermFreq();\n      fieldState.maxTermFrequency = Math.max(postings.termFreqs[termID], fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      postings.termFreqs[termID] = Math.addExact(postings.termFreqs[termID], getTermFreq());\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f344bb33ca91f48e99c061980115b46fa84fc8f5","date":1496903283,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (termFreqAtt.getTermFrequency() != 1) {\n        throw new IllegalStateException(\"field \\\"\" + fieldInfo.name + \"\\\": must index term freq while using custom TermFrequencyAttribute\");\n      }\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = getTermFreq();\n      fieldState.maxTermFrequency = Math.max(postings.termFreqs[termID], fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      postings.termFreqs[termID] = Math.addExact(postings.termFreqs[termID], getTermFreq());\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (termFreqAtt.getTermFrequency() != 1) {\n        throw new IllegalStateException(\"field \\\"\" + fieldInfo.name + \"\\\": must index term freq while using custom TermFrequencyAttribute\");\n      }\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = getTermFreq();\n      fieldState.maxTermFrequency = Math.max(postings.termFreqs[termID], fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      postings.termFreqs[termID] = Math.addExact(postings.termFreqs[termID], getTermFreq());\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (termFreqAtt.getTermFrequency() != 1) {\n        throw new IllegalStateException(\"field \\\"\" + fieldInfo.name + \"\\\": must index term freq while using custom TermFrequencyAttribute\");\n      }\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = getTermFreq();\n      fieldState.maxTermFrequency = Math.max(postings.termFreqs[termID], fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      postings.termFreqs[termID] = Math.addExact(postings.termFreqs[termID], getTermFreq());\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = 1;\n      fieldState.maxTermFrequency = Math.max(1, fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, ++postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3cc3fa1ecad75b99ec55169e44628808f9866ad","date":1592311545,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField#addTerm(int).mjava","sourceNew":"  @Override\n  void addTerm(final int termID, final int docID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (termFreqAtt.getTermFrequency() != 1) {\n        throw new IllegalStateException(\"field \\\"\" + getFieldName() + \"\\\": must index term freq while using custom TermFrequencyAttribute\");\n      }\n      if (docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docID != postings.lastDocIDs[termID]) {\n      assert docID > postings.lastDocIDs[termID]:\"id: \"+docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = getTermFreq();\n      fieldState.maxTermFrequency = Math.max(postings.termFreqs[termID], fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      postings.termFreqs[termID] = Math.addExact(postings.termFreqs[termID], getTermFreq());\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  void addTerm(final int termID) {\n    final FreqProxPostingsArray postings = freqProxPostingsArray;\n    assert !hasFreq || postings.termFreqs[termID] > 0;\n\n    if (!hasFreq) {\n      assert postings.termFreqs == null;\n      if (termFreqAtt.getTermFrequency() != 1) {\n        throw new IllegalStateException(\"field \\\"\" + fieldInfo.name + \"\\\": must index term freq while using custom TermFrequencyAttribute\");\n      }\n      if (docState.docID != postings.lastDocIDs[termID]) {\n        // New document; now encode docCode for previous doc:\n        assert docState.docID > postings.lastDocIDs[termID];\n        writeVInt(0, postings.lastDocCodes[termID]);\n        postings.lastDocCodes[termID] = docState.docID - postings.lastDocIDs[termID];\n        postings.lastDocIDs[termID] = docState.docID;\n        fieldState.uniqueTermCount++;\n      }\n    } else if (docState.docID != postings.lastDocIDs[termID]) {\n      assert docState.docID > postings.lastDocIDs[termID]:\"id: \"+docState.docID + \" postings ID: \"+ postings.lastDocIDs[termID] + \" termID: \"+termID;\n      // Term not yet seen in the current doc but previously\n      // seen in other doc(s) since the last flush\n\n      // Now that we know doc freq for previous doc,\n      // write it & lastDocCode\n      if (1 == postings.termFreqs[termID]) {\n        writeVInt(0, postings.lastDocCodes[termID]|1);\n      } else {\n        writeVInt(0, postings.lastDocCodes[termID]);\n        writeVInt(0, postings.termFreqs[termID]);\n      }\n\n      // Init freq for the current document\n      postings.termFreqs[termID] = getTermFreq();\n      fieldState.maxTermFrequency = Math.max(postings.termFreqs[termID], fieldState.maxTermFrequency);\n      postings.lastDocCodes[termID] = (docState.docID - postings.lastDocIDs[termID]) << 1;\n      postings.lastDocIDs[termID] = docState.docID;\n      if (hasProx) {\n        writeProx(termID, fieldState.position);\n        if (hasOffsets) {\n          postings.lastOffsets[termID] = 0;\n          writeOffsets(termID, fieldState.offset);\n        }\n      } else {\n        assert !hasOffsets;\n      }\n      fieldState.uniqueTermCount++;\n    } else {\n      postings.termFreqs[termID] = Math.addExact(postings.termFreqs[termID], getTermFreq());\n      fieldState.maxTermFrequency = Math.max(fieldState.maxTermFrequency, postings.termFreqs[termID]);\n      if (hasProx) {\n        writeProx(termID, fieldState.position-postings.lastPositions[termID]);\n        if (hasOffsets) {\n          writeOffsets(termID, fieldState.offset);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["e2aa5e951cc02d4c8152098ebec9c4bac57b3a65","3394716f52b34ab259ad5247e7595d9f9db6e935"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"83ede60c0b5bb96ad193414bbd663193b56689b3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"f344bb33ca91f48e99c061980115b46fa84fc8f5":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4","e72e3ade782716457071fee4033f18689acc4c4f"],"28288370235ed02234a64753cdbf0c6ec096304a":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["e2aa5e951cc02d4c8152098ebec9c4bac57b3a65","52c7e49be259508735752fba88085255014a6ecf"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626","e2aa5e951cc02d4c8152098ebec9c4bac57b3a65"],"e2aa5e951cc02d4c8152098ebec9c4bac57b3a65":["d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626"],"e72e3ade782716457071fee4033f18689acc4c4f":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626","e2aa5e951cc02d4c8152098ebec9c4bac57b3a65"],"d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626":["83ede60c0b5bb96ad193414bbd663193b56689b3"],"52c7e49be259508735752fba88085255014a6ecf":["e2aa5e951cc02d4c8152098ebec9c4bac57b3a65"],"d3cc3fa1ecad75b99ec55169e44628808f9866ad":["28288370235ed02234a64753cdbf0c6ec096304a"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d3cc3fa1ecad75b99ec55169e44628808f9866ad"]},"commit2Childs":{"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4":["f344bb33ca91f48e99c061980115b46fa84fc8f5","28288370235ed02234a64753cdbf0c6ec096304a","e72e3ade782716457071fee4033f18689acc4c4f","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["83ede60c0b5bb96ad193414bbd663193b56689b3"],"83ede60c0b5bb96ad193414bbd663193b56689b3":["d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626"],"f344bb33ca91f48e99c061980115b46fa84fc8f5":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"28288370235ed02234a64753cdbf0c6ec096304a":["d3cc3fa1ecad75b99ec55169e44628808f9866ad"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"e2aa5e951cc02d4c8152098ebec9c4bac57b3a65":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","3394716f52b34ab259ad5247e7595d9f9db6e935","c7869f64c874ebf7f317d22c00baf2b6857797a6","d6f074e73200c07d54f242d3880a8da5a35ff97b","52c7e49be259508735752fba88085255014a6ecf"],"e72e3ade782716457071fee4033f18689acc4c4f":["f344bb33ca91f48e99c061980115b46fa84fc8f5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"d2d5b1f6ad16c5f1ce7e0a00225e2c9ffd0bc626":["c7869f64c874ebf7f317d22c00baf2b6857797a6","e2aa5e951cc02d4c8152098ebec9c4bac57b3a65","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"52c7e49be259508735752fba88085255014a6ecf":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"d3cc3fa1ecad75b99ec55169e44628808f9866ad":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","c7869f64c874ebf7f317d22c00baf2b6857797a6","d6f074e73200c07d54f242d3880a8da5a35ff97b","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}