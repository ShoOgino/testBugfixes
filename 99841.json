{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.pendingDeleteCount != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.pendingDeleteCount);\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        final int delCount = rld.pendingDeleteCount + info.getDelCount();\n        assert delCount <= info.docCount;\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            readerPool.release(sr, false);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.pendingDeleteCount != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.pendingDeleteCount);\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        final int delCount = rld.pendingDeleteCount + info.getDelCount();\n        assert delCount <= info.docCount;\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            readerPool.release(sr, false);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae695f21c50b03702b5d0fa2543d5af844bb7cd3","date":1331554994,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.pendingDeleteCount != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.pendingDeleteCount);\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        final int delCount = rld.pendingDeleteCount + info.getDelCount();\n        assert delCount <= info.docCount;\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            readerPool.release(sr, false);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":["9ce667c6d3400b22523701c549c0d35e26da8b46","32feb7c2c571b402d2e231bd8e3b6add4af6d6eb"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.pendingDeleteCount != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.pendingDeleteCount);\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        final int delCount = rld.pendingDeleteCount + info.getDelCount();\n        assert delCount <= info.docCount;\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            readerPool.release(sr, false);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b","date":1337136355,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n        // nocommit\n                                             payloadProcessorProvider, (MutableFieldInfos)merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d2dee33619431ada2a7a07f5fe2dbd94bac6a460","date":1337274029,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new MutableFieldInfos(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getHasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // LUCENE-3403: set hasVectors after merge(), so that it is properly set.\n      merge.info.setHasVectors(mergeState.fieldInfos.hasVectors());\n      merge.info.setHasProx(mergeState.fieldInfos.hasProx());\n      merge.info.setHasFreq(mergeState.fieldInfos.hasFreq());\n      merge.info.setHasDocValues(mergeState.fieldInfos.hasDocValues());\n      merge.info.setHasNorms(mergeState.fieldInfos.hasNorms());\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (merge.info.getHasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (merge.info.getHasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (merge.info.getHasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (merge.info.getHasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (merge.info.getHasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n        // nocommit\n                                             payloadProcessorProvider, (MutableFieldInfos)merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fc834f3412d287003cc04691da380b69ab983239","date":1337276089,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new MutableFieldInfos(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getHasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // LUCENE-3403: set hasVectors after merge(), so that it is properly set.\n      merge.info.setHasVectors(mergeState.fieldInfos.hasVectors());\n      merge.info.setHasProx(mergeState.fieldInfos.hasProx());\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new MutableFieldInfos(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getHasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // LUCENE-3403: set hasVectors after merge(), so that it is properly set.\n      merge.info.setHasVectors(mergeState.fieldInfos.hasVectors());\n      merge.info.setHasProx(mergeState.fieldInfos.hasProx());\n      merge.info.setHasFreq(mergeState.fieldInfos.hasFreq());\n      merge.info.setHasDocValues(mergeState.fieldInfos.hasDocValues());\n      merge.info.setHasNorms(mergeState.fieldInfos.hasNorms());\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (merge.info.getHasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (merge.info.getHasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (merge.info.getHasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (merge.info.getHasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (merge.info.getHasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4a8b14bc4241c302311422d5c6f7627f8febb86e","date":1337291675,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new MutableFieldInfos(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // LUCENE-3403: set hasVectors after merge(), so that it is properly set.\n      merge.info.setHasProx(mergeState.fieldInfos.hasProx());\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new MutableFieldInfos(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getHasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // LUCENE-3403: set hasVectors after merge(), so that it is properly set.\n      merge.info.setHasVectors(mergeState.fieldInfos.hasVectors());\n      merge.info.setHasProx(mergeState.fieldInfos.hasProx());\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dc97c61094c5498702b29cc2e8309beac50c23dc","date":1337293692,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new MutableFieldInfos(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new MutableFieldInfos(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // LUCENE-3403: set hasVectors after merge(), so that it is properly set.\n      merge.info.setHasProx(mergeState.fieldInfos.hasProx());\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a851824c09818632c94eba41e60ef5e72e323c8e","date":1337355760,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new MutableFieldInfos(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4356000e349e38c9fb48034695b7c309abd54557","date":1337460341,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      // nocommit should segment merger do this!?  else\n      // other places must do so...??? addIndexes...\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // nocommit need try/success thingy...?  ie must\n      // remove all seg files if we fail to write the .si?\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(merge.info, mergeState.fieldInfos);\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"352763be0465236f8e2ac188aa1b761cb3e1c9ee","date":1337516554,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      // nocommit should segment merger do this!?  else\n      // other places must do so...??? addIndexes...\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // nocommit need try/success thingy...?  ie must\n      // remove all seg files if we fail to write the .si?\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      // nocommit should segment merger do this!?  else\n      // other places must do so...??? addIndexes...\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // nocommit need try/success thingy...?  ie must\n      // remove all seg files if we fail to write the .si?\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(merge.info, mergeState.fieldInfos);\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9b2af6b2c05418fb9df466c739ed5b3a153eadde","date":1337520269,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          createCompoundFile(infoStream, directory, compoundFileName, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why do we set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }          \n        }\n      }\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             // nocommit\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      // nocommit should segment merger do this!?  else\n      // other places must do so...??? addIndexes...\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // nocommit need try/success thingy...?  ie must\n      // remove all seg files if we fail to write the .si?\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b512a6470fbb93c320e0cc8519ec0fe94efa13e","date":1337522360,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          createCompoundFile(infoStream, directory, compoundFileName, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }          \n        }\n      }\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          createCompoundFile(infoStream, directory, compoundFileName, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why do we set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }          \n        }\n      }\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1494abe5dc85557ec2e2772f87660d48f831c3a5","date":1337614370,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n      merge.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          createCompoundFile(infoStream, directory, compoundFileName, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }          \n        }\n      }\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6dce319de558e8b80705326dd04d578f74767d9","date":1337618331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n      merge.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n      merge.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      // nocommit stop doing this once we call non-wimpy\n      // ctor when we make the merge.info:\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a46feaa8775cb79964b568371b8eedaef5f576b","date":1337620767,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n      merge.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n      merge.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n      merge.info.clearFilesCache();\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.docCount = mergeState.mergedDocCount;\n      merge.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9ee159418514037b0fa456cf8b5d6c91e2bf5557","date":1337721836,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfosFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":["2edef7afebca00bf81a8bef95d44ea971ba309fa"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"129c6e8ac0c0d9a110ba29e4b5f1889374f30076","date":1337725510,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"00f06a4178989089b29a77d6dce7c86dfb8b6931","date":1337729247,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4e84d639980c2b2eb5d41330d5ff68d143239495","date":1337729749,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, new FieldInfos.Builder(globalFieldNumberMap), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0f6a6419266ce0a74e9f1501938a86a4c94d5af7","date":1337731230,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"662f233ff219b7c334eb6c65cd68cc71b27a4ffe","date":1337732885,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      // nocommit use setter and make this a SetOnce:\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb5728b83dbb3e002cdd22adfe6caf103a96ef15","date":1337791289,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      // nocommit use setter and make this a SetOnce:\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // nocommit ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"203d7d3cb7712e10ef33009a63247ae40c302d7a","date":1337798111,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.setDocCount(mergeState.mergedDocCount);\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.docCount = mergeState.mergedDocCount;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.docCount + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.docCount;\n  }\n\n","bugFix":null,"bugIntro":["0859dec0aa7a485aa0081147f533c5987b4b47ac"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"16cbef32b882ec68df422af3f08845ec82620335","date":1337802266,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      merge.info.info.setDocCount(mergeState.mergedDocCount);\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b3c0b74d0a1220dbfbdb366a60df468dbb2c285f","date":1337803847,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // nocommit why on earth do we suddenly set success back to false here!?\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.name;\n\n    int mergedDocCount = 0;\n\n    List<SegmentInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,\n                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments) + \" mergeVectors=\" + merge.info.getFieldInfos().hasVectors());\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.docCount: \"delCount=\" + delCount + \" info.docCount=\" + info.docCount + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.docCount) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;\n\n      // Record which codec was used to write the segment\n      merge.info.setCodec(codec);\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + mergedDocCount);\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n      \n      if (useCompoundFile) {\n        success = false;\n        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n\n        try {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"create compound file \" + compoundFileName);\n          }\n          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(compoundFileName);\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merge.info.files());\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(compoundFileName);\n            return 0;\n          }\n        }\n\n        merge.info.setUseCompoundFile(true);\n      }\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return mergedDocCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e25729298aefe258b77e1b2676ae1088c1a2c49d","date":1338320376,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":["c95a819869502635864dac0a788f874787e3395b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19b128c23e9f1b66a9f8518e95ec99fd965d0bb7","date":1338503231,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + info + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + info + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2edef7afebca00bf81a8bef95d44ea971ba309fa","date":1339101284,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfosWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":["9ee159418514037b0fa456cf8b5d6c91e2bf5557"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":["b1405362241b561f5590ff4a87d5d6e173bcd9cf","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c95a819869502635864dac0a788f874787e3395b","date":1341394787,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":["9ce667c6d3400b22523701c549c0d35e26da8b46","e25729298aefe258b77e1b2676ae1088c1a2c49d","8a16d06e7522604de20b2d758d9b9464bb30fe02","0061262413ecc163d6eebba1b5c43ab91a0c2dc5"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b4c18e3a5a8908e0fa2ea7c1a3507a214b70153b","date":1341673943,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2acf500f78aa12b92e371fd89c719291986b6b90","date":1341846236,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46d8ada1fff8d18cb197c38c7983225162599948","date":1341853497,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge)\n    throws CorruptIndexException, IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n    merge.readerLiveDocs = new ArrayList<Bits>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        final SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n        merge.readerLiveDocs.add(liveDocs);\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader, liveDocs, delCount);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(\"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc124b3b129ef11a255212f3af482b771c5b3a6c","date":1344947616,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             payloadProcessorProvider, globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f24f21e70a092329fc6f920115592dc9529d379","date":1349391034,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState = merger.merge();\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":["0859dec0aa7a485aa0081147f533c5987b4b47ac"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e80fef3b60b4c0a460f7de813603daf3d48b569","date":1350401924,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n\n      if (poolReaders && mergedSegmentWarmer != null) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b47dabfbaff6449eedcd4321017ab2f73dfa06ab","date":1360797548,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b41f996b22bd5518650f897d050088ff808ec03","date":1360969107,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad252c98ff183bc59bd0617be14fa46f9696d6fc","date":1363962178,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(),\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    SegmentMerger merger = new SegmentMerger(merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(), checkAbort,\n                                             globalFieldNumberMap, context);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        if (delCount < info.info.getDocCount()) {\n          merger.add(reader);\n        }\n        segUpto++;\n      }\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"66b61ab77ab36893d701d693f1b6df2a383bb7b5","date":1364405461,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(),\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(),\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(),\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getMergeReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper, config.getTermIndexInterval(),\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0859dec0aa7a485aa0081147f533c5987b4b47ac","date":1376498602,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":["203d7d3cb7712e10ef33009a63247ae40c302d7a","5f24f21e70a092329fc6f920115592dc9529d379"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        mergeState = merger.merge();\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(true, context);\n        assert reader != null;\n\n        // Notify that we are merging, so that we can later copy the updates\n        // that were received while merging to the merged segment.\n        rld.setMerging(true);\n        \n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(true, IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader.core, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":["e7b7defbb9b6dd128f30374dce48d25526e60f83"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"75e4e08ceec867127dcd9913a5ebbc46cf85a28d","date":1379651991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReaderForMerge(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(true, IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReader(true, context);\n        assert reader != null;\n\n        // Notify that we are merging, so that we can later copy the updates\n        // that were received while merging to the merged segment.\n        rld.setMerging(true);\n        \n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(true, IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe","date":1381909398,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n        SegmentReader reader = rld.getReaderForMerge(context);\n        assert reader != null;\n\n        // Carefully pull the most recent live docs:\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized(this) {\n          // Must sync to ensure BufferedDeletesStream\n          // cannot change liveDocs/pendingDeleteCount while\n          // we pull a copy:\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(true, IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentInfoPerCommit info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndLiveDocs rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a5eff83eba6305c34151d77c8a71495fb0b7808","date":1391866853,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<SegmentReader>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<String>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, \n          context, config.getCheckIntegrityAtMerge());\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, \n          context, config.getCheckIntegrityAtMerge());\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, context);\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"027bee21e09164c9ee230395405076d1e0034b30","date":1401521821,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, \n          context, config.getCheckIntegrityAtMerge());\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info, this);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, \n          context, config.getCheckIntegrityAtMerge());\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ee59f646cf24586a449cad77391a60a3ac8d8959","date":1408015131,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge,MergePolicy).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#mergeMiddle(MergePolicy.OneMerge).mjava","sourceNew":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge, MergePolicy mergePolicy) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, \n          context, config.getCheckIntegrityAtMerge());\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info, this);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","sourceOld":"  /** Does the actual (time-consuming) work of the merge,\n   *  but without holding synchronized lock on IndexWriter\n   *  instance */\n  private int mergeMiddle(MergePolicy.OneMerge merge) throws IOException {\n\n    merge.checkAborted(directory);\n\n    final String mergedName = merge.info.info.name;\n\n    List<SegmentCommitInfo> sourceSegments = merge.segments;\n    \n    IOContext context = new IOContext(merge.getMergeInfo());\n\n    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);\n    final TrackingDirectoryWrapper dirWrapper = new TrackingDirectoryWrapper(directory);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merging \" + segString(merge.segments));\n    }\n\n    merge.readers = new ArrayList<>();\n\n    // This is try/finally to make sure merger's readers are\n    // closed:\n    boolean success = false;\n    try {\n      int segUpto = 0;\n      while(segUpto < sourceSegments.size()) {\n\n        final SegmentCommitInfo info = sourceSegments.get(segUpto);\n\n        // Hold onto the \"live\" reader; we will use this to\n        // commit merged deletes\n        final ReadersAndUpdates rld = readerPool.get(info, true);\n\n        // Carefully pull the most recent live docs and reader\n        SegmentReader reader;\n        final Bits liveDocs;\n        final int delCount;\n\n        synchronized (this) {\n          // Must sync to ensure BufferedDeletesStream cannot change liveDocs,\n          // pendingDeleteCount and field updates while we pull a copy:\n          reader = rld.getReaderForMerge(context);\n          liveDocs = rld.getReadOnlyLiveDocs();\n          delCount = rld.getPendingDeleteCount() + info.getDelCount();\n\n          assert reader != null;\n          assert rld.verifyDocCounts();\n\n          if (infoStream.isEnabled(\"IW\")) {\n            if (rld.getPendingDeleteCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount() + \" pendingDelCount=\" + rld.getPendingDeleteCount());\n            } else if (info.getDelCount() != 0) {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" delCount=\" + info.getDelCount());\n            } else {\n              infoStream.message(\"IW\", \"seg=\" + segString(info) + \" no deletes\");\n            }\n          }\n        }\n\n        // Deletes might have happened after we pulled the merge reader and\n        // before we got a read-only copy of the segment's actual live docs\n        // (taking pending deletes into account). In that case we need to\n        // make a new reader with updated live docs and del count.\n        if (reader.numDeletedDocs() != delCount) {\n          // fix the reader's live docs and del count\n          assert delCount > reader.numDeletedDocs(); // beware of zombies\n\n          SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.getDocCount() - delCount);\n          boolean released = false;\n          try {\n            rld.release(reader);\n            released = true;\n          } finally {\n            if (!released) {\n              newReader.decRef();\n            }\n          }\n\n          reader = newReader;\n        }\n\n        merge.readers.add(reader);\n        assert delCount <= info.info.getDocCount(): \"delCount=\" + delCount + \" info.docCount=\" + info.info.getDocCount() + \" rld.pendingDeleteCount=\" + rld.getPendingDeleteCount() + \" info.getDelCount()=\" + info.getDelCount();\n        segUpto++;\n      }\n\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.mergeMiddle: merging \" + merge.getMergeReaders());\n      \n      // we pass merge.getMergeReaders() instead of merge.readers to allow the\n      // OneMerge to return a view over the actual segments to merge\n      final SegmentMerger merger = new SegmentMerger(merge.getMergeReaders(),\n          merge.info.info, infoStream, dirWrapper,\n          checkAbort, globalFieldNumberMap, \n          context, config.getCheckIntegrityAtMerge());\n\n      merge.checkAborted(directory);\n\n      // This is where all the work happens:\n      MergeState mergeState;\n      boolean success3 = false;\n      try {\n        if (!merger.shouldMerge()) {\n          // would result in a 0 document segment: nothing to merge!\n          mergeState = new MergeState(new ArrayList<AtomicReader>(), merge.info.info, infoStream, checkAbort);\n        } else {\n          mergeState = merger.merge();\n        }\n        success3 = true;\n      } finally {\n        if (!success3) {\n          synchronized(this) {  \n            deleter.refresh(merge.info.info.name);\n          }\n        }\n      }\n      assert mergeState.segmentInfo == merge.info.info;\n      merge.info.info.setFiles(new HashSet<>(dirWrapper.getCreatedFiles()));\n\n      // Record which codec was used to write the segment\n\n      if (infoStream.isEnabled(\"IW\")) {\n        if (merge.info.info.getDocCount() == 0) {\n          infoStream.message(\"IW\", \"merge away fully deleted segments\");\n        } else {\n          infoStream.message(\"IW\", \"merge codec=\" + codec + \" docCount=\" + merge.info.info.getDocCount() + \"; merged segment has \" +\n                           (mergeState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (mergeState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (mergeState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (mergeState.fieldInfos.hasProx() ? \"freqs\" : \"no freqs\"));\n        }\n      }\n\n      // Very important to do this before opening the reader\n      // because codec must know if prox was written for\n      // this segment:\n      //System.out.println(\"merger set hasProx=\" + merger.hasProx() + \" seg=\" + merge.info.name);\n      boolean useCompoundFile;\n      synchronized (this) { // Guard segmentInfos\n        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info, this);\n      }\n\n      if (useCompoundFile) {\n        success = false;\n\n        Collection<String> filesToRemove = merge.info.files();\n\n        try {\n          filesToRemove = createCompoundFile(infoStream, directory, checkAbort, merge.info.info, context);\n          success = true;\n        } catch (IOException ioe) {\n          synchronized(this) {\n            if (merge.isAborted()) {\n              // This can happen if rollback or close(false)\n              // is called -- fall through to logic below to\n              // remove the partially created CFS:\n            } else {\n              handleMergeException(ioe, merge);\n            }\n          }\n        } catch (Throwable t) {\n          handleMergeException(t, merge);\n        } finally {\n          if (!success) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"hit exception creating compound file during merge\");\n            }\n\n            synchronized(this) {\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n              deleter.deleteNewFiles(merge.info.files());\n            }\n          }\n        }\n\n        // So that, if we hit exc in deleteNewFiles (next)\n        // or in commitMerge (later), we close the\n        // per-segment readers in the finally clause below:\n        success = false;\n\n        synchronized(this) {\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(filesToRemove);\n\n          if (merge.isAborted()) {\n            if (infoStream.isEnabled(\"IW\")) {\n              infoStream.message(\"IW\", \"abort merge after building CFS\");\n            }\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n            deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n            return 0;\n          }\n        }\n\n        merge.info.info.setUseCompoundFile(true);\n      } else {\n        // So that, if we hit exc in commitMerge (later),\n        // we close the per-segment readers in the finally\n        // clause below:\n        success = false;\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      boolean success2 = false;\n      try {\n        codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, merge.info.info, mergeState.fieldInfos, context);\n        success2 = true;\n      } finally {\n        if (!success2) {\n          synchronized(this) {\n            deleter.deleteNewFiles(merge.info.files());\n          }\n        }\n      }\n\n      // TODO: ideally we would freeze merge.info here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", String.format(Locale.ROOT, \"merged segment size=%.3f MB vs estimate=%.3f MB\", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));\n      }\n\n      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();\n      if (poolReaders && mergedSegmentWarmer != null && merge.info.info.getDocCount() != 0) {\n        final ReadersAndUpdates rld = readerPool.get(merge.info, true);\n        final SegmentReader sr = rld.getReader(IOContext.READ);\n        try {\n          mergedSegmentWarmer.warm(sr);\n        } finally {\n          synchronized(this) {\n            rld.release(sr);\n            readerPool.release(rld);\n          }\n        }\n      }\n\n      // Force READ context because we merge deletes onto\n      // this reader:\n      if (!commitMerge(merge, mergeState)) {\n        // commitMerge will return false if this merge was\n        // aborted\n        return 0;\n      }\n\n      success = true;\n\n    } finally {\n      // Readers are already closed in commitMerge if we didn't hit\n      // an exc:\n      if (!success) {\n        closeMergeReaders(merge, true);\n      }\n    }\n\n    return merge.info.info.getDocCount();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["fc834f3412d287003cc04691da380b69ab983239"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"00f06a4178989089b29a77d6dce7c86dfb8b6931":["129c6e8ac0c0d9a110ba29e4b5f1889374f30076"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"16cbef32b882ec68df422af3f08845ec82620335":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"2acf500f78aa12b92e371fd89c719291986b6b90":["c95a819869502635864dac0a788f874787e3395b","b4c18e3a5a8908e0fa2ea7c1a3507a214b70153b"],"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b":["ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["ad252c98ff183bc59bd0617be14fa46f9696d6fc"],"ad252c98ff183bc59bd0617be14fa46f9696d6fc":["b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"129c6e8ac0c0d9a110ba29e4b5f1889374f30076":["9ee159418514037b0fa456cf8b5d6c91e2bf5557"],"b4c18e3a5a8908e0fa2ea7c1a3507a214b70153b":["c95a819869502635864dac0a788f874787e3395b"],"3b41f996b22bd5518650f897d050088ff808ec03":["7e80fef3b60b4c0a460f7de813603daf3d48b569","b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["2acf500f78aa12b92e371fd89c719291986b6b90"],"5f24f21e70a092329fc6f920115592dc9529d379":["bc124b3b129ef11a255212f3af482b771c5b3a6c"],"027bee21e09164c9ee230395405076d1e0034b30":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["fb5728b83dbb3e002cdd22adfe6caf103a96ef15"],"38e3b736c7ca086d61b7dbb841c905ee115490da":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"fb5728b83dbb3e002cdd22adfe6caf103a96ef15":["662f233ff219b7c334eb6c65cd68cc71b27a4ffe"],"a45bec74b98f6fc05f52770cfb425739e6563960":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"2edef7afebca00bf81a8bef95d44ea971ba309fa":["19b128c23e9f1b66a9f8518e95ec99fd965d0bb7"],"9b2af6b2c05418fb9df466c739ed5b3a153eadde":["352763be0465236f8e2ac188aa1b761cb3e1c9ee"],"7e80fef3b60b4c0a460f7de813603daf3d48b569":["5f24f21e70a092329fc6f920115592dc9529d379"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["2edef7afebca00bf81a8bef95d44ea971ba309fa","2acf500f78aa12b92e371fd89c719291986b6b90"],"9ee159418514037b0fa456cf8b5d6c91e2bf5557":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"c95a819869502635864dac0a788f874787e3395b":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"9a46feaa8775cb79964b568371b8eedaef5f576b":["b6dce319de558e8b80705326dd04d578f74767d9"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["fe33227f6805edab2036cbb80645cc4e2d1fa424"],"ee59f646cf24586a449cad77391a60a3ac8d8959":["027bee21e09164c9ee230395405076d1e0034b30"],"ae695f21c50b03702b5d0fa2543d5af844bb7cd3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a851824c09818632c94eba41e60ef5e72e323c8e":["dc97c61094c5498702b29cc2e8309beac50c23dc"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["46d8ada1fff8d18cb197c38c7983225162599948","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"1494abe5dc85557ec2e2772f87660d48f831c3a5":["4b512a6470fbb93c320e0cc8519ec0fe94efa13e"],"4356000e349e38c9fb48034695b7c309abd54557":["a851824c09818632c94eba41e60ef5e72e323c8e"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"19b128c23e9f1b66a9f8518e95ec99fd965d0bb7":["e25729298aefe258b77e1b2676ae1088c1a2c49d"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["2edef7afebca00bf81a8bef95d44ea971ba309fa"],"4e84d639980c2b2eb5d41330d5ff68d143239495":["00f06a4178989089b29a77d6dce7c86dfb8b6931"],"b47dabfbaff6449eedcd4321017ab2f73dfa06ab":["7e80fef3b60b4c0a460f7de813603daf3d48b569"],"e072d0b1fc19e0533d8ce432eed245196bca6fde":["0859dec0aa7a485aa0081147f533c5987b4b47ac"],"5eb2511ababf862ea11e10761c70ee560cd84510":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["2a5eff83eba6305c34151d77c8a71495fb0b7808"],"b3c0b74d0a1220dbfbdb366a60df468dbb2c285f":["16cbef32b882ec68df422af3f08845ec82620335"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"e25729298aefe258b77e1b2676ae1088c1a2c49d":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"0f6a6419266ce0a74e9f1501938a86a4c94d5af7":["4e84d639980c2b2eb5d41330d5ff68d143239495"],"0859dec0aa7a485aa0081147f533c5987b4b47ac":["a45bec74b98f6fc05f52770cfb425739e6563960"],"352763be0465236f8e2ac188aa1b761cb3e1c9ee":["4356000e349e38c9fb48034695b7c309abd54557"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","0859dec0aa7a485aa0081147f533c5987b4b47ac"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["9a46feaa8775cb79964b568371b8eedaef5f576b"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["5f24f21e70a092329fc6f920115592dc9529d379","7e80fef3b60b4c0a460f7de813603daf3d48b569"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"dc97c61094c5498702b29cc2e8309beac50c23dc":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"fc834f3412d287003cc04691da380b69ab983239":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"46d8ada1fff8d18cb197c38c7983225162599948":["c95a819869502635864dac0a788f874787e3395b","2acf500f78aa12b92e371fd89c719291986b6b90"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["ae695f21c50b03702b5d0fa2543d5af844bb7cd3","b3c0b74d0a1220dbfbdb366a60df468dbb2c285f"],"2a5eff83eba6305c34151d77c8a71495fb0b7808":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"b6dce319de558e8b80705326dd04d578f74767d9":["1494abe5dc85557ec2e2772f87660d48f831c3a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ee59f646cf24586a449cad77391a60a3ac8d8959"],"662f233ff219b7c334eb6c65cd68cc71b27a4ffe":["0f6a6419266ce0a74e9f1501938a86a4c94d5af7"],"4b512a6470fbb93c320e0cc8519ec0fe94efa13e":["9b2af6b2c05418fb9df466c739ed5b3a153eadde"]},"commit2Childs":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["dc97c61094c5498702b29cc2e8309beac50c23dc"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["027bee21e09164c9ee230395405076d1e0034b30","5eb2511ababf862ea11e10761c70ee560cd84510"],"00f06a4178989089b29a77d6dce7c86dfb8b6931":["4e84d639980c2b2eb5d41330d5ff68d143239495"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["38e3b736c7ca086d61b7dbb841c905ee115490da","ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"16cbef32b882ec68df422af3f08845ec82620335":["b3c0b74d0a1220dbfbdb366a60df468dbb2c285f"],"2acf500f78aa12b92e371fd89c719291986b6b90":["bc124b3b129ef11a255212f3af482b771c5b3a6c","fe33227f6805edab2036cbb80645cc4e2d1fa424","46d8ada1fff8d18cb197c38c7983225162599948"],"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["a45bec74b98f6fc05f52770cfb425739e6563960","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"ad252c98ff183bc59bd0617be14fa46f9696d6fc":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"129c6e8ac0c0d9a110ba29e4b5f1889374f30076":["00f06a4178989089b29a77d6dce7c86dfb8b6931"],"b4c18e3a5a8908e0fa2ea7c1a3507a214b70153b":["2acf500f78aa12b92e371fd89c719291986b6b90"],"3b41f996b22bd5518650f897d050088ff808ec03":[],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","5f24f21e70a092329fc6f920115592dc9529d379","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"5f24f21e70a092329fc6f920115592dc9529d379":["7e80fef3b60b4c0a460f7de813603daf3d48b569","db4fdbf3d262768eabc027cd8321edca0cd11fa8"],"027bee21e09164c9ee230395405076d1e0034b30":["ee59f646cf24586a449cad77391a60a3ac8d8959"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["16cbef32b882ec68df422af3f08845ec82620335"],"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"fb5728b83dbb3e002cdd22adfe6caf103a96ef15":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"a45bec74b98f6fc05f52770cfb425739e6563960":["0859dec0aa7a485aa0081147f533c5987b4b47ac"],"2edef7afebca00bf81a8bef95d44ea971ba309fa":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"9b2af6b2c05418fb9df466c739ed5b3a153eadde":["4b512a6470fbb93c320e0cc8519ec0fe94efa13e"],"7e80fef3b60b4c0a460f7de813603daf3d48b569":["3b41f996b22bd5518650f897d050088ff808ec03","b47dabfbaff6449eedcd4321017ab2f73dfa06ab","db4fdbf3d262768eabc027cd8321edca0cd11fa8"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["fc834f3412d287003cc04691da380b69ab983239"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"9ee159418514037b0fa456cf8b5d6c91e2bf5557":["129c6e8ac0c0d9a110ba29e4b5f1889374f30076"],"c95a819869502635864dac0a788f874787e3395b":["2acf500f78aa12b92e371fd89c719291986b6b90","b4c18e3a5a8908e0fa2ea7c1a3507a214b70153b","46d8ada1fff8d18cb197c38c7983225162599948"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["2a5eff83eba6305c34151d77c8a71495fb0b7808"],"9a46feaa8775cb79964b568371b8eedaef5f576b":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"ee59f646cf24586a449cad77391a60a3ac8d8959":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ae695f21c50b03702b5d0fa2543d5af844bb7cd3":["f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b","38e3b736c7ca086d61b7dbb841c905ee115490da","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a851824c09818632c94eba41e60ef5e72e323c8e":["4356000e349e38c9fb48034695b7c309abd54557"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"1494abe5dc85557ec2e2772f87660d48f831c3a5":["b6dce319de558e8b80705326dd04d578f74767d9"],"4356000e349e38c9fb48034695b7c309abd54557":["352763be0465236f8e2ac188aa1b761cb3e1c9ee"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"19b128c23e9f1b66a9f8518e95ec99fd965d0bb7":["2edef7afebca00bf81a8bef95d44ea971ba309fa"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["c95a819869502635864dac0a788f874787e3395b"],"4e84d639980c2b2eb5d41330d5ff68d143239495":["0f6a6419266ce0a74e9f1501938a86a4c94d5af7"],"b47dabfbaff6449eedcd4321017ab2f73dfa06ab":["ad252c98ff183bc59bd0617be14fa46f9696d6fc","3b41f996b22bd5518650f897d050088ff808ec03"],"e072d0b1fc19e0533d8ce432eed245196bca6fde":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"5eb2511ababf862ea11e10761c70ee560cd84510":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["1f3b037cd083286b2af89f96e768f85dcd8072d6","5eb2511ababf862ea11e10761c70ee560cd84510"],"b3c0b74d0a1220dbfbdb366a60df468dbb2c285f":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"e25729298aefe258b77e1b2676ae1088c1a2c49d":["19b128c23e9f1b66a9f8518e95ec99fd965d0bb7"],"0f6a6419266ce0a74e9f1501938a86a4c94d5af7":["662f233ff219b7c334eb6c65cd68cc71b27a4ffe"],"352763be0465236f8e2ac188aa1b761cb3e1c9ee":["9b2af6b2c05418fb9df466c739ed5b3a153eadde"],"0859dec0aa7a485aa0081147f533c5987b4b47ac":["e072d0b1fc19e0533d8ce432eed245196bca6fde","3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"9d153abcf92dc5329d98571a8c3035df9bd80648":["9ee159418514037b0fa456cf8b5d6c91e2bf5557"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"dc97c61094c5498702b29cc2e8309beac50c23dc":["a851824c09818632c94eba41e60ef5e72e323c8e"],"fc834f3412d287003cc04691da380b69ab983239":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"46d8ada1fff8d18cb197c38c7983225162599948":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["e25729298aefe258b77e1b2676ae1088c1a2c49d"],"2a5eff83eba6305c34151d77c8a71495fb0b7808":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"b6dce319de558e8b80705326dd04d578f74767d9":["9a46feaa8775cb79964b568371b8eedaef5f576b"],"662f233ff219b7c334eb6c65cd68cc71b27a4ffe":["fb5728b83dbb3e002cdd22adfe6caf103a96ef15"],"4b512a6470fbb93c320e0cc8519ec0fe94efa13e":["1494abe5dc85557ec2e2772f87660d48f831c3a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","3b41f996b22bd5518650f897d050088ff808ec03","38e3b736c7ca086d61b7dbb841c905ee115490da","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","5eb2511ababf862ea11e10761c70ee560cd84510","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","db4fdbf3d262768eabc027cd8321edca0cd11fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}