{"path":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer#setUp().mjava","commits":[{"id":"8493925b2e70246f0961df584c01a8c2e61ee52f","date":1523611602,"type":0,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer#setUp().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    UserDictionary userDictionary = readDict();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerUnigram = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, true);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerDecompound = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.DISCARD, false);\n        return new TokenStreamComponents(tokenizer);\n      }\n    };\n    analyzerDecompoundKeep = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.MIXED, false);\n        return new TokenStreamComponents(tokenizer);\n      }\n    };\n    analyzerReading = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false);\n        KoreanReadingFormFilter filter = new KoreanReadingFormFilter(tokenizer);\n        return new TokenStreamComponents(tokenizer, filter);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c6453827f947004a68ad9db7418781e9df2f660","date":1523626811,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer#setUp().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    UserDictionary userDictionary = readDict();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerUnigram = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, true);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerDecompound = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.DISCARD, false);\n        return new TokenStreamComponents(tokenizer);\n      }\n    };\n    analyzerDecompoundKeep = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.MIXED, false);\n        return new TokenStreamComponents(tokenizer);\n      }\n    };\n    analyzerReading = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false);\n        KoreanReadingFormFilter filter = new KoreanReadingFormFilter(tokenizer);\n        return new TokenStreamComponents(tokenizer, filter);\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9a6a8e09e9e2d9479c718093a32f3a8c19455af","date":1558962924,"type":3,"author":"Namgyu Kim","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer#setUp().mjava","pathOld":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/TestKoreanTokenizer#setUp().mjava","sourceNew":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    UserDictionary userDictionary = readDict();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerWithPunctuation = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false, false);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerUnigram = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, true);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerDecompound = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.DISCARD, false);\n        return new TokenStreamComponents(tokenizer);\n      }\n    };\n    analyzerDecompoundKeep = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.MIXED, false);\n        return new TokenStreamComponents(tokenizer);\n      }\n    };\n    analyzerReading = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false);\n        KoreanReadingFormFilter filter = new KoreanReadingFormFilter(tokenizer);\n        return new TokenStreamComponents(tokenizer, filter);\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    UserDictionary userDictionary = readDict();\n    analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerUnigram = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, true);\n        return new TokenStreamComponents(tokenizer, tokenizer);\n      }\n    };\n    analyzerDecompound = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.DISCARD, false);\n        return new TokenStreamComponents(tokenizer);\n      }\n    };\n    analyzerDecompoundKeep = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.MIXED, false);\n        return new TokenStreamComponents(tokenizer);\n      }\n    };\n    analyzerReading = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new KoreanTokenizer(newAttributeFactory(), userDictionary,\n            DecompoundMode.NONE, false);\n        KoreanReadingFormFilter filter = new KoreanReadingFormFilter(tokenizer);\n        return new TokenStreamComponents(tokenizer, filter);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c9a6a8e09e9e2d9479c718093a32f3a8c19455af":["5c6453827f947004a68ad9db7418781e9df2f660"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8493925b2e70246f0961df584c01a8c2e61ee52f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c9a6a8e09e9e2d9479c718093a32f3a8c19455af"],"5c6453827f947004a68ad9db7418781e9df2f660":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8493925b2e70246f0961df584c01a8c2e61ee52f"]},"commit2Childs":{"c9a6a8e09e9e2d9479c718093a32f3a8c19455af":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8493925b2e70246f0961df584c01a8c2e61ee52f","5c6453827f947004a68ad9db7418781e9df2f660"],"8493925b2e70246f0961df584c01a8c2e61ee52f":["5c6453827f947004a68ad9db7418781e9df2f660"],"5c6453827f947004a68ad9db7418781e9df2f660":["c9a6a8e09e9e2d9479c718093a32f3a8c19455af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}