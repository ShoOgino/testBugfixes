{"path":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","commits":[{"id":"42a18cb0bca2c4ac9747f31c7a74fac90c661f39","date":1171363388,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestNewIndexModifierDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    RAMDirectory startDir = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new WhitespaceAnalyzer(),\n        true);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n          Field.Index.UN_TOKENIZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n          Field.Index.TOKENIZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      IndexWriter modifier = new IndexWriter(dir,\n          new WhitespaceAnalyzer(), false);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                    Field.Index.UN_TOKENIZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                    Field.Index.TOKENIZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Whether we succeeded or failed, check that all\n        // un-referenced files were in fact deleted (ie,\n        // we did not create garbage). Just create a\n        // new IndexFileDeleter, have it delete\n        // unreferenced files, then verify that in fact\n        // no files were deleted:\n        String[] startFiles = dir.list();\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        IndexFileDeleter d = new IndexFileDeleter(infos, dir);\n        d.findDeletableFiles();\n        d.deleteFiles();\n        String[] endFiles = dir.list();\n\n        Arrays.sort(startFiles);\n        Arrays.sort(endFiles);\n\n        // for(int i=0;i<startFiles.length;i++) {\n        // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n        // }\n\n        if (!Arrays.equals(startFiles, endFiles)) {\n          String successStr;\n          if (success) {\n            successStr = \"success\";\n          } else {\n            successStr = \"IOException\";\n            err.printStackTrace();\n          }\n          fail(\"reader.close() failed to delete unreferenced files after \"\n              + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n              + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n              + arrayToString(endFiles));\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n              + \":exception when creating IndexReader after disk full during close: \"\n              + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        Hits hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm));\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length();\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName\n                + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    RAMDirectory startDir = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new WhitespaceAnalyzer(),\n        true);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n          Field.Index.UN_TOKENIZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n          Field.Index.TOKENIZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      NewIndexModifier modifier = new NewIndexModifier(dir,\n          new WhitespaceAnalyzer(), false);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                    Field.Index.UN_TOKENIZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                    Field.Index.TOKENIZED));\n                modifier.updateDocument(\n                    new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier\n                    .deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Whether we succeeded or failed, check that all\n        // un-referenced files were in fact deleted (ie,\n        // we did not create garbage). Just create a\n        // new IndexFileDeleter, have it delete\n        // unreferenced files, then verify that in fact\n        // no files were deleted:\n        String[] startFiles = dir.list();\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        IndexFileDeleter d = new IndexFileDeleter(infos, dir);\n        d.findDeletableFiles();\n        d.deleteFiles();\n        String[] endFiles = dir.list();\n\n        Arrays.sort(startFiles);\n        Arrays.sort(endFiles);\n\n        // for(int i=0;i<startFiles.length;i++) {\n        // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n        // }\n\n        if (!Arrays.equals(startFiles, endFiles)) {\n          String successStr;\n          if (success) {\n            successStr = \"success\";\n          } else {\n            successStr = \"IOException\";\n            err.printStackTrace();\n          }\n          fail(\"reader.close() failed to delete unreferenced files after \"\n              + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n              + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n              + arrayToString(endFiles));\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n              + \":exception when creating IndexReader after disk full during close: \"\n              + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        Hits hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm));\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length();\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName\n                + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b6187898fc4413ccd18229711786550a280383c","date":1173776782,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          IndexFileDeleter d = new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    RAMDirectory startDir = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new WhitespaceAnalyzer(),\n        true);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n          Field.Index.UN_TOKENIZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n          Field.Index.TOKENIZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      IndexWriter modifier = new IndexWriter(dir,\n          new WhitespaceAnalyzer(), false);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                    Field.Index.UN_TOKENIZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                    Field.Index.TOKENIZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Whether we succeeded or failed, check that all\n        // un-referenced files were in fact deleted (ie,\n        // we did not create garbage). Just create a\n        // new IndexFileDeleter, have it delete\n        // unreferenced files, then verify that in fact\n        // no files were deleted:\n        String[] startFiles = dir.list();\n        SegmentInfos infos = new SegmentInfos();\n        infos.read(dir);\n        IndexFileDeleter d = new IndexFileDeleter(infos, dir);\n        d.findDeletableFiles();\n        d.deleteFiles();\n        String[] endFiles = dir.list();\n\n        Arrays.sort(startFiles);\n        Arrays.sort(endFiles);\n\n        // for(int i=0;i<startFiles.length;i++) {\n        // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n        // }\n\n        if (!Arrays.equals(startFiles, endFiles)) {\n          String successStr;\n          if (success) {\n            successStr = \"success\";\n          } else {\n            successStr = \"IOException\";\n            err.printStackTrace();\n          }\n          fail(\"reader.close() failed to delete unreferenced files after \"\n              + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n              + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n              + arrayToString(endFiles));\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n              + \":exception when creating IndexReader after disk full during close: \"\n              + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        Hits hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm));\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length();\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName\n                + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":["fde68de507dbf344495d7b5e8052866fe5f254ab"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          IndexFileDeleter d = new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          IndexFileDeleter d = new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["83bbb041887bbef07b8a98d08a0e1713ce137039"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fde68de507dbf344495d7b5e8052866fe5f254ab","date":1189434831,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          IndexFileDeleter d = new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          IndexFileDeleter d = new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":["8b6187898fc4413ccd18229711786550a280383c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"83bbb041887bbef07b8a98d08a0e1713ce137039","date":1200330381,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          IndexFileDeleter d = new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0018e7a0579df5d3de71d0bd878322a7abef04d9","date":1202242049,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e82780afe6097066eb5befb86e9432f077667e3d","date":1202756169,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      RAMDirectory startDir = new RAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // Whether we succeeded or failed, check that all\n          // un-referenced files were in fact deleted (ie,\n          // we did not create garbage). Just create a\n          // new IndexFileDeleter, have it delete\n          // unreferenced files, then verify that in fact\n          // no files were deleted:\n          String[] startFiles = dir.list();\n          SegmentInfos infos = new SegmentInfos();\n          infos.read(dir);\n          new IndexFileDeleter(dir, new KeepOnlyLastCommitDeletionPolicy(), infos, null, null);\n          String[] endFiles = dir.list();\n\n          Arrays.sort(startFiles);\n          Arrays.sort(endFiles);\n\n          // for(int i=0;i<startFiles.length;i++) {\n          // System.out.println(\" startFiles: \" + i + \": \" + startFiles[i]);\n          // }\n\n          if (!Arrays.equals(startFiles, endFiles)) {\n            String successStr;\n            if (success) {\n              successStr = \"success\";\n            } else {\n              successStr = \"IOException\";\n              err.printStackTrace();\n            }\n            fail(\"reader.close() failed to delete unreferenced files after \"\n                 + successStr + \" (\" + diskFree + \" bytes): before delete:\\n    \"\n                 + arrayToString(startFiles) + \"\\n  after delete:\\n    \"\n                 + arrayToString(endFiles));\n          }\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be","date":1204801324,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5af07783dbc171e26a694c4f7d735e30c2769faa","date":1211569075,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          Hits hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm));\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length();\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a","date":1221082732,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.NOT_ANALYZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.ANALYZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.UN_TOKENIZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.TOKENIZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.UN_TOKENIZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.TOKENIZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4ae99f08f69aa3acba7cd75134e8447eb747559","date":1222344278,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.NOT_ANALYZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.ANALYZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.NOT_ANALYZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.ANALYZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8d1458a2543cbd30cbfe7929be4dcb5c5251659","date":1254582241,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.NOT_ANALYZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.ANALYZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, true);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.NOT_ANALYZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.ANALYZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a046c0c310bc77931fc8441bd920053b607dd14","date":1254584734,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.NOT_ANALYZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.ANALYZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, true);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.NOT_ANALYZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.ANALYZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87c966e9308847938a7c905c2e46a56d8df788b8","date":1255035452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir,\n                                         new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    for(int pass=0;pass<2;pass++) {\n      boolean autoCommit = (0==pass);\n\n      // First build up a starting index:\n      MockRAMDirectory startDir = new MockRAMDirectory();\n      IndexWriter writer = new IndexWriter(startDir, autoCommit,\n                                           new WhitespaceAnalyzer(), true);\n      for (int i = 0; i < 157; i++) {\n        Document d = new Document();\n        d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                        Field.Index.NOT_ANALYZED));\n        d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                        Field.Index.ANALYZED));\n        writer.addDocument(d);\n      }\n      writer.close();\n\n      long diskUsage = startDir.sizeInBytes();\n      long diskFree = diskUsage + 10;\n\n      IOException err = null;\n\n      boolean done = false;\n\n      // Iterate w/ ever increasing free disk space:\n      while (!done) {\n        MockRAMDirectory dir = new MockRAMDirectory(startDir);\n        dir.setPreventDoubleWrite(false);\n        IndexWriter modifier = new IndexWriter(dir, autoCommit,\n                                               new WhitespaceAnalyzer());\n\n        modifier.setMaxBufferedDocs(1000); // use flush or close\n        modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n        // For each disk size, first try to commit against\n        // dir that will hit random IOExceptions & disk\n        // full; after, give it infinite disk space & turn\n        // off random IOExceptions & retry w/ same reader:\n        boolean success = false;\n\n        for (int x = 0; x < 2; x++) {\n\n          double rate = 0.1;\n          double diskRatio = ((double)diskFree) / diskUsage;\n          long thisDiskFree;\n          String testName;\n\n          if (0 == x) {\n            thisDiskFree = diskFree;\n            if (diskRatio >= 2.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 4.0) {\n              rate /= 2;\n            }\n            if (diskRatio >= 6.0) {\n              rate = 0.0;\n            }\n            if (debug) {\n              System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n            }\n            testName = \"disk full during reader.close() @ \" + thisDiskFree\n              + \" bytes\";\n          } else {\n            thisDiskFree = 0;\n            rate = 0.0;\n            if (debug) {\n              System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n            }\n            testName = \"reader re-use after disk full\";\n          }\n\n          dir.setMaxSizeInBytes(thisDiskFree);\n          dir.setRandomIOExceptionRate(rate, diskFree);\n\n          try {\n            if (0 == x) {\n              int docId = 12;\n              for (int i = 0; i < 13; i++) {\n                if (updates) {\n                  Document d = new Document();\n                  d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                  Field.Index.NOT_ANALYZED));\n                  d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                  Field.Index.ANALYZED));\n                  modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n                } else { // deletes\n                  modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                  // modifier.setNorm(docId, \"contents\", (float)2.0);\n                }\n                docId += 12;\n              }\n            }\n            modifier.close();\n            success = true;\n            if (0 == x) {\n              done = true;\n            }\n          }\n          catch (IOException e) {\n            if (debug) {\n              System.out.println(\"  hit IOException: \" + e);\n              e.printStackTrace(System.out);\n            }\n            err = e;\n            if (1 == x) {\n              e.printStackTrace();\n              fail(testName + \" hit IOException after disk space was freed up\");\n            }\n          }\n\n          // If the close() succeeded, make sure there are\n          // no unreferenced files.\n          if (success)\n            TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n          // Finally, verify index is not corrupt, and, if\n          // we succeeded, we see all docs changed, and if\n          // we failed, we see either all docs or no docs\n          // changed (transactional semantics):\n          IndexReader newReader = null;\n          try {\n            newReader = IndexReader.open(dir, true);\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName\n                 + \":exception when creating IndexReader after disk full during close: \"\n                 + e);\n          }\n\n          IndexSearcher searcher = new IndexSearcher(newReader);\n          ScoreDoc[] hits = null;\n          try {\n            hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n          }\n          catch (IOException e) {\n            e.printStackTrace();\n            fail(testName + \": exception when searching: \" + e);\n          }\n          int result2 = hits.length;\n          if (success) {\n            if (x == 0 && result2 != END_COUNT) {\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + END_COUNT);\n            } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n              // It's possible that the first exception was\n              // \"recoverable\" wrt pending deletes, in which\n              // case the pending deletes are retained and\n              // then re-flushing (with plenty of disk\n              // space) will succeed in flushing the\n              // deletes:\n              fail(testName\n                   + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          } else {\n            // On hitting exception we still may have added\n            // all docs:\n            if (result2 != START_COUNT && result2 != END_COUNT) {\n              err.printStackTrace();\n              fail(testName\n                   + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                   + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n            }\n          }\n\n          searcher.close();\n          newReader.close();\n\n          if (result2 == END_COUNT) {\n            break;\n          }\n        }\n\n        dir.close();\n\n        // Try again with 10 more bytes of free space:\n        diskFree += 10;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["1085ea837da8f1e96697e17cf73e1d08e7329261","1085ea837da8f1e96697e17cf73e1d08e7329261","1085ea837da8f1e96697e17cf73e1d08e7329261","11c6df42fb3eba174c3ca0d9a5194eaecd893b77","11c6df42fb3eba174c3ca0d9a5194eaecd893b77","11c6df42fb3eba174c3ca0d9a5194eaecd893b77"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir,\n                                         new WhitespaceAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             new WhitespaceAnalyzer(Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir,\n                                         new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir,\n                                         new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             new WhitespaceAnalyzer(TEST_VERSION_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir,\n                                         new WhitespaceAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             new WhitespaceAnalyzer(Version.LUCENE_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT).setMaxBufferedDocs(1000)\n          .setMaxBufferedDeleteTerms(1000));\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir,\n                                         new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             new WhitespaceAnalyzer(TEST_VERSION_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir,\n                                         new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             new WhitespaceAnalyzer(TEST_VERSION_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT).setMaxBufferedDocs(1000)\n          .setMaxBufferedDeleteTerms(1000));\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(1000)\n          .setMaxBufferedDeleteTerms(1000));\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir,\n                                         new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir,\n                                             new WhitespaceAnalyzer(TEST_VERSION_CURRENT), IndexWriter.MaxFieldLength.UNLIMITED);\n\n      modifier.setMaxBufferedDocs(1000); // use flush or close\n      modifier.setMaxBufferedDeleteTerms(1000); // use flush or close\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"42607aa380c892dc1ec0ab26e86a575c28e13618","date":1268641604,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(1000)\n          .setMaxBufferedDeleteTerms(1000));\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    boolean debug = false;\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(1000)\n          .setMaxBufferedDeleteTerms(1000));\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (debug) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (debug) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (debug) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriterDelete#testOperationsOnDiskFull(boolean).mjava","sourceNew":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(1000)\n          .setMaxBufferedDeleteTerms(1000));\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","sourceOld":"  /**\n   * Make sure if modifier tries to commit but hits disk full that modifier\n   * remains consistent and usable. Similar to TestIndexReader.testDiskFull().\n   */\n  private void testOperationsOnDiskFull(boolean updates) throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n\n    // First build up a starting index:\n    MockRAMDirectory startDir = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(startDir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    for (int i = 0; i < 157; i++) {\n      Document d = new Document();\n      d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                      Field.Index.NOT_ANALYZED));\n      d.add(new Field(\"content\", \"aaa \" + i, Field.Store.NO,\n                      Field.Index.ANALYZED));\n      writer.addDocument(d);\n    }\n    writer.close();\n\n    long diskUsage = startDir.sizeInBytes();\n    long diskFree = diskUsage + 10;\n\n    IOException err = null;\n\n    boolean done = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while (!done) {\n      MockRAMDirectory dir = new MockRAMDirectory(startDir);\n      dir.setPreventDoubleWrite(false);\n      IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(\n          TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setMaxBufferedDocs(1000)\n          .setMaxBufferedDeleteTerms(1000));\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for (int x = 0; x < 2; x++) {\n\n        double rate = 0.1;\n        double diskRatio = ((double)diskFree) / diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree\n            + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate, diskFree);\n\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for (int i = 0; i < 13; i++) {\n              if (updates) {\n                Document d = new Document();\n                d.add(new Field(\"id\", Integer.toString(i), Field.Store.YES,\n                                Field.Index.NOT_ANALYZED));\n                d.add(new Field(\"content\", \"bbb \" + i, Field.Store.NO,\n                                Field.Index.ANALYZED));\n                modifier.updateDocument(new Term(\"id\", Integer.toString(docId)), d);\n              } else { // deletes\n                modifier.deleteDocuments(new Term(\"id\", Integer.toString(docId)));\n                // modifier.setNorm(docId, \"contents\", (float)2.0);\n              }\n              docId += 12;\n            }\n          }\n          modifier.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        }\n        catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // If the close() succeeded, make sure there are\n        // no unreferenced files.\n        if (success)\n          TestIndexWriter.assertNoUnreferencedFiles(dir, \"after writer.close\");\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, true);\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName\n               + \":exception when creating IndexReader after disk full during close: \"\n               + e);\n        }\n\n        IndexSearcher searcher = new IndexSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        }\n        catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (x == 0 && result2 != END_COUNT) {\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + END_COUNT);\n          } else if (x == 1 && result2 != START_COUNT && result2 != END_COUNT) {\n            // It's possible that the first exception was\n            // \"recoverable\" wrt pending deletes, in which\n            // case the pending deletes are retained and\n            // then re-flushing (with plenty of disk\n            // space) will succeed in flushing the\n            // deletes:\n            fail(testName\n                 + \": method did not throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName\n                 + \": method did throw exception but hits.length for search on term 'aaa' is \"\n                 + result2 + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"83bbb041887bbef07b8a98d08a0e1713ce137039":["fde68de507dbf344495d7b5e8052866fe5f254ab"],"c4ae99f08f69aa3acba7cd75134e8447eb747559":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"fde68de507dbf344495d7b5e8052866fe5f254ab":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"0a046c0c310bc77931fc8441bd920053b607dd14":["c4ae99f08f69aa3acba7cd75134e8447eb747559","e8d1458a2543cbd30cbfe7929be4dcb5c5251659"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["5af07783dbc171e26a694c4f7d735e30c2769faa"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["e82780afe6097066eb5befb86e9432f077667e3d"],"0018e7a0579df5d3de71d0bd878322a7abef04d9":["83bbb041887bbef07b8a98d08a0e1713ce137039"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["8b6187898fc4413ccd18229711786550a280383c"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"42a18cb0bca2c4ac9747f31c7a74fac90c661f39":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["c4ae99f08f69aa3acba7cd75134e8447eb747559"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["87c966e9308847938a7c905c2e46a56d8df788b8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5af07783dbc171e26a694c4f7d735e30c2769faa":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"e82780afe6097066eb5befb86e9432f077667e3d":["0018e7a0579df5d3de71d0bd878322a7abef04d9"],"8b6187898fc4413ccd18229711786550a280383c":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"42607aa380c892dc1ec0ab26e86a575c28e13618":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"87c966e9308847938a7c905c2e46a56d8df788b8":["0a046c0c310bc77931fc8441bd920053b607dd14"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["42607aa380c892dc1ec0ab26e86a575c28e13618"]},"commit2Childs":{"83bbb041887bbef07b8a98d08a0e1713ce137039":["0018e7a0579df5d3de71d0bd878322a7abef04d9"],"c4ae99f08f69aa3acba7cd75134e8447eb747559":["0a046c0c310bc77931fc8441bd920053b607dd14","e8d1458a2543cbd30cbfe7929be4dcb5c5251659"],"fde68de507dbf344495d7b5e8052866fe5f254ab":["83bbb041887bbef07b8a98d08a0e1713ce137039"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"0a046c0c310bc77931fc8441bd920053b607dd14":["87c966e9308847938a7c905c2e46a56d8df788b8"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["c4ae99f08f69aa3acba7cd75134e8447eb747559"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["5af07783dbc171e26a694c4f7d735e30c2769faa"],"0018e7a0579df5d3de71d0bd878322a7abef04d9":["e82780afe6097066eb5befb86e9432f077667e3d"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["fde68de507dbf344495d7b5e8052866fe5f254ab"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["42607aa380c892dc1ec0ab26e86a575c28e13618"],"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["0a046c0c310bc77931fc8441bd920053b607dd14"],"42a18cb0bca2c4ac9747f31c7a74fac90c661f39":["8b6187898fc4413ccd18229711786550a280383c"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"5af07783dbc171e26a694c4f7d735e30c2769faa":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"e82780afe6097066eb5befb86e9432f077667e3d":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"8b6187898fc4413ccd18229711786550a280383c":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"87c966e9308847938a7c905c2e46a56d8df788b8":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"42607aa380c892dc1ec0ab26e86a575c28e13618":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}