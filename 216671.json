{"path":"src/test/org/apache/lucene/index/TestIndexWriter#xxxtestNegativePositions().mjava","commits":[{"id":"3215ae1377fc1ca1790921d75dd39cb764743b85","date":1237371771,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriter#xxxtestNegativePositions().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void xxxtestNegativePositions() throws Throwable {\n    SinkTokenizer tokens = new SinkTokenizer();\n    tokens.addAttribute(TermAttribute.class);\n    tokens.addAttribute(PositionIncrementAttribute.class);\n\n    AttributeSource state = new AttributeSource();\n    TermAttribute termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n    termAtt.setTermBuffer(\"a\");\n    posIncrAtt.setPositionIncrement(0);\n    tokens.add(state);\n\n    state = new AttributeSource();\n    termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n\n    termAtt.setTermBuffer(\"b\");\n    posIncrAtt.setPositionIncrement(1);\n    tokens.add(state);\n    \n    state = new AttributeSource();\n    termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n\n    termAtt.setTermBuffer(\"c\");\n    posIncrAtt.setPositionIncrement(1);\n    tokens.add(state);\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new MyAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(-1, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    SinkTokenizer tokens = new SinkTokenizer();\n    tokens.addAttribute(TermAttribute.class);\n    tokens.addAttribute(PositionIncrementAttribute.class);\n\n    AttributeSource state = new AttributeSource();\n    TermAttribute termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n    termAtt.setTermBuffer(\"a\");\n    posIncrAtt.setPositionIncrement(0);\n    tokens.add(state);\n\n    state = new AttributeSource();\n    termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n\n    termAtt.setTermBuffer(\"b\");\n    posIncrAtt.setPositionIncrement(1);\n    tokens.add(state);\n    \n    state = new AttributeSource();\n    termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n\n    termAtt.setTermBuffer(\"c\");\n    posIncrAtt.setPositionIncrement(1);\n    tokens.add(state);\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new MyAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(-1, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09c482d1e63332617181729a225b215c452d8a79","date":1237396006,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#xxxtestNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    SinkTokenizer tokens = new SinkTokenizer();\n    tokens.addAttribute(TermAttribute.class);\n    tokens.addAttribute(PositionIncrementAttribute.class);\n\n    AttributeSource state = new AttributeSource();\n    TermAttribute termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n    termAtt.setTermBuffer(\"a\");\n    posIncrAtt.setPositionIncrement(0);\n    tokens.add(state);\n\n    state = new AttributeSource();\n    termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n\n    termAtt.setTermBuffer(\"b\");\n    posIncrAtt.setPositionIncrement(1);\n    tokens.add(state);\n    \n    state = new AttributeSource();\n    termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n\n    termAtt.setTermBuffer(\"c\");\n    posIncrAtt.setPositionIncrement(1);\n    tokens.add(state);\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new MyAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(-1, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void xxxtestNegativePositions() throws Throwable {\n    SinkTokenizer tokens = new SinkTokenizer();\n    tokens.addAttribute(TermAttribute.class);\n    tokens.addAttribute(PositionIncrementAttribute.class);\n\n    AttributeSource state = new AttributeSource();\n    TermAttribute termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n    termAtt.setTermBuffer(\"a\");\n    posIncrAtt.setPositionIncrement(0);\n    tokens.add(state);\n\n    state = new AttributeSource();\n    termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n\n    termAtt.setTermBuffer(\"b\");\n    posIncrAtt.setPositionIncrement(1);\n    tokens.add(state);\n    \n    state = new AttributeSource();\n    termAtt = (TermAttribute) state.addAttribute(TermAttribute.class);\n    posIncrAtt = (PositionIncrementAttribute) state.addAttribute(PositionIncrementAttribute.class);\n\n    termAtt.setTermBuffer(\"c\");\n    posIncrAtt.setPositionIncrement(1);\n    tokens.add(state);\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new MyAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(-1, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3215ae1377fc1ca1790921d75dd39cb764743b85":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"09c482d1e63332617181729a225b215c452d8a79":["3215ae1377fc1ca1790921d75dd39cb764743b85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["09c482d1e63332617181729a225b215c452d8a79"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3215ae1377fc1ca1790921d75dd39cb764743b85"],"3215ae1377fc1ca1790921d75dd39cb764743b85":["09c482d1e63332617181729a225b215c452d8a79"],"09c482d1e63332617181729a225b215c452d8a79":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}