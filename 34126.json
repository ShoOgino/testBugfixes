{"path":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":null,"sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"623193e0f05f138bdb5a54e0d149ab4ce4bf51f5","date":1273502214,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase());\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":["868e0ed16bb29556f95c00e989da33ab5c9dfe56"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b375ac28473e1310fa9ea99d95e9c6001e3719d5","date":1274116690,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase());\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0633d6cdc3b9d1f2b0ef8e5ab78701d285db0303","date":1291156410,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01","date":1296400215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d345a86357a4042faeebfad2693a070019c95918","date":1305385272,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n        parser.parse(inputStream, parsingHandler, metadata, context);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (TikaException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/extraction/src/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"solr/contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  @Override\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      MediaType mt = MediaType.parse(streamType.trim().toLowerCase(Locale.ENGLISH));\n      parser = config.getParser(mt);\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        BaseMarkupSerializer serializer = null;\n        if (extractOnly == true) {\n          String extractFormat = params.get(ExtractingParams.EXTRACT_FORMAT, \"xml\");\n          writer = new StringWriter();\n          if (extractFormat.equals(TEXT_FORMAT)) {\n            serializer = new TextSerializer();\n            serializer.setOutputCharStream(writer);\n            serializer.setOutputFormat(new OutputFormat(\"Text\", \"UTF-8\", true));\n          } else {\n            serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          }\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        try{\n          //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n          ParseContext context = new ParseContext();//TODO: should we design a way to pass in parse context?\n          parser.parse(inputStream, parsingHandler, metadata, context);\n        } catch (TikaException e) {\n          if(ignoreTikaException)\n            log.warn(new StringBuilder(\"skip extracting text due to \").append(e.getLocalizedMessage())\n                .append(\". metadata=\").append(metadata.toString()).toString());\n          else\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n        }\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n          String[] names = metadata.names();\n          NamedList metadataNL = new NamedList();\n          for (int i = 0; i < names.length; i++) {\n            String[] vals = metadata.getValues(names[i]);\n            metadataNL.add(names[i], vals);\n          }\n          rsp.add(stream.getName() + \"_metadata\", metadataNL);\n        }\n      } catch (SAXException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01":["0633d6cdc3b9d1f2b0ef8e5ab78701d285db0303"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["d345a86357a4042faeebfad2693a070019c95918","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["b375ac28473e1310fa9ea99d95e9c6001e3719d5","0633d6cdc3b9d1f2b0ef8e5ab78701d285db0303"],"623193e0f05f138bdb5a54e0d149ab4ce4bf51f5":["1da8d55113b689b06716246649de6f62430f15c0"],"0633d6cdc3b9d1f2b0ef8e5ab78701d285db0303":["b375ac28473e1310fa9ea99d95e9c6001e3719d5"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"d345a86357a4042faeebfad2693a070019c95918":["70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["29ef99d61cda9641b6250bf9567329a6e65f901d","d345a86357a4042faeebfad2693a070019c95918"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a3776dccca01c11e7046323cfad46a3b4a471233","d345a86357a4042faeebfad2693a070019c95918"],"a3776dccca01c11e7046323cfad46a3b4a471233":["70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01","d345a86357a4042faeebfad2693a070019c95918"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["3bb13258feba31ab676502787ab2e1779f129b7a","70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b375ac28473e1310fa9ea99d95e9c6001e3719d5":["623193e0f05f138bdb5a54e0d149ab4ce4bf51f5"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"3bb13258feba31ab676502787ab2e1779f129b7a":["b375ac28473e1310fa9ea99d95e9c6001e3719d5","0633d6cdc3b9d1f2b0ef8e5ab78701d285db0303"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01":["d345a86357a4042faeebfad2693a070019c95918","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"623193e0f05f138bdb5a54e0d149ab4ce4bf51f5":["b375ac28473e1310fa9ea99d95e9c6001e3719d5"],"0633d6cdc3b9d1f2b0ef8e5ab78701d285db0303":["70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a"],"1da8d55113b689b06716246649de6f62430f15c0":["623193e0f05f138bdb5a54e0d149ab4ce4bf51f5"],"d345a86357a4042faeebfad2693a070019c95918":["c26f00b574427b55127e869b935845554afde1fa","c3a8a449466c1ff7ce2274fe73dab487256964b4","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","a3776dccca01c11e7046323cfad46a3b4a471233"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":[],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["c26f00b574427b55127e869b935845554afde1fa"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"a3776dccca01c11e7046323cfad46a3b4a471233":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"b375ac28473e1310fa9ea99d95e9c6001e3719d5":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","0633d6cdc3b9d1f2b0ef8e5ab78701d285db0303","3bb13258feba31ab676502787ab2e1779f129b7a"],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"3bb13258feba31ab676502787ab2e1779f129b7a":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c3a8a449466c1ff7ce2274fe73dab487256964b4","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}