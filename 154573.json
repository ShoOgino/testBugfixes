{"path":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","commits":[{"id":"b26b95c804ccc233c7f7290bf5f7befe43baea94","date":1245802310,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","pathOld":"/dev/null","sourceNew":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( cs );\n    List real = getTokens( ts );\n    List expect = tokens( \"i,1,0,1 i,1,2,3 jj,1,4,5 kkk,1,6,7 llll,1,8,10 cc,1,11,15 b,1,16,19 a,1,20,22\" );\n    assertTokEqualOff( expect, real );\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc","date":1251117853,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","sourceNew":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( cs );\n    assertTokenStreamContents(ts,\n      new String[]{\"i\",\"i\",\"jj\",\"kkk\",\"llll\",\"cc\",\"b\",\"a\"},\n      new int[]{0,2,4,6,8,11,16,20},\n      new int[]{1,3,5,7,10,15,19,22}\n    );\n  }\n\n","sourceOld":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( cs );\n    List real = getTokens( ts );\n    List expect = tokens( \"i,1,0,1 i,1,2,3 jj,1,4,5 kkk,1,6,7 llll,1,8,10 cc,1,11,15 b,1,16,19 a,1,20,22\" );\n    assertTokEqualOff( expect, real );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","sourceNew":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( Version.LUCENE_CURRENT, cs );\n    assertTokenStreamContents(ts,\n      new String[]{\"i\",\"i\",\"jj\",\"kkk\",\"llll\",\"cc\",\"b\",\"a\"},\n      new int[]{0,2,4,6,8,11,16,20},\n      new int[]{1,3,5,7,10,15,19,22}\n    );\n  }\n\n","sourceOld":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( cs );\n    assertTokenStreamContents(ts,\n      new String[]{\"i\",\"i\",\"jj\",\"kkk\",\"llll\",\"cc\",\"b\",\"a\"},\n      new int[]{0,2,4,6,8,11,16,20},\n      new int[]{1,3,5,7,10,15,19,22}\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","sourceNew":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( TEST_VERSION_CURRENT, cs );\n    assertTokenStreamContents(ts,\n      new String[]{\"i\",\"i\",\"jj\",\"kkk\",\"llll\",\"cc\",\"b\",\"a\"},\n      new int[]{0,2,4,6,8,11,16,20},\n      new int[]{1,3,5,7,10,15,19,22}\n    );\n  }\n\n","sourceOld":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( Version.LUCENE_CURRENT, cs );\n    assertTokenStreamContents(ts,\n      new String[]{\"i\",\"i\",\"jj\",\"kkk\",\"llll\",\"cc\",\"b\",\"a\"},\n      new int[]{0,2,4,6,8,11,16,20},\n      new int[]{1,3,5,7,10,15,19,22}\n    );\n  }\n\n","bugFix":null,"bugIntro":["fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","pathOld":"src/test/org/apache/lucene/analysis/TestMappingCharFilter#testTokenStream().mjava","sourceNew":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( TEST_VERSION_CURRENT, cs );\n    assertTokenStreamContents(ts,\n      new String[]{\"i\",\"i\",\"jj\",\"kkk\",\"llll\",\"cc\",\"b\",\"a\"},\n      new int[]{0,2,4,6,8,11,16,20},\n      new int[]{1,3,5,7,10,15,19,22}\n    );\n  }\n\n","sourceOld":"  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(in)  h i j k ll cccc bbb aa\n  //\n  //                1111111111222\n  //      01234567890123456789012\n  //(out) i i jj kkk llll cc b a\n  //\n  //    h, 0, 1 =>    i, 0, 1\n  //    i, 2, 3 =>    i, 2, 3\n  //    j, 4, 5 =>   jj, 4, 5\n  //    k, 6, 7 =>  kkk, 6, 7\n  //   ll, 8,10 => llll, 8,10\n  // cccc,11,15 =>   cc,11,15\n  //  bbb,16,19 =>    b,16,19\n  //   aa,20,22 =>    a,20,22\n  //\n  public void testTokenStream() throws Exception {\n    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( \"h i j k ll cccc bbb aa\" ) ) );\n    TokenStream ts = new WhitespaceTokenizer( TEST_VERSION_CURRENT, cs );\n    assertTokenStreamContents(ts,\n      new String[]{\"i\",\"i\",\"jj\",\"kkk\",\"llll\",\"cc\",\"b\",\"a\"},\n      new int[]{0,2,4,6,8,11,16,20},\n      new int[]{1,3,5,7,10,15,19,22}\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b26b95c804ccc233c7f7290bf5f7befe43baea94":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc":["b26b95c804ccc233c7f7290bf5f7befe43baea94"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"]},"commit2Childs":{"b26b95c804ccc233c7f7290bf5f7befe43baea94":["9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b26b95c804ccc233c7f7290bf5f7befe43baea94"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9fa6d7a7e7208b52f1b0c4c87005d34ab0dd37dc":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}