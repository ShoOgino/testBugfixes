{"path":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","commits":[{"id":"29252e837df815b8d01fd6dff973126cced351c5","date":1521709907,"type":0,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c9595c75582a7ea7efb585014102ed83f2d9c8b","date":1523581112,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","sourceOld":"  @Test\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6b87d1f8719d7f05be003f3477450b74af13706a","date":1523590376,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","sourceOld":"  @Test\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11d6f92dfa9251d9da6d80ec5963a9cbecc90180","date":1530559969,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  //28-June-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  //28-June-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  //28-June-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd","date":1534976797,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  //28-June-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            log.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      log.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","sourceOld":"  @Test\n  //28-June-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            LOG.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      LOG.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180","date":1539076849,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  //28-June-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            log.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      log.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n  }\n\n","sourceOld":"  @Test\n  //28-June-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            log.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      log.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n\n    TimeOut timeOut = new TimeOut(20, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeOut.waitFor(\"Time out waiting for LIR state get removed\", () -> {\n      String lirPath = ZkController.getLeaderInitiatedRecoveryZnodePath(collectionName, \"shard1\");\n      try {\n        List<String> children = zkClient().getChildren(lirPath, null, true);\n        return children.size() == 0;\n      } catch (KeeperException.NoNodeException e) {\n        return true;\n      } catch (Exception e) {\n        throw new AssertionError(e);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            log.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      log.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n  }\n\n","sourceOld":"  @Test\n  //28-June-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            log.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      log.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n  }\n\n","bugFix":["11d6f92dfa9251d9da6d80ec5963a9cbecc90180"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest#deleteReplicaOnIndexing().mjava","sourceNew":"  @Test\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            log.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      }\n      throw e;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void deleteReplicaOnIndexing() throws Exception {\n    final String collectionName = \"deleteReplicaOnIndexing\";\n    CollectionAdminRequest.createCollection(collectionName, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"\", collectionName, clusterShape(1, 2));\n    AtomicBoolean closed = new AtomicBoolean(false);\n    Thread[] threads = new Thread[100];\n    for (int i = 0; i < threads.length; i++) {\n      int finalI = i;\n      threads[i] = new Thread(() -> {\n        int doc = finalI * 10000;\n        while (!closed.get()) {\n          try {\n            cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", String.valueOf(doc++)));\n          } catch (Exception e) {\n            log.error(\"Failed on adding document to {}\", collectionName, e);\n          }\n        }\n      });\n      threads[i].start();\n    }\n\n    Slice shard1 = getCollectionState(collectionName).getSlice(\"shard1\");\n    Replica nonLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(0);\n    CollectionAdminRequest.deleteReplica(collectionName, \"shard1\", nonLeader.getName()).process(cluster.getSolrClient());\n    closed.set(true);\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    try {\n      cluster.getSolrClient().waitForState(collectionName, 20, TimeUnit.SECONDS, (liveNodes, collectionState) -> collectionState.getReplicas().size() == 1);\n    } catch (TimeoutException e) {\n      log.info(\"Timeout wait for state {}\", getCollectionState(collectionName));\n      throw e;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","29252e837df815b8d01fd6dff973126cced351c5"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180"],"3c9595c75582a7ea7efb585014102ed83f2d9c8b":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"11d6f92dfa9251d9da6d80ec5963a9cbecc90180":["6b87d1f8719d7f05be003f3477450b74af13706a"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["6b87d1f8719d7f05be003f3477450b74af13706a","11d6f92dfa9251d9da6d80ec5963a9cbecc90180"],"29252e837df815b8d01fd6dff973126cced351c5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6b87d1f8719d7f05be003f3477450b74af13706a":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","3c9595c75582a7ea7efb585014102ed83f2d9c8b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["11d6f92dfa9251d9da6d80ec5963a9cbecc90180"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["6b87d1f8719d7f05be003f3477450b74af13706a","11d6f92dfa9251d9da6d80ec5963a9cbecc90180"]},"commit2Childs":{"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["3c9595c75582a7ea7efb585014102ed83f2d9c8b","6b87d1f8719d7f05be003f3477450b74af13706a"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"3c9595c75582a7ea7efb585014102ed83f2d9c8b":["6b87d1f8719d7f05be003f3477450b74af13706a"],"b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"11d6f92dfa9251d9da6d80ec5963a9cbecc90180":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","e9c81f7e703d7ccca5bc78beb61253f0a8a22afd","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"29252e837df815b8d01fd6dff973126cced351c5":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","29252e837df815b8d01fd6dff973126cced351c5"],"6b87d1f8719d7f05be003f3477450b74af13706a":["11d6f92dfa9251d9da6d80ec5963a9cbecc90180","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["b6d72c72ee67b4aa8bc8bdd91bae9069b04fc180"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}