{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","commits":[{"id":"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","date":1528168051,"type":1,"author":"David Smiley","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testWithSynonym().mjava","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    BytesRef payload = new BytesRef(\"payload\");\n    completionTokenStream.setPayload(payload);\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new String[] {payload.utf8ToString(), payload.utf8ToString()}, new int[] { 1, 1 }, null, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":1,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testWithSynonym().mjava","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    BytesRef payload = new BytesRef(\"payload\");\n    completionTokenStream.setPayload(payload);\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new String[] {payload.utf8ToString(), payload.utf8ToString()}, new int[] { 1, 1 }, null, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":1,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testWithSynonym().mjava","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    BytesRef payload = new BytesRef(\"payload\");\n    completionTokenStream.setPayload(payload);\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new String[] {payload.utf8ToString(), payload.utf8ToString()}, new int[] { 1, 1 }, null, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","date":1574619880,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","sourceNew":"  @SuppressWarnings(\"deprecation\")\n  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    org.apache.lucene.analysis.synonym.SynonymFilter filter = new org.apache.lucene.analysis.synonym.SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9c3baacabd473e8ecd6c4948aabacead49b88e","date":1574700980,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @SuppressWarnings(\"deprecation\")\n  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    org.apache.lucene.analysis.synonym.SynonymFilter filter = new org.apache.lucene.analysis.synonym.SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2","date":1591961131,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testWithSynonym().mjava","sourceNew":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    @SuppressWarnings(\"deprecation\")\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","sourceOld":"  @Test\n  public void testWithSynonym() throws Exception {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    builder.add(new CharsRef(\"mykeyword\"), new CharsRef(\"mysynonym\"), true);\n    Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(\"mykeyword\"));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n    ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter);\n    assertTokenStreamContents(stream, new String[] {\"mykeyword\", \"mysynonym\"}, null, null, new int[] { 1, 0 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f592209545c71895260367152601e9200399776d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2"]},"commit2Childs":{"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b70042a8a492f7054d480ccdd2be9796510d4327","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","f592209545c71895260367152601e9200399776d"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2"],"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}