{"path":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","commits":[{"id":"daa9f76a48e97bb2d40fc67ecdaad33d166d596e","date":1488856307,"type":0,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    doTestDatePointFieldRangeFacet(\"number_p_dt_dv\", \"number_p_dt\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac5a6354a5800dd1ade225010d614eeb8acf9152","date":1499731103,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","sourceNew":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_dv\";\n    String nonDocValuesField = \"number_p_dt\";\n    int numValues = 10 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values, sortedValues;\n    long min, max;\n    DateGapCeiling gap;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = values.stream().sorted().collect(Collectors.toList());\n      min = sortedValues.get(0);\n      max = sortedValues.get(sortedValues.size() - 1);\n    } while (max > MAX_DATE_EPOCH_MILLIS || min <= MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    int[] bucketCount = new int[numBuckets];\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (long value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value));\n      while (value >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      ++bucketCount[bucketNum];\n    }\n\n    for (int i = 0 ; i < numValues ; i++) {\n      assertU(adoc(\"id\", String.valueOf(i), docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString()));\n    }\n    assertU(commit());\n\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + numValues + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    long maxPlusGap = gap.addTo(max);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),\n        \"facet.range.gap\", gap.toString()),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),   \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    maxPlusGap = gap.addTo(max);\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"filter\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    doTestDatePointFieldRangeFacet(\"number_p_dt_dv\", \"number_p_dt\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f9a989a32a073c55e3aef6f807a3474184bbcf49","date":1499930209,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","sourceNew":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_dv\";\n    String nonDocValuesField = \"number_p_dt\";\n    int numValues = 10 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values, sortedValues;\n    long min, max;\n    DateGapCeiling gap;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = values.stream().sorted().collect(Collectors.toList());\n      min = sortedValues.get(0);\n      max = sortedValues.get(sortedValues.size() - 1);\n    } while (max > MAX_DATE_EPOCH_MILLIS || min <= MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    int[] bucketCount = new int[numBuckets];\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (long value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value));\n      while (value >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      ++bucketCount[bucketNum];\n    }\n\n    for (int i = 0 ; i < numValues ; i++) {\n      assertU(adoc(\"id\", String.valueOf(i), docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString()));\n    }\n    assertU(commit());\n\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + numValues + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    long maxPlusGap = gap.addTo(max);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),\n        \"facet.range.gap\", gap.toString()),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),   \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    maxPlusGap = gap.addTo(max);\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"filter\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    doTestDatePointFieldRangeFacet(\"number_p_dt_dv\", \"number_p_dt\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb569fd721c41eafc2a2d788499a7df490c7f1a5","date":1499930871,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","sourceNew":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_dv\";\n    String nonDocValuesField = \"number_p_dt\";\n    int numValues = 10 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values, sortedValues;\n    long min, max;\n    DateGapCeiling gap;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = values.stream().sorted().collect(Collectors.toList());\n      min = sortedValues.get(0);\n      max = sortedValues.get(sortedValues.size() - 1);\n    } while (max > MAX_DATE_EPOCH_MILLIS || min <= MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    int[] bucketCount = new int[numBuckets];\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (long value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value));\n      while (value >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      ++bucketCount[bucketNum];\n    }\n\n    for (int i = 0 ; i < numValues ; i++) {\n      assertU(adoc(\"id\", String.valueOf(i), docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString()));\n    }\n    assertU(commit());\n\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + numValues + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    long maxPlusGap = gap.addTo(max);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),\n        \"facet.range.gap\", gap.toString()),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),   \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    maxPlusGap = gap.addTo(max);\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"filter\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    doTestDatePointFieldRangeFacet(\"number_p_dt_dv\", \"number_p_dt\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e844d4f9ba6804f10747d7e51e83a9a8868c94","date":1500054875,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","sourceNew":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_dv\";\n    String nonDocValuesField = \"number_p_dt\";\n    int numValues = 10 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values, sortedValues;\n    long min, max;\n    DateGapCeiling gap;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = values.stream().sorted().collect(Collectors.toList());\n      min = sortedValues.get(0);\n      max = sortedValues.get(sortedValues.size() - 1);\n    } while (max > MAX_DATE_EPOCH_MILLIS || min < MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    int[] bucketCount = new int[numBuckets];\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (long value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value));\n      while (value >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      ++bucketCount[bucketNum];\n    }\n\n    for (int i = 0 ; i < numValues ; i++) {\n      assertU(adoc(\"id\", String.valueOf(i), docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString()));\n    }\n    assertU(commit());\n\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + numValues + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal) \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    long maxPlusGap = gap.addTo(max);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),\n        \"facet.range.gap\", gap.toString()),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),   \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    maxPlusGap = gap.addTo(max);\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"filter\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_dv\";\n    String nonDocValuesField = \"number_p_dt\";\n    int numValues = 10 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values, sortedValues;\n    long min, max;\n    DateGapCeiling gap;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = values.stream().sorted().collect(Collectors.toList());\n      min = sortedValues.get(0);\n      max = sortedValues.get(sortedValues.size() - 1);\n    } while (max > MAX_DATE_EPOCH_MILLIS || min <= MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    int[] bucketCount = new int[numBuckets];\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (long value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value));\n      while (value >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      ++bucketCount[bucketNum];\n    }\n\n    for (int i = 0 ; i < numValues ; i++) {\n      assertU(adoc(\"id\", String.valueOf(i), docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString()));\n    }\n    assertU(commit());\n\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + numValues + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    long maxPlusGap = gap.addTo(max);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),\n        \"facet.range.gap\", gap.toString()),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),   \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    maxPlusGap = gap.addTo(max);\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"filter\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aaf90fc29510e72665ac7934f34c3d1c25efad64","date":1500354819,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testDatePointFieldRangeFacet().mjava","sourceNew":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_dv\";\n    String nonDocValuesField = \"number_p_dt\";\n    int numValues = 10 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values, sortedValues;\n    long min, max;\n    DateGapCeiling gap;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = values.stream().sorted().collect(Collectors.toList());\n      min = sortedValues.get(0);\n      max = sortedValues.get(sortedValues.size() - 1);\n    } while (max > MAX_DATE_EPOCH_MILLIS || min < MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    int[] bucketCount = new int[numBuckets];\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (long value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value));\n      while (value >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      ++bucketCount[bucketNum];\n    }\n\n    for (int i = 0 ; i < numValues ; i++) {\n      assertU(adoc(\"id\", String.valueOf(i), docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString()));\n    }\n    assertU(commit());\n\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + numValues + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal) \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    long maxPlusGap = gap.addTo(max);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),\n        \"facet.range.gap\", gap.toString()),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),   \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    maxPlusGap = gap.addTo(max);\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"filter\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testDatePointFieldRangeFacet() throws Exception {\n    String docValuesField = \"number_p_dt_dv\";\n    String nonDocValuesField = \"number_p_dt\";\n    int numValues = 10 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Long> values, sortedValues;\n    long min, max;\n    DateGapCeiling gap;\n    do {\n      values = getRandomLongs(numValues, false, MAX_DATE_EPOCH_MILLIS);\n      sortedValues = values.stream().sorted().collect(Collectors.toList());\n      min = sortedValues.get(0);\n      max = sortedValues.get(sortedValues.size() - 1);\n    } while (max > MAX_DATE_EPOCH_MILLIS || min <= MIN_DATE_EPOCH_MILLIS);\n    long initialGap = BigInteger.valueOf(max).subtract(BigInteger.valueOf(min))\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact();\n    gap = new DateGapCeiling(BigInteger.valueOf(max + initialGap).subtract(BigInteger.valueOf(min)) // padding for rounding\n        .divide(BigInteger.valueOf(numBuckets)).longValueExact());\n    int[] bucketCount = new int[numBuckets];\n    int bucketNum = 0;\n    long minBucketVal = min;\n    // System.err.println(\"min:\" + Instant.ofEpochMilli(min) + \"   max: \" + Instant.ofEpochMilli(max) + \"   gap: \" + gap);\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n    for (long value : sortedValues) {\n      // System.err.println(\"value: \" + Instant.ofEpochMilli(value));\n      while (value >= gap.addTo(minBucketVal)) {\n        ++bucketNum;\n        minBucketVal = gap.addTo(minBucketVal);\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + Instant.ofEpochMilli(minBucketVal));\n      }\n      ++bucketCount[bucketNum];\n    }\n\n    for (int i = 0 ; i < numValues ; i++) {\n      assertU(adoc(\"id\", String.valueOf(i), docValuesField, Instant.ofEpochMilli(values.get(i)).toString(),\n          nonDocValuesField, Instant.ofEpochMilli(values.get(i)).toString()));\n    }\n    assertU(commit());\n\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    testStrings[numBuckets] = \"//*[@numFound='\" + numValues + \"']\";\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    long maxPlusGap = gap.addTo(max);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),\n        \"facet.range.gap\", gap.toString()),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(),   \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min;\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + Instant.ofEpochMilli(minBucketVal).toString() \n          + \"'][.='\" + bucketCount[i] + \"']\";\n      minBucketVal = gap.addTo(minBucketVal);\n    }\n    maxPlusGap = gap.addTo(max);\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"filter\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField, \n        \"facet.range.start\", Instant.ofEpochMilli(min).toString(),\n        \"facet.range.end\", Instant.ofEpochMilli(maxPlusGap).toString(), \n        \"facet.range.gap\", gap.toString(), \n        \"facet.range.method\", \"dv\"),\n        testStrings);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"daa9f76a48e97bb2d40fc67ecdaad33d166d596e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"aaf90fc29510e72665ac7934f34c3d1c25efad64":["fb569fd721c41eafc2a2d788499a7df490c7f1a5","17e844d4f9ba6804f10747d7e51e83a9a8868c94"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fb569fd721c41eafc2a2d788499a7df490c7f1a5":["daa9f76a48e97bb2d40fc67ecdaad33d166d596e","f9a989a32a073c55e3aef6f807a3474184bbcf49"],"17e844d4f9ba6804f10747d7e51e83a9a8868c94":["ac5a6354a5800dd1ade225010d614eeb8acf9152"],"ac5a6354a5800dd1ade225010d614eeb8acf9152":["daa9f76a48e97bb2d40fc67ecdaad33d166d596e"],"f9a989a32a073c55e3aef6f807a3474184bbcf49":["daa9f76a48e97bb2d40fc67ecdaad33d166d596e","ac5a6354a5800dd1ade225010d614eeb8acf9152"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["17e844d4f9ba6804f10747d7e51e83a9a8868c94"]},"commit2Childs":{"daa9f76a48e97bb2d40fc67ecdaad33d166d596e":["fb569fd721c41eafc2a2d788499a7df490c7f1a5","ac5a6354a5800dd1ade225010d614eeb8acf9152","f9a989a32a073c55e3aef6f807a3474184bbcf49"],"aaf90fc29510e72665ac7934f34c3d1c25efad64":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["daa9f76a48e97bb2d40fc67ecdaad33d166d596e"],"fb569fd721c41eafc2a2d788499a7df490c7f1a5":["aaf90fc29510e72665ac7934f34c3d1c25efad64"],"17e844d4f9ba6804f10747d7e51e83a9a8868c94":["aaf90fc29510e72665ac7934f34c3d1c25efad64","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ac5a6354a5800dd1ade225010d614eeb8acf9152":["17e844d4f9ba6804f10747d7e51e83a9a8868c94","f9a989a32a073c55e3aef6f807a3474184bbcf49"],"f9a989a32a073c55e3aef6f807a3474184bbcf49":["fb569fd721c41eafc2a2d788499a7df490c7f1a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["aaf90fc29510e72665ac7934f34c3d1c25efad64","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}