{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#createCompoundFile(InfoStream,Directory,String,CheckAbort,SegmentInfo,IOContext).mjava","commits":[{"id":"9b2af6b2c05418fb9df466c739ed5b3a153eadde","date":1337520269,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#createCompoundFile(InfoStream,Directory,String,CheckAbort,SegmentInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#createCompoundFile(Directory,String,CheckAbort,SegmentInfo,IOContext).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  static final Collection<String> createCompoundFile(InfoStream infoStream, Directory directory, String fileName, CheckAbort checkAbort, final SegmentInfo info, IOContext context)\n          throws IOException {\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"create compound file \" + fileName);\n    }\n    assert info.getDocStoreOffset() == -1;\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = new CompoundFileDirectory(directory, fileName, context, true);\n    IOException prior = null;\n    try {\n      for (String file : files) {\n        directory.copy(cfsDir, file, file, context);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } catch(IOException ex) {\n      prior = ex;\n    } finally {\n      IOUtils.closeWhileHandlingException(prior, cfsDir);\n    }\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  static final Collection<String> createCompoundFile(Directory directory, String fileName, CheckAbort checkAbort, final SegmentInfo info, IOContext context)\n          throws IOException {\n    assert info.getDocStoreOffset() == -1;\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = new CompoundFileDirectory(directory, fileName, context, true);\n    try {\n      for (String file : files) {\n        directory.copy(cfsDir, file, file, context);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } finally {\n      cfsDir.close();\n    }\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1494abe5dc85557ec2e2772f87660d48f831c3a5","date":1337614370,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#createCompoundFile(InfoStream,Directory,CheckAbort,SegmentInfo,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#createCompoundFile(InfoStream,Directory,String,CheckAbort,SegmentInfo,IOContext).mjava","sourceNew":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  static final Collection<String> createCompoundFile(InfoStream infoStream, Directory directory, CheckAbort checkAbort, final SegmentInfo info, IOContext context)\n          throws IOException {\n\n    final String fileName = IndexFileNames.segmentFileName(info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"create compound file \" + fileName);\n    }\n    assert info.getDocStoreOffset() == -1;\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = new CompoundFileDirectory(directory, fileName, context, true);\n    IOException prior = null;\n    try {\n      for (String file : files) {\n        directory.copy(cfsDir, file, file, context);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } catch(IOException ex) {\n      prior = ex;\n    } finally {\n      IOUtils.closeWhileHandlingException(prior, cfsDir);\n    }\n\n    Set<String> siFiles = new HashSet<String>();\n    siFiles.add(fileName);\n    siFiles.add(IndexFileNames.segmentFileName(info.name, \"\", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));\n    info.setFiles(siFiles);\n\n    return files;\n  }\n\n","sourceOld":"  /**\n   * NOTE: this method creates a compound file for all files returned by\n   * info.files(). While, generally, this may include separate norms and\n   * deletion files, this SegmentInfo must not reference such files when this\n   * method is called, because they are not allowed within a compound file.\n   */\n  static final Collection<String> createCompoundFile(InfoStream infoStream, Directory directory, String fileName, CheckAbort checkAbort, final SegmentInfo info, IOContext context)\n          throws IOException {\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"create compound file \" + fileName);\n    }\n    assert info.getDocStoreOffset() == -1;\n    // Now merge all added files\n    Collection<String> files = info.files();\n    CompoundFileDirectory cfsDir = new CompoundFileDirectory(directory, fileName, context, true);\n    IOException prior = null;\n    try {\n      for (String file : files) {\n        directory.copy(cfsDir, file, file, context);\n        checkAbort.work(directory.fileLength(file));\n      }\n    } catch(IOException ex) {\n      prior = ex;\n    } finally {\n      IOUtils.closeWhileHandlingException(prior, cfsDir);\n    }\n\n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9b2af6b2c05418fb9df466c739ed5b3a153eadde":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1494abe5dc85557ec2e2772f87660d48f831c3a5":["9b2af6b2c05418fb9df466c739ed5b3a153eadde"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9b2af6b2c05418fb9df466c739ed5b3a153eadde","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9b2af6b2c05418fb9df466c739ed5b3a153eadde":["1494abe5dc85557ec2e2772f87660d48f831c3a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"1494abe5dc85557ec2e2772f87660d48f831c3a5":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","1494abe5dc85557ec2e2772f87660d48f831c3a5"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}