{"path":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"modules/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   * @throws ParseException\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"046829b17e246624c179b94d5a20cb53fa945e87","date":1367880720,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":"  /**\n   * Called when parser parses an input term that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term (one that has\n   * just a single <code>*</code> character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term that contains one or more wildcard\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n\n    if (termStr == null){\n      //can't imagine this would ever happen\n      throw new ParseException(\"Passed null value as term to getWildcardQuery\");\n    }\n    if ( ! getAllowLeadingWildcard() && (termStr.startsWith(\"*\") || termStr.startsWith(\"?\"))) {\n      throw new ParseException(\"'*' or '?' not allowed as first character in WildcardQuery\"\n                              + \" unless getAllowLeadingWildcard() returns true\");\n    }\n    \n    Matcher wildcardMatcher = wildcardPattern.matcher(termStr);\n    StringBuilder sb = new StringBuilder();\n    int last = 0;\n  \n    while (wildcardMatcher.find()){\n      // continue if escaped char\n      if (wildcardMatcher.group(1) != null){\n        continue;\n      }\n     \n      if (wildcardMatcher.start() > 0){\n        String chunk = termStr.substring(last, wildcardMatcher.start());\n        String analyzed = analyzeSingleChunk(field, termStr, chunk);\n        sb.append(analyzed);\n      }\n      //append the wildcard character\n      sb.append(wildcardMatcher.group(2));\n     \n      last = wildcardMatcher.end();\n    }\n    if (last < termStr.length()){\n      sb.append(analyzeSingleChunk(field, termStr, termStr.substring(last)));\n    }\n    return super.getWildcardQuery(field, sb.toString());\n  }\n\n","sourceOld":"  /**\n   * Called when parser\n   * parses an input term token that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term token (one\n   * that has just a single * character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code> \n   * but not for <code>*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term token that contains one or more wild card\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n    List<String> tlist = new ArrayList<String>();\n    List<String> wlist = new ArrayList<String>();\n    /* somewhat a hack: find/store wildcard chars\n     * in order to put them back after analyzing */\n    boolean isWithinToken = (!termStr.startsWith(\"?\") && !termStr.startsWith(\"*\"));\n    StringBuilder tmpBuffer = new StringBuilder();\n    char[] chars = termStr.toCharArray();\n    for (int i = 0; i < termStr.length(); i++) {\n      if (chars[i] == '?' || chars[i] == '*') {\n        if (isWithinToken) {\n          tlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = false;\n      } else {\n        if (!isWithinToken) {\n          wlist.add(tmpBuffer.toString());\n          tmpBuffer.setLength(0);\n        }\n        isWithinToken = true;\n      }\n      tmpBuffer.append(chars[i]);\n    }\n    if (isWithinToken) {\n      tlist.add(tmpBuffer.toString());\n    } else {\n      wlist.add(tmpBuffer.toString());\n    }\n\n    // get Analyzer from superclass and tokenize the term\n    TokenStream source;\n    \n    int countTokens = 0;\n    try {\n      source = getAnalyzer().tokenStream(field, new StringReader(termStr));\n      source.reset();\n    } catch (IOException e1) {\n      throw new RuntimeException(e1);\n    }\n    CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);\n    while (true) {\n      try {\n        if (!source.incrementToken()) break;\n      } catch (IOException e) {\n        break;\n      }\n      String term = termAtt.toString();\n      if (!\"\".equals(term)) {\n        try {\n          tlist.set(countTokens++, term);\n        } catch (IndexOutOfBoundsException ioobe) {\n          countTokens = -1;\n        }\n      }\n    }\n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      // ignore\n    }\n\n    if (countTokens != tlist.size()) {\n      /* this means that the analyzer used either added or consumed \n       * (common for a stemmer) tokens, and we can't build a WildcardQuery */\n      throw new ParseException(\"Cannot build WildcardQuery with analyzer \"\n          + getAnalyzer().getClass() + \" - tokens added or lost\");\n    }\n\n    if (tlist.size() == 0) {\n      return null;\n    } else if (tlist.size() == 1) {\n      if (wlist != null && wlist.size() == 1) {\n        /* if wlist contains one wildcard, it must be at the end, because:\n         * 1) wildcards are not allowed in 1st position of a term by QueryParser\n         * 2) if wildcard was *not* in end, there would be *two* or more tokens */\n        return super.getWildcardQuery(field, tlist.get(0)\n            + wlist.get(0).toString());\n      } else {\n        /* we should never get here! if so, this method was called\n         * with a termStr containing no wildcard ... */\n        throw new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n      }\n    } else {\n      /* the term was tokenized, let's rebuild to one token\n       * with wildcards put back in postion */\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < tlist.size(); i++) {\n        sb.append( tlist.get(i));\n        if (wlist != null && wlist.size() > i) {\n          sb.append(wlist.get(i));\n        }\n      }\n      return super.getWildcardQuery(field, sb.toString());\n    }\n  }\n\n","bugFix":["f11899016a0460a7ea2e4b008d002e1e75c7d867","7e2cb543b41c145f33390f460ee743d6693c9c6c","00746ad002a54281629e3b6f3eb39833a33f093e","4625cb7ffd7c9caaf2d62b206ba9a382d68da82c","10c49614cb8b943c412debb24ccb614128394470","874880417e0b2612f777ecd0afe39e0d90486752","a7347509fad0711ac30cb15a746e9a3830a38ebd","9b5756469957918cac40a831acec9cf01c8c2bb3","e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ea4107f60b9f95623c16025c9c247412ff809092","date":1468333987,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Called when parser parses an input term that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term (one that has\n   * just a single <code>*</code> character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term that contains one or more wildcard\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n\n    if (termStr == null){\n      //can't imagine this would ever happen\n      throw new ParseException(\"Passed null value as term to getWildcardQuery\");\n    }\n    if ( ! getAllowLeadingWildcard() && (termStr.startsWith(\"*\") || termStr.startsWith(\"?\"))) {\n      throw new ParseException(\"'*' or '?' not allowed as first character in WildcardQuery\"\n                              + \" unless getAllowLeadingWildcard() returns true\");\n    }\n    \n    Matcher wildcardMatcher = wildcardPattern.matcher(termStr);\n    StringBuilder sb = new StringBuilder();\n    int last = 0;\n  \n    while (wildcardMatcher.find()){\n      // continue if escaped char\n      if (wildcardMatcher.group(1) != null){\n        continue;\n      }\n     \n      if (wildcardMatcher.start() > 0){\n        String chunk = termStr.substring(last, wildcardMatcher.start());\n        String analyzed = analyzeSingleChunk(field, termStr, chunk);\n        sb.append(analyzed);\n      }\n      //append the wildcard character\n      sb.append(wildcardMatcher.group(2));\n     \n      last = wildcardMatcher.end();\n    }\n    if (last < termStr.length()){\n      sb.append(analyzeSingleChunk(field, termStr, termStr.substring(last)));\n    }\n    return super.getWildcardQuery(field, sb.toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#getWildcardQuery(String,String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Called when parser parses an input term that contains one or more wildcard\n   * characters (like <code>*</code>), but is not a prefix term (one that has\n   * just a single <code>*</code> character at the end).\n   * <p>\n   * Example: will be called for <code>H?user</code> or for <code>H*user</code>.\n   * <p>\n   * Depending on analyzer and settings, a wildcard term may (most probably will)\n   * be lower-cased automatically. It <b>will</b> go through the default Analyzer.\n   * <p>\n   * Overrides super class, by passing terms through analyzer.\n   *\n   * @param  field   Name of the field query will use.\n   * @param  termStr Term that contains one or more wildcard\n   *                 characters (? or *), but is not simple prefix term\n   *\n   * @return Resulting {@link Query} built for the term\n   */\n  @Override\n  protected Query getWildcardQuery(String field, String termStr) throws ParseException {\n\n    if (termStr == null){\n      //can't imagine this would ever happen\n      throw new ParseException(\"Passed null value as term to getWildcardQuery\");\n    }\n    if ( ! getAllowLeadingWildcard() && (termStr.startsWith(\"*\") || termStr.startsWith(\"?\"))) {\n      throw new ParseException(\"'*' or '?' not allowed as first character in WildcardQuery\"\n                              + \" unless getAllowLeadingWildcard() returns true\");\n    }\n    \n    Matcher wildcardMatcher = wildcardPattern.matcher(termStr);\n    StringBuilder sb = new StringBuilder();\n    int last = 0;\n  \n    while (wildcardMatcher.find()){\n      // continue if escaped char\n      if (wildcardMatcher.group(1) != null){\n        continue;\n      }\n     \n      if (wildcardMatcher.start() > 0){\n        String chunk = termStr.substring(last, wildcardMatcher.start());\n        String analyzed = analyzeSingleChunk(field, termStr, chunk);\n        sb.append(analyzed);\n      }\n      //append the wildcard character\n      sb.append(wildcardMatcher.group(2));\n     \n      last = wildcardMatcher.end();\n    }\n    if (last < termStr.length()){\n      sb.append(analyzeSingleChunk(field, termStr, termStr.substring(last)));\n    }\n    return super.getWildcardQuery(field, sb.toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ea4107f60b9f95623c16025c9c247412ff809092":["046829b17e246624c179b94d5a20cb53fa945e87"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["046829b17e246624c179b94d5a20cb53fa945e87","ea4107f60b9f95623c16025c9c247412ff809092"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ea4107f60b9f95623c16025c9c247412ff809092"],"046829b17e246624c179b94d5a20cb53fa945e87":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"]},"commit2Childs":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["046829b17e246624c179b94d5a20cb53fa945e87"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"ea4107f60b9f95623c16025c9c247412ff809092":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"046829b17e246624c179b94d5a20cb53fa945e87":["ea4107f60b9f95623c16025c9c247412ff809092","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}