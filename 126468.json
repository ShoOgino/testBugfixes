{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.pendingDeleteCount;\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.pendingDeleteCount;\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae695f21c50b03702b5d0fa2543d5af844bb7cd3","date":1331554994,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    assert docUpto == merge.info.docCount;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.pendingDeleteCount;\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":["9ce667c6d3400b22523701c549c0d35e26da8b46","32feb7c2c571b402d2e231bd8e3b6add4af6d6eb"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    assert docUpto == merge.info.docCount;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We enrolled in mergeInit:\n      assert rld != null;\n      currentLiveDocs = rld.liveDocs;\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.pendingDeleteCount;\n        }\n      } else if (currentLiveDocs != null) {\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.pendingDeleteCount + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.docCount - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.docCount;\n      }\n    }\n\n    assert docUpto == merge.info.info.docCount;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    assert docUpto == merge.info.docCount;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"203d7d3cb7712e10ef33009a63247ae40c302d7a","date":1337798111,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.docCount - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.docCount;\n      }\n    }\n\n    assert docUpto == merge.info.info.docCount;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfo> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfo info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.docCount;\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.docCount - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.docCount;\n      }\n    }\n\n    assert docUpto == merge.info.docCount;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c95a819869502635864dac0a788f874787e3395b","date":1341394787,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":["8a16d06e7522604de20b2d758d9b9464bb30fe02"],"bugIntro":["36d84416fc00253f9e834f8dba14fa89b298e64e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readerLiveDocs.get(i);\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"119ae5b0966bbb5d6948c7f86207613595764d2e","date":1357249026,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":["9ce667c6d3400b22523701c549c0d35e26da8b46","c19f985e36a65cc969e8e564fe337a0d41512075"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    // If new deletes were applied while we were merging\n    // (which happens if eg commit() or getReader() is\n    // called during our merge), then it better be the case\n    // that the delGen has increased for all our merged\n    // segments:\n    assert mergedDeletes == null || minGen > merge.info.getBufferedDeletesGen();\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"66b61ab77ab36893d701d693f1b6df2a383bb7b5","date":1364405461,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMergedDeletes(MergePolicy.OneMerge).mjava","sourceNew":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n    MergePolicy.DocMap docMap = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                  docMap = merge.getDocMap(mergeState);\n                  assert docMap.isConsistent(merge.info.info.getDocCount());\n                }\n                mergedDeletes.delete(docMap.map(docUpto));\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n              docMap = merge.getDocMap(mergeState);\n              assert docMap.isConsistent(merge.info.info.getDocCount());\n            }\n            mergedDeletes.delete(docMap.map(docUpto));\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","sourceOld":"  /** Carefully merges deletes for the segments we just\n   *  merged.  This is tricky because, although merging will\n   *  clear all deletes (compacts the documents), new\n   *  deletes may have been flushed to the segments since\n   *  the merge was started.  This method \"carries over\"\n   *  such new deletes onto the newly merged segment, and\n   *  saves the resulting deletes file (incrementing the\n   *  delete generation for merge.info).  If no deletes were\n   *  flushed, no new deletes file is saved. */\n  synchronized private ReadersAndLiveDocs commitMergedDeletes(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMergeDeletes\");\n\n    final List<SegmentInfoPerCommit> sourceSegments = merge.segments;\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMergeDeletes \" + segString(merge.segments));\n    }\n\n    // Carefully merge deletes that occurred after we\n    // started merging:\n    int docUpto = 0;\n    long minGen = Long.MAX_VALUE;\n\n    // Lazy init (only when we find a delete to carry over):\n    ReadersAndLiveDocs mergedDeletes = null;\n\n    for(int i=0; i < sourceSegments.size(); i++) {\n      SegmentInfoPerCommit info = sourceSegments.get(i);\n      minGen = Math.min(info.getBufferedDeletesGen(), minGen);\n      final int docCount = info.info.getDocCount();\n      final Bits prevLiveDocs = merge.readers.get(i).getLiveDocs();\n      final Bits currentLiveDocs;\n      final ReadersAndLiveDocs rld = readerPool.get(info, false);\n      // We hold a ref so it should still be in the pool:\n      assert rld != null: \"seg=\" + info.info.name;\n      currentLiveDocs = rld.getLiveDocs();\n\n      if (prevLiveDocs != null) {\n\n        // If we had deletions on starting the merge we must\n        // still have deletions now:\n        assert currentLiveDocs != null;\n        assert prevLiveDocs.length() == docCount;\n        assert currentLiveDocs.length() == docCount;\n\n        // There were deletes on this segment when the merge\n        // started.  The merge has collapsed away those\n        // deletes, but, if new deletes were flushed since\n        // the merge started, we must now carefully keep any\n        // newly flushed deletes but mapping them to the new\n        // docIDs.\n\n        // Since we copy-on-write, if any new deletes were\n        // applied after merging has started, we can just\n        // check if the before/after liveDocs have changed.\n        // If so, we must carefully merge the liveDocs one\n        // doc at a time:\n        if (currentLiveDocs != prevLiveDocs) {\n\n          // This means this segment received new deletes\n          // since we started the merge, so we\n          // must merge them:\n          for(int j=0;j<docCount;j++) {\n            if (!prevLiveDocs.get(j)) {\n              assert !currentLiveDocs.get(j);\n            } else {\n              if (!currentLiveDocs.get(j)) {\n                if (mergedDeletes == null) {\n                  mergedDeletes = readerPool.get(merge.info, true);\n                  mergedDeletes.initWritableLiveDocs();\n                }\n                mergedDeletes.delete(docUpto);\n              }\n              docUpto++;\n            }\n          }\n        } else {\n          docUpto += info.info.getDocCount() - info.getDelCount() - rld.getPendingDeleteCount();\n        }\n      } else if (currentLiveDocs != null) {\n        assert currentLiveDocs.length() == docCount;\n        // This segment had no deletes before but now it\n        // does:\n        for(int j=0; j<docCount; j++) {\n          if (!currentLiveDocs.get(j)) {\n            if (mergedDeletes == null) {\n              mergedDeletes = readerPool.get(merge.info, true);\n              mergedDeletes.initWritableLiveDocs();\n            }\n            mergedDeletes.delete(docUpto);\n          }\n          docUpto++;\n        }\n      } else {\n        // No deletes before or after\n        docUpto += info.info.getDocCount();\n      }\n    }\n\n    assert docUpto == merge.info.info.getDocCount();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (mergedDeletes == null) {\n        infoStream.message(\"IW\", \"no new deletes since merge started\");\n      } else {\n        infoStream.message(\"IW\", mergedDeletes.getPendingDeleteCount() + \" new deletes since merge started\");\n      }\n    }\n\n    merge.info.setBufferedDeletesGen(minGen);\n\n    return mergedDeletes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c95a819869502635864dac0a788f874787e3395b":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["c95a819869502635864dac0a788f874787e3395b","119ae5b0966bbb5d6948c7f86207613595764d2e"],"38e3b736c7ca086d61b7dbb841c905ee115490da":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"ae695f21c50b03702b5d0fa2543d5af844bb7cd3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["119ae5b0966bbb5d6948c7f86207613595764d2e"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["ae695f21c50b03702b5d0fa2543d5af844bb7cd3","203d7d3cb7712e10ef33009a63247ae40c302d7a"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","c95a819869502635864dac0a788f874787e3395b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"119ae5b0966bbb5d6948c7f86207613595764d2e":["c95a819869502635864dac0a788f874787e3395b"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"]},"commit2Childs":{"c95a819869502635864dac0a788f874787e3395b":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","fe33227f6805edab2036cbb80645cc4e2d1fa424","119ae5b0966bbb5d6948c7f86207613595764d2e"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["38e3b736c7ca086d61b7dbb841c905ee115490da","ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"ae695f21c50b03702b5d0fa2543d5af844bb7cd3":["38e3b736c7ca086d61b7dbb841c905ee115490da","9d153abcf92dc5329d98571a8c3035df9bd80648","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["c95a819869502635864dac0a788f874787e3395b","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"119ae5b0966bbb5d6948c7f86207613595764d2e":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","38e3b736c7ca086d61b7dbb841c905ee115490da","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}