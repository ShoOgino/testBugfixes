{"path":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2b0f649857e40b1429ab946a302da32f695eed9f","date":1339002543,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d94feb02e9c604630d8a6758abcb40cbfa91f5d","date":1340964157,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, 0);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, 0);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, 0);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f45457a742a53533c348c4b990b1c579ff364467","date":1353197071,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, 0);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, 0);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, 0);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, 0);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["60ba444201d2570214b6fcf1d15600dc1a01f548","386d1b0dcb065f1bfc494b1407cb41c536b95485"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"050ba1ba249733cac50c2612418b7179591d2df9","date":1374633633,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f948dd442d23baa6cbb28daf77c8db78b351329","date":1378742876,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c","date":1399816179,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93dd449115a9247533e44bab47e8429e5dccbc6d","date":1400258396,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    // NOTE: intentional insanity!!\n    final FieldCache.Ints docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f4ef381bf0c2d618c6db830d3dd668c6901c05a","date":1402592253,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      LightAutomaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmptyLight();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnionLight(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      LightAutomaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmptyLight();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnionLight(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c84485629d80d203608e8975a1139de9933cc38","date":1403166128,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = BasicAutomata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      if (random().nextBoolean()) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: reduce the automaton\");\n        }\n        a.reduce();\n      }\n\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.shutdown();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b316f82baae88f5e279893a9cb7eee51fd8902f","date":1415131390,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.FLAG_NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = TestUtil.docs(random(), te, null, docsEnum, DocsEnum.FLAG_NONE);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.FLAG_NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0088660bdc1c051f58fbc38626d61ccf22dfd3e0","date":1427444574,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, null, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7543e96e2d4820e09334d36a699b998ed963f4f","date":1476121426,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = 0;\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = 0;\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    final NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID.get(docID), termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = 0;\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiTerms.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = 0;\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"617d6d4150e0fb2acef8980ce51e3b8e628fb200","date":1580326292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    int numIterations = atLeast(3);\n    for(int iter=0;iter<numIterations;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = 0;\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiTerms.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n\n    final int numTerms = atLeast(300);\n    //final int numTerms = 50;\n\n    final Set<String> terms = new HashSet<>();\n    final Collection<String> pendingTerms = new ArrayList<>();\n    final Map<BytesRef,Integer> termToID = new HashMap<>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random().nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    int[] docIDToID = new int[r.maxDoc()];\n    NumericDocValues values = MultiDocValues.getNumericValues(r, \"id\");\n    for(int i=0;i<r.maxDoc();i++) {\n      assertEquals(i, values.nextDoc());\n      docIDToID[i] = (int) values.longValue();\n    }\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<>();\n      final double keepPct = random().nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = Automata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random().nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = Automata.makeStringUnion(sortedAcceptTerms);\n      }\n      \n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false, 1000000, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random().nextBoolean() ? null : acceptTermsArray[random().nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = 0;\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiTerms.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        PostingsEnum postingsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + (actual == null ? \"null\" : actual.utf8ToString()));\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          postingsEnum = TestUtil.docs(random(), te, postingsEnum, PostingsEnum.NONE);\n          final int docID = postingsEnum.nextDoc();\n          assertTrue(docID != DocIdSetIterator.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["f45457a742a53533c348c4b990b1c579ff364467","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"b7543e96e2d4820e09334d36a699b998ed963f4f":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7f4ef381bf0c2d618c6db830d3dd668c6901c05a":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"56572ec06f1407c066d6b7399413178b33176cd8":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a","93dd449115a9247533e44bab47e8429e5dccbc6d"],"f45457a742a53533c348c4b990b1c579ff364467":["02331260bb246364779cb6f04919ca47900d01bb"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4","0088660bdc1c051f58fbc38626d61ccf22dfd3e0"],"0088660bdc1c051f58fbc38626d61ccf22dfd3e0":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["7f4ef381bf0c2d618c6db830d3dd668c6901c05a"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["0f4464508ee83288c8c4585b533f9faaa93aa314","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"5c84485629d80d203608e8975a1139de9933cc38":["93dd449115a9247533e44bab47e8429e5dccbc6d","4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["d4d69c535930b5cce125cff868d40f6373dc27d4","050ba1ba249733cac50c2612418b7179591d2df9"],"050ba1ba249733cac50c2612418b7179591d2df9":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"2b0f649857e40b1429ab946a302da32f695eed9f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8d94feb02e9c604630d8a6758abcb40cbfa91f5d":["2b0f649857e40b1429ab946a302da32f695eed9f"],"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"617d6d4150e0fb2acef8980ce51e3b8e628fb200":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"8b316f82baae88f5e279893a9cb7eee51fd8902f":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"51f5280f31484820499077f41fcdfe92d527d9dc":["8b316f82baae88f5e279893a9cb7eee51fd8902f"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0f4464508ee83288c8c4585b533f9faaa93aa314","b7543e96e2d4820e09334d36a699b998ed963f4f"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0088660bdc1c051f58fbc38626d61ccf22dfd3e0"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640","d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["02331260bb246364779cb6f04919ca47900d01bb"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a","b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["2b0f649857e40b1429ab946a302da32f695eed9f","8d94feb02e9c604630d8a6758abcb40cbfa91f5d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["fe33227f6805edab2036cbb80645cc4e2d1fa424","02331260bb246364779cb6f04919ca47900d01bb"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["5c84485629d80d203608e8975a1139de9933cc38"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["8d94feb02e9c604630d8a6758abcb40cbfa91f5d","02331260bb246364779cb6f04919ca47900d01bb"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["b7543e96e2d4820e09334d36a699b998ed963f4f"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["617d6d4150e0fb2acef8980ce51e3b8e628fb200"],"02331260bb246364779cb6f04919ca47900d01bb":["8d94feb02e9c604630d8a6758abcb40cbfa91f5d"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"b7543e96e2d4820e09334d36a699b998ed963f4f":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","04e775de416dd2d8067b10db1c8af975a1d5017e"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"7f4ef381bf0c2d618c6db830d3dd668c6901c05a":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"56572ec06f1407c066d6b7399413178b33176cd8":[],"f45457a742a53533c348c4b990b1c579ff364467":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"0088660bdc1c051f58fbc38626d61ccf22dfd3e0":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","0f4464508ee83288c8c4585b533f9faaa93aa314"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["b7543e96e2d4820e09334d36a699b998ed963f4f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["5c84485629d80d203608e8975a1139de9933cc38"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["56572ec06f1407c066d6b7399413178b33176cd8","b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c","93dd449115a9247533e44bab47e8429e5dccbc6d"],"5c84485629d80d203608e8975a1139de9933cc38":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["6613659748fe4411a7dcf85266e55db1f95f7315"],"050ba1ba249733cac50c2612418b7179591d2df9":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"2b0f649857e40b1429ab946a302da32f695eed9f":["8d94feb02e9c604630d8a6758abcb40cbfa91f5d","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"8d94feb02e9c604630d8a6758abcb40cbfa91f5d":["fe33227f6805edab2036cbb80645cc4e2d1fa424","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"617d6d4150e0fb2acef8980ce51e3b8e628fb200":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8b316f82baae88f5e279893a9cb7eee51fd8902f":["51f5280f31484820499077f41fcdfe92d527d9dc"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","0088660bdc1c051f58fbc38626d61ccf22dfd3e0"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["2f948dd442d23baa6cbb28daf77c8db78b351329","050ba1ba249733cac50c2612418b7179591d2df9"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","d4d69c535930b5cce125cff868d40f6373dc27d4"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["7f4ef381bf0c2d618c6db830d3dd668c6901c05a","56572ec06f1407c066d6b7399413178b33176cd8","5c84485629d80d203608e8975a1139de9933cc38"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["8b316f82baae88f5e279893a9cb7eee51fd8902f"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"04e775de416dd2d8067b10db1c8af975a1d5017e":["617d6d4150e0fb2acef8980ce51e3b8e628fb200"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["2b0f649857e40b1429ab946a302da32f695eed9f"],"02331260bb246364779cb6f04919ca47900d01bb":["f45457a742a53533c348c4b990b1c579ff364467","15250ca94ba8ab3bcdd476daf6bf3f3febb92640","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","56572ec06f1407c066d6b7399413178b33176cd8","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}