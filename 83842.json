{"path":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","commits":[{"id":"5c0af45b07833be5922ae261245816cc39091b6d","date":1354907459,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42f51b3ab4258ff4623227b0db011b8bb83db5c7","date":1358164991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8917bfede3b4ca30f4305c1e391e9218959cd723","date":1358189662,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"811cdb4a80352766eb0c762e48972707a924e5cd","date":1358767313,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d","date":1358784296,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"239f79ed06f0979cfe1911ec5fba32b94fda43c1","date":1359553898,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        // complements return counts for all ordinals, so force ALL_PARENTS indexing\n        // so that it's easier to compare\n        FacetIndexingParams fip = getFacetIndexingParams(partitionSize, true);\n        initIndex(fip);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, fip); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, fip); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61d5f95d14e5b9b046998c51e16709a398c15226","date":1359603451,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        // complements return counts for all ordinals, so force ALL_PARENTS indexing\n        // so that it's easier to compare\n        FacetIndexingParams fip = getFacetIndexingParams(partitionSize, true);\n        initIndex(fip);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, fip); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, fip); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"571abba77e55fea386a38c0024f72ffa5b37a9ad","date":1360272747,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        // complements return counts for all ordinals, so force ALL_PARENTS indexing\n        // so that it's easier to compare\n        FacetIndexingParams fip = getFacetIndexingParams(partitionSize, true);\n        initIndex(fip);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, fip); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, fc);\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, fip); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        // complements return counts for all ordinals, so force ALL_PARENTS indexing\n        // so that it's easier to compare\n        FacetIndexingParams fip = getFacetIndexingParams(partitionSize, true);\n        initIndex(fip);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, fip); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, fip); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4b31c82c6df2339d0c31b592f919be77383dac10"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"607428da722dcb3e86bbd11c63de8986e6275c36","date":1360334150,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        // complements return counts for all ordinals, so force ALL_PARENTS indexing\n        // so that it's easier to compare\n        FacetIndexingParams fip = getFacetIndexingParams(partitionSize, true);\n        initIndex(fip);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, fip); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, fc);\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, fip); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        // complements return counts for all ordinals, so force ALL_PARENTS indexing\n        // so that it's easier to compare\n        FacetIndexingParams fip = getFacetIndexingParams(partitionSize, true);\n        initIndex(fip);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, fip); \n        FacetsCollector fc = FacetsCollector.create(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, fc);\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, fip); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial = 0; nTrial < RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (AssertionError e) {\n            if (nTrial >= RETRIES - 1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d":["811cdb4a80352766eb0c762e48972707a924e5cd"],"42f51b3ab4258ff4623227b0db011b8bb83db5c7":["5c0af45b07833be5922ae261245816cc39091b6d"],"8917bfede3b4ca30f4305c1e391e9218959cd723":["407687e67faf6e1f02a211ca078d8e3eed631027","42f51b3ab4258ff4623227b0db011b8bb83db5c7"],"407687e67faf6e1f02a211ca078d8e3eed631027":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5c0af45b07833be5922ae261245816cc39091b6d"],"07155cdd910937cdf6877e48884d5782845c8b8b":["8917bfede3b4ca30f4305c1e391e9218959cd723","f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d"],"571abba77e55fea386a38c0024f72ffa5b37a9ad":["239f79ed06f0979cfe1911ec5fba32b94fda43c1"],"607428da722dcb3e86bbd11c63de8986e6275c36":["571abba77e55fea386a38c0024f72ffa5b37a9ad"],"61d5f95d14e5b9b046998c51e16709a398c15226":["07155cdd910937cdf6877e48884d5782845c8b8b","239f79ed06f0979cfe1911ec5fba32b94fda43c1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"239f79ed06f0979cfe1911ec5fba32b94fda43c1":["f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d"],"5c0af45b07833be5922ae261245816cc39091b6d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["607428da722dcb3e86bbd11c63de8986e6275c36"],"811cdb4a80352766eb0c762e48972707a924e5cd":["42f51b3ab4258ff4623227b0db011b8bb83db5c7"]},"commit2Childs":{"f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d":["07155cdd910937cdf6877e48884d5782845c8b8b","239f79ed06f0979cfe1911ec5fba32b94fda43c1"],"42f51b3ab4258ff4623227b0db011b8bb83db5c7":["8917bfede3b4ca30f4305c1e391e9218959cd723","811cdb4a80352766eb0c762e48972707a924e5cd"],"8917bfede3b4ca30f4305c1e391e9218959cd723":["07155cdd910937cdf6877e48884d5782845c8b8b"],"407687e67faf6e1f02a211ca078d8e3eed631027":["8917bfede3b4ca30f4305c1e391e9218959cd723"],"07155cdd910937cdf6877e48884d5782845c8b8b":["61d5f95d14e5b9b046998c51e16709a398c15226"],"571abba77e55fea386a38c0024f72ffa5b37a9ad":["607428da722dcb3e86bbd11c63de8986e6275c36"],"607428da722dcb3e86bbd11c63de8986e6275c36":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"61d5f95d14e5b9b046998c51e16709a398c15226":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["407687e67faf6e1f02a211ca078d8e3eed631027","5c0af45b07833be5922ae261245816cc39091b6d"],"239f79ed06f0979cfe1911ec5fba32b94fda43c1":["571abba77e55fea386a38c0024f72ffa5b37a9ad","61d5f95d14e5b9b046998c51e16709a398c15226"],"5c0af45b07833be5922ae261245816cc39091b6d":["42f51b3ab4258ff4623227b0db011b8bb83db5c7","407687e67faf6e1f02a211ca078d8e3eed631027"],"811cdb4a80352766eb0c762e48972707a924e5cd":["f96e4a056f7ee1bafbfb8a06c5bd93f7708e560d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["61d5f95d14e5b9b046998c51e16709a398c15226","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}