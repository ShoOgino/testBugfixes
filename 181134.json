{"path":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","commits":[{"id":"6795c6bc2f5a6b2a2230cb20ff4744003faf7802","date":1333839972,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"/dev/null","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random, t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random, a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random, t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random, a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n            final Tokenizer t = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","date":1429550638,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"085e5eccb1e06e3bfb487813880adc54c888dd02","date":1483875517,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","pathOld":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers#testMockGraphTokenFilterBasic().mjava","sourceNew":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","sourceOld":"  public void testMockGraphTokenFilterBasic() throws Exception {\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      // Make new analyzer each time, because MGTF has fixed\n      // seed:\n      final Analyzer a = new Analyzer() {\n          @Override\n          protected TokenStreamComponents createComponents(String fieldName) {\n            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n            final TokenStream t2 = new MockGraphTokenFilter(random(), t);\n            return new TokenStreamComponents(t, t2);\n          }\n        };\n      \n      checkAnalysisConsistency(random(), a, false, \"a b c d e f g h i j k\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","085e5eccb1e06e3bfb487813880adc54c888dd02"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["6795c6bc2f5a6b2a2230cb20ff4744003faf7802"],"085e5eccb1e06e3bfb487813880adc54c888dd02":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"6795c6bc2f5a6b2a2230cb20ff4744003faf7802":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["085e5eccb1e06e3bfb487813880adc54c888dd02"]},"commit2Childs":{"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6795c6bc2f5a6b2a2230cb20ff4744003faf7802"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","085e5eccb1e06e3bfb487813880adc54c888dd02"],"085e5eccb1e06e3bfb487813880adc54c888dd02":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6795c6bc2f5a6b2a2230cb20ff4744003faf7802":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}