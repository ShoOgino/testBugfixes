{"path":"modules/analysis/common/src/java/org/apache/lucene/analysis/util/WordlistLoader#getWordSet(Class[#],String,String).mjava","commits":[{"id":"790c3f61c9b891d66d919c5d10db9fa5216eb0f1","date":1274818604,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/java/org/apache/lucene/analysis/util/WordlistLoader#getWordSet(Class[#],String,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/analysis/WordlistLoader#getWordSet(Class[#],String,String).mjava","sourceNew":"  /**\n   * Loads a text file associated with a given class (See\n   * {@link Class#getResourceAsStream(String)}) and adds every line as an entry\n   * to a {@link Set} (omitting leading and trailing whitespace). Every line of\n   * the file should contain only one word. The words need to be in lower-case if\n   * you make use of an Analyzer which uses LowerCaseFilter (like\n   * StandardAnalyzer).\n   * \n   * @param aClass\n   *          a class that is associated with the given stopwordResource\n   * @param stopwordResource\n   *          name of the resource file associated with the given class\n   * @param comment\n   *          the comment string to ignore\n   * @return a {@link Set} with the file's words\n   */\n  public static Set<String> getWordSet(Class<?> aClass,\n      String stopwordResource, String comment) throws IOException {\n    final Reader reader = new BufferedReader(new InputStreamReader(aClass\n        .getResourceAsStream(stopwordResource), \"UTF-8\"));\n    try {\n      return getWordSet(reader, comment);\n    } finally {\n      reader.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Loads a text file associated with a given class (See\n   * {@link Class#getResourceAsStream(String)}) and adds every line as an entry\n   * to a {@link Set} (omitting leading and trailing whitespace). Every line of\n   * the file should contain only one word. The words need to be in lower-case if\n   * you make use of an Analyzer which uses LowerCaseFilter (like\n   * StandardAnalyzer).\n   * \n   * @param aClass\n   *          a class that is associated with the given stopwordResource\n   * @param stopwordResource\n   *          name of the resource file associated with the given class\n   * @param comment\n   *          the comment string to ignore\n   * @return a {@link Set} with the file's words\n   */\n  public static Set<String> getWordSet(Class<?> aClass,\n      String stopwordResource, String comment) throws IOException {\n    final Reader reader = new BufferedReader(new InputStreamReader(aClass\n        .getResourceAsStream(stopwordResource), \"UTF-8\"));\n    try {\n      return getWordSet(reader, comment);\n    } finally {\n      reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a24f16e684000b5854634d7139339a792cc97927","date":1320888085,"type":4,"author":"Simon Willnauer","isMerge":false,"pathNew":"/dev/null","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/util/WordlistLoader#getWordSet(Class[#],String,String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Loads a text file associated with a given class (See\n   * {@link Class#getResourceAsStream(String)}) and adds every line as an entry\n   * to a {@link Set} (omitting leading and trailing whitespace). Every line of\n   * the file should contain only one word. The words need to be in lower-case if\n   * you make use of an Analyzer which uses LowerCaseFilter (like\n   * StandardAnalyzer).\n   * \n   * @param aClass\n   *          a class that is associated with the given stopwordResource\n   * @param stopwordResource\n   *          name of the resource file associated with the given class\n   * @param comment\n   *          the comment string to ignore\n   * @return a {@link Set} with the file's words\n   */\n  public static Set<String> getWordSet(Class<?> aClass,\n      String stopwordResource, String comment) throws IOException {\n    final Reader reader = new BufferedReader(new InputStreamReader(aClass\n        .getResourceAsStream(stopwordResource), \"UTF-8\"));\n    try {\n      return getWordSet(reader, comment);\n    } finally {\n      reader.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a24f16e684000b5854634d7139339a792cc97927":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a24f16e684000b5854634d7139339a792cc97927"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a24f16e684000b5854634d7139339a792cc97927":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["a24f16e684000b5854634d7139339a792cc97927"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}