{"path":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","commits":[{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      Configuration conf = new Configuration();\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      FileSystem fs;\n      try {\n        URI uri = new URI(hdfsUri);\n        fs = FileSystem.newInstance(uri, conf);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n      }\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c51d60d4f34c66a3ee711805d96a5fbe0a83740","date":1372986050,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","sourceNew":"  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      Configuration conf = new Configuration();\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      FileSystem fs;\n      try {\n        URI uri = new URI(hdfsUri);\n        fs = FileSystem.newInstance(uri, conf);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n      }\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a0c04b71951333291abc7f317109a6a5957bd28","date":1457097827,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","sourceNew":"  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c801a37c38aedbd2ddbd27f2aaeb30cd5c7af0f","date":1552317217,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bdf107cf16be0f22504ae184fed81596665a244","date":1576012524,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a229cb50768e988c50a2106bdae3a92154f428bf","date":1576051038,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1","date":1579200426,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      TestInjection.skipIndexWriterCommitOnClose = true;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n      \n      h.close();\n      \n\n      \n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.append(new Path(logDir, files[files.length-1]));\n    \n      dos.writeLong(0xffffffffffffffffL);\n      dos.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      dos.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7c51d60d4f34c66a3ee711805d96a5fbe0a83740":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2c801a37c38aedbd2ddbd27f2aaeb30cd5c7af0f":["3a0c04b71951333291abc7f317109a6a5957bd28"],"a229cb50768e988c50a2106bdae3a92154f428bf":["2c801a37c38aedbd2ddbd27f2aaeb30cd5c7af0f","6bdf107cf16be0f22504ae184fed81596665a244"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7c51d60d4f34c66a3ee711805d96a5fbe0a83740"],"6bdf107cf16be0f22504ae184fed81596665a244":["2c801a37c38aedbd2ddbd27f2aaeb30cd5c7af0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["6bdf107cf16be0f22504ae184fed81596665a244"],"3a0c04b71951333291abc7f317109a6a5957bd28":["7c51d60d4f34c66a3ee711805d96a5fbe0a83740"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"]},"commit2Childs":{"7c51d60d4f34c66a3ee711805d96a5fbe0a83740":["37a0f60745e53927c4c876cfe5b5a58170f0646c","3a0c04b71951333291abc7f317109a6a5957bd28"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["7c51d60d4f34c66a3ee711805d96a5fbe0a83740"],"2c801a37c38aedbd2ddbd27f2aaeb30cd5c7af0f":["a229cb50768e988c50a2106bdae3a92154f428bf","6bdf107cf16be0f22504ae184fed81596665a244"],"a229cb50768e988c50a2106bdae3a92154f428bf":[],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["849494cf2f3a96af5c8c84995108ddd8456fcd04","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"6bdf107cf16be0f22504ae184fed81596665a244":["a229cb50768e988c50a2106bdae3a92154f428bf","b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a0c04b71951333291abc7f317109a6a5957bd28":["2c801a37c38aedbd2ddbd27f2aaeb30cd5c7af0f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a229cb50768e988c50a2106bdae3a92154f428bf","37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}