{"path":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","commits":[{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","pathOld":"/dev/null","sourceNew":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      infoStream.println(\"\\ncloseDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["49adbad5232116eb2448ea8166464e6a68bca007"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b1405362241b561f5590ff4a87d5d6e173bcd9cf","date":1190107634,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","sourceNew":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      infoStream.println(\"\\ncloseDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      infoStream.println(\"\\ncloseDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"49adbad5232116eb2448ea8166464e6a68bca007","date":1202851885,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","sourceNew":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      infoStream.println(\"\\ncloseDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      infoStream.println(\"\\ncloseDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da3e8c2fef4ea558379c4c0879b3bcdecde41bcd","date":1206037293,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","sourceNew":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      infoStream.println(\"\\ncloseDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n        assert 4+numDocsInStore*16 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION):\n          \"after flush: tvx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n        assert numDocsInStore*8 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION):\n          \"after flush: fdx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      infoStream.println(\"\\ncloseDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84acdfa12c18361ff932244db20470fce117e52d","date":1206384355,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","sourceNew":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      message(\"closeDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n        assert 4+numDocsInStore*16 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION):\n          \"after flush: tvx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n        assert numDocsInStore*8 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION):\n          \"after flush: fdx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      infoStream.println(\"\\ncloseDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n        assert 4+numDocsInStore*16 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION):\n          \"after flush: tvx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n        assert numDocsInStore*8 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION):\n          \"after flush: fdx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4","date":1206538765,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","sourceNew":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      message(\"closeDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n        assert 4+numDocsInStore*16 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION):\n          \"after flush: tvx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n        assert 4+numDocsInStore*8 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION):\n          \"after flush: fdx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      message(\"closeDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n        assert 4+numDocsInStore*16 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION):\n          \"after flush: tvx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n        assert numDocsInStore*8 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION):\n          \"after flush: fdx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5350389bf83287111f7760b9e3db3af8e3648474","date":1216372812,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","sourceNew":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  synchronized String closeDocStore() throws IOException {\n    \n    assert allThreadsIdle();\n\n    if (infoStream != null)\n      message(\"closeDocStore: \" + openFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n    \n    boolean success = false;\n\n    try {\n      initFlushState(true);\n      closedFiles.clear();\n\n      consumer.closeDocStore(flushState);\n      assert 0 == openFiles.size();\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      success = true;\n      return s;\n    } finally {\n      if (!success) {\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  String closeDocStore() throws IOException {\n\n    assert allThreadsIdle();\n\n    List flushedFiles = files();\n\n    if (infoStream != null)\n      message(\"closeDocStore: \" + flushedFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n\n    if (flushedFiles.size() > 0) {\n      files = null;\n\n      if (tvx != null) {\n        // At least one doc in this run had term vectors enabled\n        assert docStoreSegment != null;\n        tvx.close();\n        tvf.close();\n        tvd.close();\n        tvx = null;\n        assert 4+numDocsInStore*16 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION):\n          \"after flush: tvx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.VECTORS_INDEX_EXTENSION;\n      }\n\n      if (fieldsWriter != null) {\n        assert docStoreSegment != null;\n        fieldsWriter.close();\n        fieldsWriter = null;\n        assert 4+numDocsInStore*8 == directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION):\n          \"after flush: fdx size mismatch: \" + numDocsInStore + \" docs vs \" + directory.fileLength(docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION) + \" length in bytes of \" + docStoreSegment + \".\" + IndexFileNames.FIELDS_INDEX_EXTENSION;\n      }\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      return s;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore().mjava","sourceNew":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  synchronized String closeDocStore() throws IOException {\n    \n    assert allThreadsIdle();\n\n    if (infoStream != null)\n      message(\"closeDocStore: \" + openFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n    \n    boolean success = false;\n\n    try {\n      initFlushState(true);\n      closedFiles.clear();\n\n      consumer.closeDocStore(flushState);\n      assert 0 == openFiles.size();\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      success = true;\n      return s;\n    } finally {\n      if (!success) {\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Closes the current open doc stores an returns the doc\n   *  store segment name.  This returns null if there are *\n   *  no buffered documents. */\n  synchronized String closeDocStore() throws IOException {\n    \n    assert allThreadsIdle();\n\n    if (infoStream != null)\n      message(\"closeDocStore: \" + openFiles.size() + \" files to flush to segment \" + docStoreSegment + \" numDocs=\" + numDocsInStore);\n    \n    boolean success = false;\n\n    try {\n      initFlushState(true);\n      closedFiles.clear();\n\n      consumer.closeDocStore(flushState);\n      assert 0 == openFiles.size();\n\n      String s = docStoreSegment;\n      docStoreSegment = null;\n      docStoreOffset = 0;\n      numDocsInStore = 0;\n      success = true;\n      return s;\n    } finally {\n      if (!success) {\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"49adbad5232116eb2448ea8166464e6a68bca007":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4":["84acdfa12c18361ff932244db20470fce117e52d"],"da3e8c2fef4ea558379c4c0879b3bcdecde41bcd":["49adbad5232116eb2448ea8166464e6a68bca007"],"5350389bf83287111f7760b9e3db3af8e3648474":["dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4"],"84acdfa12c18361ff932244db20470fce117e52d":["da3e8c2fef4ea558379c4c0879b3bcdecde41bcd"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["5350389bf83287111f7760b9e3db3af8e3648474"]},"commit2Childs":{"49adbad5232116eb2448ea8166464e6a68bca007":["da3e8c2fef4ea558379c4c0879b3bcdecde41bcd"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["49adbad5232116eb2448ea8166464e6a68bca007"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4":["5350389bf83287111f7760b9e3db3af8e3648474"],"da3e8c2fef4ea558379c4c0879b3bcdecde41bcd":["84acdfa12c18361ff932244db20470fce117e52d"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"84acdfa12c18361ff932244db20470fce117e52d":["dbb7b6f10bff9eedd5c9bc6cf9222ffbb2df74d4"],"5350389bf83287111f7760b9e3db3af8e3648474":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}