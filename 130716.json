{"path":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","commits":[{"id":"023adf1fcf97d9ed3f15d57669a8e116623d28bb","date":1226534503,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","pathOld":"/dev/null","sourceNew":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      CachingTokenFilter tokenStream = new CachingTokenFilter(analyzer\n          .tokenStream(FIELD_NAME, new StringReader(text)));\n      SpanScorer spanscorer = new SpanScorer(query, FIELD_NAME, tokenStream);\n      Highlighter highlighter = new Highlighter(this, spanscorer);\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(spanscorer, 5));\n      tokenStream.reset();\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n\n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      CachingTokenFilter tokenStream = new CachingTokenFilter(analyzer\n          .tokenStream(FIELD_NAME, new StringReader(text)));\n      SpanScorer spanscorer = new SpanScorer(query, FIELD_NAME, tokenStream);\n      Highlighter highlighter = new Highlighter(this, spanscorer);\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(spanscorer, 20));\n      tokenStream.reset();\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"943c3f9cf96b8df37f4273d66a66182e2a669467","date":1249394171,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","sourceNew":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      CachingTokenFilter tokenStream = new CachingTokenFilter(analyzer\n          .tokenStream(FIELD_NAME, new StringReader(text)));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      CachingTokenFilter tokenStream = new CachingTokenFilter(analyzer\n          .tokenStream(FIELD_NAME, new StringReader(text)));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","sourceOld":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      CachingTokenFilter tokenStream = new CachingTokenFilter(analyzer\n          .tokenStream(FIELD_NAME, new StringReader(text)));\n      SpanScorer spanscorer = new SpanScorer(query, FIELD_NAME, tokenStream);\n      Highlighter highlighter = new Highlighter(this, spanscorer);\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(spanscorer, 5));\n      tokenStream.reset();\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n\n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      CachingTokenFilter tokenStream = new CachingTokenFilter(analyzer\n          .tokenStream(FIELD_NAME, new StringReader(text)));\n      SpanScorer spanscorer = new SpanScorer(query, FIELD_NAME, tokenStream);\n      Highlighter highlighter = new Highlighter(this, spanscorer);\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(spanscorer, 20));\n      tokenStream.reset();\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c16ba100a31d292b7b4c893a3cdf1994e75a3201","date":1249608645,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","sourceNew":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","sourceOld":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      CachingTokenFilter tokenStream = new CachingTokenFilter(analyzer\n          .tokenStream(FIELD_NAME, new StringReader(text)));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      CachingTokenFilter tokenStream = new CachingTokenFilter(analyzer\n          .tokenStream(FIELD_NAME, new StringReader(text)));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f148c02ddd6ba981c65ca685d0e56c3a98368e1","date":1254892102,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","sourceNew":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","sourceOld":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.length(); i++) {\n      String text = hits.doc(i).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42607aa380c892dc1ec0ab26e86a575c28e13618","date":1268641604,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","sourceNew":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","sourceOld":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testSimpleSpanFragmenter().mjava","sourceNew":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","sourceOld":"  public void testSimpleSpanFragmenter() throws Exception {\n    doSearching(\"\\\"piece of text that is very long\\\"\");\n\n    int maxNumFragmentsRequired = 2;\n\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(this, scorer);\n    \n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 5));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n\n    }\n    \n    doSearching(\"\\\"been shot\\\"\");\n\n    maxNumFragmentsRequired = 2;\n    \n    scorer = new QueryScorer(query, FIELD_NAME);\n    highlighter = new Highlighter(this, scorer);\n\n    for (int i = 0; i < hits.totalHits; i++) {\n      String text = searcher.doc(hits.scoreDocs[i].doc).get(FIELD_NAME);\n      TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));\n\n      highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer, 20));\n\n      String result = highlighter.getBestFragments(tokenStream, text,\n          maxNumFragmentsRequired, \"...\");\n      if (VERBOSE) System.out.println(\"\\t\" + result);\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c16ba100a31d292b7b4c893a3cdf1994e75a3201":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"023adf1fcf97d9ed3f15d57669a8e116623d28bb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"42607aa380c892dc1ec0ab26e86a575c28e13618":["0f148c02ddd6ba981c65ca685d0e56c3a98368e1"],"0f148c02ddd6ba981c65ca685d0e56c3a98368e1":["c16ba100a31d292b7b4c893a3cdf1994e75a3201"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["023adf1fcf97d9ed3f15d57669a8e116623d28bb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["42607aa380c892dc1ec0ab26e86a575c28e13618"]},"commit2Childs":{"c16ba100a31d292b7b4c893a3cdf1994e75a3201":["0f148c02ddd6ba981c65ca685d0e56c3a98368e1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["023adf1fcf97d9ed3f15d57669a8e116623d28bb"],"023adf1fcf97d9ed3f15d57669a8e116623d28bb":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"42607aa380c892dc1ec0ab26e86a575c28e13618":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0f148c02ddd6ba981c65ca685d0e56c3a98368e1":["42607aa380c892dc1ec0ab26e86a575c28e13618"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["c16ba100a31d292b7b4c893a3cdf1994e75a3201"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}