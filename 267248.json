{"path":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","commits":[{"id":"c5c99ad021f3da085fcb66220598a8f91dc5e453","date":1462242046,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    // note: we assume a shared files system to backup a collection, since a collection is distributed\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n\n    //Validating if the directory already exists.\n    if (Files.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Backup directory already exists: \" + backupPath);\n    }\n    Files.createDirectory(backupPath); // create now\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(\"location\", backupPath.toString()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    Path zkBackup =  backupPath.resolve(\"zk_backup\");\n    zkStateReader.getConfigManager().downloadConfigDir(configName, zkBackup.resolve(\"configs\").resolve(configName));\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n    Files.write(zkBackup.resolve(\"collection_state.json\"),\n        Utils.toJSON(Collections.singletonMap(collectionName, collection)));\n\n    Path propertiesPath = backupPath.resolve(\"backup.properties\");\n    Properties properties = new Properties();\n\n    properties.put(\"backupName\", backupName);\n    properties.put(\"collection\", collectionName);\n    properties.put(\"collection.configName\", configName);\n    properties.put(\"startTime\", startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    try (Writer os = Files.newBufferedWriter(propertiesPath, StandardCharsets.UTF_8)) {\n      properties.store(os, \"Snapshot properties file\");\n    }\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c7a21395bae9e2f61aeb639f47aaca771c426ed","date":1462255690,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    // note: we assume a shared files system to backup a collection, since a collection is distributed\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n\n    //Validating if the directory already exists.\n    if (Files.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Backup directory already exists: \" + backupPath);\n    }\n    Files.createDirectory(backupPath); // create now\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(\"location\", backupPath.toString()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    Path zkBackup =  backupPath.resolve(\"zk_backup\");\n    zkStateReader.getConfigManager().downloadConfigDir(configName, zkBackup.resolve(\"configs\").resolve(configName));\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n    Files.write(zkBackup.resolve(\"collection_state.json\"),\n        Utils.toJSON(Collections.singletonMap(collectionName, collection)));\n\n    Path propertiesPath = backupPath.resolve(\"backup.properties\");\n    Properties properties = new Properties();\n\n    properties.put(\"backupName\", backupName);\n    properties.put(\"collection\", collectionName);\n    properties.put(\"collection.configName\", configName);\n    properties.put(\"startTime\", startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    try (Writer os = Files.newBufferedWriter(propertiesPath, StandardCharsets.UTF_8)) {\n      properties.store(os, \"Snapshot properties file\");\n    }\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55b50463286869f584cf849d1587a0fcd54d1dfa","date":1462378517,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    // note: we assume a shared files system to backup a collection, since a collection is distributed\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n\n    //Validating if the directory already exists.\n    if (Files.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Backup directory already exists: \" + backupPath);\n    }\n    Files.createDirectory(backupPath); // create now\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(\"location\", backupPath.toString()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    Path zkBackup =  backupPath.resolve(\"zk_backup\");\n    zkStateReader.getConfigManager().downloadConfigDir(configName, zkBackup.resolve(\"configs\").resolve(configName));\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n    Files.write(zkBackup.resolve(\"collection_state.json\"),\n        Utils.toJSON(Collections.singletonMap(collectionName, collection)));\n\n    Path propertiesPath = backupPath.resolve(\"backup.properties\");\n    Properties properties = new Properties();\n\n    properties.put(\"backupName\", backupName);\n    properties.put(\"collection\", collectionName);\n    properties.put(\"collection.configName\", configName);\n    properties.put(\"startTime\", startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    try (Writer os = Files.newBufferedWriter(propertiesPath, StandardCharsets.UTF_8)) {\n      properties.store(os, \"Snapshot properties file\");\n    }\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","date":1466705968,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","sourceNew":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    String location = message.getStr(ZkStateReader.BACKUP_LOCATION);\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    // note: we assume a shared files system to backup a collection, since a collection is distributed\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n\n    //Validating if the directory already exists.\n    if (Files.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Backup directory already exists: \" + backupPath);\n    }\n    Files.createDirectory(backupPath); // create now\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(\"location\", backupPath.toString()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    Path zkBackup =  backupPath.resolve(\"zk_backup\");\n    zkStateReader.getConfigManager().downloadConfigDir(configName, zkBackup.resolve(\"configs\").resolve(configName));\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n    Files.write(zkBackup.resolve(\"collection_state.json\"),\n        Utils.toJSON(Collections.singletonMap(collectionName, collection)));\n\n    Path propertiesPath = backupPath.resolve(\"backup.properties\");\n    Properties properties = new Properties();\n\n    properties.put(\"backupName\", backupName);\n    properties.put(\"collection\", collectionName);\n    properties.put(\"collection.configName\", configName);\n    properties.put(\"startTime\", startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    try (Writer os = Files.newBufferedWriter(propertiesPath, StandardCharsets.UTF_8)) {\n      properties.store(os, \"Snapshot properties file\");\n    }\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","sourceOld":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    // note: we assume a shared files system to backup a collection, since a collection is distributed\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n\n    //Validating if the directory already exists.\n    if (Files.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Backup directory already exists: \" + backupPath);\n    }\n    Files.createDirectory(backupPath); // create now\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(\"location\", backupPath.toString()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    Path zkBackup =  backupPath.resolve(\"zk_backup\");\n    zkStateReader.getConfigManager().downloadConfigDir(configName, zkBackup.resolve(\"configs\").resolve(configName));\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n    Files.write(zkBackup.resolve(\"collection_state.json\"),\n        Utils.toJSON(Collections.singletonMap(collectionName, collection)));\n\n    Path propertiesPath = backupPath.resolve(\"backup.properties\");\n    Properties properties = new Properties();\n\n    properties.put(\"backupName\", backupName);\n    properties.put(\"collection\", collectionName);\n    properties.put(\"collection.configName\", configName);\n    properties.put(\"startTime\", startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    try (Writer os = Files.newBufferedWriter(propertiesPath, StandardCharsets.UTF_8)) {\n      properties.store(os, \"Snapshot properties file\");\n    }\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c623a7f72be34d6c45bee682028c50327d9e4b7","date":1467791293,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","sourceNew":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, collectionName);\n\n    // Backup location\n    URI backupPath = repository.createURI(location, backupName);\n\n    //Validating if the directory already exists.\n    if (repository.exists(backupPath)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"The backup directory already exists: \" + backupPath);\n    }\n\n    // Create a directory to store backup details.\n    repository.createDirectory(backupPath);\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    backupMgr.downloadConfigDir(location, backupName, configName);\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collectionState = zkStateReader.getClusterState().getCollection(collectionName);\n    backupMgr.writeCollectionState(location, backupName, collectionName, collectionState);\n\n    Properties properties = new Properties();\n\n    properties.put(BackupManager.BACKUP_NAME_PROP, backupName);\n    properties.put(BackupManager.COLLECTION_NAME_PROP, collectionName);\n    properties.put(COLL_CONF, configName);\n    properties.put(BackupManager.START_TIME_PROP, startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    backupMgr.writeBackupProperties(location, backupName, properties);\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","sourceOld":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    String location = message.getStr(ZkStateReader.BACKUP_LOCATION);\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    // note: we assume a shared files system to backup a collection, since a collection is distributed\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n\n    //Validating if the directory already exists.\n    if (Files.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Backup directory already exists: \" + backupPath);\n    }\n    Files.createDirectory(backupPath); // create now\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(\"location\", backupPath.toString()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    Path zkBackup =  backupPath.resolve(\"zk_backup\");\n    zkStateReader.getConfigManager().downloadConfigDir(configName, zkBackup.resolve(\"configs\").resolve(configName));\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n    Files.write(zkBackup.resolve(\"collection_state.json\"),\n        Utils.toJSON(Collections.singletonMap(collectionName, collection)));\n\n    Path propertiesPath = backupPath.resolve(\"backup.properties\");\n    Properties properties = new Properties();\n\n    properties.put(\"backupName\", backupName);\n    properties.put(\"collection\", collectionName);\n    properties.put(\"collection.configName\", configName);\n    properties.put(\"startTime\", startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    try (Writer os = Files.newBufferedWriter(propertiesPath, StandardCharsets.UTF_8)) {\n      properties.store(os, \"Snapshot properties file\");\n    }\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","bugFix":null,"bugIntro":["af3193c66df8e8324d4bce9f66df967af9e8c602","af3193c66df8e8324d4bce9f66df967af9e8c602"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","date":1471585465,"type":5,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/BackupCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME);\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n    BackupManager backupMgr = new BackupManager(repository, ocmh.zkStateReader, collectionName);\n\n    // Backup location\n    URI backupPath = repository.createURI(location, backupName);\n\n    //Validating if the directory already exists.\n    if (repository.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The backup directory already exists: \" + backupPath);\n    }\n\n    // Create a directory to store backup details.\n    repository.createDirectory(backupPath);\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : ocmh.zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      ocmh.sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    ocmh.processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = ocmh.zkStateReader.readConfigName(collectionName);\n    backupMgr.downloadConfigDir(location, backupName, configName);\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collectionState = ocmh.zkStateReader.getClusterState().getCollection(collectionName);\n    backupMgr.writeCollectionState(location, backupName, collectionName, collectionState);\n\n    Properties properties = new Properties();\n\n    properties.put(BackupManager.BACKUP_NAME_PROP, backupName);\n    properties.put(BackupManager.COLLECTION_NAME_PROP, collectionName);\n    properties.put(COLL_CONF, configName);\n    properties.put(BackupManager.START_TIME_PROP, startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    backupMgr.writeBackupProperties(location, backupName, properties);\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","sourceOld":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, collectionName);\n\n    // Backup location\n    URI backupPath = repository.createURI(location, backupName);\n\n    //Validating if the directory already exists.\n    if (repository.exists(backupPath)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"The backup directory already exists: \" + backupPath);\n    }\n\n    // Create a directory to store backup details.\n    repository.createDirectory(backupPath);\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    backupMgr.downloadConfigDir(location, backupName, configName);\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collectionState = zkStateReader.getClusterState().getCollection(collectionName);\n    backupMgr.writeCollectionState(location, backupName, collectionName, collectionState);\n\n    Properties properties = new Properties();\n\n    properties.put(BackupManager.BACKUP_NAME_PROP, backupName);\n    properties.put(BackupManager.COLLECTION_NAME_PROP, collectionName);\n    properties.put(COLL_CONF, configName);\n    properties.put(BackupManager.START_TIME_PROP, startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    backupMgr.writeBackupProperties(location, backupName, properties);\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/BackupCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME);\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n    BackupManager backupMgr = new BackupManager(repository, ocmh.zkStateReader, collectionName);\n\n    // Backup location\n    URI backupPath = repository.createURI(location, backupName);\n\n    //Validating if the directory already exists.\n    if (repository.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The backup directory already exists: \" + backupPath);\n    }\n\n    // Create a directory to store backup details.\n    repository.createDirectory(backupPath);\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : ocmh.zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      ocmh.sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    ocmh.processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = ocmh.zkStateReader.readConfigName(collectionName);\n    backupMgr.downloadConfigDir(location, backupName, configName);\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collectionState = ocmh.zkStateReader.getClusterState().getCollection(collectionName);\n    backupMgr.writeCollectionState(location, backupName, collectionName, collectionState);\n\n    Properties properties = new Properties();\n\n    properties.put(BackupManager.BACKUP_NAME_PROP, backupName);\n    properties.put(BackupManager.COLLECTION_NAME_PROP, collectionName);\n    properties.put(COLL_CONF, configName);\n    properties.put(BackupManager.START_TIME_PROP, startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    backupMgr.writeBackupProperties(location, backupName, properties);\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","sourceOld":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, collectionName);\n\n    // Backup location\n    URI backupPath = repository.createURI(location, backupName);\n\n    //Validating if the directory already exists.\n    if (repository.exists(backupPath)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"The backup directory already exists: \" + backupPath);\n    }\n\n    // Create a directory to store backup details.\n    repository.createDirectory(backupPath);\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    backupMgr.downloadConfigDir(location, backupName, configName);\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collectionState = zkStateReader.getClusterState().getCollection(collectionName);\n    backupMgr.writeCollectionState(location, backupName, collectionName, collectionState);\n\n    Properties properties = new Properties();\n\n    properties.put(BackupManager.BACKUP_NAME_PROP, backupName);\n    properties.put(BackupManager.COLLECTION_NAME_PROP, collectionName);\n    properties.put(COLL_CONF, configName);\n    properties.put(BackupManager.START_TIME_PROP, startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    backupMgr.writeBackupProperties(location, backupName, properties);\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processBackupAction(ZkNodeProps,NamedList).mjava","sourceNew":null,"sourceOld":"  private void processBackupAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    String collectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME);\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n    Instant startTime = Instant.now();\n\n    // note: we assume a shared files system to backup a collection, since a collection is distributed\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n\n    //Validating if the directory already exists.\n    if (Files.exists(backupPath)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Backup directory already exists: \" + backupPath);\n    }\n    Files.createDirectory(backupPath); // create now\n\n    log.info(\"Starting backup of collection={} with backupName={} at location={}\", collectionName, backupName,\n        backupPath);\n\n    for (Slice slice : zkStateReader.getClusterState().getCollection(collectionName).getActiveSlices()) {\n      Replica replica = slice.getLeader();\n\n      String coreName = replica.getStr(CORE_NAME_PROP);\n\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.BACKUPCORE.toString());\n      params.set(NAME, slice.getName());\n      params.set(\"location\", backupPath.toString()); // note: index dir will be here then the \"snapshot.\" + slice name\n      params.set(CORE_NAME_PROP, coreName);\n\n      sendShardRequest(replica.getNodeName(), params, shardHandler, asyncId, requestMap);\n      log.debug(\"Sent backup request to core={} for backupName={}\", coreName, backupName);\n    }\n    log.debug(\"Sent backup requests to all shard leaders for backupName={}\", backupName);\n\n    processResponses(results, shardHandler, true, \"Could not backup all replicas\", asyncId, requestMap);\n\n    log.info(\"Starting to backup ZK data for backupName={}\", backupName);\n\n    //Download the configs\n    String configName = zkStateReader.readConfigName(collectionName);\n    Path zkBackup =  backupPath.resolve(\"zk_backup\");\n    zkStateReader.getConfigManager().downloadConfigDir(configName, zkBackup.resolve(\"configs\").resolve(configName));\n\n    //Save the collection's state. Can be part of the monolithic clusterstate.json or a individual state.json\n    //Since we don't want to distinguish we extract the state and back it up as a separate json\n    DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n    Files.write(zkBackup.resolve(\"collection_state.json\"),\n        Utils.toJSON(Collections.singletonMap(collectionName, collection)));\n\n    Path propertiesPath = backupPath.resolve(\"backup.properties\");\n    Properties properties = new Properties();\n\n    properties.put(\"backupName\", backupName);\n    properties.put(\"collection\", collectionName);\n    properties.put(\"collection.configName\", configName);\n    properties.put(\"startTime\", startTime.toString());\n    //TODO: Add MD5 of the configset. If during restore the same name configset exists then we can compare checksums to see if they are the same.\n    //if they are not the same then we can throw an error or have an 'overwriteConfig' flag\n    //TODO save numDocs for the shardLeader. We can use it to sanity check the restore.\n\n    try (Writer os = Files.newBufferedWriter(propertiesPath, StandardCharsets.UTF_8)) {\n      properties.store(os, \"Snapshot properties file\");\n    }\n\n    log.info(\"Completed backing up ZK data for backupName={}\", backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4c623a7f72be34d6c45bee682028c50327d9e4b7":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"],"c5c99ad021f3da085fcb66220598a8f91dc5e453":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4c623a7f72be34d6c45bee682028c50327d9e4b7","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["1c7a21395bae9e2f61aeb639f47aaca771c426ed"],"1c7a21395bae9e2f61aeb639f47aaca771c426ed":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c5c99ad021f3da085fcb66220598a8f91dc5e453"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["4c623a7f72be34d6c45bee682028c50327d9e4b7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["55b50463286869f584cf849d1587a0fcd54d1dfa","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"55b50463286869f584cf849d1587a0fcd54d1dfa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1c7a21395bae9e2f61aeb639f47aaca771c426ed"]},"commit2Childs":{"4c623a7f72be34d6c45bee682028c50327d9e4b7":["403d05f7f8d69b65659157eff1bc1d2717f04c66","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"c5c99ad021f3da085fcb66220598a8f91dc5e453":["1c7a21395bae9e2f61aeb639f47aaca771c426ed"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["4c623a7f72be34d6c45bee682028c50327d9e4b7"],"1c7a21395bae9e2f61aeb639f47aaca771c426ed":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","55b50463286869f584cf849d1587a0fcd54d1dfa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c5c99ad021f3da085fcb66220598a8f91dc5e453","1c7a21395bae9e2f61aeb639f47aaca771c426ed","55b50463286869f584cf849d1587a0fcd54d1dfa"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"55b50463286869f584cf849d1587a0fcd54d1dfa":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}