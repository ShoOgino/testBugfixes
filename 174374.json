{"path":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","commits":[{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,int,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, int readBufferSize, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.readBufferSize = readBufferSize;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, readBufferSize, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"67aadace85f701c87a4e0721eedcda25d8415a70","date":1314201925,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = dir.openCompoundInput(IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final SegmentCodecs segmentCodecs = si.getSegmentCodecs();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final Codec codec = segmentCodecs.codec();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = codec.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"11f75174865a8734695cd60a4093339a4e63fcbb","date":1323039567,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms\n      norms = codec.normsFormat().normsReader(cfsDir, si, fieldInfos, context, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc61a492eb4d507139c1e134e26eb7b1b005d586","date":1323049530,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().normsReader(cfsDir, si, fieldInfos, context, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms\n      norms = codec.normsFormat().normsReader(cfsDir, si, fieldInfos, context, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().normsReader(cfsDir, si, fieldInfos, context, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().normsReader(cfsDir, si, fieldInfos, context, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ce667c6d3400b22523701c549c0d35e26da8b46","date":1324405053,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().normsReader(cfsDir, si, fieldInfos, context, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n\n      final Directory storeDir;\n      if (si.getDocStoreOffset() != -1) {\n        if (si.getDocStoreIsCompoundFile()) {\n          storeCFSReader = new CompoundFileDirectory(dir,\n              IndexFileNames.segmentFileName(si.getDocStoreSegment(), \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n              context, false);\n          storeDir = storeCFSReader;\n          assert storeDir != null;\n        } else {\n          storeCFSReader = null;\n          storeDir = dir;\n          assert storeDir != null;\n        }\n      } else if (si.getUseCompoundFile()) {\n        storeDir = cfsReader;\n        storeCFSReader = null;\n        assert storeDir != null;\n      } else {\n        storeDir = dir;\n        storeCFSReader = null;\n        assert storeDir != null;\n      }\n      \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(storeDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(storeDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().normsReader(cfsDir, si, fieldInfos, context, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6e3376a314fcc2b31bc46d399c2ff23552b78d6","date":1325780477,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n\n      final Directory storeDir;\n      if (si.getDocStoreOffset() != -1) {\n        if (si.getDocStoreIsCompoundFile()) {\n          storeCFSReader = new CompoundFileDirectory(dir,\n              IndexFileNames.segmentFileName(si.getDocStoreSegment(), \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n              context, false);\n          storeDir = storeCFSReader;\n          assert storeDir != null;\n        } else {\n          storeCFSReader = null;\n          storeDir = dir;\n          assert storeDir != null;\n        }\n      } else if (si.getUseCompoundFile()) {\n        storeDir = cfsReader;\n        storeCFSReader = null;\n        assert storeDir != null;\n      } else {\n        storeDir = dir;\n        storeCFSReader = null;\n        assert storeDir != null;\n      }\n      \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(storeDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(storeDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().normsReader(cfsDir, si, fieldInfos, context, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n\n      final Directory storeDir;\n      if (si.getDocStoreOffset() != -1) {\n        if (si.getDocStoreIsCompoundFile()) {\n          storeCFSReader = new CompoundFileDirectory(dir,\n              IndexFileNames.segmentFileName(si.getDocStoreSegment(), \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n              context, false);\n          storeDir = storeCFSReader;\n          assert storeDir != null;\n        } else {\n          storeCFSReader = null;\n          storeDir = dir;\n          assert storeDir != null;\n        }\n      } else if (si.getUseCompoundFile()) {\n        storeDir = cfsReader;\n        storeCFSReader = null;\n        assert storeDir != null;\n      } else {\n        storeDir = dir;\n        storeCFSReader = null;\n        assert storeDir != null;\n      }\n      \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(storeDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(storeDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6aefa60f1ef9bec0dd4a76a2a23df98e2837a418","date":1327839887,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n\n      final Directory storeDir;\n      if (si.getDocStoreOffset() != -1) {\n        if (si.getDocStoreIsCompoundFile()) {\n          storeCFSReader = new CompoundFileDirectory(dir,\n              IndexFileNames.segmentFileName(si.getDocStoreSegment(), \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n              context, false);\n          storeDir = storeCFSReader;\n          assert storeDir != null;\n        } else {\n          storeCFSReader = null;\n          storeDir = dir;\n          assert storeDir != null;\n        }\n      } else if (si.getUseCompoundFile()) {\n        storeDir = cfsReader;\n        storeCFSReader = null;\n        assert storeDir != null;\n      } else {\n        storeDir = dir;\n        storeCFSReader = null;\n        assert storeDir != null;\n      }\n      \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(storeDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(storeDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n\n      final Directory storeDir;\n      if (si.getDocStoreOffset() != -1) {\n        if (si.getDocStoreIsCompoundFile()) {\n          storeCFSReader = new CompoundFileDirectory(dir,\n              IndexFileNames.segmentFileName(si.getDocStoreSegment(), \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n              context, false);\n          storeDir = storeCFSReader;\n          assert storeDir != null;\n        } else {\n          storeCFSReader = null;\n          storeDir = dir;\n          assert storeDir != null;\n        }\n      } else if (si.getUseCompoundFile()) {\n        storeDir = cfsReader;\n        storeCFSReader = null;\n        assert storeDir != null;\n      } else {\n        storeDir = dir;\n        storeCFSReader = null;\n        assert storeDir != null;\n      }\n      \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(storeDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(storeDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"09cced0ffd4d11eee37ef7655cc4096103909122","date":1327939357,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n\n      final Directory storeDir;\n      if (si.getDocStoreOffset() != -1) {\n        if (si.getDocStoreIsCompoundFile()) {\n          storeCFSReader = new CompoundFileDirectory(dir,\n              IndexFileNames.segmentFileName(si.getDocStoreSegment(), \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n              context, false);\n          storeDir = storeCFSReader;\n          assert storeDir != null;\n        } else {\n          storeCFSReader = null;\n          storeDir = dir;\n          assert storeDir != null;\n        }\n      } else if (si.getUseCompoundFile()) {\n        storeDir = cfsReader;\n        storeCFSReader = null;\n        assert storeDir != null;\n      } else {\n        storeDir = dir;\n        storeCFSReader = null;\n        assert storeDir != null;\n      }\n      \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(storeDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(storeDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8a7c31f59586d5869ce6b3a47f84c8875711d5d2","date":1327941530,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    \n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"acd6a6fbd39f77d10a24d0462322299f8066b025","date":1327941655,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    \n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"296df632fd63421ea20756fa11ad36fbc6f4c8a9","date":1327957998,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n\n      final Directory storeDir;\n      if (si.getDocStoreOffset() != -1) {\n        if (si.getDocStoreIsCompoundFile()) {\n          storeCFSReader = new CompoundFileDirectory(dir,\n              IndexFileNames.segmentFileName(si.getDocStoreSegment(), \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n              context, false);\n          storeDir = storeCFSReader;\n          assert storeDir != null;\n        } else {\n          storeCFSReader = null;\n          storeDir = dir;\n          assert storeDir != null;\n        }\n      } else if (si.getUseCompoundFile()) {\n        storeDir = cfsReader;\n        storeCFSReader = null;\n        assert storeDir != null;\n      } else {\n        storeDir = dir;\n        storeCFSReader = null;\n        assert storeDir != null;\n      }\n      \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(storeDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(storeDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"410e066f093e407222d9681429d209084e783149","date":1327958394,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    segment = si.name;\n    final Codec codec = si.getCodec();\n    this.context = context;\n    this.dir = dir;\n    \n    boolean success = false;\n    \n    try {\n      Directory dir0 = dir;\n      if (si.getUseCompoundFile()) {\n        cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(segment, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n        dir0 = cfsReader;\n      } else {\n        cfsReader = null;\n      }\n      cfsDir = dir0;\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState, dir);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n\n      final Directory storeDir;\n      if (si.getDocStoreOffset() != -1) {\n        if (si.getDocStoreIsCompoundFile()) {\n          storeCFSReader = new CompoundFileDirectory(dir,\n              IndexFileNames.segmentFileName(si.getDocStoreSegment(), \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n              context, false);\n          storeDir = storeCFSReader;\n          assert storeDir != null;\n        } else {\n          storeCFSReader = null;\n          storeDir = dir;\n          assert storeDir != null;\n        }\n      } else if (si.getUseCompoundFile()) {\n        storeDir = cfsReader;\n        storeCFSReader = null;\n        assert storeDir != null;\n      } else {\n        storeDir = dir;\n        storeCFSReader = null;\n        assert storeDir != null;\n      }\n      \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(storeDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(storeDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"67aadace85f701c87a4e0721eedcda25d8415a70":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"11f75174865a8734695cd60a4093339a4e63fcbb":["7b91922b55d15444d554721b352861d028eb8278"],"410e066f093e407222d9681429d209084e783149":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["7b91922b55d15444d554721b352861d028eb8278","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"6aefa60f1ef9bec0dd4a76a2a23df98e2837a418":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6"],"09cced0ffd4d11eee37ef7655cc4096103909122":["6aefa60f1ef9bec0dd4a76a2a23df98e2837a418"],"8a7c31f59586d5869ce6b3a47f84c8875711d5d2":["09cced0ffd4d11eee37ef7655cc4096103909122"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bc61a492eb4d507139c1e134e26eb7b1b005d586":["11f75174865a8734695cd60a4093339a4e63fcbb"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6","acd6a6fbd39f77d10a24d0462322299f8066b025"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"acd6a6fbd39f77d10a24d0462322299f8066b025":["8a7c31f59586d5869ce6b3a47f84c8875711d5d2"],"7b91922b55d15444d554721b352861d028eb8278":["67aadace85f701c87a4e0721eedcda25d8415a70"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["7b91922b55d15444d554721b352861d028eb8278","bc61a492eb4d507139c1e134e26eb7b1b005d586"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"f6e3376a314fcc2b31bc46d399c2ff23552b78d6":["9ce667c6d3400b22523701c549c0d35e26da8b46"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"67aadace85f701c87a4e0721eedcda25d8415a70":["7b91922b55d15444d554721b352861d028eb8278"],"11f75174865a8734695cd60a4093339a4e63fcbb":["bc61a492eb4d507139c1e134e26eb7b1b005d586"],"410e066f093e407222d9681429d209084e783149":[],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6aefa60f1ef9bec0dd4a76a2a23df98e2837a418":["09cced0ffd4d11eee37ef7655cc4096103909122"],"09cced0ffd4d11eee37ef7655cc4096103909122":["8a7c31f59586d5869ce6b3a47f84c8875711d5d2"],"8a7c31f59586d5869ce6b3a47f84c8875711d5d2":["acd6a6fbd39f77d10a24d0462322299f8066b025"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["d083e83f225b11e5fdd900e83d26ddb385b6955c"],"bc61a492eb4d507139c1e134e26eb7b1b005d586":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["410e066f093e407222d9681429d209084e783149","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"acd6a6fbd39f77d10a24d0462322299f8066b025":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"7b91922b55d15444d554721b352861d028eb8278":["11f75174865a8734695cd60a4093339a4e63fcbb","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","d083e83f225b11e5fdd900e83d26ddb385b6955c","5d004d0e0b3f65bb40da76d476d659d7888270e8","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","9ce667c6d3400b22523701c549c0d35e26da8b46"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["67aadace85f701c87a4e0721eedcda25d8415a70","5d004d0e0b3f65bb40da76d476d659d7888270e8"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6"],"f6e3376a314fcc2b31bc46d399c2ff23552b78d6":["410e066f093e407222d9681429d209084e783149","6aefa60f1ef9bec0dd4a76a2a23df98e2837a418","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["410e066f093e407222d9681429d209084e783149","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}