{"path":"lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","commits":[{"id":"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","date":1465936684,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer#incrementToken().mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   *\n   * @see org.apache.lucene.analysis.TokenStream#next()\n   */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    skippedPositions = 0;\n\n    while(true) {\n      int tokenType = scanner.getNextToken();\n\n      if (tokenType == StandardTokenizerImpl.YYEOF) {\n        return false;\n      }\n\n      if (scanner.yylength() <= maxTokenLength) {\n        posIncrAtt.setPositionIncrement(skippedPositions+1);\n        scanner.getText(termAtt);\n        final int start = scanner.yychar();\n        offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));\n        typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);\n        return true;\n      } else\n        // When we skip a too-long term, we still increment the\n        // position increment\n        skippedPositions++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b266fe0ac2172d4ad87cff12bd9bf9f8c8247345"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b266fe0ac2172d4ad87cff12bd9bf9f8c8247345","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"b266fe0ac2172d4ad87cff12bd9bf9f8c8247345":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}