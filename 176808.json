{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final TermAttribute termAtt = addAttribute(TermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.setTermBuffer( terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final TermAttribute termAtt = addAttribute(TermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.setTermBuffer( terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a775c547c3519b47efd41c09cb47100ddb9604c7","date":1270914087,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final TermAttribute termAtt = addAttribute(TermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.setTermBuffer( terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28427ef110c4c5bf5b4057731b83110bd1e13724","date":1276701452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = newDirectory(random);\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory(random);\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = newDirectory(random);\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory(random);\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a6c7b564e6275fb0c0e137d84fda55b447c19d9c","date":1286438356,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a13a126d15299d5c1e117ea99ddae6fb0fa3f209","date":1291909583,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocsEnum.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getDeletedDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3a0403b45dfe384fae4a1b6e96c3265d000c498","date":1321445981,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir, false);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir, false);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir, false);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir, false);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    s.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31f025ae60076ae95274433f3fe8e6ace2857a87","date":1326669465,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"));\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["31f025ae60076ae95274433f3fe8e6ace2857a87"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5f4e87790277826a2aea119328600dfb07761f32","a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"a775c547c3519b47efd41c09cb47100ddb9604c7":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["d572389229127c297dd1fa5ce4758e1cec41e799"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["28427ef110c4c5bf5b4057731b83110bd1e13724"],"a6c7b564e6275fb0c0e137d84fda55b447c19d9c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"31f025ae60076ae95274433f3fe8e6ace2857a87":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a13a126d15299d5c1e117ea99ddae6fb0fa3f209":["a6c7b564e6275fb0c0e137d84fda55b447c19d9c"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"d572389229127c297dd1fa5ce4758e1cec41e799":["a775c547c3519b47efd41c09cb47100ddb9604c7"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["f2c5f0cb44df114db4228c8f77861714b5cabaea","962d04139994fce5193143ef35615499a9a96d78"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["a6c7b564e6275fb0c0e137d84fda55b447c19d9c","a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"5f4e87790277826a2aea119328600dfb07761f32":["d572389229127c297dd1fa5ce4758e1cec41e799","28427ef110c4c5bf5b4057731b83110bd1e13724"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["79c2cb24929f2649a8875fb629086171f914d5ce","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a13a126d15299d5c1e117ea99ddae6fb0fa3f209","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["1509f151d7692d84fae414b2b799ac06ba60fcb4","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"a775c547c3519b47efd41c09cb47100ddb9604c7":["d572389229127c297dd1fa5ce4758e1cec41e799"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","962d04139994fce5193143ef35615499a9a96d78"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","31f025ae60076ae95274433f3fe8e6ace2857a87"],"79c2cb24929f2649a8875fb629086171f914d5ce":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a6c7b564e6275fb0c0e137d84fda55b447c19d9c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"28427ef110c4c5bf5b4057731b83110bd1e13724":["b21422ff1d1d56499dec481f193b402e5e8def5b","5f4e87790277826a2aea119328600dfb07761f32"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","1c5b026d03cbbb03ca4c0b97d14e9839682281dc","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a6c7b564e6275fb0c0e137d84fda55b447c19d9c":["a13a126d15299d5c1e117ea99ddae6fb0fa3f209","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"31f025ae60076ae95274433f3fe8e6ace2857a87":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a775c547c3519b47efd41c09cb47100ddb9604c7"],"a13a126d15299d5c1e117ea99ddae6fb0fa3f209":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","ab5cb6a74aefb78aa0569857970b9151dfe2e787","a3776dccca01c11e7046323cfad46a3b4a471233"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","79c2cb24929f2649a8875fb629086171f914d5ce","d083e83f225b11e5fdd900e83d26ddb385b6955c","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a05409176bd65129d67a785ee70e881e238a9aef"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"d572389229127c297dd1fa5ce4758e1cec41e799":["28427ef110c4c5bf5b4057731b83110bd1e13724","5f4e87790277826a2aea119328600dfb07761f32"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"5f4e87790277826a2aea119328600dfb07761f32":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"962d04139994fce5193143ef35615499a9a96d78":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}