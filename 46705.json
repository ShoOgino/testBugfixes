{"path":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","commits":[{"id":"6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7","date":1092245915,"type":1,"author":"Christoph Goller","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile().mjava","sourceNew":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Field norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final void createCompoundFile()\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, segment + \".cfs\");\n\n    ArrayList files =\n      new ArrayList(COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Field norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n        \n    // Now delete the source files\n    it = files.iterator();\n    while (it.hasNext()) {\n      directory.deleteFile((String) it.next());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24157515079eea65faeec4e1dbb01fea58444c8e","date":1118343636,"type":3,"author":"Bernhard Messer","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + IndexFileNames.COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Field norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Field norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"950f3c7592cb559e2534e5089c78833250e156a3","date":1130557968,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + IndexFileNames.COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Field norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + IndexFileNames.COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Field norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"12d40284fd9481f79444bc63bc5d13847caddd3d","date":1149902602,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + IndexFileNames.COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + IndexFileNames.COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Field norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8969a184df55d25d61e85be785987fbf830d4028","date":1168143561,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + IndexFileNames.COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + fieldInfos.size());    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + IndexFileNames.COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".f\" + i);\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      files.add(segment + \".\" + IndexFileNames.COMPOUND_EXTENSIONS[i]);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors()) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"346d5897e4c4e77ed5dbd31f7730ff30973d5971","date":1198317988,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n            new CompoundFileWriter(directory, fileName);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":["6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"902ba79f4590a41c663c447756d2e5041cbbdda9","date":1217956662,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7b6cdc70e097da94da79a655ed8f94477ff69f5","date":1220815360,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final List createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    List files =\n      new ArrayList(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final Vector createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    Vector files =\n      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa27b750ee9a51ec4bed93ef328aef9ca1e2153d","date":1255859449,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    List<String> files =\n      new ArrayList<String>(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final List createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    List files =\n      new ArrayList(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    Iterator it = files.iterator();\n    while (it.hasNext()) {\n      cfsWriter.addFile((String) it.next());\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"775efee7f959e0dd3df7960b93767d9e00b78751","date":1267203159,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    List<String> files =\n      new ArrayList<String>(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS) {\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(IndexFileNames.segmentFileName(segment, ext));\n    }\n\n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(IndexFileNames.segmentFileName(segment, IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        files.add(IndexFileNames.segmentFileName(segment, ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    List<String> files =\n      new ArrayList<String>(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {\n      String ext = IndexFileNames.COMPOUND_EXTENSIONS[i];\n\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(segment + \".\" + ext);\n    }\n\n    // Fieldable norm files\n    for (int i = 0; i < fieldInfos.size(); i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(segment + \".\" + IndexFileNames.NORMS_EXTENSION);\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {\n        files.add(segment + \".\" + IndexFileNames.VECTOR_EXTENSIONS[i]);\n      }\n    }\n\n    // Now merge all added files\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#createCompoundFile(String).mjava","sourceNew":"  final List<String> createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    List<String> files =\n      new ArrayList<String>(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS) {\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(IndexFileNames.segmentFileName(segment, ext));\n    }\n\n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(IndexFileNames.segmentFileName(segment, IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        files.add(IndexFileNames.segmentFileName(segment, ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","sourceOld":"  final List<String> createCompoundFile(String fileName)\n          throws IOException {\n    CompoundFileWriter cfsWriter =\n      new CompoundFileWriter(directory, fileName, checkAbort);\n\n    List<String> files =\n      new ArrayList<String>(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    \n    \n    // Basic files\n    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS) {\n      if (ext.equals(IndexFileNames.PROX_EXTENSION) && !hasProx())\n        continue;\n\n      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&\n                            !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))\n        files.add(IndexFileNames.segmentFileName(segment, ext));\n    }\n\n    // Fieldable norm files\n    int numFIs = fieldInfos.size();\n    for (int i = 0; i < numFIs; i++) {\n      FieldInfo fi = fieldInfos.fieldInfo(i);\n      if (fi.isIndexed && !fi.omitNorms) {\n        files.add(IndexFileNames.segmentFileName(segment, IndexFileNames.NORMS_EXTENSION));\n        break;\n      }\n    }\n\n    // Vector files\n    if (fieldInfos.hasVectors() && mergeDocStores) {\n      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {\n        files.add(IndexFileNames.segmentFileName(segment, ext));\n      }\n    }\n\n    // Now merge all added files\n    for (String file : files) {\n      cfsWriter.addFile(file);\n    }\n    \n    // Perform the merge\n    cfsWriter.close();\n   \n    return files;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"346d5897e4c4e77ed5dbd31f7730ff30973d5971":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"24157515079eea65faeec4e1dbb01fea58444c8e":["6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7"],"950f3c7592cb559e2534e5089c78833250e156a3":["24157515079eea65faeec4e1dbb01fea58444c8e"],"775efee7f959e0dd3df7960b93767d9e00b78751":["fa27b750ee9a51ec4bed93ef328aef9ca1e2153d"],"6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"902ba79f4590a41c663c447756d2e5041cbbdda9":["346d5897e4c4e77ed5dbd31f7730ff30973d5971"],"c7b6cdc70e097da94da79a655ed8f94477ff69f5":["902ba79f4590a41c663c447756d2e5041cbbdda9"],"12d40284fd9481f79444bc63bc5d13847caddd3d":["950f3c7592cb559e2534e5089c78833250e156a3"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["8969a184df55d25d61e85be785987fbf830d4028"],"fa27b750ee9a51ec4bed93ef328aef9ca1e2153d":["c7b6cdc70e097da94da79a655ed8f94477ff69f5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8969a184df55d25d61e85be785987fbf830d4028":["12d40284fd9481f79444bc63bc5d13847caddd3d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["775efee7f959e0dd3df7960b93767d9e00b78751"]},"commit2Childs":{"346d5897e4c4e77ed5dbd31f7730ff30973d5971":["902ba79f4590a41c663c447756d2e5041cbbdda9"],"24157515079eea65faeec4e1dbb01fea58444c8e":["950f3c7592cb559e2534e5089c78833250e156a3"],"950f3c7592cb559e2534e5089c78833250e156a3":["12d40284fd9481f79444bc63bc5d13847caddd3d"],"775efee7f959e0dd3df7960b93767d9e00b78751":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7":["24157515079eea65faeec4e1dbb01fea58444c8e"],"902ba79f4590a41c663c447756d2e5041cbbdda9":["c7b6cdc70e097da94da79a655ed8f94477ff69f5"],"c7b6cdc70e097da94da79a655ed8f94477ff69f5":["fa27b750ee9a51ec4bed93ef328aef9ca1e2153d"],"12d40284fd9481f79444bc63bc5d13847caddd3d":["8969a184df55d25d61e85be785987fbf830d4028"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["346d5897e4c4e77ed5dbd31f7730ff30973d5971"],"fa27b750ee9a51ec4bed93ef328aef9ca1e2153d":["775efee7f959e0dd3df7960b93767d9e00b78751"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7"],"8969a184df55d25d61e85be785987fbf830d4028":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}