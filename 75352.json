{"path":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","commits":[{"id":"c9bc1fe868bb126a5b8517d9d2abcf329f56d283","date":1219151801,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"/dev/null","sourceNew":"  private void searchIndex() throws IOException, ParseException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser( \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bf4dbfaec317df80ca6f412ce1b94b337b581e17","date":1238022314,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser( \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser( \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"943c3f9cf96b8df37f4273d66a66182e2a669467","date":1249394171,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser( \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser( \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4256bc1b3c94786287ccdfc751230374521843cf","date":1254612273,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser( \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser( \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba1116b3450a9c1642c89445d131b37344055245","date":1256329517,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(Version.LUCENE_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser( \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"464a71190fd7694704427cd763d7c957c10e935b","date":1256329736,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(Version.LUCENE_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42607aa380c892dc1ec0ab26e86a575c28e13618","date":1268641604,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, ParseException, InvalidTokenOffsetsException {\n    String q = \"t_text1:random\";\n    QueryParser parser = new QueryParser(TEST_VERSION_CURRENT,  \"t_text1\", a );\n    Query query = parser.parse( q );\n    IndexSearcher searcher = new IndexSearcher( dir, true );\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1cedb00d2dd44640194401179358a2e3ba6051bf":["464a71190fd7694704427cd763d7c957c10e935b"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"464a71190fd7694704427cd763d7c957c10e935b":["ba1116b3450a9c1642c89445d131b37344055245"],"4256bc1b3c94786287ccdfc751230374521843cf":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["bf4dbfaec317df80ca6f412ce1b94b337b581e17"],"bf4dbfaec317df80ca6f412ce1b94b337b581e17":["c9bc1fe868bb126a5b8517d9d2abcf329f56d283"],"c9bc1fe868bb126a5b8517d9d2abcf329f56d283":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ba1116b3450a9c1642c89445d131b37344055245":["4256bc1b3c94786287ccdfc751230374521843cf"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"42607aa380c892dc1ec0ab26e86a575c28e13618":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["42607aa380c892dc1ec0ab26e86a575c28e13618"]},"commit2Childs":{"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"464a71190fd7694704427cd763d7c957c10e935b":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"4256bc1b3c94786287ccdfc751230374521843cf":["ba1116b3450a9c1642c89445d131b37344055245"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["4256bc1b3c94786287ccdfc751230374521843cf"],"bf4dbfaec317df80ca6f412ce1b94b337b581e17":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"c9bc1fe868bb126a5b8517d9d2abcf329f56d283":["bf4dbfaec317df80ca6f412ce1b94b337b581e17"],"ba1116b3450a9c1642c89445d131b37344055245":["464a71190fd7694704427cd763d7c957c10e935b"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["42607aa380c892dc1ec0ab26e86a575c28e13618"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c9bc1fe868bb126a5b8517d9d2abcf329f56d283"],"42607aa380c892dc1ec0ab26e86a575c28e13618":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}