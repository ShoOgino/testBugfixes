{"path":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","commits":[{"id":"706a7a3396c030cc66dda92a0492eb492131c4c0","date":1509705614,"type":0,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"/dev/null","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 1000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"/dev/null","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 1000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ed8370202451d0f469c0ae886c8bd7f90a128e4","date":1510224487,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 1000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader, false);  // ParallelReader mucks up updated DVs\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 1000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":["265563d104adb4195ba71535ee217ae242a9006f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"265563d104adb4195ba71535ee217ae242a9006f","date":1510236177,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 1000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 1000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader, false);  // ParallelReader mucks up updated DVs\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":["5ed8370202451d0f469c0ae886c8bd7f90a128e4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b31781f87f2e572b5c28caf2f83400abe6c05fe7","date":1511944192,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 1000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7732a106554be0db3e03ac5211e46f6e0c285b8","date":1511975378,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1aad05eeff7818b0833c02ac6b743aa72054963b","date":1512093122,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 1000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a31eb60856fd1cd4135391802a25d8d576d3e65","date":1519033812,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n    IndexSearcher searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e16ac84f9e5d560008fe1554462ff8b853b3d3c","date":1520142134,"type":3,"author":"Erick","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":["1b92f673a8027e5fb106d73b5d3e321f2c4db3f6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"789fb338d3c53b4478938723d60f6623e764ca38","date":1521535944,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f3b88d2756ecf97de296c8ea67c79187af5a6a63","date":1523529874,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  @Test\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5d36ba65c7e095c7938bfc2343a9a6cf689bfb43","date":1523531370,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  @Test\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    //RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = newSearcher(reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1b92f673a8027e5fb106d73b5d3e321f2c4db3f6","date":1523872632,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","sourceOld":"  @Test\n  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":["7e16ac84f9e5d560008fe1554462ff8b853b3d3c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"36d13f271b6649357e07f71f7e46559479f69b5b","date":1523888226,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c9d00c591703058371b3dc36f4957a6f24ca302","date":1527233410,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(QueryCachingPolicy.ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5754bd6f04f13b67e9575f8b226a0303c31c7d5","date":1573506453,"type":3,"author":"ginger","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestLRUQueryCache#testDocValuesUpdatesDontBreakCache().mjava","sourceNew":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true, Float.POSITIVE_INFINITY);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocValuesUpdatesDontBreakCache() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig().setMergePolicy(NoMergePolicy.INSTANCE);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    w.addDocument(new Document());\n    w.commit();\n    DirectoryReader reader = DirectoryReader.open(w);\n\n    // IMPORTANT:\n    // Don't use newSearcher(), because that will sometimes use an ExecutorService, and\n    // we need to be single threaded to ensure that LRUQueryCache doesn't skip the cache\n    // due to thread contention\n    IndexSearcher searcher = new AssertingIndexSearcher(random(), reader);\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n\n    LRUQueryCache cache = new LRUQueryCache(1, 10000, context -> true);\n    searcher.setQueryCache(cache);\n\n    DVCacheQuery query = new DVCacheQuery(\"field\");\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());\n    assertEquals(1, searcher.count(query));\n    assertEquals(1, query.scorerCreatedCount.get());  // should be cached\n\n    Document doc = new Document();\n    doc.add(new NumericDocValuesField(\"field\", 1));\n    doc.add(newTextField(\"text\", \"text\", Store.NO));\n    w.addDocument(doc);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // first segment cached\n\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(2, query.scorerCreatedCount.get());  // both segments cached\n\n\n    w.updateNumericDocValue(new Term(\"text\", \"text\"), \"field\", 2l);\n    reader.close();\n    reader = DirectoryReader.open(w);\n    searcher = new AssertingIndexSearcher(random(), reader); // no newSearcher(reader) - see comment above\n    searcher.setQueryCachingPolicy(ALWAYS_CACHE);\n    searcher.setQueryCache(cache);\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(3, query.scorerCreatedCount.get());   // second segment no longer cached due to DV update\n\n    assertEquals(2, searcher.count(query));\n    assertEquals(4, query.scorerCreatedCount.get());    // still no caching\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e16ac84f9e5d560008fe1554462ff8b853b3d3c":["3a31eb60856fd1cd4135391802a25d8d576d3e65"],"706a7a3396c030cc66dda92a0492eb492131c4c0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1b92f673a8027e5fb106d73b5d3e321f2c4db3f6":["5d36ba65c7e095c7938bfc2343a9a6cf689bfb43"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["7e16ac84f9e5d560008fe1554462ff8b853b3d3c","789fb338d3c53b4478938723d60f6623e764ca38"],"b31781f87f2e572b5c28caf2f83400abe6c05fe7":["265563d104adb4195ba71535ee217ae242a9006f"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","706a7a3396c030cc66dda92a0492eb492131c4c0"],"6c9d00c591703058371b3dc36f4957a6f24ca302":["36d13f271b6649357e07f71f7e46559479f69b5b"],"36d13f271b6649357e07f71f7e46559479f69b5b":["1b92f673a8027e5fb106d73b5d3e321f2c4db3f6"],"5d36ba65c7e095c7938bfc2343a9a6cf689bfb43":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","f3b88d2756ecf97de296c8ea67c79187af5a6a63"],"5ed8370202451d0f469c0ae886c8bd7f90a128e4":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"b5754bd6f04f13b67e9575f8b226a0303c31c7d5":["6c9d00c591703058371b3dc36f4957a6f24ca302"],"265563d104adb4195ba71535ee217ae242a9006f":["5ed8370202451d0f469c0ae886c8bd7f90a128e4"],"f3b88d2756ecf97de296c8ea67c79187af5a6a63":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"c7732a106554be0db3e03ac5211e46f6e0c285b8":["b31781f87f2e572b5c28caf2f83400abe6c05fe7"],"1aad05eeff7818b0833c02ac6b743aa72054963b":["265563d104adb4195ba71535ee217ae242a9006f","c7732a106554be0db3e03ac5211e46f6e0c285b8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"789fb338d3c53b4478938723d60f6623e764ca38":["7e16ac84f9e5d560008fe1554462ff8b853b3d3c"],"3a31eb60856fd1cd4135391802a25d8d576d3e65":["1aad05eeff7818b0833c02ac6b743aa72054963b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b5754bd6f04f13b67e9575f8b226a0303c31c7d5"]},"commit2Childs":{"7e16ac84f9e5d560008fe1554462ff8b853b3d3c":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","789fb338d3c53b4478938723d60f6623e764ca38"],"706a7a3396c030cc66dda92a0492eb492131c4c0":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"1b92f673a8027e5fb106d73b5d3e321f2c4db3f6":["36d13f271b6649357e07f71f7e46559479f69b5b"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["5d36ba65c7e095c7938bfc2343a9a6cf689bfb43","f3b88d2756ecf97de296c8ea67c79187af5a6a63"],"b31781f87f2e572b5c28caf2f83400abe6c05fe7":["c7732a106554be0db3e03ac5211e46f6e0c285b8"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["5ed8370202451d0f469c0ae886c8bd7f90a128e4"],"6c9d00c591703058371b3dc36f4957a6f24ca302":["b5754bd6f04f13b67e9575f8b226a0303c31c7d5"],"5d36ba65c7e095c7938bfc2343a9a6cf689bfb43":["1b92f673a8027e5fb106d73b5d3e321f2c4db3f6"],"36d13f271b6649357e07f71f7e46559479f69b5b":["6c9d00c591703058371b3dc36f4957a6f24ca302"],"5ed8370202451d0f469c0ae886c8bd7f90a128e4":["265563d104adb4195ba71535ee217ae242a9006f"],"265563d104adb4195ba71535ee217ae242a9006f":["b31781f87f2e572b5c28caf2f83400abe6c05fe7","1aad05eeff7818b0833c02ac6b743aa72054963b"],"b5754bd6f04f13b67e9575f8b226a0303c31c7d5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f3b88d2756ecf97de296c8ea67c79187af5a6a63":["5d36ba65c7e095c7938bfc2343a9a6cf689bfb43"],"c7732a106554be0db3e03ac5211e46f6e0c285b8":["1aad05eeff7818b0833c02ac6b743aa72054963b"],"1aad05eeff7818b0833c02ac6b743aa72054963b":["3a31eb60856fd1cd4135391802a25d8d576d3e65"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["706a7a3396c030cc66dda92a0492eb492131c4c0","d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"789fb338d3c53b4478938723d60f6623e764ca38":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"3a31eb60856fd1cd4135391802a25d8d576d3e65":["7e16ac84f9e5d560008fe1554462ff8b853b3d3c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}