{"path":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws CorruptIndexException, IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws CorruptIndexException, IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws CorruptIndexException, IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":["b68b0aeb05de4dd5b24fc5ffd51e2fbd5d571df2"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"714058a3bd900646d4df5e21af2d4e109ed3e4bc","date":1341692336,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2acf500f78aa12b92e371fd89c719291986b6b90","date":1341846236,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46d8ada1fff8d18cb197c38c7983225162599948","date":1341853497,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws CorruptIndexException, IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0bf41419d452997826ec5f17684993377be77f49","date":1386629618,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":["b68b0aeb05de4dd5b24fc5ffd51e2fbd5d571df2"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d89d7e4e5101347833eea558851bf4209218619","date":1396265641,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, StandardCharsets.UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, StandardCharsets.UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, StandardCharsets.UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.shutdown();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, StandardCharsets.UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, StandardCharsets.UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, StandardCharsets.UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.shutdown();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8e966c067d1296ec349b51042bd4a8cc4888bd4c","date":1526450385,"type":4,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo#openExampleIndex().mjava","sourceNew":null,"sourceOld":"  private void openExampleIndex() throws IOException {\n    //Create a RAM-based index from our test data file\n    RAMDirectory rd = new RAMDirectory();\n    IndexWriterConfig iwConfig = new IndexWriterConfig(analyzer);\n    IndexWriter writer = new IndexWriter(rd, iwConfig);\n    InputStream dataIn = getServletContext().getResourceAsStream(\"/WEB-INF/data.tsv\");\n    BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, StandardCharsets.UTF_8));\n    String line = br.readLine();\n    final FieldType textNoNorms = new FieldType(TextField.TYPE_STORED);\n    textNoNorms.setOmitNorms(true);\n    while (line != null) {\n      line = line.trim();\n      if (line.length() > 0) {\n        //parse row and create a document\n        StringTokenizer st = new StringTokenizer(line, \"\\t\");\n        Document doc = new Document();\n        doc.add(new Field(\"location\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"salary\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"type\", st.nextToken(), textNoNorms));\n        doc.add(new Field(\"description\", st.nextToken(), textNoNorms));\n        writer.addDocument(doc);\n      }\n      line = br.readLine();\n    }\n    writer.close();\n\n    //open searcher\n    // this example never closes it reader!\n    IndexReader reader = DirectoryReader.open(rd);\n    searcher = new IndexSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["0bf41419d452997826ec5f17684993377be77f49","7d89d7e4e5101347833eea558851bf4209218619"],"2acf500f78aa12b92e371fd89c719291986b6b90":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","714058a3bd900646d4df5e21af2d4e109ed3e4bc"],"7d89d7e4e5101347833eea558851bf4209218619":["0bf41419d452997826ec5f17684993377be77f49"],"46d8ada1fff8d18cb197c38c7983225162599948":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","2acf500f78aa12b92e371fd89c719291986b6b90"],"714058a3bd900646d4df5e21af2d4e109ed3e4bc":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0bf41419d452997826ec5f17684993377be77f49":["2acf500f78aa12b92e371fd89c719291986b6b90"],"8e966c067d1296ec349b51042bd4a8cc4888bd4c":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["b89678825b68eccaf09e6ab71675fc0b0af1e099","2acf500f78aa12b92e371fd89c719291986b6b90"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["2acf500f78aa12b92e371fd89c719291986b6b90","0bf41419d452997826ec5f17684993377be77f49"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["7d89d7e4e5101347833eea558851bf4209218619"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8e966c067d1296ec349b51042bd4a8cc4888bd4c"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"2acf500f78aa12b92e371fd89c719291986b6b90":["46d8ada1fff8d18cb197c38c7983225162599948","0bf41419d452997826ec5f17684993377be77f49","fe33227f6805edab2036cbb80645cc4e2d1fa424","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"7d89d7e4e5101347833eea558851bf4209218619":["5eb2511ababf862ea11e10761c70ee560cd84510","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"46d8ada1fff8d18cb197c38c7983225162599948":[],"714058a3bd900646d4df5e21af2d4e109ed3e4bc":["2acf500f78aa12b92e371fd89c719291986b6b90"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"0bf41419d452997826ec5f17684993377be77f49":["5eb2511ababf862ea11e10761c70ee560cd84510","7d89d7e4e5101347833eea558851bf4209218619","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"8e966c067d1296ec349b51042bd4a8cc4888bd4c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["8e966c067d1296ec349b51042bd4a8cc4888bd4c"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["2acf500f78aa12b92e371fd89c719291986b6b90","46d8ada1fff8d18cb197c38c7983225162599948","714058a3bd900646d4df5e21af2d4e109ed3e4bc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424","74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}