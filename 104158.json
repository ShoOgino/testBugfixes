{"path":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","commits":[{"id":"327863a2fd61e831028b6c56c8fef6b00a44eb0b","date":1302686439,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue(\n        new BufferedDeletes(false));\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78248211b373c5a9b53071bf888805d4fab51bd3","date":1303919265,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue(\n        new BufferedDeletes(false));\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    Term template = new Term(\"id\");\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(template.createTerm(ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fa5ed548a2e7179ad03d6dfef30e19b8c06a8e2","date":1311898374,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      frozenSet.add(t);\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    assertEquals(uniqueValues, new HashSet<Term>(Arrays.asList(queue\n        .freezeGlobalBuffer(null).terms)));\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":["3ca8f587a46da69f4b3ba9679411af9f7d7cb4ea","7e4c214a1f904dde76f5611b56d4081533055b3b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3ca8f587a46da69f4b3ba9679411af9f7d7cb4ea","date":1311954340,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    Set<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copy(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n    assertEquals(uniqueValues.size(), frozenSet.size());\n    assertEquals(uniqueValues, frozenSet);\n   \n  }\n\n","sourceOld":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      frozenSet.add(t);\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":["9fa5ed548a2e7179ad03d6dfef30e19b8c06a8e2"],"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6e919043fa85ee891123768dd655a98edbbf63c","date":1322225413,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    Set<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n    assertEquals(uniqueValues.size(), frozenSet.size());\n    assertEquals(uniqueValues, frozenSet);\n   \n  }\n\n","sourceOld":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    Set<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copy(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n    assertEquals(uniqueValues.size(), frozenSet.size());\n    assertEquals(uniqueValues, frozenSet);\n   \n  }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testStressDeleteQueue().mjava","sourceNew":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    Set<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n    assertEquals(uniqueValues.size(), frozenSet.size());\n    assertEquals(uniqueValues, frozenSet);\n   \n  }\n\n","sourceOld":"  public void testStressDeleteQueue() throws InterruptedException {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    Set<Term> uniqueValues = new HashSet<Term>();\n    final int size = 10000 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n      uniqueValues.add(new Term(\"id\", ids[i].toString()));\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    AtomicInteger index = new AtomicInteger(0);\n    final int numThreads = 2 + random.nextInt(5);\n    UpdateThread[] threads = new UpdateThread[numThreads];\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new UpdateThread(queue, index, ids, latch);\n      threads[i].start();\n    }\n    latch.countDown();\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n\n    for (UpdateThread updateThread : threads) {\n      DeleteSlice slice = updateThread.slice;\n      queue.updateSlice(slice);\n      BufferedDeletes deletes = updateThread.deletes;\n      slice.apply(deletes, BufferedDeletes.MAX_INT);\n      assertEquals(uniqueValues, deletes.terms.keySet());\n    }\n    queue.tryApplyGlobalSlice();\n    Set<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n    assertEquals(uniqueValues.size(), frozenSet.size());\n    assertEquals(uniqueValues, frozenSet);\n   \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["e6e919043fa85ee891123768dd655a98edbbf63c"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"3ca8f587a46da69f4b3ba9679411af9f7d7cb4ea":["9fa5ed548a2e7179ad03d6dfef30e19b8c06a8e2"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","78248211b373c5a9b53071bf888805d4fab51bd3"],"327863a2fd61e831028b6c56c8fef6b00a44eb0b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2553b00f699380c64959ccb27991289aae87be2e":["a3776dccca01c11e7046323cfad46a3b4a471233","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"9fa5ed548a2e7179ad03d6dfef30e19b8c06a8e2":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"78248211b373c5a9b53071bf888805d4fab51bd3":["327863a2fd61e831028b6c56c8fef6b00a44eb0b"],"e6e919043fa85ee891123768dd655a98edbbf63c":["3ca8f587a46da69f4b3ba9679411af9f7d7cb4ea"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","9fa5ed548a2e7179ad03d6dfef30e19b8c06a8e2"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"3ca8f587a46da69f4b3ba9679411af9f7d7cb4ea":["e6e919043fa85ee891123768dd655a98edbbf63c"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","135621f3a0670a9394eb563224a3b76cc4dddc0f","d083e83f225b11e5fdd900e83d26ddb385b6955c","a3776dccca01c11e7046323cfad46a3b4a471233"],"327863a2fd61e831028b6c56c8fef6b00a44eb0b":["78248211b373c5a9b53071bf888805d4fab51bd3"],"2553b00f699380c64959ccb27991289aae87be2e":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"9fa5ed548a2e7179ad03d6dfef30e19b8c06a8e2":["3ca8f587a46da69f4b3ba9679411af9f7d7cb4ea"],"a3776dccca01c11e7046323cfad46a3b4a471233":["2553b00f699380c64959ccb27991289aae87be2e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["135621f3a0670a9394eb563224a3b76cc4dddc0f","b3e06be49006ecac364d39d12b9c9f74882f9b9f","327863a2fd61e831028b6c56c8fef6b00a44eb0b","a3776dccca01c11e7046323cfad46a3b4a471233"],"78248211b373c5a9b53071bf888805d4fab51bd3":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"e6e919043fa85ee891123768dd655a98edbbf63c":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}