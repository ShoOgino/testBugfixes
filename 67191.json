{"path":"lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#doTest(boolean,int,boolean).mjava","commits":[{"id":"fb10b6bcde550b87d8f10e5f010bd8f3021023b6","date":1274974592,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#doTest(boolean,int,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#doTest(boolean,boolean,int,boolean).mjava","sourceNew":"  private void doTest(boolean addToEmptyIndex,\n      int numExpectedPayloads, boolean multipleCommits) throws IOException {\n    Directory[] dirs = new Directory[2];\n    populateDirs(dirs, multipleCommits);\n\n    Directory dir = new MockRAMDirectory();\n    if (!addToEmptyIndex) {\n      populateDocs(dir, multipleCommits);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), NUM_DOCS);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), NUM_DOCS);\n    }\n\n    // Add two source dirs. By not adding the dest dir, we ensure its payloads\n    // won't get processed.\n    Map<Directory, DirPayloadProcessor> processors = new HashMap<Directory, DirPayloadProcessor>();\n    for (Directory d : dirs) {\n      processors.put(d, new PerTermPayloadProcessor());\n    }\n    IndexWriter writer = new IndexWriter(dir, getConfig());\n    writer.setPayloadProcessorProvider(new PerDirPayloadProcessor(processors));\n\n    IndexReader[] readers = new IndexReader[dirs.length];\n    for (int i = 0; i < readers.length; i++) {\n      readers[i] = IndexReader.open(dirs[i]);\n    }\n    try {\n      writer.addIndexes(readers);\n    } finally {\n      for (IndexReader r : readers) {\n        r.close();\n      }\n    }\n    writer.close();\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), numExpectedPayloads);\n    // the second term should always have all payloads\n    numExpectedPayloads = NUM_DOCS * dirs.length\n        + (addToEmptyIndex ? 0 : NUM_DOCS);\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), numExpectedPayloads);\n  }\n\n","sourceOld":"  private void doTest(boolean addIndexesNoOptimize, boolean addToEmptyIndex,\n      int numExpectedPayloads, boolean multipleCommits) throws IOException {\n    Directory[] dirs = new Directory[2];\n    populateDirs(dirs, multipleCommits);\n\n    Directory dir = new MockRAMDirectory();\n    if (!addToEmptyIndex) {\n      populateDocs(dir, multipleCommits);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), NUM_DOCS);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), NUM_DOCS);\n    }\n\n    // Add two source dirs. By not adding the dest dir, we ensure its payloads\n    // won't get processed.\n    Map<Directory, DirPayloadProcessor> processors = new HashMap<Directory, DirPayloadProcessor>();\n    for (Directory d : dirs) {\n      processors.put(d, new PerTermPayloadProcessor());\n    }\n    IndexWriter writer = new IndexWriter(dir, getConfig());\n    writer.setPayloadProcessorProvider(new PerDirPayloadProcessor(processors));\n\n    if (!addIndexesNoOptimize) {\n      IndexReader[] readers = new IndexReader[dirs.length];\n      for (int i = 0; i < readers.length; i++) {\n        readers[i] = IndexReader.open(dirs[i]);\n      }\n      try {\n        writer.addIndexes(readers);\n      } finally {\n        for (IndexReader r : readers) {\n          r.close();\n        }\n      }\n    } else {\n      writer.addIndexesNoOptimize(dirs);\n    }\n    writer.close();\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), numExpectedPayloads);\n    // the second term should always have all payloads\n    numExpectedPayloads = NUM_DOCS * dirs.length\n        + (addToEmptyIndex ? 0 : NUM_DOCS);\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), numExpectedPayloads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#doTest(Random,boolean,int,boolean).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#doTest(boolean,int,boolean).mjava","sourceNew":"  private void doTest(Random random, boolean addToEmptyIndex,\n      int numExpectedPayloads, boolean multipleCommits) throws IOException {\n    Directory[] dirs = new Directory[2];\n    populateDirs(random, dirs, multipleCommits);\n\n    Directory dir = new MockRAMDirectory();\n    if (!addToEmptyIndex) {\n      populateDocs(random, dir, multipleCommits);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), NUM_DOCS);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), NUM_DOCS);\n    }\n\n    // Add two source dirs. By not adding the dest dir, we ensure its payloads\n    // won't get processed.\n    Map<Directory, DirPayloadProcessor> processors = new HashMap<Directory, DirPayloadProcessor>();\n    for (Directory d : dirs) {\n      processors.put(d, new PerTermPayloadProcessor());\n    }\n    IndexWriter writer = new IndexWriter(dir, getConfig(random));\n    writer.setPayloadProcessorProvider(new PerDirPayloadProcessor(processors));\n\n    IndexReader[] readers = new IndexReader[dirs.length];\n    for (int i = 0; i < readers.length; i++) {\n      readers[i] = IndexReader.open(dirs[i]);\n    }\n    try {\n      writer.addIndexes(readers);\n    } finally {\n      for (IndexReader r : readers) {\n        r.close();\n      }\n    }\n    writer.close();\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), numExpectedPayloads);\n    // the second term should always have all payloads\n    numExpectedPayloads = NUM_DOCS * dirs.length\n        + (addToEmptyIndex ? 0 : NUM_DOCS);\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), numExpectedPayloads);\n  }\n\n","sourceOld":"  private void doTest(boolean addToEmptyIndex,\n      int numExpectedPayloads, boolean multipleCommits) throws IOException {\n    Directory[] dirs = new Directory[2];\n    populateDirs(dirs, multipleCommits);\n\n    Directory dir = new MockRAMDirectory();\n    if (!addToEmptyIndex) {\n      populateDocs(dir, multipleCommits);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), NUM_DOCS);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), NUM_DOCS);\n    }\n\n    // Add two source dirs. By not adding the dest dir, we ensure its payloads\n    // won't get processed.\n    Map<Directory, DirPayloadProcessor> processors = new HashMap<Directory, DirPayloadProcessor>();\n    for (Directory d : dirs) {\n      processors.put(d, new PerTermPayloadProcessor());\n    }\n    IndexWriter writer = new IndexWriter(dir, getConfig());\n    writer.setPayloadProcessorProvider(new PerDirPayloadProcessor(processors));\n\n    IndexReader[] readers = new IndexReader[dirs.length];\n    for (int i = 0; i < readers.length; i++) {\n      readers[i] = IndexReader.open(dirs[i]);\n    }\n    try {\n      writer.addIndexes(readers);\n    } finally {\n      for (IndexReader r : readers) {\n        r.close();\n      }\n    }\n    writer.close();\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), numExpectedPayloads);\n    // the second term should always have all payloads\n    numExpectedPayloads = NUM_DOCS * dirs.length\n        + (addToEmptyIndex ? 0 : NUM_DOCS);\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), numExpectedPayloads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider#doTest(boolean,int,boolean).mjava","sourceNew":null,"sourceOld":"  private void doTest(boolean addToEmptyIndex,\n      int numExpectedPayloads, boolean multipleCommits) throws IOException {\n    Directory[] dirs = new Directory[2];\n    populateDirs(dirs, multipleCommits);\n\n    Directory dir = new MockRAMDirectory();\n    if (!addToEmptyIndex) {\n      populateDocs(dir, multipleCommits);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), NUM_DOCS);\n      verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), NUM_DOCS);\n    }\n\n    // Add two source dirs. By not adding the dest dir, we ensure its payloads\n    // won't get processed.\n    Map<Directory, DirPayloadProcessor> processors = new HashMap<Directory, DirPayloadProcessor>();\n    for (Directory d : dirs) {\n      processors.put(d, new PerTermPayloadProcessor());\n    }\n    IndexWriter writer = new IndexWriter(dir, getConfig());\n    writer.setPayloadProcessorProvider(new PerDirPayloadProcessor(processors));\n\n    IndexReader[] readers = new IndexReader[dirs.length];\n    for (int i = 0; i < readers.length; i++) {\n      readers[i] = IndexReader.open(dirs[i]);\n    }\n    try {\n      writer.addIndexes(readers);\n    } finally {\n      for (IndexReader r : readers) {\n        r.close();\n      }\n    }\n    writer.close();\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p1\"), numExpectedPayloads);\n    // the second term should always have all payloads\n    numExpectedPayloads = NUM_DOCS * dirs.length\n        + (addToEmptyIndex ? 0 : NUM_DOCS);\n    verifyPayloadExists(dir, \"p\", new BytesRef(\"p2\"), numExpectedPayloads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6","b21422ff1d1d56499dec481f193b402e5e8def5b"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"b21422ff1d1d56499dec481f193b402e5e8def5b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}