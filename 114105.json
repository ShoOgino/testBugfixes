{"path":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","commits":[{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":1,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"/dev/null","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"20c968c14aace7cf49843bf2c1fafc7fd3845659","date":1533133859,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null, false);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a9be06eb0504cb6312c2a585959299e40280d9ba","date":1534415825,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      trySplit(collectionName, null, SHARD1, 3);\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null, false);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName, props, client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      trySplit(collectionName, null, SHARD1, 3);\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      trySplit(collectionName, null, SHARD1, 3);\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":["1816753738ff1f27f11b38030e83c0ded050b7a4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4","date":1588172214,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName, props, client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard shard1_{} docCount = {}\", i, docCount);\n      }\n\n      collectionClient.commit();\n\n      trySplit(collectionName, null, SHARD1, 3);\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName, props, client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      trySplit(collectionName, null, SHARD1, 3);\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName, props, client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard shard1_{} docCount = {}\", i, docCount);\n      }\n\n      collectionClient.commit();\n\n      trySplit(collectionName, null, SHARD1, 3);\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName, props, client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard shard1_{} docCount = {}\", i, docCount);\n      }\n\n      collectionClient.commit();\n\n      trySplit(collectionName, null, SHARD1, 3);\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["a9be06eb0504cb6312c2a585959299e40280d9ba"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"a9be06eb0504cb6312c2a585959299e40280d9ba":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["b94236357aaa22b76c10629851fe4e376e0cea82"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"a9be06eb0504cb6312c2a585959299e40280d9ba":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["a9be06eb0504cb6312c2a585959299e40280d9ba"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}